423
DefaultEventBus not thread safe · Issue #423 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I wrote a prototype for our project, I chose vert.x as a middleware which involves consumes messages from kafka and redirecting it to mongoDB, since consumer api in kafka is a blocking api so I create a work verticle, after consuming about 50k messages, I found my cpu utilization was nearly 100% and consuming verticle stuck , I then found it was cause by a infinitive loop in HashMap.put() which was called by getHandlerCloseHook(context).entries.add(new HandlerEntry(address, handler)) in DefaultEventBus.registerHandler().
I think it was caused by concurrently calling the put or remove on the HashMap by a worker verticle, thus causing the HashMap to be broken.
After I change the
It seems everything was ok.
I wondering if it is proper to change the HashSet to ConcurrentHashSet, if so shall I make a pull request?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

1225
ExecuteBlocking timeout · Issue #1225 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
It should be possible to set specify a timeout in an executeBlocking that happens when no worker thread is available before this timeout.
This would be used in JDBCClient for instance, etc...
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

1247
Deadlock if the connection is still being used while HttpClient is closing · Issue #1247 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
This happens in Vert.x 3.2. In thread 5717, we hold the lock on HttpClientImpl.close (lock #1) and then we try to acquire a lock on ClientConnection.close (lock #2). In thread 7035, we hold a lock #2 in ClientConnection.handleClosed and try to hold a lock #1 at HttpClientImpl.checkClosed. And boom, we get a deadlock.
I don't have a good repro now since it's quite hard to reproduce consistently. But I can demonstrate from the stack trace:
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

1302
EventLoop thread blocked on Vertx.clusteredVertx() · Issue #1302 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Vertx 3.2.1.
Sometimes EventLoop thread blocked on Vertx.clusteredVertx().
Method Vertx.clusteredVertx() called on the main java thread on application startup.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

1343
Websocket deadlock during handshake · Issue #1343 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

1355
Deadlock between ClientConnection and HttpClientRequestImpl · Issue #1355 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
After a week attached to our load balancer which does a simple poll to one of our rest end points (we have no other traffic right now) all 4 machines (4 instances) end up in deadlock and had to be "kill -9"ed , which  in theory brought down our whole DC. Since we are in testing stages this was not a big problem but I imagine to most it would be a bit hair raising.
Also looking at the traffic it seems our load-balancer (a cisco content switch with ACE module) sends a request gets the response then resets the connection. I believe this behaviour is causing the deadlock, since this is important for us to go live I will try create a test to replicate this behaviour.
This was running 3.2.0 code (Ive seen no fixes in 3.2.1) and using JVM 1.8_74 on RHEL 6.5
Here is the jstack information.
Debugger attached successfully.
Server compiler detected.
Deadlock Detection:
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

1466
Deadlock in ServerConnection / HttpClientRequestImpl · Issue #1466 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We use an HttpClient per thread, and this just happened.
Found one Java-level deadlock:
Java stack information for the threads listed above:
There is a chance that it's just a glitch, we had some weird behaviour, two instances launched instead of one or something...
Also, this code looks a bit dangerous (io.vertx.core.http.impl.HttpClientRequestImpl#getLock):
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

1521
Lock is not released in clustered vertx · Issue #1521 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When I updated the Vertx version, this code stopped working:
It only executes the code at the first time, but the lock is not released. The execution reaches the release point. What can be the problem?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

1535
Deadlock with HTTP proxy app · Issue #1535 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I've implemented a reverse HTTP proxy with vert.x-ceylon version 3.2.0. I have now several times found the app in deadlock state, after which it does not respond to new conncetion attempts anymore. Here is an example:
Found one Java-level deadlock:
Java stack information for the threads listed above:
The org.otherone.vhostproxy.vertx.MyPump class in the middle of both traces is a customized version of the standard PumpImpl class which adds just some logging after the write() call. It does not hold any locks when calling vert.x apis.
I strongly assume both threads are processing tasks related to the same request, since they lock against the same connection object, and in HTTP/1 only one response can be streaming data at once.
To me it seems the deadlock arises because in both HttpServerResponseImpl and HttpClientResponseImpl the methods involved in the deadlock all hold locks while calling both upstream and downstream methods. By downstream I mean the pump calling HttpServerResponseImpl.write() and HttpClientResponseImpl.resume(), and by upstream I mean HttpServerResponseImpl.handleDrained() and HttpClientResponseImpl.handleChunk() calling the pump.  The pump is located at the "top", coordinating traffic between two downstream connections. As can be seen all four vertx http methods hold or attempt to hold locks. Having written numerous proxy, router and gateway software products in the past I have learned that this locking model is not deadlock-safe. One robust solution to this is to decide on a locking model where locks are allowed to be held a) only while calling downstream code or b) only while calling upstream code. Locking-while-calling-downstream has seemed sensible to me so that's what I have used.
So if one would decide not to allow locks during upstream calls, the solution (where there is state that actually needs protection) is to introduce state instead. So for example HttpClientResponseImpl.handleChunk() that wants to deliver new stream data upstream, instead of doing (pseudocode):
Introducing state variables typically makes the classes more complex as they may need to check whether they are "in the middle of something", but this should avoid deadlocks as long as it is clear what is upstream and what downstream. And in case it is not, don't hold locks when calling other components at all and use state in all cases..
To further visualize what I'm trying to say here, here's before & after sequence diagrams - arrows towards the pump are upstream calls and arrows away from te pump are downstream calls:
I would be interested in hearing what you think. I am considering looking deeper into the HTTP classes and see if I can get some pull requests going myself..
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

1573
Blocked thread warning when opening or closing an AsyncFile  · Issue #1573 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Users have reported blocked thread warning when opening or closing an AsyncFile.
Here are example stack traces:
and
One user provided more details and reported he was using a mapped Windows shared drive.
I have been able to reproduce the opening issue by a slow network filesystem (with twickle and nbd).
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

1581
File close is done from the wrong thread · Issue #1581 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Got this thread warning from time to time due to AsyncFileImpl.close is called from Vert.x event loop.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

1598
Asynchronous read/write done on wrong thread · Issue #1598 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The open/close issue has been addressed here #1573 . Async read/write still is blocking.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<


1633
Context#executeBlocking does not log blocked threads · Issue #1633 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

1739
Vertx Deadlock:  ServerConnection.handleClosed() v. SockJSSession.write() · Issue #1739 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
This deadlock is happening on v3.2.1, however it appears that the same lock inversion problem exists on the current v3.3.3.   I will be trying to created a tiny, canned example to repro this soon, but because it involves a 'channel inactive' call I'm thinking this is far more of a timing issue instead of a connection/load issue.
Also, all locking here is OUTSIDE of our 'acme' code, and inside the vertx codebase.  From my understanding of these stack traces and the threading model, this essentially means that any SockJSSession.write() call (regardless of the thread it is called from) can deadlock with a 'ServerConnection.handleClose()' call.
some package names have been changed to 'acme' to protect the innocent:
Found 1 deadlock.
Heap
The only options we see right now to work around this are either (A) reducing the eventloop threadpool size to one, or (B) somehow acquiring and synchronizing on the appropriate ServerConnection instance BEFORE we make a SockJSSession.write() call.  This option (B) must be done before all calls to 'synchronized' SockJSSession methods, not just .write().
The  'bus bridge impl' that we are using is based on the impl at:
with minor modifications to support a 'PING' socket data message type.  The ping support just pokes some bean internal state, doesn't do any other socket read/write calls, and it independent of the above stack trace.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

1742
File caching implementation not thread safe · Issue #1742 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The FileResolver implementation of caching is not thread safe. The problem occurs when the same file (that is about to be cached) is concurrently being read from multiple verticles. This issue can be reproduced with FileSystem#readFileBlocking, however, I believe that async implementation will yield similar results.
The problem here is the following. Consider a use case, when a file is read in multiple verticles in parallel. This file does not reside in a local filesystem, and as such Vert.x will try to cache the file by moving it to the .vertx directory.
First verticle that hits FileResolver#resolveFile will trigger the copying action of the resource to the designated .vertx cache directory. Only after this copy action is finished, the file will be read - thus this verticle will read complete data.
Every other instance that hits FileResolver#resolveFile will find the cached file during resolution - as the file is currently being copied over there - however, it might happen that it will read the cached file before it is copied completely - thus this verticle will read only partial data.
The problem can be reproduced by running supplied verticle in multiple instances. The verticle only reads 10 files from attached jar (all are 1MB in size) and outputs the size of read payload.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

1791
createHttpServer: io.vertx.core.VertxException: Thread blocked. ver 3.3.3 · Issue #1791 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I followed the example, but an error occurred.
An error does not occur in 3.2.1 but an error occurs in 3.3.3.
Is this a JDK issue? my jdk version is 1.8.0_73
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

1814
httpclient deadlock · Issue #1814 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
my app locked today,then i print the stack log:
Found one Java-level deadlock:
Java stack information for the threads listed above:
Found 1 deadlock.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

1834
Don't call HttpServer request/ws close handler holding locks · Issue #1834 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Motivation:
currently the ServerWebSocket and HttpServerRequest close handlers are called under synchronized lock of the connection. This can create deadlocks in SockJSSocket because a SockJSSocket may uses different request/websocket (reconnects) and event loops.
Change:
when processing a Netty close event, call the close handlers in the next tick (i.e scheduled to run on context).
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

682
Synchronize require() in Ruby verticles · Issue #682 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When starting multiple instances of the same module/verticle type concurrently, and where the verticle does a require(), this can result in failures because require() in the shared ruby runtime is not threadsafe.
We can fix this by overriding the require() method with a version that synchronizes access to the original version.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

1248
Shared instance of HttpClient is not guaranteed to be executed in the same thread · Issue #1248 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
This does not behave as I expected where the callback of HttpClient called inside event loop is not guaranteed to be called back in the same event loop due to the connection from another event loop is reused in another event loop.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

1469
HttpClientMetrics#createEndpoint may be called multiple times for the same endpoint · Issue #1469 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The implementation of io.vertx.core.http.impl.ConnectionManager.QueueManager#getConnQueue can lead to HttpClientMetrics#createEndpoint being called multiple times for the same endpoint if different threads try to use a fresh HTTP client:
HttpClientMetrics#createEndpoint is called from the ConnQueue constructor so a single instance of ConnQueue must be created if none is in the map.
Otherwise SPI implementations my leak resources acquired in #createEndpoint as #closeEndpoint would never be called for the corresponding queue instance.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

1657
EventLoopContext#executeFromIO fails when executed by Netty GlobalEventExecutor · Issue #1657 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When Netty uses its GlobalEventExecutor thread and propagates into Vertx, EventLoopContext#executeFromIO does not expect such thread and fails to execute the task:
for instance:
This can happen if the creation of a Bootstrap fails, in this case the promise is created with the GlobalEventExecutor (see AbstractBootstrap#initAndRegister())
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

1731
Consult vert.x a multithreade problem · Issue #1731 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The program starts with 3 threads, the thread pool is set to 2, but the result is only two threads.
Program code is as follows：
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

1892
Race condition in Future setHandler/completion between threads · Issue #1892 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In one of our projects we have encountered a problem with CompositeFuture.all() when running "outside"
of a verticle (in junit tests). Here is a sample program:
After a while it prints something like
Inside implementation of CompositeFutureImpl.all() the setHandler() function is called upon each future in the composition (in our case two). The problem here is that the completion of futures runs in a different thread than setting the handler. Neither of the functions (setHandler() nor complete()) are atomic and it may result in
a situation when the handler is never called. The problem seems to be more fundamental. The future
implementation (FutureImpl) is not thread safe and using it from different threads may cause difficulties.
When running inside a verticle it's ok because asynchronous callbacks are serialized within the event loop
and should not run concurrently.
I don't know if this is an expected behaviour and Futures (and their compositions) should be used only
within verticles. Our understanding based on looking into the implementation of CompositeFutureImpl is that
the intention was to make it thread safe.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

57
Race condition in clustering · Issue #57 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

60
Race condition in event bus sending · Issue #60 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When two or more event loops attempt to send to the new server concurrently and the connection has not yet been setup
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

303
Race condition in deploying modules · Issue #303 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
If deploy two modules of same name at same time, can result in one not being deployed.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

1289
Worker verticle cannot synchronously wait for EventBus.send even when using additional workpool thread · Issue #1289 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The general idea is:
execute in an worker verticle
instantiate a countdown latch
wait for countdown latch.
From my observations the eventbus.send finish execution however nothing happens on the eventbus. The target does not get any message.
I tracked a bit the problem inside EventBus.send and it leads me to HazelcastAsyncMultiMap.get implementation which does an executeBlocking which is ordered with the caller.
The body of execute blocking in HazelcastAsyncMultiMap.get is never executed.
This is strange however because the eventbus.send is executed by another worker thread than the caller.
Is this the expected behavior? Seems to me like a problem.
Some code:
Sorry but the project is not compileable as a standalone but you can just copy this class. Will notify when i make the project work as a standalone project.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

1307
ConcurrentModificationException from ConnectionManager.close · Issue #1307 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I got this exception from HttpClient.close:
I'm guessing the problem is with the synchronization on the methods of the inner ConnectionQueue class that access the allConnections member:
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

zzzzzz

2065
Vert.x ReadStream hangs in paused if WriteStream fails · Issue #2065 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have the following usecase for a vert.x aplication:
write a REST handler for a GET request
in this handler copy data from a ReadStream onto the response
This looked straight forward, in the handler I would create the ReadStream and then use a Pump to pipe the stream onto the response (WriteStream).
I noticed however that it can happen that the client closes the HTTP connection to my handler while the pump is still active. In this situation I had expected an exception on the WriteStream instance to occurs. However this is not the case, instead the WriteStream#writeQueueFull method returns "true" which sets the ReadStream into paused mode. It now waits for a drain event, but this event is never sent, because the write connection has been closed. The result is that over time the number of open (paused) ReadStreams grows, eventually generating a leak.
What is the correct way to handle this situation?
The first aspect that looks strange is that there is no exception on the write stream. But even if I were able to figure out the error situation (e.g. by listening on the close event on the response), what am I supposed to do with the ReadStream? It cannot be canceled but it also cannot stay open. The approach I can think of is to pump its content into a nil stream (i.e. consume it but ignore its content).
Overall this makes the complete pumping process pretty complicated.
The example below shows a simple testcase to reproduce the issue. The main method makes a request against a verticle and closed the connection immediately.
On the server (i.e. in the verticle) no exception is triggered, instead the ReadStream is locked in paused state.
The output of the sample code is:
request
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

2171
SockJSSession needs to use the transport thread when using the transport · Issue #2171 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Currently the SockJSSession uses the transport for write/close operations from any thread. This can cause deadlocks when used from external threads or because the transport thread has changed (for instance a session reconnection with an scaled http server).
It can be fixed by recording the transport context when the transport is associated with the session (register method) and doing a runOnContext when the current context is not the same. This shall also prevent race conditions for instance a write operation is scheduled from a non vertx thread, the register method is called and gives a new transport to the session. In this case the write will be rescheduled.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

2288
httpclient allows request to be created in a context other than the one an httpclient was instantiated in resulting in a deadlock on pumping. · Issue #2288 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi there,
Here's a reproducer for #2287. Perhaps it would make sense to bind an http client request to the context in which it is created (like AyncFile) instead of the context in which it's first used or throw an exception. In my case this is only an issue in tests since I need to access some of the internal sfs api associated with a verticle instance. Another option could enhance the vertx unit artifact by creating a rule to deploy a verticle and allow a test to be run in the context of a verticle instead of the context of the RunTestOnContext rule so that resources initialized for a test (AsyncFile) could be pumped to an http client request that made an initial connection using a verticle context. The example below is trivial... in a more complex application, it becomes difficult to manage the current behavior during test execution. A non trivial example of an api might look like volumeReplicaGroup.consume(size, newArrayList(MD5, SHA512), asyncFile) and the http clients used internally by the volume replica group may or may not already be bound to the verticle context instead of the test context asycFile is bound to (it would depend on if the verticle had attempted to use the client).
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

2296
Thread blocked · Issue #2296 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

2418
Possible deadlock when trying to get multiple locks · Issue #2418 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Here is the code, which illustrates the problem.
The Consumer verticle acuires lock1 and gets stuck.
I have reproduced the same problem using HazelcastClusterManager and IgniteClusterManager.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<


2916
HTTP event handler should not be called when holding a lock · Issue #2916 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We still have event handlers that are called while holding a lock which can lead to deadlocks.
We should remove them.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

2982
HTTP Client - Deadlock · Issue #2982 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Sometimes, it appears that some eventloops are blocked while doing some http client relative stuff (Vert.x 3.7.0)
Here is a threaddump:
I'm trying to provide a simple reproducer but it seems that the deadlock is pretty hard to reproduce.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

2991
Spring Async + Vert.x issue - Vert.x thread / Netty eventloop blocked (may be a bug) · Issue #2991 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
When an async spring task is getting executed, vertx/netty threads are blocked.
To see the issue in action:
Result: The https will keep on processing and will not complete with status code 200 until we move forward the breakpoint.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

3021
Thread blocked for long time · Issue #3021 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
What is the issue is related too? And what is the possible way to solve it?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

3028
[Worker pool - ExecuteBlocking] Queing delay too high · Issue #3028 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello,
During some load testing on our architecture based on VertX I found some issues concerning the use of ExecuteBlocking. I don't know yet if it comes from our way of doing or if something weird is going on.
1. Context
We are calling an endpoint that is in charge of execute some I/O (a rest call to a third party). For that we are executing that I/O in a executeBlocking() method (using vertx.executeBlocking() with ordered = false).
Unfortunately, we can't use the Vertx webclient for that purpose
2. Configuration
We are using 4 event loops (fix to 4 as we have only 2 CPU on our hardware) and a worker pool size of 100 using 4 verticles.
The I/O blocking process is executed in a average of 200ms.
The load test is using JMeter (on the same local machine) using 1000 threads that will call this specific endpoint (using HTTP).
For the verticle deployment we are using a specific Verticle that is in charge of deploying the "business verticles" based on configuration via  vertx.deployVerticle. The business verticle to deploy is configured that way :
3. Where is the potential problem ?
The average response time of the call is around 2 seconds.
The delay is caused by the time to send the blocking task to the worker pool.
As we can see in the metrics most of the queue_delay is around 2 seconds.
As we can see the worker pool is busy but it seems that some threads are waiting sometimes (indicating that he seems not "over charged"). (we've tried adding more threads in the pool but it didn't change anything, more threads were waiting, that's all).
The event loops are not blocked (we don't have any warnings, and we've set the warning to 100ms).
We've set timers to correlate data for the queuing delay and we've noticed the same numbers (2 seconds delay for a process to be executed).
Here is a trace (from Jaeger) displaying the duration for one specific call during load testing :
We can see that the process inside the execute blocking is taking around 200ms but before that the process was doing nothing but waiting to be processed.
Questions :
Do we have missed a configuration ?
Is there something we're doing wrong ?
How can we explain that delay ?
Can we avoid the queuing delay in some way ?
This kind of contention is not happening with lower concurrency (like 100 threads)
We've tried to have one worker pool per verticle (so 4 worker pool) to avoid potential contention but it didn't change anything at first sight.
We can't have more than 2 CPU on our hardware
We are using Vertx 3.7.1
Thank you and don't hesitate to ask me anything that can help you investigate this.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

3124
Deadlock in ASyncFileImpl/PipeImpl (using vertx-web-client and request.sendStream(asyncFile)) · Issue #3124 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
Using vertx 3.8.1
Using something like (kotlin+coroutine) :
It happens that the call never return, but it's random (Never when I tried to extract a reproducer, almost always in the real context, of course).
To investigate, I've copied PipeImpl and ASyncFileImpl and added some trace. (Modified version in attached files with output)
It's seems like at some time, something has kept the monitor of ASyncFileImpl instance, preventing the resume call  to execute the method.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

3126
Clustered Lock is not released if more locks are requested than available worker threads · Issue #3126 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am facing this issue while migrating from vertx 3.5.4 to 3.7.x.
If I am requesting more locks than available workers, then lock is not released in vertx versions 3.6.x and 3.7.x. Please find the reproducer below:
Above same code works if I change vertx version to 3.5.4.
Also if I reduce numTestEvents in dataprovider(for above reproducer code) to a number less than 20 then also everything seems to be working.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

3142
Deadlock when deploying several instances of a verticle a starting net server · Issue #3142 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
This is a regression on 3.8.2 due to #3117
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

3232
Vertx#close Future will not callback the handler · Issue #3232 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The Future returned by vertx.close() never completes because the thread pool has been shut down.
The first of these works, the second doesn't:
Sync.await is just a blocking method that waits for a future to complete using setHandler.
The output from that is:
and it never completes.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

3253
io.vertx.core.VertxException: Thread blocked · Issue #3253 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

3335
FileSystemImpl.existsInternal can block event loop thread · Issue #3335 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Version
Invoking vertx.filesystem().exists() can block the event loop thread. This is because resolveFile() runs in the event loop thread instead of in the worker thread:
Do you have a reproducer?
You can mock calls to resolveFile() to sleep for any amount of time or set a breakpoint on the resolveFile call as a test runs. Wait up to the blocked thread checker interval and unpause execution. BlockedThreadChecker will report that the thread has been blocked.
Steps to reproduce
See above.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

3468
Thread blocked in io.vertx.core.net.impl.clientconnection.ConnectionManager.getConnection · Issue #3468 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
While upgrading https from Vert.x 4.0.0 milestone 4 to milestone 5, we noticed a serious issue with HttpClient connections being thread blocked.. It seems to appear when connection can not be made to a remote host. Using same client and issuing another request that also fails results in a thread blocked warning and a halt of the event loop..
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

3469
HTTP client retry on same host can self deadlock · Issue #3469 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The HTTP client retrying the same host on a failure can self deadlock because it will close the pool after it performs the callback. It should close the pool before so when it retries and fail it does not retry indefinitely.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

3474
Thread blocked with drainHandler, writeQueueFull  · Issue #3474 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
POSTing many buffers to an echoing server gives thread blocked failures when we use drainHandler+writeQueueFull approach.
The same POST with write and a completion handler does not.
Write with handler is a much simpler strategy, but from documentation it's not clear whether it's an alternative for drainHandler. In any case we cannot explain our thread blocked problems with drainHandler.
What's the best strategy for writing?
Environment
Below is a unit test with test methods drainHandler and  writeHandler. Each test sends 10 times 2 GB to an echoing server (part of unit test).
always completes and memory usage is low.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

3658
Race condition throws an unhandled exception in CompositeFuture.all · Issue #3658 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Version
Which version(s) did you encounter this bug ?
3.9.2, but this is likely in newer versions as well.
Context
When at least two futures executing on different threads are passed to CompositeFuture.all(), there is a race condition throwing an unhandled and unexpected exception if the futures both fail at virtually the same time.
The gap between this synchronized block in all method reached when a future fails
and the synchronized block in doComplete method
can create a situation where a subsequent future/thread sees that composite.isComplete() is false, yet making it to doComplete method, returning false after seeing result is not null.
After returning from tryFail method, this then throws the unhandled and unexpected exception in fail method
Steps to reproduce
Here is a simple test with @RunWith(VertxUnitRunner.class) treating unhandled exceptions as unit test failures.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

3860
Blocked thread anomaly · Issue #3860 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The following message implies the thread has been blocked for several times longer than the JRE has been running.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

3921
EventBus cannot handle received message when using Future inside · Issue #3921 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Version
Context
I encountered an exception which looks suspicious while executeBlocking when handling received message in EventBus MessageConsumer
Do you have a reproducer?
This is a test you can add it in LocalEventBusTest
It is exception when I debug in my project, hope this help
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

4069
Deadlock when closing Vertx and WorkerExecutor concurrently · Issue #4069 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I met a deadlock issue recently on Vertx version 4.1.1 and after investigated and looked into the VertxImpl, CloseFuture, WorkerExecutorImpl, it looks like the deadlock happened in Vertx, please take a look:
In my case, the deadlock issue is hit when the vertx.close and workerExecutor.close happened to be called at same time, one from main thread and another from eventloop thread. (the workerExecutor is created by the vertx.createSharedWorkerExecutor)
Backtrace printed by jstack:
Found one Java-level deadlock:
Found 1 deadlock.
Checked vertx 4.1.1 code and find:
When closing WorkerExecutor, it will do:
Lock self (WorkerExecutorImpl)
Remove self from CloseFuture
Close SharedWorkerPool, which require lock Vertx
When closing Vertx, it will do:
Lock self (VertxImpl)
Close CloseFuture, which synchronized copy the list of callbacks and invoke them outside of the synchronized block, one of the callback is to close the same WorkerExecutorImpl instance as above
So, when the copy of callbacks in CloseFuture happened before removing the WorkerExecutorImpl from CloseFuture, it will still be called and cause deadlock
T1
Start close Vertx, locked VertxImpl instance
T2
Start close WorkerExecutor, locked WorkerExecutorImpl instance
T3
In CloseFuture, the list of callbacks are copied
T4
Remove WorkerExecutorImpl instance from CloseFuture. But since the callback is already copied in T3, this doesn't prevent the callback from being called
T5
The callback of close WorkerExecutorImpl instance is called. This require lock on the WorkerExecutorImpl instance, which was acquired by eventloop thread at T2. So it is waiting for the lock to be released by eventloop thread
T6
Close SharedWorkerPool, and this require lock on the VertxImpl instance, which was acquired by main thread at T1. So it is waiting for the lock to be released by main thread
Deadlock
Deadlock
The issue seems still exist in 4.1.2
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

4104
WorkerExecutor.executeBlocking sometimes holds a lock on the WorkerExecutor after the blocking call has completed · Issue #4104 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I ran into a Java deadlock in a large application, and based on the stack trace of the blocked threads, it seems to be caused by each thread running WorkerExecutor.executeBlocking on the same two WorkerExecutor instances, but in a different order. One thread looked like this:
And the other like this:
If that fut.onComplete call runs after the blockingCodeHandler has finished, the asyncResultHandler will be executed right away on the current thread. This means that we stay inside of the synchronized block as we continue on. If one thread does
we1.executeBlocking(...) followed by we2.executeBlocking(...), and another thread does it in the reverse order, and the first call each thread makes ends up running asyncResultHandler right away, you deadlock.
Do you have a reproducer?
Here is a simple JUnit test that reproduces it:
Note that you also need to add a breakpoint on this line in WorkerExecuteImpl.executeBlocking, to ensure that the blockingCodeHandler always finishes before fut.onComplete runs:
I used the Intellij "Evaluate and log" breakpoint option to insert a 200ms sleep on this line, which lead to consistent reproductions when executing the above test.
Steps to reproduce
I suspect this is hard to reliably reproduce outside of a carefully constructed test, because the timing requirements are so specific.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

4275
ConnectionBase exception handler should not be called within the synchronized block · Issue #4275 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

2012
Race condition in AsyncFileImpl writesOutstanding · Issue #2012 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
If an AsyncFileImpl is written to from a thread different to the context that created then the long counter writesOutstanding can get into an invalid state. This is because the counter is updated from both the caller's thread and also on the context when a write is complete.
Fix is to use an AtomicLong for writesOutstanding:
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

2115
WebClient: downloading url to file signals completion prematurely · Issue #2115 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When I download file using BodyCodec.pipe(file) and try to read it right after completion, I sometimes read empty file (the data is not here).
Following code reproduces bug (it's not 100% reproducible, for me it fails only on heavily loaded CI):
It calls stream.end() which underneath calls AsyncFileImpl.close() and then signals completion right away, without waiting for close to finish. In fact this creates race condition between handler and file closing. So code which listens for completion event may receive this event before close() takes place (which means the data in file will be truncated).
I fixed it locally by making my own copy of StreamingBodyCodec which signals completion to my code after file is closed via separate future (which is very hacky). After this fix bug stopped reproducing. But it would be nice to have it fixed in master as well.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

2292
Possible race condition with chunked responses after upgrading to 3.5.0 (now with reproducer) · Issue #2292 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello,
after upgrading to vert.x 3.5.0 we've been seeing a consistent problem with one of our service APIs: when replying with chunked responses over SSL, clients are reporting encoding errors when processing the response.
The problem is that after a certain load threshold (not sure if the number of such chunks of their size but I can consistently repro it in our service with >4000 chunks) the client will receive invalid chunks and break the connection.
On the server side the problem surfaces with a long list of ClosedChannelException instances which for me I believe was a red herring as a root cause. Trying to debug the service, I noticed that the exceptions are legitimate and caused by a Connection reset by peer exception which is swallowed by netty:
The channel will then be closed and triggering the large number of ClosedChannelException instances when the originally scheduled zrange commands complete.
But there is no symptom on the server-side to describe an encoding problem so my hypothesis is that the client breaks the connection when it receives the first bad chunk thus triggering the Connection reset by peer which in turn surfaces the ClosedChannelException. So I think this is a symptom of a more delicate problem.
When this happens, curl -raw on the web server's endpoint will display some chunks but then stop with one of the following errors:
Also, comparing the payload observed by curl with what the server should provide, the chunk size appears to be correct every time but the chunk content is truncated at random points along the way.
All of the above leads me to believe that the response is indeed corrupted but I can't figure out why/when/how or by whom the chunked response is corrupted in the stack:
Other observations:
the problem is isolated to versions above 3.5.0 (does not repro in 3.5.0.Beta1 or below and the service code which triggers this behavior hasn't been changed in a while)
it only appears with https and toggling OpenSSL has no effect
for low number of chunks (less than 1000) it rarely reproduces on a cold service start but consistently reproduces afterwards
the actual payload (string content) does not affect it. Considering that there are times in which it does not reproduce with the same content, I believe it behaves like a race condition and not like an input validation bug
debugging appears to be adding synchronization and changes the behavior. I never succeeded in reproducing it while trying to observe this breakpoint. What I did was to condition the breakpoint to fire when contentLength == 0 (marking the end of the response). With the breakpoint enabled, it never reproduces. With the breakpoint muted, it always reproduces.
looking at the change history, my initial idea was that the change which added this behavior was due to this issue (Serialize messages sent to the connection in the order of the synchronization monitor) which was closed with these changes. But after confirming that all messages are written from the event-loop thread, I think it's not relevant.
HttpServerOptions.setMaxChunkSize has no effect.
HttpServerResponse.setWriteQueueMaxSize has no effect.
A reproducer can be consulted here.
Any pointers/help to get to the root cause of this issue would be greatly appreciated.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

2534
Event loop context executing with wrong thread · Issue #2534 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I'm running it on a AWS instance, it shouldn't matter but maybe network performance is important in case this is caused by a race condition.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

2773
HttpClient race condition when getting a connection from the pool being closed · Issue #2773 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Currently there is a race condition with the HttpClient between a client request and a connection close. The pool delivers the client request in the next tick and the connection might be removed from the pool between this the schedule and the delivery. At this moment the client does not know the connection was closed and is never aware of the connection close.
We should avoid a next tick in this situation, i.e when the client request is fulfilled with a valid connection, it should be called immediately to avoid the race.
Currently the fact that the connection pool can hold connections with multiples context does not allow to run the pool requests on the pool and thus the situation is hard to avoid without a re-check before the connection is delivered. A better solution might be to attach a vertx context on the pool and consider all connections will use the same context, this would allow to eliminate the race easily.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

3196
HTTP/1 stream should synchronise when updating the connection stream · Issue #3196 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Currently when sending the request the HTTP/1 stream will update the connection state without synchronisation which can lead to race conditions. We should synchronise properly so the other parts reading the state will see the correct state.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

3438
Race Condition in HttpClientImpl.getConnectionForRequest, ConnectionManager.getConnection · Issue #3438 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am using the Vert.x 4.0.0-SNAPSHOT stack with an AdoptOpenJDK 11.0.7 on Ubuntu 20.04. The first time I encountered this was with a Hazelcast-managed distibuted Vertx system (with only one node) with both a standard HTTP server and a vertx-grpc server running on two different ports (both with TLS/SNI enabled). After making a few successful calls to both, I closed the client (cleanly) and I let it rest for a few minutes. Then the console started to output that same error at what seems to be a sub-second interval :
Now I get it everytime I let the system run overnight. I'm the sole user of the system.
Does this ring a bell ? I can't try to use it with the 3.x stack because the Vertx-grpc has a completely different codebase fo 4.0.0.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

3687
Connection pool can create connections which ignore keep alive settings · Issue #3687 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Version
3.9.1 but this also happens on latest commit
Context
Since some time we've seen WebClient throwing Connection reset error on first request after a period of inactivity. I know that our gateway closes inactive connections after some time. The question was why WebClient doesn't close such connections, the default keep alive settings should remove inactive connections after 60 seconds. After some debugging I tracked the issue down to Pool having connections that don't have expirationTimestamp set. I believe there's some race condition with how connections are created and consumed. The flow is like this:
First request is started. First connection will be created but it takes significant time for it to be connected.
In the same time a second request is started. A second connection will be created but this one connects instantly.
Second request finishes.
Second connection is now available and it's used to complete the first request.
First connection has finished connecting but the waiter list is empty. It will sit unused in the pool. expirationTimestamp is not set so keep alive settings are ignored.
After some time our gateway closes the inactive connection by sending RST packet.
Third request is started, it will use that first connection (now closed on the gateway side) and throw Connection reset error.
Do you have a reproducer?
See here.
Note that I added a delay in HttpChannelConnector to simulate slow first connection. This reproduces the issue reliably. Of course in our environment I can reproduce the issue with unchanged vertx 3.9.1 and 3.9.4.
Steps to reproduce
A pool now has a connection that won't be removed even if its keep alive time passes (expirationTimestamp of this connection is 0).
Extra
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

3763
clientRequest not available in Interceptor · Issue #3763 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Version
Context
In my interceptor, I want to know (once the request was done) what the request method was. To me it looks like I should retrieve the clientRequest from the HttpContext and from that object i can ask getMethod(). But the clientRequest method always returns null (although according to documentation, this should only happen during PREPARE_REQUEST phase, not in later phases.
Reproducer
this test prints
ignore the rest of the project, that was for another issue.
Extra
I debugged a bit. in HttpContext line 558, clientRequest field is assigned, and I figured that cool, it must be working. But when i let the code continue to execute, breakpoint at line 549 is hit and clientRequest is again set to null. So looks like there is a race condition or so between the request's onComplete handler and the continuation handler.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

3994
Two distinct HttpServer creations with port 0 yield the same random port (usually) · Issue #3994 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Summary
Two individual calls to vertx.createHttpServer(...) with port 0 yield the same random port (usually, see note on race condition futher down).
In context of Quarkus, this is irritating for users because Quarkus will print something like:
Furthermore, something seems to break after a very special sequence of QuarkusTests (that I'm not allowed to share due to closed source) in Quarkus 2.0.0 which uses vert.x 4.1, but that doesn't happen with Quarkus 1.13.7 which uses vert.x 3.something.
See quarkusio/quarkus#18154 for details.
This problem vanishes if I use a fixed port for https (my tests are using http anyway, not https).
While debugging/adding logging, I think I have also found a concurrency issue in TCPServerBase that I have described here:
Do you have a reproducer?
See Quarkus based reproducer in quarkusio/quarkus#18154
Extra
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

4221
Pool can deliver lease with null connection · Issue #4221 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
A race can happen in the pool when it delivers a lease. Leases are created as pool post actions and sometimes can read a connection from a slot that became null in the meantime the post action is executed.
This leads in an NPE in the HttpClient that instead should not get non null closed connection, instead of a null connection. (reported here #4220 (comment))
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

4297
Race condition when use RecordParser with concatMapCompletable and observeOn · Issue #4297 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I encountered some issues when using RecordParser with concatMapCompletable and observeOn like the following code to process records one by one on worker thread:
The issues including:
Sometime the RecordParser will suddenly stop emitting record, there's no error and not reached end of file and it is not disposed... it just stuck there.
Sometime a MissingBackpressureException is thrown
After investigated and tried create a unit test for this issue, it looks like a race condition on RecordParserImpl:
Usually the record is emitted from RecordParserImpl on event loop thread. (RecordParserImpl.handle)
However, when backpressure exists (concatMapCompletable here), it can be the thread running on downstream to request item from upstream. (RecordParserImpl.fetch)
In my case, the inner stream of concatMapCompletable is switched to a worker thread using observeOn, so it will be the worker thread requesting item from RecordParserImpl during backpressure.
When the RecordParserImpl.handle running on event loop thread and the RecordParserImpl.fetch running on worker thread are called at same time, race condition happens because RecordParserImpl is not written in thread-safe way.
The race condition includes but not limited to:
In RecordParserImpl.handleParsing(), both thread may passed the parsing check and do the parsing concurrently
demand could be modified concurrently and result in unexpected value
When RecordParserImpl.handle has filled all demand and paused upstream, but before parsing is set to false, the RecordParserImpl.fetch could add demand and exit quickly due to parsing is true, and then it will stuck - upstream is paused so RecordParserImpl.handle will not be called again, downstream has requested item and is waiting for next item.
Steps to reproduce
Here's a unit test that could reproduce the issue:
In the printed log, we can see the xx: Read record yy log can sometime be printed on event loop thread (RecordParserImpl.handle) and sometime be printed on shared worker thread (due to backpressure, RecordParserImpl.fetch)
The backtrace for issue 1 looks like:
The source did not signal an event for 5 seconds and has been terminated.java.util.concurrent.TimeoutException: The source did not signal an event for 5 seconds and has been terminated.
The backtrace for issue 2 looks like:
Not sure if it is a problem in RecordParser or concatMapCompletable (is it expected for upstream to be requested on worker thread in this case?) or maybe it is not a desired to use them in this way?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

2492
Deploying HelloWorld Verticle in OpenShift v3.7.46 ThreadDumps · Issue #2492 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thought I would start with this group, but it may be more of an OpenShift issue.
We are seeing threads block deploying the simplest of applications.  We are new to Vertx, so it could be how we have something configured in the Dockerfile.  Attached is the console dump from the OpenShift pod, and the Dockerfile we use to build the image (we do not use fabric8 yet to deploy to our main OpenShift clusters).
OpenShift Master: v3.7.46
Vertx Maven Version: 3.5.2.CR3
I can run the same, generated container locally in Docker (version 18.03) on CentOs without seeing these issues.
Thanks for any help.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

2598
Vertx HTTP Thread block unknown warning issue · Issue #2598 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
times to times we get this thread-block warning exception. any idea?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

2670
Client connections on GlobalEventExecutor thread that are not propagated to the application · Issue #2670 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Sometimes the Netty's bootstrap may notify client connections on the GlobalEventExecutor thread when it happens early in the boostrap when an event-loop has not been yet determined. Vertx expects notifications to happen on the event loop thread and this results in a Uh oh! Event loop context executing with wrong thread! failure.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

2684
executeBlocking callback run on the wrong thread for asynchronous future resolution · Issue #2684 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Currently the executeBlocking(Handler<Future<T>>, Handler<AsyncResult<T>>) might execute the callback on the wrong thread when the runOnContext(...) execution loses the race against the thread that completes the future. This never happens when the worker thread completes the future, but it can happen when the worker thread hands off the future to another thread that completes it.
This happen in the Mongo client and fails with a stack-trace like:
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

2798
io.vertx.core.VertxException: Thread blocked · Issue #2798 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi there,
i am already using vertx.executeBlocking() but i always get this exception:
For explanaition:
I download some files from ftp server and this takes some time. So i have also tried to set the checker interval:
but this doesn't have any effect.
It is a clustered vertx instance (source file).
What can i do to solve this problem? Or how can i increase the limit?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

2943
Vertx hangs instead of closing while using Micrometer · Issue #2943 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I'm trying to use Vertx + Micrometer and I see that that when I want to call vertx#close the application doesn't exit and some threads from the Micrometer class stay there forever.
However when I run the both standalone (either Vertx or Micrometer), everything is fine. So this issue only happens when I try to use both at the same time.
Here's a screen shot of what I see when I try to close the vertx instance, but it hangs.
Below you can find a link to the repository capable of reproducing the issue.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

3548
Verticles deployed with multiple instances do not scale processing evenly over the event loop threads · Issue #3548 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Observation
Observed during profiling cpu processing that vertx event loop threads are not evenly utilized in the scenario where multiple verticle instances are deployed.
Expected that with multi-reactor pattern, the event loop thread processing could be delegated evenly over the number of processing cores of the server.
Context
During performance testing with vertx http servers listening and created over multiple verticle instances, we see in profiling that only 1 of the vert event loop threads are using for processing incoming http requests handled on the Router.
Steps to reproduce
Start a http server using code similar to below test listeing on port 8080.
Start http traffic into the server with a client tool.  I used 5 requests per second with client written using vertx and http2 protocol.  I can show the code for this client if needed.
With a profiler (used yourkit), observe the threads cpu utilization and filter out the vertx event loop threads.
Observe only 1 of the threads is used while the others are used in processing.
Related question on stack overflow:
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

4139
Example code of Hibernate reactive Docs might create another new Vertx instance · Issue #4139 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Questions
Hibernate reactive Docs seems non-rigorous.It will create a new Vertx instance when I run the example code,and it might cause some operations to be not thread-safe.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

2370
HttpClient pool gets inconsistent on a synchronous connection failure · Issue #2370 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The HttpClient pool assumes that the underlying ConnectionProvider will make an asynchronous callback, which is the case with the asynchronous DNS resolver but not with the JVM synchronous resolver when the host cannot be resolved.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

3064
HttpServerResponse operation should not fail synchronously when the stream is is closed · Issue #3064 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We already have made some improvements here and for we should have the same behaviour for other related responses methods.
when the stream is ended (by the user) then it should fail synchronously because it is a programming mistake
when the stream is closed then it should not fail synchronously but should fail asynchronously. In Vert.x 4 the synchronous operation return a Future result that be failed in this case.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

3140
Do not lock the handler calls in AsyncFile · Issue #3140 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Currently the AsyncFile implementation calls the file handlers in a synchronized block. This synchronization is only useful for reading the handler and should not be used when calling them.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

4024
Concurrency issue in listener of TCPServerBase#listen · Issue #4024 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Version
Context
I stumbled upon a concurrency issue while debugging TCPServerBase in context of #3994:
There is a race between what's happening in that listener that is registered via bindFuture.addListener(...) and the code that is running directly in that listen method after doBind() is done.
That listener is setting the "outer" field id with the actual port but that field is also pre-set before that listener with port 0.
So dependening who is faster (the listener or the outer method code), the final sharedNetServers.put(id, this); will either pick up the id with the actual port or the one with 0. This is even less predictable due to id not having volatile or synchronized.
The effect while debugging was that if I waited before sharedNetServers.put(id, this);, I was getting another random port for each verticle (correct term?) while without debugging all got the same random port.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

4278
ArrayList concurrency error when deploying the verticles · Issue #4278 · eclipse-vertx/vert.x · GitHub
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi
We have an intermitent problem with the startup of our applications, in a few attempts I can reproduce so it it quite often to occur.
This is the error:
method: registerVerticleFactory
The exception is thrown by ArrayList.sort, here is the code
So from my analysis the ArrayList is being modified while it is being sorted.
We have 20 verticles in this application, so we iterate over the collection of class names and invoke the method below from
rxDeployVerticle(String name, DeploymentOptions options)
Please let me know if any additional information is required.
Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

