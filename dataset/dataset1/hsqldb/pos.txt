ClassLoader problem causing file lock error. If you attempt to open a connection on Windows through two seperate ClassLoader(CL) who each have their parent set to null you will get the ;DB in use by another process error. This occurs even if the first CL has been null'd because either the lock hasn't been GC'd or it has to do with Windows not releasing the lock properly. The easiest way to reproduce this is to create two JUnit tasks which both attempt to open a connection then run those JUnit tasks through ANT.
NIO lock problem. I am getting an exception when trying to allocate a connection. I tried to clean database files before running the program, with no success. It was tested on Compaq Tru64 platform, java version. The same code _works_ on Win2000 or Linux (also java ver 1.4) with no problem, so maybe this is just a buggy Java NIO API on Tru64. But I need to make it running on Tru64 somehow. Is there any way to avoid using NIO API in hsqldb? Right now I just commented all code in
Server hangs on select statement. The attached zip file contains a SELECT statement that worked in 1.7.1 but in 1.7.2 RC1 doesn't work. In 1.7.2 the server gets locked up and CPU utilization goes to 100%. I then have to kill the server. I tested this statement with org.hsqldb.util. DatabaseManagerSwing and with DbVisualizer (commercial SQL manager) and with my Java application. I got the same results. This statement works fine with a MySQL version of my database. The zip files contains the SELECT statement, the db script (pinyin.script), the server.properties and pinyin. properties and db.properties
File Locks not released when CMI Fails.We would like to make it so that we can restore the Hypersonic data when it gets corrupted but when getConnection() fails it doesn't release the locks on the files so we can't do this. I just created a database and then changed some of the data values in the .script file and I got this exception: If you need any more information then let me know.
lockfile and mac osx. We have mac osx server where users home directories are mounted by several clients. On the client, hsqldb fails to start due to a problem in the locking system. Here is an example with hsqldb logging turned on. Notice that the directory is empty, and hence the database cannot exist yet, and hence is not being accessed by any other process. However, hsqldb fails to start saying org.hsqldb.HsqlException: The database is already in use by another process: It runs fine if I use a local disk. I presume this is some incompatibility between the hsqldb file locking system and apple's afp disk mounting system???
Restart of engine fails due to spurious locking issue. I have noticed that despite closing all connections and exiting a standalone database, at least one connection still remains. The defect is manifested in HSQLDB 1.7.3 and HSQLDB 1.8.0 RC 8. If you compile and run the sample code below, it will run fine for the first time. Second time (if it is run immediately after the first time say within 2-3 seconds after completion of first execution) it fails everytime citing a database locked exception! The only workaround I could think of was to use the un-documented function:
TEXT tbl - source file is locked until restarting the engine. Hello, hsql team! TEXT table - after making it READONLY the source file is still locked and cannot be changed until restarting the DB-engine. It happens only when the table is switched from read-write to read-only mode. When the table has already been READONLY, the source file is not locked. I hope, that the source file should be unlocked after setting READONLY and/or DESC mode.
CMI hangs on shutdown in 1.8. Hi, I'm getting a deadlock when doing a database shutdown. The deadlock is easier to reproduce on slower system. It appears that HsqlTimer$Task first locks the cancel_mutex and then inside HsqlTimer$TaskQueue.signalTaskCancelled, a task queue. The HsqlTimer.nextTask first locks the queue, and then inside HsqlTimer$Task.isCancelled, the cancel_mutex.
Deadlock when using setWriteDelay. while executing "SET WRITE DELAY" I get a deadlock (as usual not every time) between the Timer thread and the thread executing the SQL. Here's the thread
Deadlock in 1.9a2. Using hsqldb 1.9 alpha2, I encountered a deadlock, wherein one thread was attempting to get a new connection to the db, while another was in the middle of checkpoint. I'm using a mixture of cached and memory tables. Relevant bits from the stack dump below.
Deadlock in b3. Circular dependency between SessionManager and Logger causes thread deadlocks (see attachment). However, it seems to be easily avoided in this instance by removing line Log.java:430 in addition to the code commented out below it. There's a second reference to database.sessionManager on 780, but it seems safe.
hsqldb.b3 locks up. I ran a multithreaded test and had several threads lock up in this state: I'm running on 1.6.0_03-b05/RHEL 2.6.9
1.9rc4: Deadlock. Hello, hsqldb went into a deadlock (please see attachment stack_trace.txt for stack trace). Beginning of the script file is at the end of the above attachment.multiple, concurrent read threads, setup using single write thread, executing concurrently with the reads. db is a mixture of memory and cached tables, cached table has blobs, total db size ~1GB
Apparent deadlock with r 3281. While running an application against a HSQL server which imports and exports XML files, I found that after upgrading from HSQL 1.9 revision 3271 (or perhaps 3274) to revision 3281, situations which resemble a deadlock started occurring. They involve the affected client only - other clients connected to the same server can continue working undisturbed, and the server still responds to them. Basing on the method in which the client hangs, it could be attempting to execute something like: ...but I am not sure if this is always the method which hangs. Others might be involved, simultaneous activities by other clients might be involved, and the SQL involved might vary. A thread dump from the client looks like this:
ClassNotFoundException while testing r3310. While trying to gather data about the deadlock problem which I described previously, I attempted to start testing with SVN revision 3310. However, transitioning to this revision in regular manner failed, producing ClassNotFoundExceptions. After issuing these exceptions, the server utilized a lot of CPU for 7 minutes (sorry, couldn't wait longer), and didn't manage to reach readiness for work. That's when I sent it the "-QUIT" signal to produce a thread dump.
Deadlock in 2.0.0 RC8. Concurrent transactions frequently cause deadlock. Downgrade to 1.8 fixes the issues
Deadlock between CMI and CMI. I'm using HSQLDB 2.0.0 (in-memory) with Hibernate and am experiencing a deadlock when multiple threads persist lobs concurrently. I've replicated the problem in a very simple test case, and it happens immediately. See below for stack traces from deadlocked threads.
Deadlock between CMI and CMI. Similar to the bug 3072706, i can reproduce this problem with hsql in-memory (14-Nov-2011,2.0.1-rc3SNAPSHOT) and hibernate 3.6. I got a deadlock when multiple threads persist lobs concurrently. One thread got a lock on the database, but have to wait before a synchronized method (LobManager.adjustUsageCount). The other thread wants the lock too, but is in the synchronized method LobManager.setCharsForNewClob. See below for stack traces from deadlocked threads.
deadlock in ScriptWriterBase (checkpoint). sync order against BufferedOutputStream and ScriptWriterText are inconsistent; checkpoint causes deadlock:
CMI can cause deadlock. I am experiencing deadlock when two different threads attempt to close the database with hsqldb 2.0.0 and 2.1.0. The issue is that Thread-1 acquires a lock on SessionManager@58a983 when SessionManager.closeAllSession() is called. Thread-1 is also attempting to invoke Session.close() the active sessions (i.e. Session@e107d9) which requires a lock on the session. Meanwhile, Thread-2 has already acquired a lock on Session@e107d9 when it called Session.execute(). Thread-2 is also attempting to acquire a lock on SessionManager@58a983 for SessionManager.closeAllSessions, but the lock was already obtained by Thread-1. I have posted a more concise summary and the relevant thread dumps below. Deadlock summary
HSQLDB hangs forever on a deadlock case. Get a table with two rows and a primary key: Then, in two connections: I expect an exception "deadlock" on query 4. However, HSQL hangs forever yet on query 2 :( Is there a workaround? How can I detect a dead lock? My application can work with several different RDBMS, and with other systems I can detect a deadlock, roll the current transaction back and re-try my queries a bit later. With HSQL DB in this case my application hangs forever :(
Checkpoint deadlock in mvcc read_committed mode versions 2.2.6. I use HSQLDB for an image caching system. The images themselves are stored on disk but an image statistics (last access, usages etc) and location on disk are stored in HSQLDB. I experience deadlocks at the point the logfile is processed and emptied. Even though not sure this is because of my own code (it locks rows when updating statistics and when records are evicted, Spring and Hibernate should commit the sessions), I haven't experienced any deadlock issues with MYSQL so far. I have a unittest that reproduces this issue on my machine. It runs 10 concurrent threads that read from the database (read and update same record's stats) and 1 thread that inserts records. I tried both direct jdbc:hsqldb:file: connections and standalone instance with jdbc:hsqldb:hsql connections. My connection string (issue happens with both cached and normal table settings): Furthermore I use a 20 connection pool (dbcp2). I captured the session data together with a threaddump, see attachment.
Deadlock when using HyperSQL 2.3.4 with Flyway migrations. When using the Flyway database migration system with HyperSQL 2.3.4, the attempted application of migrations results in deadlock. Version 2.3.3 works as expected and I found that the code change causing the deadlock is the following code added to TransactionManagerCommon.java line 558 in commit r5537: For some context, one of the first things that Flyway does when it starts is open up a connection to the database and lock its metadata table. The migrations are applied in a separate connection. The code pasted above gets run a few method calls below the executeCompiledStatement method in Session.java (this method is what is trying to execute my first migration). The getTransactionSessions method is adding the session that Flyway uses to lock its metadata table to the "tempSet" of the session that is executing the migration. This effectively causes the executeCompiledStatement method in Session.java (around line 1355) to wait forever -- the session that Flyway is using to lock its metadata table doesn't commit (and therefore release its lock) until all the migrations have run, so the count down latch will never decrement: The deadlock described above can be replicated by using Spring Boot's flyway sample and modifying the pom.xml so that the application uses HyperSQL 2.3.4 instead of H2. The unit tests for the sample show the deadlock occuring -- the build and units tests get run by running the following command: The output of the command will stop and lock up after outputting the following:
Error DELETE with referential integrity DELETE ON CASCADE. We use HSQLDB 2.3.3. We decided not to use 2.3.4 because of bug 1441 (Deadlock when using HyperSQL 2.3.4 with Flyway migrations). We had a problem trying to delete a record from a table woth referential constraint in DELETE CASCADE. Below you can find DDL to create some tables of our database
The row from table core.mainCols contains a columnMap that throws this exception because the number of elements of array is less than columnMap indexes.
HSQLDB Deadlock using 2.4.1 and MVCC. We encounter a recurrent deadlock issue using the 2.4.1 version in one production environment. We have been using this version for a long time in various environments and have not seen deadlock issues until now. The issue appeared recently in this production environment, and is reappearing regularly after restarting the application and waiting for a few day of usage. The database is quite big, with million rows in some tables. The hsqldb server is configured in MVCC mode and sessions use READ_COMMITED transaction isolation. We did not change the defaults for hsqldb.tx_conflict_rollback or hsqldb.tx_interrupt_rollback. I wonder if these settings should be modified to prevent the deadlock from happening. After connecting to the database manually and inspecting the session, we observed that a checkpoint session is waiting for the following session, which never seems to terminate: The checkpoint statement, on the other hand is preventing many transactions to complete (which I believe is expected). We tried to manually end the blocking session 5969 using ALTER SESSION RELEASE (and then CLOSE), but the session does not seem to respond, we tried as well END STATEMENT without success. We tried as well to use ALTER SESSION RELEASE | CLOSE on the CHECKPOINT (6076), and here it disappeared, but all other sessions waiting for this checkpoint session 6076 were not unlocked and are still displaying THIS_WAITING_FOR 6076. It is quite difficult to understand the root cause of the issue as we cannot identify the origin of the 5969 session, which statement it ran, etc. If we could forcefully provoke an error on this transaction, we could hopefully see in our logs the error and thus could identify the origin. For now we are leaving the server in this deadlock state to hopefully investigate further.
Extraneous sleep  in Log class. In version 1.61 of hsqldb in the CMI method there is a 3 second sleep that seems to be there to do some sort of concurrency checking. I could not find anyplace where the lock file is actually created. I believe this is unnecessary code and can be removed. It would significantly improve start-up time.
Lock File Does Not Work. In the latest release the Database in use exception is no longer thrown. I have tracked this down to substantial changes in the lock file functionality. I turned on the new hsqldb.lock_file property. In this new version instead of getting a SQL State 08001 with a nice Database in use message you get File input/output error XXXX.backup java.io.FileNotFoundException: XXXX.data (The requested operation cannot be performed on a file with a user-mapped section open) In some cases during my testing my database got corrupted and I had to restore a backup in order to continue testing.
LOCK TABLE <TABLE> WRITE causes NullPointerException. When you perform a "LOCK TABLE <TABLENAME> WRITE" the following exception is thrown.
Multiple start possible - lock file does not work. The lock file does not work - at least in NON NIO case. The attached patch improves the situation for me. The issue #2547727 may be related.
rollback handling. Looks like a similar issue to comment #2 to 2828178. Transaction failed with index constraint violation (which shouldn't be possible, but I'm investigating), and an attempt to rollback caused a series of calamities (please see attached stack trace). Another unfortunate consequence was the fact that the CountUpDownLatch was left in locked state:
Table never unlocked after select with autoCommit off.Seems to me this is another aspect to bug 2805121 but I couldn't attach to that so here's a new bug. This is against the latest support snapshot (3rd Sep)Simply doing a select statement in a session with autoCommit off will mean the referenced table(s) NEVER get unlocked. Obviously this is bad.The statement in bug 2805121 that the latch count does not increase for select statmeents seems to be false. I originally hit this with 3 sessions doing selects from a table and another trying to do an insert (each in separate threads). The count in the CountUpDownLatch was 3 and never changed causing the program to lock up. This can be easily reproduced with the code attached.
Dead lock with Hibernate test suite. I tried to update Hibernate test suite to use hsqldb 2.0 but it seems there is a dead lock. You can get the code from http. Simply update parent/pom.xml to use org.hsqldb:hsqldb:2.0.0 instead of hsqldb:hsqldb:1.8.0.2 and run mvn clean test -Phsqldb. The build is stuck on test org.hibernate.test.jpa.lock.JPALockTest. Here is the thread dump: Do you have an idea of the cause of the issue.
Select keeps readlock even if resultset is processed. It seems that a select issued in 1 connection (autoCommit=false) keeps a lock on the table even if the select is completely processed (it does not have any results in our case). An insert executed from another connection blocks on the select statement. See attached sample program, this program completes using hsql 1.8 but hangs using version 1.9.
lock java process. When I use the latest version of hsqldb, after insert data with unitils-dbunit, I have a lock of java process. Below, the tread dump.
Embeded Blocks in Multithreaded environment I'm usgin v2.0.1RC2 embeded with my application. It get blocked arbitrarily when two threads that share the same connection executes two statements (one each). Is not possible to share connections?
CountUpDownLatch seems insufficiently concurrent. In a highly threaded environment (64-256 simultaneous connections all accessing an embedded db with a mix of read/write, mostly read), I get stuck at the latch.await() call in Session.executeCompiledStatement(); various others have reported this on the forum. It is a bear to replicate, but seems more prone to happen with more cores (my machine is a quad-core). In looking at the code, CountUpDownLatch seems problematic; the filed 'count' is not volaitle, which means under concurrent access, different threads can increment incorrectly. FOr example: Thread 1 calls countDown(), in its memory picture 3-1 becomes 2. at the same time Thread 2 call countUp(); in its memory picture it has it's own copy of count, no volatile, so 3+1 becomes 4, when it should have been 3. In fact, while volatile will help, it should probably be an AtomicInteger, or similar structure. Volatile would however be enough if the CountUpDownLatch is accessed by separate threads under an exclusive lock; a surface look indicates this is the case. Exclusive locking however does not guarantee the memory barrier effect of volatile. Without doing more looking in TransactionManagerCommon et al, I can't tell if the methods within CountUpDownLatch are meant to be atomic; setCount() in particular seems like it should execute synchronized from all other CountUpDownLatch methods, but the usage pattern of CountUpDownLatch may protect against this.
missing syncronized block for time conversion. The following error occurs on HSQL version 1.8.0 & 1.8.1: Problem is in class: HsqlDateTime the following method should be fixed - to add syncronized block on the calendar object:
dead lock when checkpoint. When hsqldb execute a checkpoint, the entry point is org.hsqldb.persist.Logger.checkpoint, at here it will get a lock of logger, Then it will go to session.commit, in here, it will try to get a write lock of transaction, that's ok. But when we execute a select sequence statement, the execute order of updating of sequence is: get a write lock of transaction,then try to get a lock of logger, that's dead lock. Note: I am running on a non-English environment, so I translate some key-word to English by myself, maybe some words are different.
Failed to use Hibernate StatelessSession with version 2.1. It seems there is an issue when you try to get a result from an Hibernate query using a StatelessSession, no result is returned and it causes a dead lock. When using version 1.8 everything works fine.
Concurrent write while backup. sorry if this issue was already discussed in another thread that I didn't find. We're currently implementing a solution where the backup is performed while the server is running. The SQL statements are executed using the JDBC connection. As you know, while the backup is performed, the database is locked. This means all reading/writing processes are blocked. Here comes the bug description: After the backup is complete, all writing processes are unblocked, thus a new .log file is being created. And it starts with the INSERT statement (for table XXX). If you close the Java program without closing the database (e.g. process got killed, power failure,..), the log file continues to exist. On next startup, you get an exception that the table XXX was not found and the rest of the log file is being ignored. Finally, the log file is deleted so it's not even obvious WHY the table XXX was not found. And here comes the workaround: if you perform a checkpoint right after the backup, everything seems to be fine (was not able to reproduce this error) - but I won't bet .. Attached, you have a cropped version of the source code to reproduce the problem (~80% of executions). You may need to adjust the iterations and backup waiting time. The idea is that the backup starts WHILE the thread is writing data.
NPE when data fiel is locked on disk. I think, HSQLDB should throw a meaningful exception that cane be recognized as "datafile is locked".
sql in SQL routine fail to acquire lock. Please see attached doc file for description and related ready-to-run files. In a normal SQL, if we use MVCC+Read_Committed, and setAutoCommit(false), then when issue SQL like "Update xx", we will get the row lock until commit. In SQL routine, we cannot acquire row lock when issue SQL like "Update xx". However, it will be able to detect the lock acquired by other transactions. [Will pause if lock acquired by other transactions] Below is a simple example to simulate the case: 1. A Java program called Locker to acquired a row lock on a row on FIX.LOCK_TBL table; 2. A Java program called SPRunner to run a SQL routine. The SQL routine will run below. Note that when the SQL routine run to 2.2, it will pause because a open transaction by 1. This is to simulate a "Sleep" inside the SQL routine. 3. A Java program called Attacker to run. If the row lock of BB table execId='100' has been taken by SPRunner, then Attacker should wait until SPRunner release. However, the result is that Attacker can run immediately, check the table, found the f_2 value changed to 6. It proves sql statement in SQL routine fail to acquire row lock.
Starvation issues with LOCKS transaction mode. I'm seeing starvation problems with LOCKS transaction mode. Basically, in a single-writer/multiple-readers scenario, there seem to be many reader threads hanging on the latch.await call, with very little reason, given the waited sessions committed already (which should count down the latch). I had some little time to look at the code and I believe it may be an issue in the transaction manager resetLocks and resetLatches methods: waited sets are computed by the former in session order, and then latches are released/updated in the *same* order; this may cause the first session (the one who got the locks) to terminate *before* the dependant sessions have inserted themselves as waiting sessions, hence causing the waiting sessions (the ones who do not got the locks) hanging forever on the latch (as the session that should have counted them down completed already). Here's attached a patch to "unlock" sessions after all waiting sets have been computed.
invalid transaction state: active SQL-transaction in stateme. I have two methods. They have test porpouses. One method executes a lot of insertions and updates in a few concurrent threads for one table. For such concurrent case I'm using MVCC transactional control mode. So, I set such mode before test will do any action. As soon as first method finished - second method starts and tries to return transactional mode back to defualt (LOCKS). But it failed with such error: What I've tried and checked: Nothing helped me. Could you check - is there any issues with switching between different transaction modes or I'm doing something totally wrong? Is it allowed to change such mode for one connection multiple times?
Pessimitic lock is lost after changing a property using SQL. In our application we're synchronizing threads using pessimistic lock on a row in a revision table We have following scenario: ERROR: After changing a property in HSQLDB an another thread (with a another transaction) that is waiting in select for update gets the lock (the first transaction is not closed yet!) From this point both threads are thinking, they have the lock they and are doing their job simultaneously. This leads at the end to an inconsistency in our data.
READ COMMITTED isolation level and table locks. Insert new data to the table block other transactions on the same table. This does not happens in MySQL and PostgreSql. This behavior makes it hard to tests complex application using HSQLDB as in memory database. See example code in attachment. Is there a workaround for this compatibility problem
Concurrency problem with CMI. I have noticed a thread locking problem when concurrently querying database for large results containing timestamps (calling org.hsqldb.jdbc.JDBCResultSet.getTimestamp() repeatedly from different threads). After some debugging I narrowed it down to this method: HsqlDateTime.convertMillisToCalendar() which contains synchronized block on a static Calendar field tempCalGMT: This obviously presents a bottleneck when getting timestamp results from ResultSet using multiple threads, so I am wondering if it can perhaps be refactored in order to be more suitable for multithreaded applications?
SessionManager <-> Session Deadlock. Please, find the attachment with the Bamboo report for the Dead Lock around Session and SessionManager. The synchronized Session.close() waits for the synchronized SessionManager.removeSession(), when the synchronized SessionManager.close() waits for the synchronized CMI. Thank you in advance!
SELECT...FOR UPDATE locking unexpected behaviour. There is a thread about this that has some background info here: Basically, I'm trying to use SELECT...FOR UPDATE to coordinate access to a shared pool of tasks where each task is represented as a row. The goal is to ensure that each task is picked up by one thread only. Each thread queries for a "pending" task and then, while holding the update lock, changes that task from "pending" to "processing" so that no other "pending" query will return that task. This method has the expected behaviour on other DBs I've tried but not HSql. I've attached a test program showing the issue. You can just import it into Eclipse. I tried this program against a SAP HANA database and it works in the expected way.
Database Lock Acquisition Failure. We run hsqldb in a web environment, with Servlets under Jboss. Our stable version uses 2.3.2 but we encountered issues with query aggregates which were solved with a 2.3.4 upgrade. However upon restarting, we get a lock acquisition failure, which we have determined to be caused by the Database.reopen failing due to RuntimeException raised by LoggerFramework which is as it turns out because the name of the Database is empty. We have created a simple patch to change the database name check, but have not verified any other use cases in hsqldb aside from our own. Apologies if this is a duplicate issue, we have compared against trunk and saw there are no similar changes.
MVCC: write lock broken on savepoint rollback. Hello HSQLDB team. I've just encounter a bug on HSQLDB v 2.3.4. I've updated library to 2.4.0 but bug still exists. I will attach TestNG test case to illustrate a bug. Main scenario is (all performs in single transaction): I think it is a bug, because: I'm using in-memory MVCC HSQLDB to test my application on a fast embedded DB. I know about "select ... for update" statement, but a "dummy update" should be tested too (some DB has bugs with "for update", like MariaDB)
Issue with select for update statement. I am encountering an issue using hsqldb and "select for update" statement In a nutshell, when the "select for update" is executed, it does not seem to lock the row (or the table) during the time of the transaction. I have made a small program that reproduces the issue on hsqldb which can be found in the attachment. The same program works with Oracle and other dbs. The program executes the following statements by 3 threads: Then each thread updates a global oid. If another thread founds the same oid as it own, the program stops. As it is, the program should not stop. I have the same behavior with the 2.5.0 version and the trunk version. All the configuration I am using can be found in the resources directory.
DDL blocking on transaction in other connection with mvcc transaction model. When a transaction is running on one connection, and some data is selected in that transaction, then DDL in another connection will hang, but only with the MVCC transaction mode. From the docs it seems to me there should be no blocking in this case. See attached sample java program, run agains the latest 2.6.1 build
Sporadic lock timeout. We see sporadic errors with HSQLDB (2.3.6+) that have to do with lock timeouts. The error is unfortunately not easily reproducible, but it happens a few times a week in the Hibernate testsuite. You can download the report here which contains more information about the error in documentation/target/reports/tests/test/index.html: The test failing here is org.hibernate.userguide.sql.SQLTest#test_sql_hibernate_scalar_named_query_example, but sometimes it's a different test that fails. Here is another failure in a different test: The relevant portion of the stacktrace is this: No idea why it runs into a timeout only from time to time. Other databases work fine.
outofmemory error. We have multithreded application and many thread use DB at the same time (I know that HSLQ does not support this.Each one have to wait).They are using SQL statements like. then I have got java.lang.outofmemory.
NPE at ServerConnection thread. We had been using HSQLDB for a long time and some time ago have switched to 2.x version. Unfortunately, recently we have got freezing of our application in our old and reliable DB related code. The reason is NPE in HSQLDB's ServerConnection thread. The problem is stable reproduced on the latest HSQLDB 2.2.5 and looks like this. Exception in thread "HSQLDB Connection @1ebd75b" java.lang.NullPointerException This NPE brings to opening new server socket without closing the old one. As result, client code doesn't know anything about server side problem and waiting answer on the old socket forever: I've attached java example for the problem reproducing. Just start it and NPE will appear. For now, I've found temp. workaround for the problem: set FETCH_SIZE const in the example to zero. Another known workaround is to use separate connection per table access via ResultSet.
IllegalArgumentException in multi-threaded application. The current version 2.2.8 is not completely thread safe. Under heavy load the method org.hsqldb.HsqlDateTime.convertMillisFromCalendar may fail. You get an IllegalArgumentException, if this happens.
HSQLDB can hang if the database is corrupted. HSQLDB can sometimes hang on start after unsuccessful shutdown (e.g.: power loss). We've observed this against 2.3.2 and subsequent versions. The stack trace is as follows (trunk). Apparently, if (length == 0) condition, under certain circumstances, can never be met: Since database corruption can't be avoided entirely, it makes sense to replace the while (true) loop with at least while (!Thread.interrupted()), so that the client can interrupt the thread and break out of an endless loop.
Spurious unique index constraint violation on inserts. When inserting rows into the following table: using READ_COMMITTED / MVCC mode, and multiple threads to do inserting, spurious SQLIntegrityConstraintViolations are thrown (and also, mysteriously, all my stderr output seems to get consumed, don't know why but it's made debugging this very tricky) Having checked to ensure that there is in fact no violation of the constraint actually occurring, I wondered whether it might be that the unique index itself is failing because the resource_name field contents are "too big". Sure enough, using much shorter resource_names makes the problem go away. Spent all day tracking this one down :)
create view problem. this causes a race condition. Don't know if you should stop or just say don't do it cause it hurts. Fix if you do it is to edit .script file and delete view.
Race condition in CMI. This method waits for current state to change from SERVER_STATE_OPENNING. But the implementation of Server.java 1.8.0RC8 does not always hold that condition. The code reads: The problem is that if the newly started ServerThread is not (or too late) activated by the OS. Therefore it cannot set the state field to SERVER_STATE_OPENING and the while-loop is never entered. To fix the race condition, make sure the state equals SERVER_STATE_OPENING before entering the wait loop. I cut&pasted line 1973 from Server.run() and now it looks like:
Explicitly calling CMI causes low-probability hangs. Attached is a demo program which starts an HSQLDB server using the Server class. It tries to terminate the server by calling stop() and then shutdown(). With a rather low but still real probability (about a once per 100 runs) the shutdown() call hangs. I have observed that omitting the explicit shutdown() call and nulling the Server object instead works more reliably, perhaps even 100% reliably. It seems like some race condition or threading issue, but I'm not qualified to dig deeper. You can compile the sample using: