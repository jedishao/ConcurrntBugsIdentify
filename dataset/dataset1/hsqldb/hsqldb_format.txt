Error in Build.Hi,When i try to execute the script build (build the jararchive) i can't because the javac give me thefollowing error :I can't find the class org.hsql.Map (used in classjdbcconnect)My version of JVM is 1.1.8Please send me the correct sourceBest RegardsJoao Luis
Please Support multiple ResultSets!Currently, the jdbcStatement class does NOT supportmultiple ResultSets. (This is clearly documented inthe javadocs, and is also obvious from looking at thesource code.)However, this makes this class USELESS for executinggeneral stored procedures (which OFTEN do mutiplequeries -- doing complex stuff like this is usuallythe whole point behind using stored procedures).
bug in the getMoreResults() method.The getMoreResults() method of org.hsql.jdbcStatementclass fails to follow the Statement interface specsexactly. This causes problems with code that shouldwork.The basic problem is that getMoreResults() fails toadvance the current ResultSet. (It also fails to closethe current ResultSet, which is also a violation ofthe spec.)Since HypersonicSQL currently does not supportmultiple ResultSets, what SHOULD happen if the specsare to be exactly followed is that the next ResultSetshould be advanced to null after closing the initialone when getMoreResults() is called.Below is the current (and buggy) implementation ofgetMoreResults():To illustrate the current bug, and also to test thatthe above patch actually solves the probelm, considerthe following code which works with any properlywritten JDBC Statement implementation (but fails inHypersonicSQL):From the Javadoc on Statment:The above code fails with updates (but not queries)because the loop never ends. This happens becausefails to return -1 the second time that it is called.If the above patch to getMoreResults()were in place, then getUpdateCount() WOULD recognizethat the current RS is null and then would return -1.
DatabaseMetaData.getExportedKeys broken.I am writting a java program that analizes therelations among the different tables in the database.When I create a table using FOREIGN KEY, Hypersonicclasses don't write to the SYSTEM_EXPORTEDKEYS table.Then, when I call to the getExportedKeys method, Iobtain no data.Thanks.
DatabaseMetaData.getExportedKeys() inop.I am writting a java program that analizes therelations among the different tables in the database.When I create a table using FOREIGN KEY, Hypersonicclasses don't write to the SYSTEM_EXPORTEDKEYS table.Then, when I call to the getExportedKeys method, Iobtain no data.Thanks.
LONGVARBINARY error using setObject.using hsql version 1.42When using setObject to set the value of a binarycolumn a class cast error occurs.I have made the following changes that solved theproblem:
Fix for &amp;amp;quot;SELECT x, SUM(y)&amp;amp;quot; &amp;amp;amp; &amp;amp;quot;GROUP BY x.The following sql does not work correctly:It returns a single null row.The bug is in Select.java, getResults() method
Fix for &amp;amp;quot;SELECT x, SUM(y)&amp;amp;quot; &amp;amp;amp; &amp;amp;quot;GROUP BY x.The following sql does not work correctly:It returns a single null row.The bug is in Select.java, getResults() method
Code transition and standards.On 2001-04-04 nobody@nowhere screamed in frustrationaand said:I'd like to supply some fixes we made to HSQL overthe time. However, we need to be able to reconcilethose changes with whatever you did to HSQL.This is _impossible_ to do, since all files changeddue to your formatting changes. There's no way to findout what changed between 1.43 and 1.60RC2.Do you have any kind of change history documenting thechanges you made?I can't even just grab the newest sources - I addedsome testing framework to HSQL that I'd hate to lose.Is there any way to merge stuff back?This is an ongoing issue and will be cross-posted asan open bug as we transition our customers to the newcode base.For the future of this project, NOTHING IS MOREIMPORTANT THAN THIS! At least until we get the CVStree in place. Mark has offered to do this on anindividual basis but we need two things from thedevelopers:a) someone to volunteer to be trained by Mark to dothis for customers/users (could be - SHOULD BE -multiple someones (ideally 3))b) someone to ride herd on this in the future (again,should be more than one) and assist me in thisspecifically, keeping me aware and honest - THIS KIND
No docs on DB transition.Need to add documentation on transition issues fromother RDBMS's, the strengths and weaknesses of HSQLDBin various use-cases and other new-user documentationto next point release
PreparedStatement Timestamps.Hi,I'm using hsqldb-v1.6 for unit testing my code, and I've lately run into troublewith java.sql.Timestamp in PreparedStatement. Our code will be using PreparedStatementall the time, and there will be lots of timestamp columns, so I really hope this works out.The problem is basically that I create a PreparedStatement from a hsqldb driver connection,then call setTimestamp(int,Timestamp) on it, and when I call executeUpdate, I get the followingerror:It appears from the error message, as well as from the hsqldb source, that the Timestampobject gets converted into a string (&quot;2000-01-01 05:00:00.0&quot;), and then the stringified SQL isprocessed by the hsqldb engine. But apparently it doesn't parse the string. I'm guessing it's thenanoseconds, because in the self-tests included in hsqldb (which make good examples), there arethings like '2000-02-29 10:00:00', but nothing with nanoseconds. I don't really need nanoseconds,it's always going to be 0, but I at least need JDBC compliance: if I pass a Timestamp value, thedriver must support it.Please let me know what the status of this is. I'll gladly post this elsewhere on the SourceForgesite if there's a more appropriate place, and I'll also send source code if it helps.Thanks.
single quote in statements.If string field contains single quote it throwsexception !Can anyone here help me patching this problem ?I am using HypersonicSQL which is being closed i guess.TIANitin
Infinite loop while executing DELETE.I have a sample tiny hsqldb 1.60 database on which the following statement:causes an infinite loop in method TableFilter.findFirst.The database uses tables created with the CACHED modifier (leaving out this modifier seems to fix the problem, but is not an acceptable work-around).As the database is taken from a closed-source project, I would prefer not to upload the file publicly. Please e-mail me for the test data + code which demonstrates the bug (jpljpl@gmx.de)
not null fails on primary key.I believe without looking this is ansi 89 to haveeven though the not null is implied by being a primarykey. It is acceptable by oracle 8i, MS SQL Server, MSAccess, and hsql 1.43.
canonizing column names.I can understand why you may take this shortcut tocapitalize all column names internally to thedatabase, but it sucks if you want to use reflectionto instantiate records off of the database.You may not consider this a bug since oracle doesthis, but you won't find it in hsql 1.43, mysql, mssql, or access.The mysql database appears to rely on the applicationprogrammer being case sensitive in all cases insteadof hashing mixed and upper case names. This is theother extreme, but I still prefer it to justcapitalizing everything.Please reconsider.
bit types only take 'true' and 'false'.You should be able to change a bit value by setting itto 0 or 1. Don't know if this is ansi sql or not, butit is accepted in oracle, ms sql, ms access, mysql.I can only change bit values by setting it to 'true'or 'false'.
followups don't work on sourceforge.btw, ms sql server does not take 'true' and 'false' inupdate statements for bit types. And oracle does nothave a bit type, closest type was smallint.
now() getting parsed as timestamp.I am using the now() function to put timestamps on records. I have an insert that has a value for each column in the record, no nulls that works just fine, and includes one formatted date, and one call to now().Later I do an update with a record that has many nulls, so the columns do not appear, and two calls to the now() function. For some reason it is droppingSounds like alternate paths through the sql parser..
problem with 'SHUTDOWN COMPACT'.I'm running HSQLDB v1.60 and am having no luck gettingthe &quot;SHUTDOWN COMPACT&quot; query working. No matter what Ido, the JVM never exits properly if I use thisquery... my application is always left &quot;hanging open&quot;at the end. I finally stripped the code down to it'sbare bones... please take a look at the following codeand let me know what's wrong.It doesn't matter whether the 'file.script' databaseis brand new, has tables in it, is 'script mode'or 'cached mode'... the above app never exits. Noticethe commented out 'normal' SHUTDOWN line... it worksproperly when used.It appears that the 'SHUTDOWN COMPACT' query executesproperly and that no exception is thrown. Any ideas?I also tried the &quot;CHECKPOINT&quot; query, which seems likethe way to go, but it didn't compact the database likeI thought it would... actually, I don't know what itdid. I ran &quot;CHECKPOINT&quot; on a cached database withdeleted rows that were still &quot;hanging around&quot; afterdeletion... but the rows were still around afterthe &quot;CHECKPOINT&quot; was issued and the database wasclosed. It didn't seem to do anything. Is 'CHECKPOINT'also a problem?I'm running VA Java Enterprise, patched to v3.5.3.under Win2k. I imported the HSQLDB v1.60 java files(not the class files) into it's own VAJ project. ThisHSQLDB project is the only thing included inthe 'project path' of the above class. The workspaceclasspath is empty. The code doesn't work properlyunder the IDE, nor does the VAJ compiled version workproperly from the command line under SUN JDK v1.3.1.Thanks.
SA: User not found.Hi,Occassionally, I get this exception saying that SAis not a valid user(something along those lines).Since, sa is the default user and I haven't createdany other users, the only choice I have whileaccessing this database is to drop and recreate thewhole database since it doesnt let me login. Anysuggestions? Any one reported this problem before?Thanks for the great product.
Subselect fails when using functions.Consider following situation:This fails reporting:No progress when trying to use test._id in allplaces... It seems it doesn;'t find the column forthe &quot;select max(_id) from test&quot; part.&quot;select max(_id) from test&quot; alone works GREAT!Hope I'll see this fixed soon.returns the last inserted row :(
Insert statements misbehave in this case.Hi,No exception is thrown when I do an insert using thewrong statement:Create table varchar_test(id varchar(100) null, tstampbigint null);insert into varchar_test values(tstamp);Values are silently inserted into id column and tstampis 0.regards,Xtrimity
like &amp;quot;text%&amp;quot; does not use index.in hsqldb 1.6 the like statement does not use theindex so queries take a lot of time. It would be goodif statements:would use the index.For the first one there is a workaround which can beused:instead of:..which is with index 100 times faster!!
issues with storing objects.Hi,I am not very sure if the following is bug or not.I have attached a java file. Please execute it and uwill find the bug or error. I will try to explain thefour cases of my programMy motive is to store a string as an object typeof the hsql database.Case 1:1.) create table temp (name varchar(25), data object)2.) stored a string in first column of table andhashtable in the second column.3.) works fineCase 2:1.) create table temp (name varchar(25), data varchar(20))2.) store string in first column of table and storeanother string using setString() of preparedstatementclass.3.) works fine.Case 3:1.) create table temp (name varchar(25), data object)2.) store string in first column of table and storeanother string using setString() of preparedstatementclass.3.) Behaviour not understood. (Please see output tounderstand)Case 4:1.) create table temp (name varchar(25), data object)2.) store string in first column of table and storeanother string using setObject() of preparedstatementclass.3.) I get an error.
multiply doesn't seem to work.Hi,I'm migrating my MySQL application to use HSQLDB. Ialready fixed most of the problems but one stillremains. I try to multiply values in a simple SQLstatement 'select *,(count*price) from purchase'. Thisstatement however throws me :or This function is not supported: 12 in statementor a NumberFormatExceptionAnyway, keep up the VERY good work guys
Several Date/Time Functions Fail.Most of the date/time methods -- year, month,dayofyear, dayofweek, hour, minute, and second -- failwith java.lang.NumberFormatException when used with a
Long.MIN_VALUE.I have a row of type BIGINT and I submit a SQLstatement putting Long.toString(Long.MIN_VALUE) intothat row.Then the following exception happens.I suspect, that the Tokenizer steals the values signto apply it after parsing, so thatjava.lang.Long.parseLong ends up parsing the negativeof Long.MIN_VALUE, which is just out of range for long(Long.MAX_VALUE+1).Sorry, I have no idea, where to look for the version.I just have the hsql.jar here, and ther is nor version in the MANIFEST
Double.NaN.We use a row of type DOUBLE and put in the valueDouble.NaN, via the JDBC interface. This results in anexception complaining that NaN is not a valid rowname. We think that Double.NaN should mapped to SQLvalue NULL and vice versa.
ResultSet incomplete - lying ?Hi,i was verry happy when I found HSQLDB, looked throughthe documentation and was even more happy.I tested it and requested a Updateable, srollableResult Set and got no error.Then I tried to used the promided functionality andgot something like &quot;Sorry not implemented yet!&quot; forfeatures like lastRow(), firstRow() or setRow().In my opinion that's essential for a scrollable ResultSet and it felt like lying to me when HSQLDB exceptedthe request for an Srollable ResultSet and didn'tprovide the elementary functionality.First I thought I'm doing something wrong but after awhile I looked into the Source code and all thefunctions where Documented with what they should dobut implemented as a simple Return of &quot;Not Yet !&quot;.I took a deeper look and I don't know how to implementthe functionality without reading a lot of the sources.So the question is:When will the implementation of ResultSet keep thePrommise to be Scrollable maybe Updateable ?It would make things a lot easyier for me ... .Sugestion: Till then you should shange the Code sothat it gives an error if someone is requesting aResultSet with not implemented Features (Scrolable,Updateable). That's the way other Databases handlethat ... .You should mention it in the Docu to, that would havesaved me a lot of time ;-).Anyway: Good work, seams to be quiet complete and thedocu is really good (Ok, not always if it comes to theJavadocs ...).Knut Pape
Droping tables drops the database.The sequence of the database CREATE TABLE statementsdetermine the order of INSERT statatements. This isdependant on Referential Integrity within the createdtables.I have a table which is in the heart of the database(holds the core PK) and desire to add an additionalcolumn at a later date (which has arrived), theexisting DB has been populated so the procedure wouldbe to:1. create a tmp table that includes the new column2. do an INSERT SELECT to copy the existing data overto the tmp table, but adding the default value for thenew column at the same time3. DROP the old table4. CREATE a new table with the old table name but withthe additional column5. do an INSERT SELECT to copy the tmp data over tothe new table6. DROP the tmp tableRight, now the bug - when re-creating the new table(point 4) the statement is inserted at the end of allthe other CREATE TABLE statments; this means that theAnd because of that sequence HSQL DB thinks the DB iscurrupt because the INSERT statements prior to newlyinserted ones a refering to something that does notcome into existances until it reaches the bottom ofthe script. The result is a NullPointerException.Do you have a way to re-order the script file while itis in memory?You help is much appreciated.Keith
[TIMESTAMP]second function.fields and throws an IllegalArgumentException fromTIME fields.Try:fix for bug 446415 else return NumberFormatException)
Error in the jdbc documentation.In the 'operating modes' documentation page (/hsqldb_v.1.61/doc/internet/hSql.html), the URL to connect to the hsql server in &quot;Server&quot; mode is written as
TINYINT: ClassCastException.Hi,I ran into a problem when converting a mySQL databseto hsqldb with the Transfer tool. The mySQL databasehas columns of type TINYINT, which cause aClassCastException. I tracked down the problem to(what appears to me) an inconsistency between thejdbcPreparedStatement class and the Column class. TheColumn class uses a Short for both a TINYINT andSMALLINT, while the jdbcPreparedStatement class uses aByte for TINYINT and a Short for SMALLINT. ThejdbcPreparedStatement.setObjectIntype(..) thenreceives a Short where it expects a Byte, causing theClassCastException.For now, I patched the jdbcPreparedStatement to alsouse a Short for both TINYINT and SMALLINT, however Iam not sure if this is the right procedure. I couldalso patch the Column class to use a Byte for TINYINT.If anyone could give me advice on the way to go, Iwill submit a patch.
Problem with CONSTRAINT PRIMARY KEY.I have been testing the 1.6.1 version of the HSQLdatabase and have come across a problem. The steps toreplicate the problem are:1. Run the DBManager and select a database URLsomething like &quot;jdbc:hsqldb:message&quot;2. Execute the following SQL statements in order:3. Check the inserted record:4. Close the DBManager5. Open the DBManager again selecting the same JDBCURL as before6. At this point, a stack trace should appear in theDBManager window, complaining about a string index outof bounds exception.7. Check for the previously inserted record:SELECT * FROM MESSAGENo records will be returned from this query.I have found a work-around, which is to specify aprimary key using the syntaxinstead of using the CONSTRAINT PRIMARY KEY syntax.I assume that what I have found is actually 2 bugs,because if you repeat the process and create themessage table only, no stack trace appears, but thepreviously inserted data is still lost.
Minor typo in build.bat.Build.bat contains following line:It should be:This may sound like a minor detail, but it caused mesome gray hair as the (Finnish?) saying goes... :)
Java 1.1 error in Log.java.Log.java contains a non-conditional call ofsetProperty function, which doesn't compile on JDKIs should be:
Recovery commits broken transactions.When HSQL restarted after a system crash, it will madethe changes made by the last *uncommited* -- thuspossibly inclompete -- transaction permanent. HSQLshould drop all changes after the last succesfullcommit from the log (providing that auto commit wasset to off).
SOUNDEX.Hi,Soundex function is not complaint with Soundex Algorithem.According to the Algorithem,The vowels are not used.If two or more adjacent (not separated by a vowel) letters have the same numeric value, only oneis used.But in your implementation it is using same numeric value.If there are not three digits after the consonants are convert, the code is filled out with zeros. Thename Lee has no consonants after the L, so the soundex code would be L000.But in your implementatiion it will give only &quot;L&quot;, basically is not padding with Zero's.It can be easily fixed. I modified the soundex function and attached to it. you can check in tothe repository.you are doing good work.RegardsAravilli Srinivasa Rao
Soundex.i,Soundex function is not complaint with Soundex Algorithem.According to the Algorithem,The vowels are not used.If two or more adjacent (not separated by a vowel) letters have the same numeric value, only oneis used.But in your implementation it is using same numeric value.If there are not three digits after the consonants are convert, the code is filled out with zeros.Thename Lee has no consonants after the L, so the soundex code would be L000.But in your implementatiion it will give only &quot;L&quot;, basically is not padding with Zero's.It can be easily fixed. I modified the soundex function and attached to it. you can check in tothe repository.RegardsAravilli Srinivasa RaoI had problem with attachment i.e why i am attaching code function here)
JDBC URL for server documented incorrect.In the 1.61 release, the file doc/internet/hSql.htmlthat the URL for a Server connection is:
Group by.Hi,I have a table with two column that pile data (serAccess, month). i am triyng to count the number of serAccess by month by doing the following SQL command:When i run it using the demo application it run ok butwhen i run from my JSP application, i only get 1,0 asresult!Please help!Nicaud Bourgault
GROUP BY in 1.6.1 still broken.The following forum thread indicates that the GROUP BYwith aggregate functions bug was fixed:Based on the results of some of my queries, it lookslike it's still not working correctly.My db table is as follows:The query I'm running is:What appears to be happening is that the groupinglogic is done last in the order of events, but donefirst in mysql.Has anyone else noticed this problem in the 1.6.1codebase?
Applet is incompatible with Java Plug In.I just got this mail from a contractor of Sun:Dear Thomas,We are about to release a new version of Java Plug Inwhich supports all Java applets, including those basedon older versions of Java. We expect this version tobe widely distributed and to replace all olderversions of Java. After extensive testing of existingapplets, we have done our best to fix allcompatibility issues. However, we have found thefollowing problem in running your applet, which cannoteasily be fixed on our end. Whenever available, wesuggest a solution that will allow your applet to runwith this new version of Java Plug-in.You can find the early-access version of Java Plug-inatin order for you to do your own testing.Thank you,The Java Plug-in TeamSun MicrosystemsURLProblemaccess deniedSuggested solutionBroken because of security model changes in Java 2.Migrate the applets to Java 2 security model.
GROUP BY FAILS WITH ALIAS.Version 143GROUP BY on a column select alias fails but works ifthe actual column name is used (order by works usingan alias).
Connection is broken for objects &amp;gt; 32k.After creating a prepared statement and using it's setObject() method with an Object (size&gt; 32k) I receive a &quot;SQLException: Connection is broken&quot; error
poor INSERT INTO implementation.When processing:will select all 1,000,000 rows from the existing tablenamed TEST, create a new table called TEST, insert the1,000,000 rows in the new table, and only then attemptto link the table into the database, at which point theoperation will fail due to the restriction on duplicatetable names that Database.linkTable() imposes.With a simple change to the code, that is: attemptingto link the new table into the database immediatelyafter it is created and before the selection result isretriveived, the example statement will returnimmediately with a &quot;TABLE ALREADY EXISTS&quot; SQLexception, saving much time and overhead.-- Will be provding patch, including support forequivalent CREATE TABLE AS syntax extention.
StringIndexOutOfBoundsException: -10.Running Standalone mode from JBoss I get this fromtime to time. After this has occurred the databaseneeds to be deleted to avoid hanging on further use.How do you properly shutdown in standalone mode? Iassume that the DB file are being left corrupted bynot closing down properly with a shutdown hook?
Self Referencing Table bug.Initial Comment:This create table statement should be legal. I need tocreate a hierarchical set of entities. As a workaroundI suppose I could modify the table after creation butthis shouldn't be necessary! Is this possible even?How do I add a foreign key as an afterthought?
supporting &amp;quot;default&amp;quot; in create table?in 1.6.0, the following sql command fails because ofpossible to support?
LIMIT limitations.In 1.61 LIMIT does not work together with DISTINCT.Has now been fixed.
SELECT .. IN from same table.In 1.61 queries in the form of SELECT .... FROM atablework, reporting &quot;Column y not found&quot;. Has now beenfixed, pending more thorough testing.
Java MIN VALUE.I get a NumberFormatException when trying to insert aJava Long.MIN_VALUE into the normal sql mapping column.
join/condition bug.following problem:with the hsql sample data (Database manager), executethe following statement:the problem arises if you add another condition like(OR 1=0) which should not change anything, butunfortunatly the statementwill now product a different resultset with lessrecordsets (exactly all records without NULL values inaddressid)This definitly seems like a bug, or?Any ideas?
Extraneous quote corrupts database.If you include an extraneous single quote (') in aninsert or update statement value, the entire databaseis corrupted. Every record is overwritten with thevalue up to the quote.Every record is set to 'It isn'.
Server crash after logging DISCONNECT.I use hsqldb 1.61In the situation where the dbengine is running as aserver, I open a connection via jdbc and close it.At that moment, the database engine logs a DISCONNECTstatement in the script file.If I close the database at that point and restart it,I get a NullPointerException on the screen:And the server won't ever respond again normally toconnections.This crash can be recovered manually by removing theDISCONNECT statement from the .script file.Of course that will be a big problem in productionenvironments. :)For myself I have solved the problem in Log.javaby adjusting thevoid write(Channel c,String s) throws SQLException {method, so that it doesn't write a DISCONNECT to thescript file.
double column names are allowed.Due to an error in my create table script I created atable with 2 columns with the same name.I don't know what the effects of this are, but I thinkit should not be allowed.Only imagine select .. from .. where a=xwith a the double column name
combined conditions don't work correctly.Okay, here is an example:Create some tables (I stripped off everything you donot need to see the problem).Now insert some test data.orthere is no result!If you use just one of the conditionsorit works. If you don't create the foreign key FK_USERor the UNIQUE clause, everything is just fine.
Version 1.62 patch breaks selftest.The suggested patches for version 1.62 includes apatch for bug 471711 by fredt. This patch generate acolumn not found error when running the selftestprogram.
EOFException executing UPDATE.(HSQLDB v1.61)I was running an application making lots of inserts,selects and updates and got the following stack dump.I know this is not a lot to go on, but I have only seenit once. This happened while executing a query likethe following:The number of ids in the query varies.I will post again if I get any more information.Thanks,Stack dump:at
Inserting Objects.I'm having problems storing java.lang.Integer andjava.lang.String objects in hsqldb 1.60.Here is the table I have created:I am inserting Objects using a PreparedStatment. Allother objects I insert (user defined objects that is)seem to work fine. No exceptions are being thrownwhile inserting. When I open the database inDatabaseManager, The preference name has been written,but the serialized object field is blank.
Null Pointer thrown from jdbcResultSet.The method getBinaryStream() throws a NullPointerexception if the data in the database is null. Thisis because it tries instantiate a ByteArrayInputStreamwith a null value (the result from getBytes())This should be changed so that the method retuns nulland does not throw the exception.See line 438 of jdbcResultSet.Maybe something like this...
NPE on connect.v1.61We got the following stack trace once while ourapplication was trying to connect to HSQL.We only saw this once, so I was not able to narrow itdown at all.
Extraneous sleep  in Log class.In version 1.61 of hsqldb in the Log.isAlreadyOpen() method there is a 3 second sleep that seems to be there to do some sort of concurrency checking. I could not find anyplace where the lock file is actually created. I believe this is unnecessary code and can be removed. It would significantly improve start-up time.
Unprotected system tables.Here's a good chuckle for anyone who's interested:database (you don't even have to be an admin user forthis)Ha, ha, ha...wimper... (:-(Here's another good one:Hey! Where did test go? I just created it, but itdoesn't show up in the treeeeeeee.The fix is simple:hsql(db) needs to disable creation of user tables withthe same names as system tables. A really naiveimplementation only needs to do agetSystemTable(create_table_name) != null to checkthis, although it is a waste to do it that way.BTWinserts, updates, deletes are also allowed againstsystem tables, but since the tables are regenerated oneach use, the DML is completely without observablkeeffect (but does consume processing time). Theseactions should be disabled too, if not too expensive...CampbellPSyes: I know that nobody with even a little hsqldbknowlege is going to do this (on purpose orotherwise). But what about the case where someone ismigrating to hsqldb, they are fairly green, and theirprevious naming conventions were *unfortunate*? Whatabout automated environments, where software choosesthe names for table creation?PPSI've known about this one for ~6 months now (basically,since I first downloaded the product and took my firstskim through the source). Sorry about not postingearlier
Exception while shutdown compact.Hello we use HSQL in a production system.The usage is very heavy msg traffic.When we try to shutdown immediately from the AdminconsoleWe observed the following exception:Then the server does not quit.We have to hit ctrl C and then edit the propertiesfile to modified = NO and restart the server torun.How does one restore from a previous backup file.Thank you
problem inserting data &gt;30k.I have a problem when I want to insert data &gt;30kb intoa longvarbinary field. For inserting I use apreparedStatement and the setBytes() method. There isno error code, the program &quot;stops&quot; only...The error occurs when hsql runs in &quot;server&quot;-mode. Itried the same insert of large data with the hsqlstandalone version and it works!Please help me, if you know a solution or hint.Peter
NumberFormatException DECIMAL.Is this a bug ?I am using hsqldb_v.1.61Boerries
commit does not work with multiple con.We are not sure if this is a limitation of hsqldb or a bug. Please clarify:We use 3 connections:If we reread the TABLE after finishing this testprogram, the new Row is not in the TABLE anymore!If we do one of the following changes, all works asCan you please clarify this issue?Thanks a lot!
foreign key problem.Suppose:table B has a foreign key on table A field nr 1 (bothtables are cached)If table A is dropped, it is still possible do to selects in table B, but when the database is stopped and restarted table B is deleted.In my opinion here is something wrong. I have 3 options :1. It should not be possible to drop table A. At the moment it is not possible to delete records in table A which are referenced in table B.2. If you can drop table A, table B should be impactedimmediatly, not after a restart of the database.3. In my opinion the best would be to put table B in amode not accessible to the users, (but it should not bedeleted, as it happens now), until table A is recreatedwith the correct foreign keys. If table A is recreatedtable b should be again accessible for select/update bythe users.
{fn hour ()} Returns 0 through 11.The hour function returns zero through eleven, insteadof zero through twenty-three, because the hour methodin Library.java used Calendar.HOUR instead ofCalendar.HOUR_OF_DAY. I've made this mistake manytimes myself. Source fix:
{fn month()} returns 0 through 11.The month function returns zero through eleven insteadof one through twelve. It's always seemed odd to methat the Calendar.MONTH returns zero through eleveninstead of one through twelve. Here's a source fix toLibrary.java:
Memory problems with cached tables.We've been using HSQL for a little while for internaltesting and such. However, we've had some troubleloading large quantities of data to cached tables.Since the HSQL code uses integer values to perform itsseeks into the data file, theoretically you should beable to store a gig or more of data. In practice,however, it seems that all the data you load remainsin memory, even when using cached tables.I've attached a Java class written by one of my co-workers that demonstrates this. No matter how largeor small the row size, it always craps out afterconsuming the available memory. It appears that theCache class is supposed to maintain a limited numberof rows in memory and persist the rest to disk, but Idon't think it really performs that function. I'vetried changing the value governing the size of thecache (even setting it as low as 20 rows), but theamount of memory consumed remains the same. Inaddition, running an analyzer reveals that Row objectsare never garbage collected.
Shutdown.Im trying to use HSQL. I've configured it and it seems to meet my needs in all but one respect.I'd like to create a JRun-style admin tool which allows the user to start and stop the databaseserver at the click of a button. I've done this with McKoi, another Java database.The problem I'm having with HSQL is restarting the database server after the user has shut itdown. The SQL &quot;Shutdown&quot; command appears to mean something other than shutdown for HSQL.After issuing the shutdown command on it, attempting to restart it causes it to issue thefollowing...... and kill whatever process it's in.I'm no expert in this area but I think this is possibly an indication that the server port is still in use.I think it might mean that the database never fully shuts down. This hurts me in the admin toolscenario because I'm running the database server as a thread within the admin tool process. Whenthe above exception is thrown the entire admin tool process is killed. The user just sees his admintool disappear. The exception is flagged, the user hits OK, the database dies and says I'm going tokill everybody near me. AAAAAAAAARRRRRRRRRRRGGGGGGGGHHHHH!!!!!!!!!Any thoughts on this would be greatly appreciated.Thanks.
*must* fix logging w.r.t. object names.It has come to my attention that there are severaloutstanding issues w.r.t. case preservation,extraneous quotes corupting the log, etc.My latest experiment shows that yet another case is not handled correctlySay one issues the statement:which is perfectly legal and reults in a table named:then the statement is logged as:When the database is restarted, all statmentspretaining to this table, of course, fail.My suggestion is that (if we continue with the currentlog format) we should double-quote all object names inthe log and escape internal double-quotes in thestandard manner by doubling them, as in:
StringIndexOutOfBound Exception.Hello,I got the following Exception with HSQL v1.61:To reproduce the exception:1- Launch database Manager and execute all the CREATESQL commands to create the database2 - Quit Database Manager3 - Launch Database Manager again and connect to thedatabase just created.Could you help me ?Thanks a lot.Rene Levantinh
SHUTDOWN fails under JVM 1.4.0. beta 3.Issuing a SHUTDOWN command to the database does notshut it down under version 1.4.0 beta 3 of the JVM.The server just hangs in some sort of limbo statewhere the server is not accepting queries but is notactually shut down either. SHUTDOWN works fine underJVMs 1.3.0 and 1.3.1.Sometimes, SHUTDOWN will work after repeated attemptsto shutdown/connect to the server from a client.When this eventually happens, (if run with &quot;-silentfalse&quot;) the message &quot;The database is shutdown&quot; isissued once for each time you attempted to shutdownthe server.
ABS function unknown.unknown function: ABS
right join throws SQLException.SEE:
Parser error in nested query.version : HSQLdb1.61The parser has some problems with nested queries thatare combined via 'where in'try the following :Gives as result :SQLErrorandwork both fine.By the way,I could work around the problem by rewriting the query.Alexander
Compatability Issues in J2SDK1.4.0.assert is now a keyword within Java2 v1.4.0 and sothe program will no longer compile.Thanks
Updates not being applied.When I send an SQL Update command using executeUpdate(), I do not get a JDBC error, but the updates are notapplied. I am issing a commit after the SQL Update.If close the JDBC connection, or issue a CHECKPOINT,the update is applied.Any ideas?Thanks,Dave Connerth
Literals in SELECT, not enough results.Version: 1.61I'm trying to insert data using a INSERT INTO ...SELECT ... GROUP BY ... statement. As part of thestatement, I need literal values. If the literals areplaced before a SUM() expression, I only get a singlerow returned. If after the expression, I get how everymany the SUM() returns. MSSQL returns the same numberin either case.
GROUP BY returns row of NULLs.Using a INSERT INTO ... SELECT ... GROUP BY ...statement. Getting 'Cannot insert NULL' when SELECTshould return nothing. It appears that the GROUP BYclause causes the SELECT return a row of NULLs whennothing is found.
Index names not local to table.This problem did not exist in 1.61!
probs with CodeSwitcher.I tried to run CodeSwitcher to switch to JDK11 on (I am not sure whether it is still allowed to use CodeSwitcher. I havent installed Ants yet.)I got the following errors:And there is a double //#endif JAVA2 in line 1263 ofRegards,Ulrich
multiple null values violate unique cons.As far as I know, NULL values should not be consideredwhen checking if an insert satisfies the uniqueconstraints defined on a table. For instance:The following should be allowed:However, with hsqldb (v 1.61), the second insert failsbecause of the unique constraint on y.Will this be corrected in a future version?Kind regards,Tijmen
NullPointerException in getBinaryStream.When I try to access a column that has been set to NULL with getBinaryStream, I get a NullPointerException. Obviously HSQLDB tries to create a ByteArrayInputStreamfrom a null-Pointer.
compile errors with J2SDK 1.4.0.Hi,with hsqldb 1.61 and J2SDK 1.4.0, I did the followingsteps:Ant version 1.4.1 compiled on October 11 2001Same error messages appear when I did in advanceant switchtojdk12Regards,Ulrich
no compile for JDK11.Hi,I tried with hsqldb 1.61 and JDK 1.3ant switchtojdk11and got the following error messages:
setProperty() in Log.java.Hi,just as a reminder:There is still the quick hack for version 1.61 in thecode of 1.70 at line 182: setProperty() which is notdefined for JDK 1.1Regards,Ulrich
IF EXISTS in hsqldb 1.70.Trying to submitleads toor without a defined table foo toRegards,Ulrich
SUM() + GROUP BY give unwanted NULL rows.Similar to previously raised bug re: GROUP returning a single row of NULL(s) when its corresponding SELECT returns nothing.Although 1.7 RC 2 fixes that bug, the following causesthe same problem:
Transfer corrupted / Error Code: -19 / State:40001.v1.7 RC1 RC2 both have the following bug:Operating in client/server mode on localhostAfter executing the select statementI get an exception:You can reproduce the error by executing the table
delete problem.i tried to use HSQLDB 1.7.0..there was a delete problem.when i restart the HSQLDB Server after i delete rows,all the rows which have the same data were deleted.for example,there were rows like below: but when i reatsrted the server ,the rows were changed like below: two rows were deleted which have the same data.colud you please consider of this problem...?
V1.70RC3: build error with jdk 1.1.8.Hi,I downloaded v1.70RC3 and found the new build.xml great(thanx to Fred).The build runs without any problems withBut, I got an error when building for/with JDK 1.1.8Complete build sequence is [init, javaversion, prepare,Regards,Ulrich
GROUP BY with ORDER BY.Hi,after inserting the test data in DatabaseManager, Isubmitted the from position, productBut, the result set is NOT ordered by name.Regards,Ulrich
Int &amp; Double problem.Version: hsqldb_v.1.61.Here is script
ASC / DESC  with DISTINCT does not work.The ASC / DESC functions when used with DISTINCT have no effect.To reproduce..This bug seems to have been present for quite sometime, and hopefully will be fixed with 1.7.0.
server.properties file not accessed.server.properties file is not loaded.I downloaded 1.7 release candidate to work on long varstrings. Database would not read our current scriptfile because the server.properties file was being ignored.Recommend modifying Server.java to load properties
Win2000 - Multi-byte char. issue.HSQL latest stable version is garbling the multi-bytecharacters in the following scenario.Platform:This is reproducible always and is happeningcontinuosly. Please contact me atsanjayag@india.hp.com for more details.ThanksSanjay
jdbcConnection.getAutoCommit broken.jdbcConnection.getAutoCommit fails to take intoaccount SET AUTOCOMMIT statments, reflecting only thelast value passed to jdbcConnection.setAutoCommit.
Wrong update decomposition in script.I recently installed the hsqldb 1.7.0RC3. After some time of testing/using it I found the following bug (?):In some cases (couldn't find out under which circumstances exactly) when hsqldb writes the UPDATE command into the script file and decomposes it intoDELETE, INSERT sequence, it distorts the WHERE clause.This happens in the following way: it compares thecorrect column, but with incorrect value, ie. withvalue of the first updated column (or the first columnin the table definition?). As the value is ofdifferent type, the next time hsqldb is started, itthrows the &quot;java.sql.SQLException: Unexpected token:37000 Unexpected token: 08&quot; exception.Here is some example:This command is called upon hsqldb server (hsqldbconsole printout):
Connection reset by peer.In client/server mode of RC4:When my client closes the connection (and thenterminates) I get the following exception on theserver side console:This is new in RC4, the previous RC's did not havethis trace.
bug in reading LONGVARCHAR.JavaDocs in jdbcResultSet.getAsciiStream says:&quot;This method is particularly suitable for retrievinglarge LONGVARCHAR values.&quot;getAsciiStream makes internal call to getUnicodeStreamand here is the definition of that method:Now the source of getBytes method:Did you saw the problem?When I try to invoke getAsciiStream it will throw SQLException because I'll try to field, defined asLONGVARCHAR but I'm actually reading it as BINARY.
SELECT -- an invisible value?I've encountered a strange behavior of hsqldb, firstin the RC3, but I didn't pay attention to it then. Nowwith the hsqldb 1.7.0RC4a, I have to face it again andI believe, it's a bug.I have a table Hierarchy with a column named Path. Oneof the rows in this table has Path='/intranet'. When Iexecute the following query:I get an empty result set.However, when I use the LIKE clause:I get really all the paths beginning with '/intranet', including the '/intranet' one.It seems like the string '/intranet' would have addedsome invisible character(s) in the end, but this can'tbe the case, bacause of the result of the followingquery: which is 9 for '/intranet'.Please, consider the possible sources of this. I cansend the database on demand (I don't wanna to send ithere to public).ThanksMartin Stepanek
Subselect error with same column names.This was sent to me by David Moles and applies to 1.61and to all RC releases of 1.7.0 up to RC4. (has not yet been fixed):I discovered another interesting quirk. Say I have thefollowing two tables:And say further that I have the following records:If I do the following query:It works, and I get 2 records, same as if I just id or evenApparently, the problem is some kind of collisionbetween fruits.name and trees.name.
Duplicate index names rejected.I have just downloaded hsqldb version 1.7rc4a.I notice that I may not create indexes with duplicatenames. This behaviour is different to the previousversion of hsqldb that I was using (1.6) where I coulddo just that. I am attempting to do this through thedatabase manager application supplied.So, the following will work in 1.6, but not in 1.7rc4a:The error message is:
Trouble with Jakarta Avalon Apps.I've tried to simply upgrade the jakarta avalon appsfrom the 1.6 to the last release (1.7RC5pre2) and I'mgetting some troubles with theHsqlSocketRequestHandler.handleConnection(socket);It seems that the SocketHandler doesnt handle theconnection...Here is a short synospis of the code:When I use a client with server jdbc connection, theconnection process get thru the 'handleConnection' butI get a &quot;Connection is broken&quot; in the demo/runManager.Also when I use the demo/runServer with the runManagerits works.Regards
Server mode &amp;  Access denied.Good evening from France,My web app opens a connection to an existing Hsqldbdatabase (server mode, hsql protocol).But when a query is executed, I get thebecause I've kept &quot;sa&quot; as username and &quot;&quot; as passwordbertrand(rougierb@users)NB : another class creates and fills the Hsql DB fromOracle but its execution is terminated before (andwithout error!)
&quot;SELECT x.y AS z&quot; DOESNT WORK.Hi,Is there any reason why statements such as thefollowing dont work properly?The alias is completely ignored and the result is anerror stating 'column CNAME not found'.I cant find anything anywhere regarding this but i apolagise if i have missed something.Regards,Mark Raynes
select count(distinct field) ....The following request doesn't work :What I get :bertrand
Join-syntax documentation.I am using 1.7rc4a.1 The syntax documentation reads that the pattern of a tablelist in a SELECT statement is tableList:I may be reading it wrong, but that seems to implythat the 'OUTER' is optional in 'LEFT OUTER JOIN', butthat is not accepted when I try it. I find that'INNER JOIN' and 'LEFT OUTER JOIN' only are accepted.Also, the error message reads: but using OUTER on its own is also rejected, so thatis a little misleading.2/ I also got the impression (from the source) thatbrackets could be used around the expression , so thateither could were acceptable. In fact only the second(without brackets) is accepted.3/ This is just a question - am I correct in thinkingthat hsqldb intentionally only supports expressions ofthe type 'col_a = col_b' when specifying the joinexpression? When I try 'col_a &gt; col_b', for instance,that is rejected. Also, it seems that only ONE joinexpression of the form: 'col_a = col_b' can be made,and that 'col_a = col_b AND col_c = col_d' is notallowed. Is that intentional?Thanks for your helpChris Cockrell
compile errors for jdk1.1.8 with v170rc5.Hi,when compiling v170rc5pre2, I got an error concerningSwingCommon.java which should not be compiled for jdkSo, I changed line 118 fromtoto exclude SwingCommon.java from being compiled.But I got some more errors later, see the messagesbelow.Regards,UlrichBecause it is used outside of its source file
DELETE fails ArrayIndexOutOfBoundsEx.
ALTER TABLE ADD COLUMN modifies indexes.The ALTER TABLE ADD COLUMN command seems to bemodifying the definition of existing indexes on thetable.For example, create a table and an index:Then, add a column:Now, the definition of the index includes bothcolumns F1 and PK.If another column is added, PK is added to the indexagain:Now, the index definition is TEST(F1, PK, PK). Thisresults in an invalid index definition and thedatabase cannot be opened.
Swing - DatabaseManager &amp; Transfer Tool.I could not get either the DataBaseManagerSwing orTransferSwing to work from the 1.70RC5 distributionjar file. I traced it down to the loading of the iconimage in both classes. After commenting out thegetIcon method call and rebuilding the jar, they bothworked. The gif image in the distribution is also nogood. I couldn't load it into any graphics program.
Text Tables - 1.70 RC5.I've spent several hours debugging text table supportin the 1.70 RC5 distribution. I was trying to createa temporary text table with the following statements:create temp text table ImportTemp (f1 varchar, f2,varchar, f3 varchar)When the set table statement was executed, it returnedthe following SLQException:not found in statement [set table ImportTempBy removing &quot;temp&quot; from the create staement, allworked well.I also noticed that after dropping the table and doinga shutdown compact, the &quot;csv&quot; file was deleted fromit's directory. I'm not sure what the rationale forthis behavior might be. If this is the planneddefault behavior, I would like to see a databaseproperty where it could be turned off, much like theproperty for setting the absolute path to the textfiles (i.e. not in the same folder as the database).
Error in creating text table with PK.With hsqldb-rc5, I tried the following statement(trying the text table functionality)CREATE TEXT TABLE B (id integer not null primary key,name varchar)And this gave the following error :Attempt to define a second primary key: S0011 Attemptto define a second primary key in statement [CREATETEXT TABLE B (id integer not null primary key, namevarchar)] / Error Code: -24 / State: S0011When I omit the 'TEXT' keyword it works fine.Alexander
ByteArray needs to be Serializable.Example:This fails because ByteArray does not implement java.io.Serializable. Making ByteArray implementSerializable does seem to solve the problem, at leastfor the example above.Thank you.
backslash not escaped in script file.Try this: Write this string to any table with varcharNote the backslash and the icelandic á characterThis is what gets written in the script file:Stop the program and restart itThe script file now contains:And everytime you start the program another u005cgets appended.
functions, operators fail in create view.Hi,You probably know, but ...your new implementation of views (RC5C) doesnot support caluclated column values.That is (assuming persons) ...results in error:SQL Error
LEFT OUTER JOIN.Hi,Following is a bug report for a bug that happens onhsqldb 1.7.0 RC5c but no problem on hsql1.6.1I have two tables defined as folows:When I did a qury asSELECTI got an error message asAnyway You have done a greate job on the hsqldbproject. Thanks a lot.hl
org.hsqldb.DatabaseInformation.getSystem.I'm working on migrating my MS access database to hsql with JBuilder 5 but when I get this error when I try to run the code hsql-1.7.0.rc5:
Total Loss of Data.There appears to be a spontaneous re-intitialization ofthe .script file Still occuring:I'm getting a exception on an increasingly regular basis.When I check the .script file, the data itself is gone,leaving the CREAT ALIAS stuff.I haven't been able to force this error to occur; eitherlocally or on mycgiserver.Anybody else had this problem again lately?Any comments most welcomeCheers - Stan
SELECT LIMIT 0 10 * INTO ....When you do a statement like &quot;SELECT LIMIT 0 10 *INTO newtable FROM oldtable where blah blah&quot; itignores the limit clause and adds all records that meetthe blah blah caluse instead of limiting them like itshould.
&quot;SELECT * INTO&quot; not writing CREATE TABLE.I just noticed that in the newest version it doesn't writethe CREATE TABLE entry on a SELECT * INTOHere's the code that it wrote in the .script fileI drop the table using:drop table ESG_CONCEPTSThen I create the new table usingand it write the above code, but it should write:because it freaks out when ESG_CONCEPTS doesn'texist.
NullPointerException when using IN.You guys should love me for this. I made a nicesimple test case and everything.-mike
jdbc primary key query failed.I use the version hsqldb_1_7_0_RC5cThe error arises, if I query over jdbc the primarykeys of atable;The same if i try it with the dababase managerThe origin is the line 515 in the file DababaseInformationit returns a null
Errror when creating table with UNIQUE a.The following schema raise 37000 Unexpectedtoken...error:
quoting problems.Quoting in SQL statements is somewhatbuggy. I believe that the user should be able to single-quoteany table name or file name to escape munging/normalizing,but several times Ihave had to settle with the munged entity name becausehsqldb can't find out where a quoted string begins andends. Examples:Unexpected token: 37000 Unexpectred token: 't3 instatement...set table t2 source 't2.csv'Notice that in the first sample I did not type 't3, Ityped 't3'; and in the second, the database created thefile &quot;'t2.csv&quot; instead of &quot;t2.csv&quot;.I do not know if this is an engine problem. That's just myfirst guess. If nobody else jumps in, I'll troubleshoot itfarther and/or make a fix once I make some headway withmy other hsqldb work.Problem experience with 1.7.0rc5.
Ungraceful In-Memory Text Table File err.With in-memory database:patchThread.java:138)I do realize that trying to set a file path with an in-memoryDB engine is a bad thing to do. I'm just suggestingthat IMO some checking should be done to preventmisleadingruntime errors like this.
doc errors in TextTables.html.I come to these opinions empirically. I've verifiedthat WRT 1.7.0rc5, the following statements are wrong.The table name must appear between &quot;TABLE&quot; andThe command fails if you use the keyword &quot;TABLE&quot;.In addition, a SET command specifies the file and theseparator character that the Text table uses:This is not &quot;wrong&quot;, just incomplete. I GUESS that &quot;DESC&quot;stands for description, but I have no clue how to set thedelimiter character(s).
minor doc error in hSqlSyntax.html.The file saysThe types on the same line are equivalent and VARCHAR_IGNORECASE and VARCHAR are on the same line. A few lines latter the document says VARCHAR_IGNORECASE is a special case-insensitiveAre VARCHAR and LONGVARCHAR equivalent in hsqldb?(According to hSqlSyntax.html they are different).In any case, for hsqldb-specific stuff (like customdatatypesuch as VARCHAR_IGNORECASE, and size limitations) itwould be good to give the users enough information to makeuse of the types.I notice that VARCHAR_IGNORECASE does not store case-insensitive data, as one could imply by the name, but thatthe behavior of some test expressions (at least) isaltered.No problem with that, as long as it is disclosed.
Tools throw null ptr ex if disconnected.Both DatabaseManager and QueryTool will give a nullpointer trace stack upon exiting the programs if the user1.7.0rc5. Standalone engine.
Buggy getImportedKeys.First, thanks for a great product!I saw that there is now finally better metadata support inhsqldb_1_7_0_RC6c:However, it seems the implementation is buggy. I havethree tables:When I call getImportedKeys on the reservations table, Iget an empty resultset. If I call getImportedKeys on theflights table, I get a resultset with one row. (the samehappens for flights).I'm quite sure this is wrong. A correct implementation ofgetImportedKeys would do the opposite. There shouldbe a resultset with two rows for reservations and anempty resultset for persons and flights. (At least that'swhat all other drivers I've seen do).Aslak
cannot create table with DEFAULT values.The create script below worked withWrong data type or data too long in DEFAULT
script corrupt: negative DEFAULT values.HSQL 1.7.0 RC5, RC6c(this bug is related to bug 565189)A table column with a negative default valuewill cause the .script file to be unusable:negative integer or double values are written tothe .script file *without* quotes. After ashutdown of the database, the .script file cannotbe parsed anymore.eg. This will corrupt the .script file:I believe the root cause lies with the Tokenizerclass. Instead of treating every single '-' characteras a SPECIAL, maybe only a sequence of two '-'characters are SPECIAL (a line comment)?Or a '-' character followed by a numeric charactercould be parsed as being part of a numeric value?I am not sure if this would be correct (I'm not sureif line comments are the only reason why'-' characters are SPECIALS)Instead of fixing the Tokenizer class, how aboutpatching the DatabaseScript class to surround*all* DEFAULT values with quotes? (See below)Or would that cause other problems?I've attached a JUnit test that identifies theproblem. The test fails with RC5 and RC6c.The test works after applying the patch.You can run the test inside JUnit or standalone with
cannot compile the db.When compiling with jdk1.4 the compiler gives thefollowing error:
SELECT MAX(ID) not working.Hi !I tested the latest version: HypersonicSQL 1.7.0 RC6with this piece of code (which works with hsqldb_v.1.61 )It gives -1 all the time (it returns &gt;0 with the other version)Thanks.
Problems under Linux and different JDK's.Hello,I had this exception on linux only (it's ok on windows os):I think that there is a limit for the instruction size,because there is no problems with instructionCheers,Philippe
JSDK 1.4 Compliance.As some may have noticed, HSQLDB wont compile onJSDK1.4. This should be easy to fix as only a fewmethods are added to driver. I am also getting lots ofdeprecation warnings - the methods with deprecatedtags are used in the code itself!
calculated values for substr etc.Hi,In 170rc6g ... Statemets like:produce:This function is not supported: IM001 This function is notThis seems to stem from the fact that the substringand other functions are looking for Integer andthat was not passed ... or top level did not reduceto Integer.Thanks,Joe
Missing things for views.Hi again,During our testing we noted:Views show in SYSTEM_TABLES as tablesand there is no ALTER VIEW xxx RENAME to yyyJoe
timestamp bug.Hi,It seems that timestamp columns still haveproblems.In version 1.7.1RC6 I did the following:-&gt; generates a date but not the correct oneas I saw, the parser does not recognize that thisis a date format-&gt; throws an exceptionThis problem was reported earlier inhe also fixed the source! But it still is not in thecurrent version :(((
NT -Database is already in use.When I have more than one process accessing thedatabase I get the following error.The stackTrace isI spent some type patching isAlreadyOpen anddistributing updates .jar files tomy users.Here is what I learned.I think the problem is the way that the file is opened.Java states that onsome systems an open file is exclusive.I think the problem is that on Windows, file operations inJava under Windowsare exclusive.Maybe we should rewrite (make sense) Log.java tomake sure that we don't try toload the properties file while we are trying to save it.Looking at the currentcode, it appears that someone could call open in onethread (DBConnection) whileisAlreadyOpen is trying to be called in another thread.Under UNIX/Linux... these are not exclusive and at leastfrom Java, there is noway to make them operate so.So... my thinking (no suggestion yet) is that we just usea static synchronizerso that the properties file is not written to during anotherwrite/readoperation.Does that make sense? It looks like we only have tomodify isAlreadyOpen,loadProperties and saveProperties...As an aside. Could a DB connection pool raise thisissue? It seems that itmight. I am using Turbine's DB connection pool with 20connections. Thisseems to work fine under Linux... obviously not findunder Windows :)KevinI have downloaded the latest 1.7 candidate and theproblem still exists. I have had a look for the bug on theHSQLDB bug list but can't find it, but I would havethought that it would have been raised previously as it isdiscussed on the HSQLDB developers mail list.
Simple SQL query equaling two columns fails.Create a tableBut should work!Workaround:
Can not store objects &gt; 64 Kb.Hi!I'm using JBoss 3.0 application server with embeddedHSQL database (I do not know, what version of hsqlJBoss uses).I have a troubles when I want to store CMP entity beanthat have a field &gt; 64 Kb.Thats, I have no troubles, when I'm storing StringBufferobject with capacity = 15000 (~62Kb), or emptyImageIcon, but I receive such message, when want tostore StringBuffer with capacity = 20000 (or ImageIconwith image data):This bug prevents me to store ImageIcons with picturedata and a large objects as a table fields :(( Is there away to win this bug?Kimerinn
Transfer Tool - no target in v1.61.RAM: 512MB (in case it matters)I noticed that if you launch the Transfer Tool directly itwill only give you a window to select the Source, you doNOT get one to select the Target.If you launch this from the DB Manager, you will getboth windows in the proper order.Any questions: drop me a line at paul.m.boos@saic.comPaul
powerbuilder connect to HSQL.using powerbuilder connect to HSQL Database byjdbc,arises &quot;memory can't read &quot;err,why?Do you try powerbuilder connect to HSQL?
Types with functions.This function is not supported: IM001 This function is not
limit on size of sql for view.It looks like the select statement for a view can only beabout 840 characters --- runs ok on create but storedtruncated. Tried something like:
Exception reconnecting / foreign key.Everytime I reconnect to a database created with thefollowing statements, I get an exception. It seems tobe due to the foreign keyconstraint originating from a non-primary key-attribute.I'm using the binary version from the web-site ofHSQLDB 1.7.0 RC6 Revision i with JDK1.4-01 under linux.
getColumnName (continued)Hello all!I had once outlined that getColumnName() in thejdbcResultSet class returned the column name insteadof the alias of the column (which is the way most jdbcdrivers use).A patch has been done for that (thanks, by the way), butit doesn't work in a client/server environment.The patch has been applied at the Jdbc client level.On the other hand, it uses a *database* property namedjdbc.get_column_name.In a client/server environment, the client and thedatabase are in two separate JVMs (and possibly ontwo different machines), so the client doesn't see thedatabase property (which is on the server).So, as a result, even if you set the property to false onthe server, the getColumnName on the client still returnsthe real column name, and not the alias. And youcannot set the property on the client because there isno server and no database there (and you can set theproperty only if you start a database).Fix:I have two main ways of fixing this.It involves a bit of thinking about the design. Should the*database* be patched to behave in the way we want to(i.e. return the label instead of the column name), orshould the *jdbc client* only be patched to behave likethat?These are completely different designs. With the secondone, each client might behave differently on the samedatabase.So let's have a look at the first solution (database patch):the jdbc.get_column_name property should affect thegetColumnName() method in class Expression. Tomake that work, the &quot;get_column_name&quot; boolean injdbcResultSet should be moved to Expression. Then,the getColumnName() method in Expression should bepatched to return the label instead of the column name ifthe get_column_name boolean is false.Right, let's have a look at the second solution (jdbcclient patch): we need the client to get propertiessomewhere. I don't mind where these properties shouldcome from (another configuration file, or simply in theurl), but the setGetColumnName(boolean) methodshould be called within the jdbc driver itself (whileinitializing the driver, or while connecting with the URL).Note that the best fix might be a combination of bothsolutions: have a parameter on the database ANDanother parameter on the jdbc client.I let you see what's best from your point of view. As forme, I think that the patch should be applied at thedatabase level (and not at the jdbc level). Anyway, thisaffects only people who set the property to false.Thanks!JY.
Bugs in test suites.The classes in org.hsqldb.test (v1.7.0RC6i) contain acouple of bugs.The main methods of the classesorg.hsqldb.test.TestSql are useless since they don't reportthe failures. If junit.*ui.TestRunner is used instead of themain methods, then class org.hsqldb.test.TestSqlPersistentshould additionally define a suite() method, since otherwisethe TestRunner detects the test*() methods inherited fromthe superclass, which I think is not intended.The last statement of org.hsqldb.test.TestSql.testMetaData()should read assertEquals(result3, result4); instead ofassertEquals(result2, result4);Method org.hsqldb.test.TestSqlPersistent.testInsertObject():the arrays arrayValue and arrayValueResult cannot becompared with arrayValue.equals(arrayValueResult). Mustiterate over their elements or use java.util.Arrays.equals((Double[]) arrayValue, (Double[]) arrayValueResult).Class org.hsqldb.test.TestSubselect: Resource dataset-subselect.xml is missing.
Oracle chokes on &quot;;&quot; at end of select.Using the transfer tool with 1.7 RC6i and oracle 8i asthe source DB.The semi-colon added to the select statement on line126 of TransferTable.java cause Oracle to throw anexception with an &quot;Invalid character&quot; message. Removingthe semi-colon solves the problem.
Missing servlet.jar in classpath.in buildJDK14.bat you seem to be missing the servlet.jarfile in the classpath even though that jar is included inthe distribution. Here's my corrected version.This is from 1.70RC6. Perhaps other scripts have thisissue also?@echo HSQLDB build file for jdk 1.4@echo *** we recommend the use of the ANT build.xmlinstead of this method@echo for all jdk's include the path to jdk1.x.x\bin inyour system path statementpause
Typo in getIndexInfo (ORDINAL_POSITON)getIndexInfo returns ORDINAL_POSITON notORDINAL_POSITION (the third 'I' is missing).P.S. This bug was found in the project LDBC, see also
Missing hsqldb.gif.The batch commands for building are missingthe ...../util/hsqldb.gif for the swing DatabaseManager
Primary key should not allow null values.The standard says (at least, most if not all otherdatabases do that), the primary keys columns don'tallow null values. HSQLDB allows null values. I think thisbehaviour should be changed.This bug was found in the LDBC project.Thomas
DELETE FROM does not update database.After a DELETE FROM order on a table, records stay visible (and selectable) until database is closed.When re-openning database, records are correctly deleted.Here my code :Any idea ?
SELECT COUNT(...) with no rows fails.If you select the count of column in a table that has norows, it throws a &quot;No data available&quot; SQLExceptionrather than returning 0.
Error processing SET INDEX on script.Some of the SET INDEX clauses that are generated by theengine in the [DB]script file are throwing aNumberFormatException in the setIndexRoot method of theTable class when the engine is started. It seems thatthere is an inconsistency between the internal indexcount for a table, and the entries generated for thoseindexes in the aforementioned clause.For example if the internal index count is 1 and theset index clause goes like &quot;SET TABLE [table] INDEX '-1-1 -1 0'&quot;, an attempt is made to parse &quot;-1 -1 0&quot; to getthe identity index root, throwing the indicated Exception.I just try-catched the problematic line, and set theidentity index root to 0 (as far as I have tested, noproblems are generated for this patch, but I don't knowif the solution is entirely correct).
when shutdown compact is issued server.when shutdown compact is issued server throws anexception as shown above.Sometimes script is flushed and is in goodcondition sometimes it is not.Sometimes it works properly.version 1.7.1DB hsqldbThank you very muchRaman Kannanrkannan@govpx.com
create view problem.Create view allows for ...select ... into xxx ...this causes a race condition.Don't know if you should stop or just say don't do itcause it hurts.Fix if you do it is to edit .script file and delete view.
ClassCastException in preparedStatement.Hi,I'm using v1.7.0 , ( v 1.7.1ALPHA also bugged)I found a bug in the methodstatic Object convertObject(Object o, int type)in Column class, when sqltype is SMALLINT or TINYINT ,this method return a Integer object.And when, I call a preparedStatement.setObject(intparameterIndex, Object x, int targetSqlType)with 'x' intanceof java.lang.Byte and targetSqlTypeequals to java.sql.Types.TINYINT ( or 'x' intanceofjava.lang.Short and targetSqlType equals tojava.sql.Types.SMALLINT ), I get the error :I modify Column.java to return the correct type ( justput a line for converting Integer to Byte / Short )and my program runs fine ( driver workes, but I don'tknow if this patch add bugs to server )
Win98 crash can corrupt script file.Windows 98, HSQLDB v1.7.0, Java 1.3.11. Start database server2. Perform a minimum of activity, it appears not tomatter what exactly3. Pull the power plug from the machine4. Database refuses to start on rebootWe have not had this problem on Win 2000 which struckus as odd, but it happens every time on 98.
LENGTH(NULL) should return NULL.It currently returns 0, that is not ANSI standard.The bug is in Library.java:This bug was found in the LDBC projectThomas
IN fails with BIGINT literal values.For a table defined as follows:The workaround is to enclose the BIGINT literals withinsingle quotes, but this compensates my cross-platformSQL.
poolman cannot connect.When i try to connect with poolman to the 1.7.0 versionof hsqldb i get the error:SQLException occurred in JDBCPool:Regards,Edwin Eversidjk
Insert Not Working Consistently.Hi,We are using HSQL 1.61. Through SQL scripts we firstcreate a schema. Then with another script we attemptto populate the database. When I run the full populationscript it fails with the message &quot;Try to insert into a non-nullable column in statement ...&quot; on the very first insert.If I run insert statements in isolation they execute justfine. Thanks.Andy
Trigger classes not loading.Bug in HSQL:
server.dbname or server.database key?After lookin at the sourcecode and noticed the thefollowing use pattern on database property.Should HsqlServerFactory use &quot;server.database&quot;property name as well?
getScale returns wrong value.This bug refers to release 1.7.0-RC3.Suppose you have a table with a field like this:quantity decimal(10,4)If you do a select on this table and look into theResultSetMetadata you can find that the getScalemethod returns always 0 instead of 4 (the getColumnsmethod in DatabaseMetadata reports the correct value of4)
ArrayIndexOutOfBoundsException in RC2.JBuilders Database Pilot came up with this exception
jdbc.get_column_name=false in 1.7.1RC3.Hi,Don't think jdbc.get_column_name=false isworking in rc3, did work in 1.7.0Joe
org.hsqldb.Library.left.This is using 1.7.1 RC1. Is this still an issue inRC3?I assume this is a collision between LEFT JOIN andthe left(s,count) library method.
Wrong results in LEFT OUTER JOIN.A LEFT OUTER JOIN does deliver wrong results whenfiltering for IS NULL. The example is using the followingsimple ER and data:
RC3 and &quot;Statement Unreachable&quot;classes14:JDK 1.4.1 FCS, ANT 141.
Forte 4: SQLState exception in 1.7.1RC3.I get this exception when Forte 4 starts up. I don't knowwhat I can do to get some more detailed information aboutthe exception.
Including null in select with where &gt;or&lt;hsqldb seems to include rows with null value for attributes with a WHERE equal/smaller/bigger operation as in this example:Both Oracle as well as mySQL return 1 (the -1 value)and do not include the &quot;null&quot; value, which &quot;seemslogical&quot; as well. However, hsqldb returns 2. I believethis is a bug.
default_pk name &quot;SYSTEM_ID&quot; problem.i have do test hsqldb version 1.7.0 with eXist (xml db)but when eXist use RDBMS as storage for itself,eXists create a table named &quot;documents&quot;.In this &quot;documents&quot; table has &quot;SYSTEM_ID&quot; column for XML Document's doc-type id.followings are the DDL for this table.you can see system_id column of this....can i ask to change org.hsqldb.Table.DEFAULT_PK 'svalue with other value can not have chance to conflict...next version of hsqldb...?
hsqlServlet not working with Resin.I had some problems using the hsqlServlet in the Resinapplication server.See:It seems that the servlet code is not correct. I alreadyincluded the code that fixes the problem.I hope it can be fixed.regards,Dennis
1.7.1 RC 4: type conversion no longer works.
shutdown compact destroys database.During a SHUTDOWN COMPACT; I get the followingThe error occurs in very particular circumstances, whena ALTER TABLE is used to add a CONSTRAINT to anexisting table, and something (?) with the order of tablegeneration is not as HSQLDB might expect.It took me some time to deduce a reproducible example.So the following test, creating TABLE vertices, thenThey both sould work as expected.I am using 1.7.1rc5, but I met this bug already before inversion 1.7.0, but was not able to deduce it at that time.ThanksDaniel Frey
Function invocation error.The invocation on stored procedures -Function.getValue() - convert its data members usingthe the Column.convertObject(Object, int) method.There are two problems with this invocation.First: All numeric SQL types gets passed into thereflection as Integers. Every attempt to use a storedprocedure that has byte, short or float arguments willfail with a 'Function not supported' error.Secondly: Byte arrays gets passed passed to theinvocation as org.hsqldb.ByteArray objects instead ofbyte[] instances. (This error can easily becircumvented with a type check immediately beforeinvocation in the Function.getValue() method.)Thanks for your good work
issue with system id column visibility.Hi Fred. Not sure if this should be considered abug or a patch suggestion. I provide no code, but adiscussion of the motivation, so here it is on Bugs:Was just thinking a tiny bit about what you said re:hiding SYSTEM_ID column by renaming it to: &quot;&quot;Here's my little test:Column already exists: in statement [create tableSo, its still not completely hidden: do we want totake the next step to unsure that it really is fullyhidden from SQL?I realize that it is now pretty unlikely that anyone intheir right mind will &quot;discover&quot; the aboveundocumented &quot;features&quot; (unless they read this ;-).But, I presume the column still has all the quirks ithad when it was named SYSTEM_ID and visible, so,in the interest of attaining true closure, I amwondering if there is not some very brief andsimple additional code we could add to truly makeit innaccessible from SQL. My initial thought onthe matter is that one could assign the column anull HsqlName.name. I'm reasonably sure there isno way to assign or get a match to a null columnname from SQL, so this would permanently hide itas well as allowing &quot;&quot; as a column name on tableswith a system id column in the same way that it isallowed on tables without a system id column (yes:I know that is ridiculous, but at least it isconsistent behaviour), without having to add somesilly crutch rules to the column expressionresolution mechanism. Are there caveats to thisapproach? If not, this is not much more than a one-liner patch that shuts the door permanently on theissue, so I think we should do it.
wrong value from HOUR( date )Have table with create_dt DATE NOT NULL column.Note: The time is around 10:50am machine time.First:The return of 19 from the HOUR( CREATE_DT ) lookslike a bug.HsqlSyntax.html documentation shows HOUR(time) buthas no indication that function is overloaded asHOUR(date). I would think it should be.For select, I was using HSQL Database Manager as SAuser, autocommit: true, readonly: falseWas hsqldb version, hsqldb_1_7_1_RC5 inside of hsql-avalon application.Machine Windows 2000 2.0 ghz
Text or mem. tables, read only db files.Using text or memory tables if *.data file is missingand database files are read only causes errors even iftables are small and are not modified.In Standalone mode,If &quot;readonly&quot; property is false, error message pops up:File input/output error: tests/database1.propertiesjava.io.FileNotFoundException:tests\database1.properties (Access is denied)If &quot;readonly&quot; property is true, error message pops up(depending on table type):Workaround is to add 0 length *.data file and set&quot;readonly&quot; to true
? trace in CachedRow.While testing 1.7.1 release ...init would fail on inputstream error forwas commented out and tests ran o.k. ...Did not try to figure out what the trace was for ...Please advise.Thanks,Joe
Outer join syntax fails.The following SQL statement works fine in HSQL 1.6.1but it fails in HSQL 1.7.x.The statement:
Incorrect resultsetmetadata.All numeric types have all scale factors and displaywidthsset to 0 when retrieved as their types. Work fine whenretrieved as string.
values in date fields change values.I compiled hsqldb v. 1.7.1 on linux with Sun's jdk1.4.1_01 and javac. I created 3 tables with one columnof type Date and insert 2 rows.On MS Windows 98 with Sun's jre 1.4.1_01 and produceddatabase when i change time zone stored dates changesvalues.On linux GMT+2On Windows GMT+1 (or GMT+3, but not the same as on linux)31-12-2002
Text Table Bug.I have been testing the CREATE Text Table. When I enterall INTEGER colums and shutdown the database and againrestart it , the values of the last column keepsincreasing by 7 in every row.My Jdk is 1.4.1OS Windows 2000 professionalSQL Statements were generated using the Database ManagerHsql was started in Server mode.
cannot select from Text Table in1.7.1.I've used Text Tables with versin 1.7.0 in a small project.All works fine (except outer join bug).After switching to current 1.7.1 using Text Tables nomorepossible. I've experimented with several different settingswithout better results.I can create an new Text Table using &quot;select * into textxxx from yyy&quot;and select data from new table. (I think all doing is inmemory until here.)But after disconnect/connet receiving this Error&quot;File input/output error: reading: java.sql.SQLException:InputStream error in statement [SET MAXROWSwhen I use sthe same select.On the other hand the meta- data of the table can beshown.My Jdk is 1.3.1OS Windows NTSQL Statements were generated using the DatabaseManagerHsql was started in Standalone mode.
Referential integrity check fails.The referential integrity check fails when a column with aFK is updated!Create these tables:
implicit type conversion ?!I've expected that the result of following statementsin all cases will return 3.3Im using v1.7.1 in standard or memory mode
transaction not rolled back.I'm using Hsqldb 1.7.1 (latest stable). The database isin multi-user mode with the following flags:-trace &quot;true&quot; -silent &quot;false&quot;If a JDBC client is interrupted abruptly then hisundergoing transaction(autocommit = false) is notaborted (rolled back), although the server displays thefact that it has disconnected this interrupted client!So, the server is aware of the transaction voidness butdoesn't roll it back.There's another thing to add here. The DatabaseMetaDatafor hsql says that it supports ONLY the READ_UNCOMMITEDlevel of transaction isolation.Isn't it a pitty? I personally like Hsql for it's lightload in terms of memory and cpu time.
features webpage needs update.One of your online documentation pages -states that a range of _current_ restrictions _will_ besolved by summer _2002_ (I put that paragraph at theend of this posting).By now, it is December-2002.Some visitors might draw false conclusions from thatwith regard to the health of this project. One mightthink, that work stopped, or that work proceeds muchslower now, or that documentation is out of date.Eitherway, this doesn't add to the visitors (especiallyhasty ones) trust into this project positively.BTW, from looking at various indicators I can see thatthis project is proceeding very well indeed.Additionally some visitors might be leftconfused/insecure as to what restrictions there_really_ are currently.Thanks for your works.Best regards.&lt;snip&gt;Current restrictions are:* GROUP BY is limited (solved by June, 2002)* HAVING, ANY, ALL are currently not implemented(solved by August, 2002)* No triggers and views (some functionality herefor v .1.7 of hsqldb, coming within days)* The size of Binary data is limited to about 32 KB(because UTF is used) (solved by June, 2002)* No server side cursors (here is a workaround forselecting big results) (may already be solved)* Empty space in the database file is not alwaysreused (here are the details and a workaround) (solvedby June, 2002)* Does not yet conform to ACID or true SQL-92 orJDBC 2 or 3 (targeted for June, 2002)&lt;/snip&gt;
Column.java  BINARY type bug.This is wrong:it should be:
Strange problem with text table.I try to create a text table with following code:Table is created ok and value foo/bar is added to thetable. After code is executed, size of testAccounts.db is5 bytes, it contains only text foo and line change after it.Password column's value bar is not added to the file. If Iselect * from account after that code is executed, itreturns only foo for username and 0 for password. If Iuse memory table (remove &quot;text&quot; from create tablecommand) everything works ok.I have tested this with hsqldb version 1.7.1 and 1.7.2alpha H. Same problem with both versions. Is this just astupid user error?
Text file sql infinitely slow response.I was excited about the text file sql capabilities. so I decidedto try v 1.7.1 on a 28000 record file and noted the responsetime for a select count(*) at about 4 secs on a 384MB850Mhz NT machine; HOWEVER, on a 350000 record filethe response time was ghastly - the query never returnedafter 5 minutes.Anybody have similar problems?
VIEWS and aggregate function no results (172_I)I have discovered this fast/small SQL engine yesterday -this is exactly I would like to use in home projects. Thiswill prevent me using Access for which I have to log withODBC. An other good alternative would be to choosemySQL but I think it too big for such a small project !Great product - I immediately thought trying my smallapplication over it transfering data (it is easy withtransfer even if there is no Views support).Unfortunately I was using &quot;Having&quot; and &quot;aggregate&quot;functions (SELECT X1,sum(X2) as Y FROM Z HAVINGsum(X2) &gt; 0) - in 1.7.2_I you can define views with thosefunctions but they don't show anything when run !
Exception on insert with select from..Unexpected token: ( in statement [inserttest case:and result isSQLErrorSerg
dup idx name on diff. tbls not allowed.If the following 4 SQL commands are issued via JDBC thelast one will result in an SQLException. Since the 2ndindex is on the table bar it should not conflict withone of the same name on foo.Details:Server was started out of the box using therunServer.bat on a Win2K machine. 2 tests wereconducted. Both the in memory database and the on diskdatabase. For the on dist test a database name of&quot;test&quot; was used.
previous() does't work when afterlast.When you do this:previous previous previousIt doesn't work because previous returns false whenafterLast condition ocurrs.I think the problem is the order of condition evaluation atjdbcResultSet.java.If you move up afterlast condition evaluation (beforeEmpty resultset or no valid row) and recompile theoutput is OK. I don't know why.HSQLDB version is 1.7.1
GROUP BY with SUM() returns fantom row.I am using ALPHA-J on Win2K, Sun JDK 1.4.1_01When the GROUP BY and SUM() are used on an empty tablea row of nulls is returned.create table foo (word varchar(20), fooi integer);select word, sum(fooi) from foo group by word;returns... (null,null)select word from foo group by word;returns an empty result set.
Boolean object failed to be serialized.Hey I guess Fred,the following tests failed with the exception down.The coloumn 4 is from type Other.The exception is:If I use aIt works fine.Alex
GRANT before CREATE VIEW + ISNULL.In my test application, I have re-written some fine views -and noticed these 2 points :1-In script file, GRANT SELECT ON view_XY TOPUBLIC is done before CREATE VIEW view_XY AS ...this means, I got often errors and I've to correct thescript file before starting database server (I am running inserver mode).2. How is working ISNULL(x,y) - as I didn't make it - I'veused CASEWHEN(x,y,z) ! What do you think ? Is thiscommand broken or I should exercice a bit more ?Yours
Slow query.I have provided a DB and query. The query executesvery slowly. However, if I break it up into several smallerqueries that do the same thing, they execute muchfaster (also included). Both queries create only 448rows. My assumption is that the query optimizer isn'tworking correctly.
Incorrect number of rows in GROUP BY query.A query with a MIN() aggregate function and a GROUP BYclause, where there are no rows that qualify for theWHERE clause, returns one row with only null values.According to ISO 9075:1999, part 2, subclause 7.11,&quot;&lt;query specification&gt;&quot;, general rule 1bI, such a queryshould return no rows:&quot;If T has 0 (zero) groups, then the result of the &lt;queryspecification&gt; is an empty table&quot;.Example:SELECT id, MIN(date_of_birth)FROM personGROUP BY idThis query returns a row with two null values, when table&quot;person&quot; is empty.
Unhappy with group by.Technically this is a bug, because of the documentation, butit may be an oversight:our SQL generator uses &quot;...group by x...&quot; where x is acolumn number containing an expression.Under HSQLDB if the expression is a date operator (e.gquarter(&lt;date&gt;) ) this does not work (SQL error).
Index not dropped when table dropped.I have an application that will periodically drop andrecreate a table. I find that in one particular casethis seem to fail regularly as an index gets left behind.When I execute the following script it willconsistantly fail.I get the following when the above is executed...
foreign-key constraint test failed.The following foreign-key constraint test failed:Can you please solve this issue?(btw: other tests concerning foreign keys I tried, weresuccessful ! )Thanks!Regards,Albert
Binary data and 'in' operator.Actually, I've found two bugs. Please, see the followingThe following statements must produce the sameresults (each statement must produce two rows):Set 2 (doesn't work. Problem with binary data and usingSet 3 (Trying to work arround set 2. Works horrible.I think rawtohex confuses the inner select &quot;oid&quot; with theouter &quot;oid&quot; and allways returns true. BUG 2!)Set 4 (trying to work around Set 3 + Set 1 problem)Ok, that's all. I hope you solve this soon as possible.Cheers.
Text Table Problems.When using text tables, the last column doesn't (on mysystem) get persisted to the files. When the server isshutdown and restarted, the missing column causes anexception.My System:To Reproduce Bug: Start attached DB in Server ModeOpen Manager and send CHECKPOINT cmdExamine the CSV and note the absence of the last column.
Text Table Field Concatenation.Zero-length characters fields when concatenated with non-null fields yield result in null or zero-length string.For example:If any of the concatenantion fields are zero-length thenDescr will be zero-length.Using the parameter: empty_is_null=falseThank You
shutdown compact corrupts data.After doing a &quot;shutdown compact&quot; in Version 1.72aL Iread the linesGeneral error in statement [CREATE CACHED TABLEARTIST ...at System.out.After that all data files are gone and the unprocessedtables are not in the script any more.It was possible to track it somewhat down; it seems anindex gets inserted which wasn't removed inDDL to reproduce:
dates are not being normalized in CURDATE()Currently, the DATE SQL type is being treated exactlylike the TIMESTAMP type. Instead, the DATE datashould be &quot;normalized&quot;, as per the java.sql.Date classdocumentation:&quot;To conform with the definition of SQL DATE, themillisecond values wrapped by a java.sql.Dateinstance must be 'normalized' by setting the hours,minutes, seconds, and milliseconds to zero in theparticular time zone with which the instance isassociated.&quot;The function curdate() is not normalizing the dates itreturns. This allows for an &quot;invalid&quot; date to be created.Here is an example of this bug:-- manually specifying today´s date should yield onerow, works okHope this helps. If you need further information,contact me at sieira@usa.net.Thanks for the great program.
Group By returning null values.If you create a simple table like this:create table test (a varchar(100),b numeric)and then you execute this:you will get a single row with null values. The expectedresult is no rows.If you executeyou will get a single row with null values. The expectedresult is a SQL error like this &quot;not a single-group groupfunction&quot;.Cheers.
LEFT JOIN regression from Alpha J =&gt; L.In Alpha J, I had built several queries using LEFT JOINto detect inequality in table1.id = table2.id such a waytable2.id is returned null !On application testing with (Alpha L), I got bad results(null are not shown) : Alpha K, Alpha L and even latestAlpha M !
now() doesn't work.Whats happened with now()? It doesn't work in alpha_m.Some changes at Tokenizer.wasValue() are in conflictwith &quot;now()&quot;. If you execute:will get:To solve this problem I removed sToken.equals(&quot;NOW&quot;)from return (at line 253 of Tokenizer.java). It works but Idon't know the effects of this change.Why &quot;NOW&quot; is there? Future features like Oracle'sSYSDATE?Cheers.
Log-Thread not exiting if any connect fails before.Hi,Using the henplus JDBC ShellI noticed, that the Logger thread in hsqldb is not exitingproperly, if any of the connect attempts to a databasefailed because of user/password failure for instance.Why I noticed this with henplus is, because henplus firsttries to connect to the database just with the JDBC-URLalone and if this fails, prompts for the password.This means, that the first connect will always fail, whilethe second will succeed, if the user/password is right.The problem is, that hsqldb starts the Logger thread withthe first attempt to connect to the database andincrements the usage count .. however that connectionnever gets used, because connecting fails and throwsan SQL-Exception (seejdbcConnection::openStandalone()). This means, that theusage count is always the number of all _attempted_connects not real connects.I did a simple fix, see attached patch. This patchinitializes the usage count with zero and _after_ theconnect is successful (i.e. if no Exception has beenthrown), the usage count is incremented. This will makesure, that the last active connection, that is close()ed,will shut down the Logger thread correctly.Note, however, that this is not a complete fix to theproblem. If we get _any_ connection that connection thatconnects correcly, then this solution will work, since thedatabase is removed and the Logger thread is closed inthe close() of that very connection if the usage countturns out to be zero. However, if _no_ connection willsucceed, then we will still have one database in thehashtable since no close() will run through (this isanother problem: in finalize(), close() is called; however ifthis is a jdbcConnection that failed to connect, then thesession is 'null' and executing a shutdown on thatsession will fail as well -- so the finalizer thread throws aNullPointerException. The finalaizer-Thread better shouldcatch any Throwable instead of only a SQL-Exception).
LEFT JOIN AND Null Values (ALPHA J)You should havebut instead you got :
Error with aggregate functions.The statement..works if field1 and field2 is of type FLOAT, but if it is oftype BIGINT, it does not work. The I get this error:
Strange Exceptions with Alpha M.Hey,I'm using the 1.7.2 since a couple of days in my testenviorment. So far everything fine.Since yesterday I'm getting strange exceptions:If I do the constraints into the create table definition thewhole create won't work.These general Exception seemed not to be veryimportant becauseI can still work with the database andbe happy. But these exception above occoured after aninsert of 32.000 records and that's was strange becauseall records are in the database (for my luck)Alex
Driver.connect not verifying user/password.Build: 1.7.2If I connect to the Server with an invalid user orinvalid password (with a good username) I get aconnection, but the next db access via the connectionfails with a:This exception should be thrown from the connect method.
Transaction, UK constraint, Rolback produce lost of data.Hi,I found some problems while using last stable version of hsqldb (1.7.1.).Transaction and Unique Constraint violation andRollback could produce unreliable db, and lost of data.I try this (from Database Manager):After that depend of the amount and type of data indestination table (in this case TUKR), some data wouldbe lost, additonaly many other commands producesame S1000 error (including SHTUDOWN).From JDBC connection behaviour is exactly the same.PK violation lads to similar results.
DatabaseManagerSwing.I recently downloaded/installed hsqldb(1_7_1). Itried running the DatabaseManagerSwing class andget the following:It apppears&quot;hsqldb.gif&quot; is not in the jar. Where did Igo wrong or was it mistakenly left out of the package?Thanks,Frank
Foreign key constraint error with trees.The foreign key constraint does not work correctelywhen used within one table.Example: The table A below is used to create a treestructure in a database table.It should be possible to fill the table with the nodesof the tree:Though the first insert would create a legal table contents, it creates an SQL Error:insert the first line directely into the hsqldb.scriptfile, restart hsqldb. This creates the root node, allother inserts work.
error 23000 after alter table with PK.Hi!I am using HSQLDB version 1.7.1.I am running the following: alter table a add column amount integer default 0 notnull;The last insert to table b fails with error 23000 - Integrity constrains Violation.Only stopping HSQLDB, and starting it again will allowthat insert to work properly.It looks like a BUG to me.Any suggestions?
IDENTITY skips numbers when table updated.I think I found a bug in ALPHA M:I have noticed in my application that a table with anIDENTITY column skips numbers when any row of thetable is updated. Here is an example:Here is the final contents of the table:Contact me at sieira@usa.net if further clarificationsare needed.Thanks.
Foreign-key constraint fails on update.I have encountered a problem with foreign keys. I´veread that others have mentioned this problem before meand that it has been fixed in later versions.I first used hsqldb_1_7_1 and then tried the same inhsqldb_1_7_2_alpha but with the same result.I´ve created to tables:I then add a team and some users (on inserts-statements the constraint works fine), when I try toupdate a user and changing his team to one that doesnot exist, it still works. That is the constraint has noeffect.Questions:Is there any way I can work around this problem, orwrite the syntax in another way?Is this problem supposed to be solved in theBest regards / Philip
DatabaseManagerSwing misses Icon.When starting org.hsqldb.util.DatabaseManager I get aNullPointerException:The reason is quite simple: There is no hsqldb.gifunder org/hsqldb/util in the JAR file (or anywhere else in the 1.7.1 release distribution).Could you please add that image file (and maybe evenadd that icon to the AWT Database Manager)?Otherwise your database is great. I currently use it toreplace a big fat Oracle database during developmentwork and regression testing :-)Hendrik Wördehoff
NullPointerException.Hellowe are using Hsqldb 1.7.2. The database isin multi-user mode with the following flags:-trace &quot;true&quot; -silent &quot;false&quot;We are getting NullPointerException in databasewindow.The following test condition is observed:To reproduce the bug, make sure HSQL database isrunning for very long time and DB is quite big.ie size ofthe database isLogged in to DB as AdministratorWe are using Connection pool to update 3 hsqldbdatabase using type 4 driver of hsqldb.Is there any workaround to solve this.Thanks in advanceNeppo/Srini
ClassLoader problem causing file lock error.If you attempt to open a connection on Windowsthrough two seperate ClassLoader(CL) who each havetheir parent set to null you will get the &quot;DB in use byanother process error&quot;. This occurs even if the first CLhas been null'd because either the lock hasn't beenGC'd or it has to do with Windows not releasing the lockproperly.The easiest way to reproduce this is to create two JUnittasks which both attempt to open a connection then runthose JUnit tasks through ANT.
PowerBuilder 8.01 crashed when trying to connect to Hsqldb.The issue could be PowerBuilder itself, but I post it hereto see if it rings any belt.From PowerBuilder 8 IDE, I can connect to Oracle 8,Informix 7, and SqlAnywhere (ASA) 6 JDBC drivers.But, when I connect to Hsqldb 1.72 rev M, then PB willcrash.Is it because Hsqldb does not implementgetColumnDisplaySize nor schema? I don't know.Ben
Problems Running on NetWare 6.JVM: JVM Version 1.3.1_06 patched to level noted below.First confirmed as a JVM (*see below*) problem byoriginal submitter, Dick Hildreth, in the Opendiscussion forum and currently under study. Mr.Hildreth's detailed report of the problem follows,followed by further posts from Mr. Hildreth andMaintainer. Original Forum thread is at:Problem report follows:BackgroundRows were disappearing from the hSQLdb 1.7.1 rundatabase.  When a record was updated, all records withkey values (char type key) lexically before theselected one would disappear. No deletes were found inthe .script file yet after doing a SELECT query, therecords would be missing. Also, running a scriptcommand in the DatabaseManager and looking at theresultant file, the recordswould also be missing. This only occurred when thehSQLdb client was running on the NetWare server (eithera calling program or hSQLdb's DataBaseManager programrunning in the NetWare GUI). A client running on aWindows box could run the update without exhibiting theproblem.Running SystemThe above occurred on a Netware 6.0 server patched toservice pack level 2. Two post sp2 patches had beenapplied: the NSS patch dated 02-01-2003/11:37AM and theTCP patch version 6.15o. The JVM was version 1.3.1service pack level 3 which showed the followinginformation under the Netware command moduleThe problem was replicated on another server with the sameconfiguration with the exception of the two post sp2patches.FixApplying a different JVM has removed this problem fromthe server. The new 1.4.0 JVM (and the required newLIBC from March 2003) has the following attributesdisplayed under the Netware command module java:With this sole change, the loss of records ceased.Bug report filed by dedmike.
InputStream error with unique indexes.Version 1.7.1 with Sun JDK 1.4.0.03 on Windows 2000:I'm getting inputStream errors and sometimesnumberformat exceptions on startup of a database.To reproduce create a new database run the attachedcreate.sql script in the manager and restart thedatabase. I get this error :TABLE IMAGE INDEX '-1 0 -1 0' contains negativenumbers.If i leave out the unique index it is running fine.Achim
Thread SQL Scripts in Help Forum.Enclosed is the SQL Script that I do not manage to haverun by the ScriptTool. It is the same that produces the&quot;Wrong data type or data too long in DEFAULT clause&quot;error from my DatabaseManager thread.
Wrong math.I am using hsqldb 1.71.Following is an example that the engine can producewrong math. This may be the result of data type (ordata precision/scale) conversion error:Ben
Problem with &quot;UPDATE ...&quot;I haven't had time to investigate this fully, so apologiesfor the lack of detail.I have some code which uses the HSQLDB in stand-alonemode. I find that when I use UPDATE to modify an entryin a table and subsequently COMMIT it, the modificationis visible only for the life time of the run time. Closingthe application and reloading it causes the pre-UPDATEdata to be retrieved. I have tried switching to CACHEDtables which had no effect. Looking at the .script fileproduced when the tables were uncached seemed toimply that the behaviour for UPDATE was implementedthrough the use of DELETE followed by INSERT and thatthe SQL that did this was not produced correctly(DELETEd all records in table then INSERTed the samerecord three times!).By changing my code to use DELETE and INSERT insteadof UPDATE. I can now get data to remain modified. Imay have missed something here.I look forward to seeing the inclusion ofCONCUR_UPDATABLE. This would have made the codingmuch easier. Not complaining though. I currently have aRDMS for an application and it saves me from thenightmare of using JDBC-ODBC -&gt; Microsoft JET... whichdidn't really appeal. Keep up the good work guys!Jon S
echo_ scripts not found.I don't know what system you use to develop hsqldb butecho_failure, echo_warning and similar commands are notpresent on my GNU/Linux Debian system. I'm using stablehsqldb version.Regards,Max
BIGINT corrupts very big negative long values.Hi all:I can't store very big negative long values(generated by a hash function) into bigint columndata type.Please test it:Very big positive longs seem to be work OK.I solve my problem storing long values as String,but long stored in native form will be better.Best regards, Marcelo.
SQL SELECT IN operator does not work.IN operator used as part of expression in SELECT sqlstatement does not work with 1.7.1.a version.
standalone is not exclusive.Hello!I'm using hsqldb 1.7.1 and don't figure out what'swrong with the standalone database url.Why is it possible to connect with DatabaseManagerSwingto a hsql database in STANDALONE (IN-PROCES) modeseveral times simultaneously??? And I can also start aserver for the same database, simultaneously , too?Looks like a bug (the database is the same for sure).Thanks.
database script file order error 1.7.1.i don't know if there's any special reason why in theclass DatabaseScript, more exactly in the methodgetScript(), the first thing you do is to iterate the vectortTable, ignoring temps and views....then you dump users, and their grants to the script fileand finally you iterate one more time on tTable, to dumpthe views creation scriptthe problem is:suppose sa creates tables, views, and a user, thengrants permission for the new user on a viewif you connect as the new user you can access theview, but if you shutdown the engine, the next time youstart it up it finds the grant .... on &lt;view&gt; statementbefore it finds the create view statement, so an errorappears saying that the view is an unknown tablei suppose there's a reason about not dumping the views,when you dump the tables (there's a line saying &quot;//fredt@users 20020221 - patch 513005 bysqlbob@users (RMP)&quot;)hope you fix it soon... actually i'm changing the order inthe script manuallythanks in advanceAlejandro Gomez
ResultSetMetaData getColumnType error.ResultSetMetaData.getColumnType() returns nullpointer exception when called, but however returnscorrect value sometimes (in another test program).The application program was checked using jdb toensure that the correct parameter was passed togetColumnType. The metadata was used to implementthe Java Swing AbstractTableModel. Other metadatafunctions also failed to return a proper value exceptgetColumnCount() which returned the correct count.Another short program was written to testResultSetMetaData.getColumnType(i) shows that thefunction worked perfectly in this case.lks@webpres.com.my
Column size ignored.I created a table with a char(1) column and the DB hadno problem to insert values of much greater length.
out of memory.Also I created the tabled as &quot;cached&quot; the database ranout of memory (test.data ~25MB)
count distinct rolls back when no records counted.executing a count distinct query, when there are norecords counted, fails. a rollback is executed an null isreturned.trace when there are records:iBanx
Failure to fire trigger on table insert.Hi,I have created a database that has 2 triggers thatshould be fired on deletes and inserts operations on atable called FILE. The trigger for deletions works fine,however the trigger for insertion fails to be fired. I havetried various combinations i.e. be fired before and afterinsertion - but the trigger for insertion never gets fired.I have enclosed a zip file that have the followingdirectories:database files. The *.bat are what is used to startup thedatabase.java source files for commicating to the database.Any further information or help - please email meCheers
cannot have foreign key constraint on same table.Is it possible to have cascading records? Each record hasa parent record. The root record references itself.Consider the create table statement below (whichworks), however you cannot insert the first recordbecause cnt_parentid is defined not null.This does not work:The foreign key is violated, because record id -1 does notexist.Thankstomsk
cannot use self join on unique column.Found in production 1.7.1 and in ALPHA_M.This bug is related to #722442To reproduce do the following:I have cascading records in several tables - each recordhas a parent record in the same table - the root hasitself as parent.I cannot define the parent id as foreign key of the id fromthe same table.Thankstomsk
CHECKPOINT DEFRAG fails on Alpha_J.If there was no prior data activity in the script file as in:Unfortunately this is a tough one to figure a workaround for.
Delete not commited.I'm using hsqldb version 1.7.1 as standalone database andJDBC driver to access. Java application is single-user, so onlyone connection is created at program start and its shared (nothreads) until the end of application. After deleting more than onerecord from some table, only one is deleted, others can bevisible in next select. Database is in (default) auto commit modeand to making me sure, I have added conn.commit() after deleteoperation. But &quot;delete problem&quot; appears again.
CREATE ALIAS issues for java.lang.Math.(min,max)see next comment
HAVING exception using TAG: latest pre ALPHA_N updates.Hi Fred.I ran into a defect that I thought initially I hadcaused with the code tagged &quot;pre ALPHA_Nrefactored code&quot;The incident does NOT manifest in the ALPHA Mfiles download.However, after some frustrating work and not beingable to find anything in my added/refactored codethat would cause this defect, I decided to do acheckout that consists of a snapshot of what wasin the hsqldb-dev CVS, just prior to the &quot;preALPHA_N refactored code&quot; tagged updates. Lo andbehold, the same defect manifests as in my localworking checkout.there are a few related defects, but the followingillustrates the biggest part of the problem, which Ibelieve is related to Expression.setTrue() orpossibly an incorrectly calculated iHavingIndex andsome unwanted interaction with aggregating value:Say, after performing the database manager &quot;inserttest data,&quot; I do a select like:select firstname, count(*) as &quot;count(*)&quot; fromCustomer group by firstnameThis is fine. I get the expected result:However, say I issue the same query but witha &quot;having&quot; clause involving the &quot;count(*)&quot; term (anyoperator and value will do...perhaps any aggregateexpression as well...I haven't tested that far yet).Then I get:So this proves that the defect was in the pre AlphaN CVS *BEFORE* the last update.I would list the stack trace using the latest CVS, sothat you don't have to translate the line numbers,except that I can't build the latest hsqldb-dev CVSdue to its missing the Token.java file inorg/hsqldb. Would you please commit this to the CVS?Thanks,Campbell
Error on using full qualified column names in insert command.Trying to update a table by using full qualified columnnames like &lt;table name&gt;.&lt;column name&gt; we geta &quot;Column not found&quot; error. Example code:Is this a bug? Do you think this syntax could besupported in future?
Serialization failure.Hi.Here is bug scenario:0) I'm starting application with in-process hsqldb server.1) I'm creating sample table (REGISTRATIONS).2) I'm inserting sample object into it.3) I'm shutdowning hsqldb server using &quot;SHUTDOWN&quot;command and exciting application;4) Second time, when I trying to start application withexisting database, a &quot;java.sql.SQLException:Serialization failure&quot; exception occurs while creatinga connection to database.I have debugged hsqldb code and checked that method&quot;readLongVarString()&quot; in TextDatabaseRowInput.readOtherprobably returns incorrect value. It reads object'sbinary data only until first carriage return in binarydata occurs.I've created demo which is packed into errorSample.zip.Here is full error stacktrace:
PreparedStatement.execute(sql) works but should not.According to the specs, &quot;If any of thePreparedStatement execute methods is called with an SQLstring as a parameter, an SQLException is thrown.&quot; Seejdbc-3_0-fr-spec.pdf, page 101, 13.2.4 Executing aPreparedStatement Object. (-fr- stands for FinalRelease, not France). You can get this document here:Currently, HSQLDB executes the statement, but it shouldthrows an Exception. This bug was found using LDBC(ldbc.sourceforge.net).
OutOfMemoryError when inserting into LONGVARBINARY column.When I create a table that has a LONGVARBINARYcolumn and try to insert data from a file in the filesystem, the java.lang.OutOfMemoryError exceptionoccurs.The documentation says that the max size of aLONGVARBINARY column is Integer.MAXVALUE, butthe problem is happening for me with a Word documentthat is about 2.8 MB.The attached Java program shows how to reproduce thebug. When the JFileChooser dialog shows up, justmake sure you pick a large Word document orPowerpoint presentation file.Unfortunately, the OutOfMemoryError exception is notpropogated properly, meaning, I am unable to &quot;catch&quot; it.I simply see the error reported in the Java console.
Problem with &quot;NOT NULL&quot; constraints on UPDATE.Version : HSQLDB 1.7.2 Alpha MThe &quot;NOT NULL&quot; constraints don't work in updatestatements.Test :This problem was not in 1.7.1 version of HSQLDB.
LEFT JOIN not work with 2 primary keys in a table.For example:will returnI tried with only one key and it works.I am using 1.7.2ALPHA M-andy santosa
Connection.close() does not release TCP/IP port.When using Connection.close() to close a connectionwith a HSQLDB server, the TCP/IP connection is notclosed until the client JVM is terminated.This can easily be checked using netstat under Windows.Open a connection (Keep the client running)-&gt; connection to port 9001 is visible in netstat /aClose the connection (keep the client JVM running!)-&gt; connection to port 9001 is still visible in netstat /aAny attempt to issue a statement using the Connectioninside the Java client will result in an errorclose client JVM-&gt; connection disappears
error selecting primary key column with itself.Create the following table and get the following error
CASEWHEN bug (with hibernate)Hello,With Hibernate &quot;joined-subclass&quot;, a statement like thisone is generated:The problem comes with the 3rd argument of the innercasewhen function (null): the data type returned isalways set to 0 and the switch inThis error occur in HSQL mode (not in STANDALONE mode).I have patched Expression.resolve(TableFilter f) this way:instead of,Everything works fine with this modification (but theyare maybe some side effects I cannot figure out).Regards,F. Wolff.
assert is a keyword.warning: as of release 1.4, assert is a keyword, andmay not be used as an identifierExample:A simple solution is to change the 'assert' to'cassert' in all files. That is what I did to solvethe problem.
Count Aggregate function  is giving wrong results sometimes.Hi,I am using HSQL database in my project.I am using following SQL query to retrieve countof packets in database.The database contains two tables RSPPdu0 andRSPSegment0.I need to retrieve the number of pdus( pduKey) peroutput portThe above query works fine in most of the cases. Butfor two different samples it is giving incorrect count of packetIn one case it gives68002 instead of giving 68000In other case12802 instead of 12800Also, this behavior is inconsistent on Solaris/Linuxand window platform. Sometimes the same query givescorrect results , sometimes incorrect.It is highly unpredictible when it will give correctresultCan u please help me in this regard ? Is this a bugrelated to HSQL database or am I wrong somewhere informing SQL query.An immediate response will be helpful.Contact id : riti@agere.comThanksRiti
Error with UPPER() in ORDER BY.I was using 1.7.2 Alpha M and I did this SQL:And it gave me this error even though it's valid SQL andworks in version 1.7.1:Here's the stacktrace:
1.7.1 Engine's LEFT method does not work.The use of the &quot;LEFT&quot; alias doesn't work:SQL ErrorUnexpected token: LEFT in statement [select left('mike',3) from test] / Error Code: -11 / State: 370001 row(s) in 0 msIf we create a new alias w/ a different name:it works just fine:select leftstr('mike', 3) from test
Group By and Binary columns.Hi,HSQL has a problem comparing binary columns ingrouped queries.I use binary columns to represent object IDs. Check this:select &quot;oid&quot;,sum(&quot;amount&quot;) as &quot;result&quot;from &quot;test&quot;group by &quot;oid&quot;If you have 30 rows with te same oid (a binary column)you will get a result set with 30 rows.I think the problem is related to HsqlHashMap. It uses aHashTable in order to store groups. Unfortunately twobyte arrays with the same content will have a difrenthashcode. HsqlHashMap assumes different groups.Thanks.
Incorrect SQL execution.This bug has been described in the help forum -- pleaseseeAttached is a .tgz file containing the database inquestion. Its user/password is sa/admin.
negative BIGINT are wrong.Hi I tried the following:the value which I gave to id is a valid java.lang.Longvalue. Is there a fix to that already ?ThanksMichele Laghilaghi@swissinfo.org
erroneous fk constraint violation.I'm using hsqldb 1.7.1.Attached to this message is a db that exhibitserroneous (as far as I cantell) behaviour. It's a little difficult for me tostrip out all of thesuperfluous (for this problem) tables, so please justconsider thePX_IDENTITY, PX_MEMBERSHIP and PX_CONTACT tables. Thereare only 3 rows totalin the entire db, so it's fairly easy to see the issue.PX_MEMBERSHIP is a simple many-to-many join table thathas fk constraint fromI get:How can this be, when PX_MEMBERSHIP is empty??
BIG script works on standalone but server.I tried to insert some data by using a BIG script.It was working for standalone database but failed inserver mode database.HSQLDB : 1.7.1, virgin, no patchesJava : IBM J2SDK 1.4.0Linux : redhat 8.0How I did it:* Run demo/runManager.sh* Open connection, standalone or server modeaccordingly* Made a new table.* Open the script (attached) and execute it.* Try to execute select * from kuisikon.Submitted by:PS: the database information is in Indonesian language,I'm sorry for not translating it, but I hope it does notmatter.
Connection Problems in standalone mode.Hypersonic DB when running in standalone(In-process -not in memory) mode does not allow the Process whichcreated the DB to use nested transcation(nestedconnection) or transcation across threads and throwsthe below ErrorERROR: The database is already in use by anotherprocessERROR: Cannot open connectionjava.sql.SQLException: The database is already inuse by another processLet me explain the scenario.1. Gets the DB connection with security user(Username=security1, pwd=&quot;pwd&quot;,url=jdbc:hsqldb:myDB&quot;). Get all the necessary data.close the connection.2. Now get the DB connection with real user(Username=real, pwd=&quot;123&quot;, url=jdbc:hsqldb:myDB&quot;). Doa lot of initialization.3. Now I have this part of code which executes a nestedtransaction. And I get the above error when the innerSo when i tried to debug hsqldb, I found the followingbug with the implementation.1. org.hsqldb.jdbcConnection holds a static instance ofHashTable-tdatabase(url,org.hsqldb.Database Objects).When closing connection the corresponding entry isremoved and the Database objects goes out of scope.2. Now when i reconnect to the same DB, it creates anentry in tdatabase. And if the finalizer for the previouslyfreed Database objects is called now the entry in thetdatabase(jdbcConnection class) is removed and if youtry to get any more connection it reports with the abovebug as it tries to create a new instance of DB instead ofcreating a new connection(openStandalone(...) methodin jdbcConnection Class).Solution.1. We must not depend on the finalizer method as wehave no controll over it.2. never call close to a connection(will be a badsolution).3. As a temporary solution i have commented methodlines in removeDatabase(...) in jdbcConnection Class andeverything appears to work fine for me.Other Details.
Column not found.Executing the below query and when getting the resultthe below error occurs.
ResultSet down not move backwards!I was able to move in both directions when usingresultset in hsqldb1.7.1, but with the code from hsqldb-dev throws the below exception when attempted tomove backwards... I am using hibernate 2.0 to accesshypersonic.jdbcResultSet.rsType can be set tojdbcStatement.rsType when creating the ResultSet.This will enable movement in both direction of the ResultSet.
NPE on SHUTDOWN when created by HsqlServerFactory.If the HSQLDB Server is created using theHsqlServerFactory then its internal socket instancevariable is never set. If a &quot;SHUTDOWN&quot; command is thenissued, a NPE will be thrown within the Server.notifymethod on the &quot;socket.close()&quot; command. The code justneeds to check to see whether or not socket is setbefore attempting to close it. See the patch to fixthis below. This is in the current release version 1.7.1Cheers,LeifIndex: Server.javaRCS file:retrieving revision 1.8
SQLEx closing Connection that is closed by server.I have been working on getting HSQLDB running within myapplication in server mode. The database is thenconnected to using a pool of JDBC Connections.Everything works great until I call SHUTDOWN as theserver is shutting down.As the server shuts down, one if its tasks is to gothrough and close all of the Connections in the JDBCpool. The problem is that the HSQLDB JDBC driverthrows and SQLException with the message, &quot;Connectionis broken&quot; for each connection as it is closed. Thisis because the socket has already been closed by HSQLDBon the server side. It makes sense to throw thisexception if a query is being made. I know this is amatter of opinion. But if the client isattempting to close the connection and the JDBC driverdetects that the connection is already closed. Itseems like it should just fall through gracefully asthe desired outcome was achieved.The following patch modifies jdbcConnection.java to dothis.This is with the current released version 1.7.1Cheers,Leif
Strange results in UNION.Hi, UNION seems to work fine with not null values:The strangest thing: [Query 2] breaks serverconnections!!!
CREATE VIEW + GRANT failes.Found in 1.7.1If you execute the attached script and then restart the database, you get an error and the database cannot be used anymore, because the CREATE VIEW will be after the
Max Aggregate Causes null row to be returned.In the query ... the max aggregate causes a single row of nulls to bereturned when Table1 and Table2 are empty.nathanila@hotmail.com
Some problems with last alpha.Hi,I had some problems with Timestamps in alpha_M (yousave 00:00 and retrieve 03:00 -- I'm at GMT-3 --). I'vedownloaded last cvs tree and that problem has beensolved.However, I've found new big problems:- I can't start a server with &quot;-database &lt;dbname&gt;&quot;command line argument. (The server always uses &quot;test&quot;)- I can't load my old database files (created by alpha_M).- Prepared statements can't execute DDL statements- Problems with Binary columns: I use binary(20)columns as Object ID. The error is:
Cannot use IDENTITY and PRIMARY KEY together.When specifying a column as an IDENTITY column, itleads to an exception when the same column is alsospecified as a PRIMARY KEY:primary key in statement [CREATE TABLE A ( ID integer IDENTITY,PRIMARY KEY(ID) )]This is especially troublesome when using Torque togenerate the sql code as Torque does generate bothIDENTITY and PRIMARY KEY (which is the usualcombination with other databases, e.g. MySQL).Since in this case the column is only overspecified, atmost a warning (if at all) should be issued, but no error.This error occurs for both the 1.7.1 release and the1.7.2 alpha (M)
Error when storing a String object in a LONGVARBINARY column.When trying to store a String object in a LONGVARBINARYcolumn while using a prepared statement, a exceptionjava.sql.SQLException: invalid character encodingis issued (1.7.2 Alpha M; a similar exception is issuedin 1.7.1). A quick look in the code revealed that it istried to convert a string that is assumed to containhex-encoded byte s into a byte array (Column:convertObject -&gt; convertString -&gt; hexToByteArray).However there is no hex string in the object, just anormal string, so the conversion is not successful.This exception is probably raised for BINARY andVARBINARY, as well (judging from Column.convertObject).
nulls in prepared statements (alpha_n)Hi,I use hsql to store Tomcat passwords. JDBCRealm seemsto prepare a statement setting a null value when theuser tries to access to a protected resource the firsttime.The cause of this bug (I'm trying to guess) is atValuePool:127 (ValuePool.getString(String val)). Thismethod is used to set Strings inRewritting getString like this:seems to work.I don't know if this problem will ocurr with allValuePool.getXXX() methods (I've not tried yet).Previous versions of hsql accept null values.Please include this bug. (I don't want to rewrite Tomcatcode.)
SAVEPOINT and ROLLBACK.andAre not document in hsqlSyntax.html but exists injavadoc class org.hsqldb.jdbcConnection.Affected versions 1.7, 1.7.1, 1.7.2-alpha M.
NullPointerException.This happens in 1.7.1 and can be seen in DBManager orthrough JDBC--- now set auto commit off and execute step by step--- Just to make sure I set the autocommit off beforeeach step since the menu doesn't show itrollbackYou get NullPointerException here
Group By and Binary columns II.Hi,Group by is not working with binary columns in alpha_n.Please, test this:This was fixed previously but the bug is here again.Cheers.
saveSorted ... negative seek offset.Hello,I'm using HSQL 1.7.1 with JRE1.3.1_03 in a Windows2000 environment. My database contains only one tablewith 8,000,000 rows which used to work fine (databasesize is 1.3 GB). But when I try to create a new index ordrop an existing index I get the following error messageafter some minutes:Negative seek offset in statement [...]&quot;where statement can beIs there any limitation in database size, table size, rowcount, or index size?GreetingsChristian
implicit DATETIME value change.Hello,I'm using HSQL 1.7.1 with JRE1.3.1_03 in a Windows2000 environment. My database contains only one tablewith 8,000,000 rows (database size is 1.3 GB) and anindexed DATETIME column. After months of working finethe following strange phenomenon occured:Sometimes all values in the DATETIME column werenormalized to a value between 0:00 and 1:00, that isthe time was divided by 24. The date part was keptcorrectly, new values were inserted correctly, too. Itseems that this occured during recovery procedure afterkilling and restarting the database process.More greetingsChristian
On delete cascade.Hi,There is a problem with foreign key constraints with 'ondelete cascade' option.Please try this:The self reference of tableB works fine without thereference to tableA.The reference to tableA works fine without the selfreference of table B.If both references are present, the script doesn't work.
PreparedStatements.Hi,Try this script:(Please note there are no rows).Why? Is something wrong?Regards.
rs.getString(&quot;name&quot;) fails.The often used first version works alright, however 2nd version, which is commented out, throws anSQLException (Column name not found).
select avg(column) - wrong results.When using select avg(col1) from test, null values areincorrect counted as zero.
Reading database from inside jar fails.Hello,I can't get hsqldb to connect to a read-only databaseinside a jar.According to the description I created a test.jar with atestdata directory containingtest.hsqldb.script,test.hsqldb.log andtest.hsqldb.properties.The test jar also contains a TestInJar class which triesto connect to the database.I Use the url &quot;jdbc:hsqldb:testdata/test.hsqldb&quot; and callSystem.setProperty(&quot;hsqldb.files_in_jar&quot;,&quot;true&quot;).Start the test with java -cp hsqldb1.7.2N.jar;test.jarTestInJar, hsqldb didn't connect to the database insidethe jar, but created a new database in the currentdirectory.The same happened when I added all the testfilesdirectly to the hsqldb.jar.Thanks for your help
Insert into Table with self FK.I was working with a table which has FK for self.I found bug with this kind of table managmentwhen inserting data with FK to selfHere is example of used table creation script:
Delete from table with self FK.I was working with a table which has FK for self.I found bug with deleting data with FK to selfHere is example of used table creation scriptand insert, update row queries
Delete with FK on delete cascade.I was working with a table which has FK for self ondelete cascade.I found bug with not correct returned number of updatedrows when deleting.Here is example of used table creation script andinsert queries for test data:
short form of group by doesn't work.Hello,after creating a little test db:select month, year,sum(value) from costs group by 1,2work in 1.7.1, but not in the current cvs.
Table not found !hi all,I am using Java,JSP and HSQLDB. I ahve used HSQLDBas Server and given the url asWith the above connection it takes as the defaultdatabase as test, how do i mention by own databasemail to viswa@infonents.com or viswajit2@yahoo.com
compute after aggregation ex) select sum(1)+sum(2)general error occurs when this kind of sql is executed.and nagative function gives another error
computing  within argument of aggregation function  ex) sele.computing within argument of aggregation function ex)select sum(a+b) ,S1000 general error java.lang.ClassCastException occurswhen this kind of sql is executed.
Error with Default Value with VARBINARY datatype.Using Alpha N of 1.7.2:This is my table declaration:This is the error:error in script file line: 133 Wrong data type or datatoo long in DEFAULT clause: FFFFFFFFFFFF in statementIf I put quotes around the 'FFFFFFFFFFFF' like so, thenit works, but then when I close the database it removesthem and then prints this error the next time I open it.Dave Johansen
SQLException: Column not found.Using Alpha N of 1.7.2:When I call any of the get methods on a ResultSet(getString(), getInt() and so on) with anything but thecolumn name in all uppercase it throws an SQLException.Is this a change in the way it works or a bug? Becauselower case column names worked in previous versions ofHypersonic.Dave Johansen
Prepared Statement param is turned to NULL.Timestamp with TimeZone processed incorrecthsqldb 172-alpha-nTry test case
COALESCE caused the client to hang and stack trace in server.Version: 1.7.2 alpha NAt the client, enter:at java.lang.Thread.run(Thread.java:536)Ben
Server died on grant select ...Version 1.7.2 Alpha NThe server will always die if my test.script hasgrant select statements. See the attached file.Error:In order to circumvent this, I have to remove by handall of the grant select statement, and then restartthe server.Ben
PowerBuilder 9.0 can not list any user or system tables.Below is the trace from the server:I think the problem is that table_schem andprocedure_schem are being null. I wonder if it hurtsanywhere else if hsqldb associates the table_schemand procedure_schem with whomever created thosetables and procedures.For example, if I connect as sa, then whatevertable/procedure I create should be stored under theschema sa.Ben
Parametrized SQL with IN in doesn't work.Tested with alpha N.This used to work on alpha M and before, e.g.now I get this exception
SET TABLE ADDR_TMP SOURCE &quot;tbl_addr.txt;fs=,;&quot;When I migrated 1.7.1's data to alpha n, the servercrashed because of lines like the following:Notice that there is a trailing &quot;;&quot;. After I manuallyremoved &quot;;&quot; then the server is happy.Ben
PreparedStatement failure.I'm using hsqldb_1_7_2_ALPHA_N and have found a problem with PreparedStatement.I have attached a JUnit test that exemplifies the problem. Basically the PreparedStatement is failing a query that a Statement is successfully executing.
ResultSetMetaData.isAutoIncrement returns false for IDENTITY.ResultSetMetaData.isAutoIncrement returns false forIDENTITY columns, also in version 1.7.2_N.From the code I understand that isAutoIncrement is asupported feature from version 1.7.2, so I thought Ishould let you know...
Problem with left join returning null.select p.propertytextid, p.internalname,ptc.textcontent as displayname, pe.expression,p.defaultexpression, dt.datatypeid, dt.javaclassname from(select descriptiontextid, propertytextid,internalname, datatypeid, defaultexpression fromproperty where appliestoperson=1) pleft join(select propertytextid, expression frompropertyexpression where objectid = 1 and objecttypeid= 7) peon p.propertytextid = pe.propertytextidleft join(select javaclassname, datatypeid from datatype) dton p.datatypeid = dt.datatypeidleft join(select textcontent, textid from textcontent wherelanguageid = 1) ptcon p.propertytextid = ptc.textidThis is the entire query that I want to use and itworks just fine with 1.7.1, but for some reason theDISPLAYNAME column (ptc.textcontent) is null whenever Ido the left join with PROPERTYEXPRESSION. If I removethe first left join (The one with PROPERTYEXPRESSION),then it returns the values just fine.Here's the DDLs for all of the tables:
Confusing error message with &quot;left join&quot;If you have a typo in &quot;left join&quot; then it chops off theSQL and gives an error message that is very confusing.I did the following:select p.internalname, tc.textcontent from(select propertytextid, internalname from property) pLEJT JOINAnd it threw an SQLException with an error aboutTEXTCONTENT being an invalid column. I think it wouldhelp if it told me that &quot;LEJT JOIN&quot; was invalid.
In XP can't do a jdbc connect with Manager UI.CAN do it programmatically in XP but not by ManagerUI. I try to connect to HypersonicSQL Server withorg.hsql.jdbcDriver andjdbc:HypersonicSQL:hsql://localhost from the ManagerUI BUT I get the following java.sql.SQL. Exceptionconnection is broken, network subsystem has failed.Is it just that the version of hsql (circa 2001) justdoesn't do XP with the UI? My email is dfheinz@aol.comthanksDaryl Heinz
Server start of 6MB database out of memory.I tried to start a server with a 6MB database, but itfailed.
Metadata ignorant about new tables.I ported an hsql1.7.1 database to 1.7.2O and have somehava code look inside the metadata for the tablenames:The old tables show up, but when I create new tables inthe 1.7.2O DatabaseManager, they aren't listed in themetadata in server as well as in-process mode.
Server shutdown failed.I can't reproduce it, but when issuing shutdown to aHsqldb1.7.2O server, I got the following exception:
1.7.2 ALPHA_O cannot read binary script file.I have a database where I converted the .script file toa binary representation (using 1.7.2 ALPHA M) using setWhen I try to open this DB (standalone) with ALPHA_O Iget an exception:When I open the DB with ALPHA_M, set logtype 0 then Ican open the DB with ALPHA_O as well.
Database works but stops writing to file.I am using hsqldb 1.7.1 with Java 1.3.0 on a SolarisFor some 10 days the database has obviously workedcorrectely but did not write any data to thehsqldb.script file:We used our Java database application during this time.The application does not hold any data outside hsqldband I could add and remove entries. However, thedatabase file date has not changed for 10 days and thelast entry is 10 days back.Consequentely, on a restart of the database, I lost allthe data.
Left join - no result.I used standard left join query.But this was not working if in ON clause isanother conditionExample:No result !!!Of course I expect that there will be result like:I also found similar reported bug whichis already closed:
Cannot specify a column type + IDENTITY together.The documentation for CREATE TABLE states:columnDefinition:with the following error message:Wrong data type: ID in statement [...]The following statement works, despite that it does not follow thegrammar rule:
NIO IllegalArgumentException.The database using NIO would try to accessa file beyond the length of the buffer causingan IllegalArgumentException. The code missedthe corner case when the seek position wasequal to the file length. Attached is a modified filethat fixes this. I no longer get theIllegalArgumentException.Also, I took the liberty of expanding the data filelinearly instead of exponentially. This seems to workin the testing I've done, and it cuts down on disk usage.Thanks for a great product!
1.7.2 ALPHA N+O: Query on SYSTEM_SESSIONS throws SQLExc.I guess there´s a problem with the SYSTEM_SESSIONStable.Here´s a short description of what I did:1. User 1 connects to a database (served byorg.hsqldb.Server).2. User 1 disconnects.3. User 2 connects to the same database.4. User 2 posts statement &quot;SELECT * FROMSYSTEM_SESSIONS&quot; which results in the following(copied from DatabaseManagerSwing)Udo
possible DatabaseManager confusion.I noticed a special case which can confuse theDatabaseManager (1.7.2P) and possibly also destroy adatabase.When copying a database from one directory to another,I only copied test.script, but forgot about thetest.properties file.When I tried to open the database with theDatabaseManager no tables were shown, the existingtest.script was ignored and the command &quot;checkpoint&quot;or &quot;shutdown&quot; would even overwrite the existing file.This behaviour is new to 1.7.2P (wasn't in 1.7.2N).Before I also used to copy .script files around and relyon the DatabaseManager to recreate adefault .properties file as needed. So I guess some usersmight get very confused about this changed behaviour.I suggest improved exception information (e.g.test.script found but no test.properties). (would also begood if a properties file is missing is missing inside a jarfile - see other bug report).I guess a question like : &quot;Shall I create a default 1.7.2properties file&quot; would be ideal.
maxlength of varchar is ignored.
NIO lock problem.I am getting an exception when trying to allocate aconnection. I tried to clean database files beforerunning the program, with no success.It was tested on Compaq Tru64 platform, &quot;java version&quot;1.4.0&quot;Java(TM) 2 Runtime Environment, Standard EditionFast VM (build 1.4.0-1.p2, native threads, mixed mode,12/10/2002-19:05)&quot;.The same code _works_ on Win2000 or Linux (also javaver 1.4) with no problem, so maybe this is just a buggyJava NIO API on Tru64. But I need to make it running onTru64 somehow.Is there any way to avoid using NIO API in hsqldb?Right now I just commented all code in
NullPointerException using IN where NULL values in column.Version:How to reproduce bug:First create the table and insert some integer values:The following select runs fine:Now insert a null value:The following select fails:So I guess you have to do a check for null beforecomparing the data in the table with the values in the INstatement.I know this worked before in 1.7.1, as my code failedtrying to switch to the latest alpha.
NullPointerException with VARCHAR and PS.When I do the following PreparedStatement:select TEXTID from TEXTCONTENT where TEXTCONTENT = ?and LANGUAGEID = ?I get this NullPointerException when I call
rs.isBeforeFirst() should return false.rs.isBeforeFirst() should return false when ResultSet isempty.
Transactions and closing server from dos bug!
wrong results with join in ALPHA_Q version.This is how to reproduce the problem:
select with where on unique indexed column doesn't work well.I'm working on 1.7.2 alpha_M (I have problems withversion alpha_R - I wrote about it in the forum)The test case is:I have server.properties file with:
create user with jdbc.With 1.7.2 R the following jdbc prepared statement&quot;create user ? password ? admin&quot;throws SQLException &quot;parameter index out of range: 1&quot;when trying to substitute the first ? with name usingsetString(1, &quot;name&quot;)This was warking correctly with 1.7.2M and before
select date/time with jdbc.our table isDo following in javanow try to select the date back using following codeThe result set returned is emptyIf I would set the exact time I set when I inserted thedate, the result set would contain the record.The same happens if I want to insert time and thenselect it with different date into a TIME column
comparison with LIKE and Pstmts fails.hi there,(see below sample code). it seems that &quot;col LIKE ?&quot; isbroken in the current release. the below code normallyshould return a row, but if I use LIKE the it does not.the result of the comparison is always false. if i simplyuse col = ?, it works as expected. seems to be a bug.!?
where column in (select.Given a tablewith content
hsqldbmin.jar looking for HSQLClientConnection.Trying to run embedded hsqldbmin.jar, and getting:This comes from src.org.hsqldb.HSQLClientConnectionHSQLClientConnection is not included in hsqldbmin.jar - itdoes implement SessionInterface which is included. A fixfor embedded mode is:I don't have the background to know if this might haveany bad side effect in server modes.
Deletion of .backup file causes db corruption w/JDBC.I deleted a .backup file (isn't this permitted?). Then Iopened the db using JDBC (DriverManager.getConnection()). This results in a &quot;database in use&quot; error, and the dbis corrupted, having 0 bytes.This sounds like a serious bug, if it is a bug. At anyrate, the system should never blow away the entire db?Thanks,Dave C.
New bug in Select/Like on primary key.Working with HSQLDB 1.7.2 - SFollowing DDL:If i'm doing the following query:select * from additionaldata where function like 'G%'the ResultSet is empty. This is definitly wrong!Using onlyselect * from additionaldata where function like '%'the whole table will be shown (this is ok)Removing the &quot;Primary Key&quot; constraint from the DDL inthe &quot;function&quot;-column causes the SQL-queries toperform properly.Any ideas about that? I'm quite sure, that the version ofHSQLDB I tried before does not behave like this.
LIKE error in v. 1.7.2_S.Hi!I created a simple cached test table:and an index to DESC column.I execute a simple Java program to fill the table withrandom numbers (200,000 records). No problem.I execute this select:I try also with LIKE '-57966%07' and don't works again.HSQLDB is unable to find the record.Thanks,Francesc Rosés
(ALPHA_S) Can't compile HsqlDateTime with earlier JDKs.One can't compile HsqlDateTime.java with JDK1.3 or earlierbecause it uses Calendar's setTimeInMillis(long) andgetTimeInMillis() methods, which were protected rather thanpublic until JDK1.4 (I think it was). Equivalents, though lessefficient, in earlier JDKs would be Calendar.setTime(newjava.util.Date(long)) andCalendar.getTime().getTime().FWIW, I've attached anupdated HsqlDateTime.java and build.xml which usecodeswitcher and a wrapper method to use the more efficientmethods when JDBC3 is defined, the less efficient ones otherwise.Using a wrapper makes the code simpler (though not so pretty) andthe optimizer should toss the overhead. Used the 'tempDate' staticmember that was lying around seemingly unused (made it private).Haven't done regression on it, no warrantee.Obviously,I'm not a developer on the project and throw it away if you like. It'sjust FWIW.Regards,T.J. Crowdertjcrowderat users
Errors in Text Tables.There is a problem with writing and then reading texttables.The problems are related to the field &quot;SystemId&quot; feature.Seems like the text tables were written without thelast column, and when reading,the extra column &quot;SystemId&quot; was created.When the last column type was not the same type ofSystemId (long, i guess),a ClassCastException was thrown, and the server hanged(as the client).I studied and fixed this problem in 2 methods:Without this (or other fix) to resolve this issue,using text tables with thefull life cycle (attaching, updating/inserting, closingbd, reopening, reading)will be impossible.The connection hangup was due to the fact that we werenot expecting aClassCastException in class ServerConnection, method run().I think a catch(Exception e) statement should be addafter the existingone for IOException and SQLException, to avoid thisproblem.Best Regards,Carlos Silva
1.7.1 zip missing hsqldb.gif in src/org/hsqldb/util.After using ant to build the standard jar or any jarincluding Swing, the DatabaseManagerSwing utility willfail to load, on a getIcon statement in CommonSwing.Upon examing the source, I see the .gif mentioned ismissing from the distro. I found one on the web, put itin hsqldb/src/org/hsqldb/util, and reran ant (the ant filedoes mention this gif explicitly for inclusion). This fixesthe problem (still a bug though, until the distro zip isfixed).
.lck file created for read-only database.Each connection to the resulting database still creates a&lt;database name&gt;.lck file, preventing it to be put in aCD-ROM, for example.This has been tested on 1.7.2 alpha N, R and S versions.
number of records.Hello!I'm writing from Palermo(Sicilia).Thanks for your hsqldb database that i'm using for a webapplication with servlet,jsp e javaBean.The version that i use is 1.7.1 but i have found a bug, ithink.I use this method to find the number of records of aResultSet :if records are 4 this method return 4 and in ResultSetthere are 4 records but if i use while loop to printrecords, it prints 3 records if i use before this method,and 4 records if i don't use this method beforeI use this ResultSet :Associazioni.Key order by key desc&quot;);What can i do to find number of records without to usethis method ?Spero di essere stato utileCiao e grazie.
LIKE bug.If you create a simple table with version 1.7.2 alpha R :then this first SELECT statement returns this lastBut this one don't, though it should !This seems to happen when you use any string function,... returns this row.However when you include another string function theproblem reappears:There was not any problem when I used the 1.7.2 alphaN version. Alpha T still have this bug.
alter table... add default not working.I'm running the following command in the DatabaseManager:alter table k alter column vc add default 'dfltval'It returns &quot;Unexpected token: ADD in statementversion A T.
saveSorted ... negative seek offset (2)Hello,I'm using HSQL 1.7.1 with JRE1.3.1_03 in a Windows2000 environment. My database contains only one tablewith 8,000,000 rows (database size is about 1 GB) andthree indexes on single columns. I had a former problemwith creating resp. dropping an index which didn't workbecause of an&quot;File input/output error: saveSorted java.io.IOException:Negative seek offset in statement [...]&quot;error (see bug submission 780397 from 2003-07-30). Isolved this problem by creating a new database andcopying the data row by row.Now I have a more serious problem: The database can'tstart anymore because of the same error (though I useda backup which has been successfully compactedbefore). When I remove the &quot;CREATE INDEX&quot; statementsfrom the script file I get InputStream-errors (becausethe index roots aren't valid anymore), when Iremove &quot;CREATE INDEX&quot; and &quot;SET TABLE INDEX&quot;commands I get no errors but have no access to thedata anymore (though the database size stays thesame).No my questions:Is there another workaround for this situation?How can I manipulate the &quot;SET TABLE INDEX&quot; commandmanually so it doesn't lead to the errors described above?Will it be possible to use an index spanning more rows in1.7.2?Greetings,Christian
Create View fails.This sequence
.new files not removed when using relative path.If I create a connection to a stand alone database usinga relative path, when I close the connection thebackup.new and script.new files do not get removed.The next time I try to connect to the database and thendisconnect I get the following exception.Example:if I use the following URL: &quot;jdbc:hsqldb:db/da_database&quot;the .new files don't get removed.But if I used: &quot;jdbc:hsqldb:C:/javaProj/Draft Assist2.00/build/db/da_database&quot; it seems to work fine.using hsqldb 1.7.1 on Win2000
't' should be interpreted as 'true' for bit columns.inserting the value 't' into a bit column isinterpreted by hsqldb (1.7.2 alpha T) as 'false'.Example :create table test (isOk bit);insert into table test (isOk) values ('t');The row will now have the value 'false'.
Corrupted .script file using DatabaseManager.Generating a database with about 300 tables usingScriptToolgenerates the database files .properties and .log. Afterusingthe DatabaseManager and closing it the data wentfrom .log tothe .script file but seems to be corrupted.The DatabaseManager changes the IDENTITY attribute ofthe primary key columns to&quot;GENERATED BY DEFAULT AS IDENTITY(START WITH 0).Using this database in my application leads to thefollowing error:Questions:Is the &quot;GENERATED BY DEFAULT ...&quot; entry ofDatabaseManager actuallyintended / needed?How can I avoid this DatabaseManager behaviour? Notethat the data in the .log file seems to match exactly my SQL statementwithout &quot;GENERATED ...&quot;?I'm using version 1.72 alpha m.
JDBC methode &quot;getScale&quot; always returns zero.There is a bug in connecting of hsqldb and Druid(druid.sf.net).Because of the &quot;not correct/not complete&quot;implementation of the &quot;getScale&quot; methodeof &quot;jdbcResultSetMetaData&quot;. Durid use this methode andhandle the colum as an Integer and not a decimal.For more information about the druid bug see:&quot;[ 838413 ] Exception with JDBC HSQLDB&quot;or:So please correct the implementation.Thanks a lot!Jochen
TestSelfQueries fails on 1.7.2_ALPHA_T.I got 3 failures (2 errors) when running the Self test,The first one is:This is mentioned in the file as:but it seems like the fix didn't take.I built hsql Windows 2000, JDK 1.4.2_02. Did I dosomething incorrectly when I built? (I have includedthe entire test output)Thanks.Chris
Does a Constraint have an Impact Over the Returned Rows.Hi,There are two tables - TABLE_A AND TABLE_B and theirdefinitions are:it returns 1 (for identifier=uidtns) row instead of 2 (doesn't return for identifier=procedure)if you delete all rows from table_a where process_id != 9(leaving two rows) it still returns one rowIf you shutdown the server and restart it only then itreturn both rows, when there are just 2 rows. It doesnot work when there are all 20 rows.
Problem with clob.We use hsqldb 1_7_2_ALPHA with Hibernate.In jdbcPreparedStatement.java in methodsetCharacterStream.At this line.Sometimes for some reasons. The reader is already at theend of the stream.MY PATCHThank you if you add this line in the next version. Nowwe use your jar, we apply the patch and give thepatched jar to the developpers.Jean-François Nadeau
CASEWHEN(SUM(some_filed),some_value) -&gt; Exception.Any CASEWHEN-type function with any aggregatingfunction as parameter causes to General error.The reason is that in this caseExpression.getAggregatedValue() requires specialalgorithm for value retrieving, but it missed. Possiblesolution is to add the code below to the first switch{} ingetAggregatedValue() method:
1.7.2 alpha T is not compatible with JDK1.3.I ran a simple test using a 1.3 JDK, but the JDBC driverwill not load because of a dependency on:Which was introduced as of JDK 1.4.Here is the exception:
DatabaseMetadata.storesUpperCaseIdentifiers() returns wrong.Method storesUpperCaseIdentifiers() on theDatabaseMetaData class returns true. But when I amsearching tables with DatabaseMetaData.getTables I haveto use lowercase in the table name.
ResultSet.isBeforeFirst() does not work as specified.The following javadoc code snippet is from JSDK 1.4.2:before the first row;position or theAFAK, this works as the specification for the JDBC API.Thus, when I have an empty ResultSet, the first call ofthe method should return false, but obviously thereturn value is initialized to true without checkingthe ResultSet, if it contains any rows.The ResultSet was generated with getTables(...) fromthe database's metadata, and I wanted to test if agiven table already exists or has to be generated.
Error in jdbcDriver / getPropertyInfo.I've found an error in jdbcDriver.java, while I waslooking in the source for some information about themethod getPropertyInfo (what I can expect from it):The properties 1..3 are all assigned to pinfo[1],overwriting the values 1..2 by value 3.
Warnings.Compiling the latest alpha release iin Eclipse gave theattached file of warnings. Mostly uneeded imports andstatic methods/fields access.
Assert Failed inside of Hypersonic.I get this error when issuing these queries on thelatest alpha version of 1.7.2 and I'm not sure why.com.tallgroup.framework.ocs.listeners.FileListener$1.run(FileListener.java:329)If you need any more info or some test data just let meknow.
Unexpected token.Sorry to submit again, but I forgot to login in thepreceeding submission. Hope you don't mind.I got unexpected token when I tried to connect to theattaches database. You can launch runManager toreproduce the error ( stand alone engine)Can you help me ? Thanks a lot.visual
bad cache logic.Bug scenario:I have obtained <TurnDetails> object (result) fromdatabase using something like:conn is database connection that is created on programinit and persists all program lifetime: static ConnectionFirst time object <result> is obtained correctly, allworks fine. I am changes several object's fields duringprogram lifetime and, after all, I want to get theoriginal unchanged object, that is stored in database.Hovewer, code described above returns me OLD objectwith CHANGED fields (in fact, there is no differencebetween object that was manipulated during programlifetime and returned object).Here is workaround for this problem: if I close andreopen database connection, i'll get fresh unchangedobject (but only first time. Each time I want to getFRESH UNCHANGED object, I should close/reopen databaseconnection, and this is too slow). Seems, thatconnection caches objects and simply returns me oldobject in spite of the fact that it was changed in memory.
Null-value update causes unrelated contraint violation.I have a schema that works well in hsqldb 1.7.1 but failsmiserably in 1.7.2RC1.I execute the following statementsThe last statement causes SQLException shown below.Notice that the values updated on the last statement isidentical to the values being inserted!Now if I executeIt works!
1.7.2 is 25% slower than 1.7.1.In my test of schema consisting a few tables andreferences (cascade delete), the performance of 1.7.2is about 25-30% slower than 1.7.1
In .log file, some command lines are corrupt.Here are the first few lines of the log file.SET AUTOCOMMIT FALSEIs there a bug in the line printer? Seems similar tothe problem I saw awhile ago on the forums (seeing "T"or some other character) at the beginning of a log fileline. This was from a database that was not cleanlyshut down.This was on a two CPU machine, Solaris, Java 1.4.0_06.I saw the same problem on Linux on 1.4.1. Perhapsthere is a synchronization issue?
File input/output error: *.backup in version 1.7.1.I'm currently using the HSQL database engine 1.7.1 onand an embedded XP environment using Sun's 1.4.1 JavaVM.On some occasions when a hard boot has occured (whilethe HsqlDB (running as a server) is running with a coupleof connections possibly still open to it, but idle), I'vefound the database files to be corrupt upon reboot (notonly the *.backup file as the captured event belowindicates, but also *.script and *.data files)The *.properties file always seems toindicate 'modified=yes' after boot up.After reboot, the following exception is thrown when theDB is started up again after a hard boot -Use SHUTDOWN to close normally. Use [Ctrl]+[C] toabort abruptlyIs there anything I could do to prevent this from occuring?
RC1: ROUND makes an exception.In construction likeselect round(coalesce(sum(<dec_column>),0),2) from<some_table>the query returns correct result if sum() returns somevalue. If sum() returns null then "General error:java.lang.NullPointerException" appears.If round() removed and sum() is null, the query returns 0as expected
Error in Server.start()? (1.7.2 RC1)HelloThis little example code does not work as expected in1.7.2 RC1The server does not stop. It seem the start() returnsbefore the server is fully started. The javadoc for thestart method clearly states:[..] it blocks only until the server's backgroundthread notifies the calling thread that the server haseither started successfully of failed to do so.IMHO the start method should block until the server iscompletly started.Futhermore I would have expected the start() method tothrow an exception if unable to start.
.script file contains wrong CREATE TRIGGER statement.I have run the following statements on a newly createddatabase:The trigger was create successfully (no error, and itwas visible in SYSTEM_TRIGGERS)Shutdown and re-connect to the database gives an error.A quick look at the .script file shows that thefollowing script is generated:Note the missing space in "CREATE TRIGGERMY_TRIGGER"which fails thus the database cannot be opened.1.7.2 RC1, JDK 1.4.2
Weird exception when column not specified.This weird exception happens when I don't specify thecolumn FREQUENCYOFUSE.Here's my DDL:If I specify the column FREQUENCYOFUSE then it worksjust fine.Let me know if you need any more information or if I'mdoing something wrong.
Indexes are mixed up when adding index.When a new index is added to a table WHICH ALREADYCONTAINS DATA, the data structures that implementthe different indexes are mixed up with each other(cross-linked). In our case, the result was that dataslowly disappeared from the table because the indexesbecame corrupted when data was updated. In one luckycase, we got an assertion error after several updates tothe table.The attachment contains a fix in the form of a diff whichcan be applied to revision 1.72 oforg/hsqldb/Table.java . It seems to be good also for the(at this time) most current version 1.87.
Internal Error : Invalid Compiled Statement ID.My testsuite of about 600 tests encounters this errorseveral times.Invalid Compiled Statement ID:
Embedded Interserct doesn't work.THis didn't work on 1.7.2 alpha M and on RC1, works onsapdb
Embedded Union doesn't work.THis didn't work on 1.7.2 alpha M and on RC1, works onsapdb
Bug with Clob functions.guillaume.nodet@deliasystems.comjdbcClob's functions getSubString() and position()handles index badly. The spec says the index shouldbegin at 1, but they are coded as if they are handled at
getTimestampString(Timestamp x, Calendar cal)  bug.Hi,The getTimestampString(Timestamp x, Calendar cal)method in org.hsqldb.HsqlDateTime class have x'smilliseconds part added twice. See the following codefor current implementation and the error place.It is not necessary to add x.getNanos() /1000000.x.getTime() already includes the millisecond part. Ithink the author thought x.getTime() just return theintegral seconds part.For example,take timestamp 2004-01-19 23:59:59.999 (from UTC+8) asx and calendar with UTC as cal, the return value is2004-01-19 16:00:00. The correct returned value shouldRegards,Rice
OutOfMemoryError when telnetting to the server.HelloIf I start the server at telnet to it using "telnetlocalhost 9001" and write "aa<enter><enter>" [1] inthe telnet prompt. Then the server will throw anOutOfMemoryError.Granted this is not ordinary usage. But I think aserver should be able to handle malformed requestswithout running out of memory. The server shouldsomehow detect that the client is bogus and ignore it.[1] do not type <enter> but hit enter...Btw this is on 1.7.2RC@jdk 1.4.1_03
setMaxRows on preparedStatement.Hi,The setMaxRows does not work for a prepredStatement. Ihad a look at the code for jdbcPreparedStatement andsaw that the executeQuery() method never updates themaxRows on the resultOut(Result) instance. The samegoes for execute().Cheers Jaco
res: urls for JWS do not work.In the file HsqlProperties.java, there is a method:public static boolean checkFileExists(StringfileName, boolean resource,the problem is, cla.getResource translates packagenames into directories, so trying to open:jdbc:hsqldb:res:dir/mydatabaseWould result in this class trying to check ifdir/mydatabase.propertiesexists, which in turn is translated asdir/mydatabase/propertiesWhich obviously does not exist. Note that this problemdoes not happen if the URL starts with / (somethingthat is not correct, since the classpath is relative,but is needed to disable the package translationmecanism). The proper solution would be to callcla.getClassLoader().getResource(). You don't even haveto pass cla as an argument, sinceThread.currentThread().getContextClassLoader() also works.Another two points:1.- In the example jnlp file that you provided, thereare some properties especified in doc/databaseinjar.txtto be put in a jnlp file as an example of useproblem is, JWS does not allow (without signing thejar) to System.getProperty() anything that does notstart with "jnlp." or "javaws.", as2.- Didn't check that too much, but it looked as ifcheckFileExists is called too often. IIRC even callingto Connection.close() does trigger a call to this one.
Inserting binary datas fails.I have a problem trying to insert a File in aLONGVARBINARY field.Here's the code I use to insert:I have the same problem when using thesetBinaryStream methos.
getMetaData() and getColumns(null, null, tableName, null)...Hi,There is a case sensitivity issue withthe code works, but nothing happens...(using 1.7.2 RC1).
2 now generates 2 different times.I have not tried the latest version, just up to alphaM, but when I have statement likeinsert (......) into ... values (.... now, now)(the statement contains multiple now calls) in certainsituations (probably depends on timing) the timesreturned by now are different and therefore the insertputs two different values into the database even thoughthe intent is to put twoof the same values there.Not sure if this is a bug, but it is definitely littleunpexpected so I am bringing it up to hear your opinion.
PreparedStatement.getParameterMetaData()HSQLDB 1.7.2 RC1Hi,PreparedStatement.getParameterMetaData() is notimplemented.Could you provide a dummy implementation to avoid:
Delete query doesn't allow conditional statements.I've attempted in every possible way to issue a deletequery that looks for <statement> and <statement> andit always gives java exception errors. The sameconditional statement works fine in the search or updatequeries.Perhaps I dont have the right syntax? But i've triedalmost every SQL variation and then some.
correlated update results change.HiIn the 1.7.1 the following worked fine:With 1.7.2 operation_seq is not updated, but the update count is correct.Has the syntax for the correlated update changed?What is the correct syntax?The SQLServer and Oracle formats that i tried causedsytax errors.thankstrevortest case:
UPDATE failure.version 1.7.1
Server hangs on select statement.The attached zip file contains a SELECT statement thatworked in 1.7.1 but in 1.7.2 RC1 doesn't work. In 1.7.2the server gets locked up and CPU utilization goes to100%. I then have to kill the server.I tested this statement with org.hsqldb.util.DatabaseManagerSwing and with DbVisualizer (commercialSQL manager) and with my Java application. I got thesame results.This statement works fine with a MySQL version of mydatabase.The zip files contains the SELECT statement, the dbscript (pinyin.script), the server.properties and pinyin.properties and db.properties
float precision lost &lt;k@kylemiller.com&gt;This is a problem in 1.7.1 and release candidate 1.7.2.if you have a float like 9.3, and call set float on aprepared statement the number saved in the db is9.3. I looked in the source and thesetFloat method on prepared statement is just a passthrough method to setDouble. The problem is when youcast a float to a double the precision changes, as in theproblem above.
null value not accepted in IN (..) clause.null values are not accepted in IN (..) clause.This would be very helpful for me, because Iprogrammatically create long IN-clauses in which nullmight occur. Having to change it all towhere xyz IN (....) or xyz=null would require someprogramming effort.
CURTIME() problems.I'm having a bunch of problems when trying to use theCURTIME() function in the 1.7.1 release.This always returns 'bad' for me.Since the BETWEEN expression covers the entire 24 hourperiod, I believe any time zone differences, if they existed,would be irrelevant and this would always return 'good'.
CURTIME() not normalized.This is related to #897591version 1.7.2Since this doesn't normalize the time to Jan 1, 1970 whereasother time values are normalized, CURTIME cannot be usedreliably in comparison operators.I believe curtime() should look more like:
different results in 1.7.2 rc1.hi,i just migrated an older cocoon application with hsqldb inserver mode from cocoon 2.0 to 2.1 rc. i also decided totry hsqldb 1.7.2 because it's new features look verypromising to me. the first problem i a came across was avery curious EOFException when trying to acces onespecial table of the database (i simply took the olddatabase files which worked very well until then). butthere is nothing special about the stucture of this tablenor it's content. looked very random to me. after playingaround with the transfer tool and various different hsqlversions i was able to use a version 1.6.2 sql dump ofmy database and (after modifying table creation to getcached tables again) open it without any hassle withversion 1.7.2 hsql server.now the dbms seemed to do it's job but i realized anenormous performance drop compared to the olderdatabase system. it looks like a communication problembecause the db server starts outputting my sqlcommands (silent = false) seconds to minutes after myservlet is activated.but the biggest problem is, i'm now getting differentresults compared to the old system. i didn't check theresults of single queries yet but i can clearly see thatthe application (kind of multi dimensional scientificsearch engine) is just producing crap with hsqldb 1.7.2.to sum it up it seems like additional constraints i throw inare not reducing the amount of results i get but enlargethe result set a lot. the app itself is used for almost 2years now without any modification to the sqlstatements or code so i consider it stable.sorry for staying so vague but i didn't find time to take acloser look at the problem yet. i did all of the systemdesign and programming years ago and the whole thingis very complex so i don't know exactly where to startwhen it comes to debuging. if you could give me a hintwhere (i mean for what kind of query) you changed codethat could possibly couse different results i would try tocheck the corresponding statements and results in detail.just a last point - i went back to version 1.7.1 asshipped with cocoon 2 and everything's working perfectagain (including import of my old database files).kind regardsp.s. i'm using jdk 1.4 for all java systems including hsqldb
CHECK CONSTRAINT column not found.Version 1.7.2RC1Following SQL generates error:
CHECK CONSTRAINT follow-up.I was in such I hurry to create the example in 900350 Imessed up the SQL; let me try again. The error I wastrying to report was:
Conflict with Turkish Regional Settings.In windows environment with Turkish regional settingsand character set, there occurs some errors.For example,, whereas the column ISIM exists:The cause of the error is the difference between turkishand english character set. In Turkish the capital of 'i' isnot 'I' but '&#304;', which is an I with a dot.Hsqldb converts all the words in an sql statement toupper case. This is done according to the default locale.So this conversion produces unrecognized characters forhsqldb database.The solution to this problem is, setting the default localeas Locale.ENGLISH in hsqldb. Or using toUpperCase(Locale.English) method, instead of toUpperCase().I hope this problem might be resolved in the futureversions of Hsqldb.Thanks for great work and effort...
update with correlated subquery does not evaluate correctly."update" throws "Single valueexpected" exception if tableX.colX contains NULL.Without the null row, update works corectly.With null row, update works on Oracle and breaks onHSQLDB 1.7.1 and 1.7.2rc1.Please see attached Java code, try to run it with andwithout line 52:insert into table2 (col1, col2) values (null, 5)commented out.
LIKE error in RC2.Abstract:Observe this is not a memory table bug. The samebehaviour appears for example in a cached table.I think is a very important bug near the final 1.7.2release.
LONGVARCHAR(size) no longer works.This worked in the older version of HSQLDB, but no inIs there a reason for that change?this works:Thanks,Thomas
Unwanted output to System.out.In 1.7.2 RC2 there are sometimes messages written toSystem.out. This should not be so. Imagine a consoleapplication that needs to write to System.out...Please disable this messages by default.Thanks,Thomas
Data loss in TEXT tables and ClassCastException.Hi,A problem concerning current release V1.7.1.The problem does not appear in 1.7.2 RC 2.But I've found nothing about it in forums (known bug)I found loss of datas in TEXWT tables files after acheckpoint. A ClassCastException appears afterrestarting and selecting data, see the case below.then it is impossible to shut down the databaseand in properties files there is modified=yes.And in the table_zone.dat, there is only :And nothing about the 4th column !Regards,
org.hsqldb.Library.monthname bug.
problem with negative long values.The attached testcase produces an error where anewative long -9129298924866545938L is stored to aBIGINT column and becomes 922310382 when it'sretrieved.Sorry, but the testcase requires Hibernate 2.x in yourclass path.
gigabyte limit.Hello,While inserting data into 1.7.2 rc2 - I run into batchupdateexpections which I believe are caused by java.nio expandingthe data file another gigabyte when the data file isalready agigabyte. java.nio has a two gigabyte limit. Java version1.4.2_03 on windows xp home addition. Thanks-Tim
Null pointer exception after crash.HelloI had a JVM crash during creation of a database. TheJVM crash was unrelated to hsql. When starting thedatabase again I get this exception in the prompt. Ifound that the [Database].properties file was createdbut empty (0 bytes). I suggest adding more errortolerant reading of the [database].properties file.Ps. I am using 1.7.2RC2
Text tables marked as read only corrupt script. 1.7.2RC2.It appears there is a bug when creating read-only texttables.Steps to reproduce:Also, SHUTDOWN COMPACT fails due to the same issue.BTW, this worked in 1.7.1. I haven't tested other 1.7.2releases.
Concat behavior col1+':'+col2 error.When runningHSQL1.7.1 just returns null.HSQL1.7.2RC2 sends an errorWrong data type: For input string: "xx"took me a moment to figure out the reason.Maybe the ideal thing would be to return
Updates ignore check constrain.Check constraint added to columns work when doinginserts but fail (are ignored) when doing updates.ExampleThis example runs and wrongfully inserts a erroneous value.drop table prospects_may_04 if exists;
sum(col) returns a Long not an Integer.When a select sum(col) query is issued on a columnwhich is integer a long is returned.Code can crashed when people update to 1.7.2 and usecasts.For large sums Long is good of course, but then peoplecould be using BigInt datatype for such columns.If you keep the returning of longs, you could make a bigannouncement in the readme.
IndexOutOfBoundsException on update.With the current 1.7.2-rc2 release, I can reproduce thecrash described by the stack trace below. The exceptionis thrown when updating a single row in a table.The environment is Windows 2000, J2SDK1.4.2. hsqldb isbeing used as the back end to an Orion applicationserver, and is running in server mode. The table beingupdated is defined as CREATE CACHED TABLE.If someone contacts me I can package up a databaseand send you the statement to provoke it. Running thestatement from the manager utility reproduces theproblem. I'd prefer not to post the database or thecontents publicly.Cheers!Jon
NPE on Constraint.replaceTable.Hi.In RC 3 (and previous, I would assume), it is possible toget a NullPointerException when atering a table,presumably when it has certain CHECK contraints. Ihaven't had the time to do a thorough test of all cases,but here is the one that caused the NPE for me:create table parent(id int primary key, name varchar);create table child(id int primary key, parent_id int, namevarchar, constraint fk_child_parent foreign key(parent_id) references parent(id), constraintcheck_child_name_is_not_null check(name is not null));alter table child drop contraint fk_child_parent;After running a short debug session, the apparent causesurfaced in the Constraint.replaceTable method, wherethe name of the main index is used without checking ifthe main index exists for the contraint. For thecheck_child_name_is_not_null constraint, there is nomain index, thus an NPE is thrown.Here's a quick patch.Fred: please verify that this is all that needs to bedone. It's been too long since I've poked about inConstraint.
RC3 Select INTO using prepared statement is broken.Was dingling about with PowerBuilder 9 and HSQLDBtoday when I noticed that a "select ...into..." issuedfrom the SQL console failed to create any table andinstead fetched a result set.Upon probing a bit, it turns out that PowerBuilderprepares the statements issued on the console beforeexecuting them....hmmm.Anyway, as of RC3, the "INTO" part of a prepared selectdoes not get executed, only the select part.After a bit of time spent today, I have a tested andworking patch for this.It will be part of my next release into CVS, due by theend of this weekend.Actually, this is a cool feature, now that it is working,since it is one of the few "prepared" DDLs that canaccept parameters.
CallableStatement set by name broken.My Fault.Bad loop and failure to create the lookup map.Fix will be like this:
HsqlDateTime.java switch to 1.2 error.HsqlDateTime.java version 1.26some methods has direct access to a Calendar instancesshould be fixed in attached file
SQLException for Empty batch.I get a "java.sql.SQLException: Invalid argument inJDBC call: Empty batch" when I do a jdbcStatement.executeBatch().I think it's an error to throw an exception in thiscase (the batch is empty). See alsoVersion "hsqldb_1_7_2_RC_3".
ArrayIndexOutOfBoundsException on select union.Problem with select statement, releases 1_7_2_RC_1,No such problem with release 1_7_1.
HSQLDB 1.7.2 RC4 with JDK1.3.Using JDK1.3 on Solaris, i'm unable to build the jar :It seems that BaseHashIterator sould bedeclared "public".Thanks.
IndexOutOfBoundsException while loading large table.Bug detected while loading up a huge table with lots offoreign keys, etc....It runs nearly to completion (running for maybe 5minutes), and then throws this. Not sure why. This isin RC_3I'm using SQuirreL around it, it is the standaloneversion loading up from a script file, here are myproperties....will try to reproduce on RC-4. The total size of thedata file is about 500 MB, script is around 20 MBcompressed. Hope this helps.
Problem with VARBINARY type.I just noticed that there's a problem with theVARBINARY data type using the current ReleaseCandidate. It drops the last character if the insertedstring is less than 10 characters.Here's the DDL:If you need any more information just let me know.
strange spaces occur with update in textfile for Table.When I update a Table (refering to a Textfile), mytextfile gets screwed up:(the dots are spaces). I get a lot of lines filled withspaces and it seems I have as many spaces as the lastline is long.properties:
RC4 - Assert Exception in standalone mode.Hi!I'm running a JDK 1.3.1 application perfectly fine withHSQL 1.43 and HSQLDB 1.7.1.But with 1.7.2 RC4 i have the following exception 1 or 2seconds after star:Assert failed: java.lang.ExceptionThis only occure in standalone mode.Server mode works fine.This working fine if my application is single threaded.As soon as more than 1 thread access the database,then this exception occure...Note: I'm using multiphtreaded prepared statements.And non-prepared statement are synchronized within theapplication...Looks like a thread safety issue since the exception isunpredictible and occure randomly in different parts ofthe application.Hope this helps...Georges
Text Tables FK problem.There is a problem with using Text tables as parentForeign key table. The HSQLDB throws an Integrityconstraint violation when attempting to insert into atable that refers to a text table unless the text table ispreviously "selected".I've attached an example to demonstrate the problem.The example basically does the following:1) create database tables. 2 tables: one cached tableUSER and one text table USER_TYPE. This is sourced byuser_types.csv. The USER table has fk constraint toUSER_TYPE table's unique index on USER_TYPE_CD.2) attempt to insert into USER table. It fails.3) select * from USER_TYPE4) re-execute same insert statement: it succeeds.
TestCacheSize.TestCacheSize results for Windows 2000.Ran 40000 and 1000000 cases in expected time.1500000 case was aborted at 18 hours (expected time2 - 4 hours).Since the 1.5 million rows case took so long, I haven'tattempted the larger cases.
Insert-Select problem in RC4.This jdbc sql query have problem.step A: create tableIt looks like jdbc will set null value not constant value 1.
File Locks not released when getConnection() Fails.We would like to make it so that we can restore theHypersonic data when it gets corrupted but whengetConnection() fails it doesn't release the locks onthe files so we can't do this. I just created adatabase and then changed some of the data values inthe .script file and I got this exception:If you need any more information then let me know.Dave Johansen
Strange Exception message on own library functions.I am working on a library function that can throwIllegalArgumentExceptions.The method itself is working and can be called from hsql(after GRANT ALL ON CLASS "de.test.Library2" TOPUBLIC).However, if an IllegalArgumentException is thrown it ispreceded byUnknownNow I know what's going on, but users might beconfused by the false "Unknown Function"package de.test;
NullPointerException in Connection.close(), RC4.I obtained NullPointerException during connection-close() method:
hsqldb 1.7.1 on Mac OS X.We are using hsqldb 1.7.1, on Mac OS X(10.3) with JDK1.4.1 bundled. Our program starts the hsqldb usingServer Mode, and connects to the hsqldb using jdbc.Our open connection codes are,We have traced into the program and found that every connection is closed.We use "netstat" on Mac OS X and found that everyconnection will create one record and it is not released.But on WindowsXP, jdk142, although every connectionalso create one record in "netstat", the above errormessage will not be displayed.We don't know if the many records in "netstat" arecorrect, or if there is any bug.We're very urgent to know the solution, and weappreciate your answer.Thanks.
Building HSQLDB with j2sdk 1.5.0-beta.When I tried to build the package withI received following errorvariable named enum is used in file Server.java but enum isa keyword in java 1.5.0I think it is easy to correctJacek
1.7.2rc5 breaks SQL statements working in 1.7.1.rc5 rejects my string query on empty strings:AND phonew like ''And it also complains about aggregate grouping.(Detailed sql to follow)I have been using hsqldb since 2000, and have not hadto modify the sql statements in my application sincesure about the exact version number) and 1.7 withoutme having to touch the sql statements.Perhaps my sql was not compliant with ansi-92 to beginwith, and rc5 is simply pointing out my original errors. Ido not know if this is the case, or whether these areactually bugs in rc5.To reproduce the Error 1:Changing the GROUP BY statement to the following fixesthe problem:GROUP BY Tickets.custid, Customers.firstaname,Customers.lastnameMy little applications had survived two major versionupgrades without sql modifications. It would have beennice if the same would have been true with 1.7.2. Inany case, keep up the good work!
CREATE USER & getConnection() inMemory mode.With In-Memory mode I try to create new user andconnect. Why it does not work?and SQLException is catched which logs:User not found: JUKUWhen I query SYSTEM_USERS then JUKU is there!
getColumns behavior changed.The behavior of jdbcDataBaseMetaData.getColumns(...)has changed in 1.7.2.With 1.7.1 I get an empty resultset back, although Iexpected to get the column list for my table.I found a workaround is to call getColumns like this:However, this breaks my existing portable databasecode.  Shouldn't 1.7.2 support wildcard for the schemaname?
wrong constraint name in violation exception.I create a table with a single column and a named uniqueconstraint on that column:Occurs both in 1.7.1. and 1.7.2 RC5I would like to retrieve the name of the violated constraintsomehow fron the SQLException thrown on the violation.
"400 Bad Request" when proxy server changes http headers.I am trying to connect to a hsqlldb database using theinternet.My ISP has some sort of proxy server in place. The httpheaders should arrive at my hsqldb server as ....Which causes a "400 Bad Request" to be returned.I cannot connect to my hsqldb server without goingthrough this "device" - www.netapp.com has details ofthe device - but I suspect it's just one of many.This occurs with RC5.
User defined ALIASes and built-in aliases.Hello! With built-in aliases, I can construct with ANDand OR as many built-in aliases together into one CALLstatement as I can and no exception is arised. But whenI CREATE my own ALIAS, it can not be constructed with ISRIs it bug or feature I do not know. We can use CASTing,but still would be nice to not to do it.Tanks in advance!AndreVersion 1.7.2 RC5 is used.
Time not accepting HH:MM.When a table has a field with type TIME, it didn't
getDatabaseMajorVersion fn -> error.Not exactly a show stopper, but I thought I'd mention it gave Abstract method exceptions when I tried to use them. I'm using getDatabaseProductVersion() instead,with no problems.HSQLDB version 1.7.1regardsIain
Order by bug of 1.7.1.We are using hsqldb 1.7.1, on WinXP with JDK1.4.2. Our program starts the hsqldb usingServer Mode, and connects to the hsqldb using jdbc.Our open connection codes are,The table to be retrieved is,The corresponding externalized SQL is,At the first time, this method could retrieve all the sixrecords from the table PP_QUESTION_PARTS, but thesecond time it is called, only four of them are retrieved,and the following records are lost,I'm very sure that every actual SQL is the same eachtime, It's so strange all the later retrievements lost thesame 2 records.Also if I changed the record to let PART_NUMBER in thesequential order like follow,Then every time the result is correct.Is it a bug?
hsqldb RC2 onward fails to start over nfs with jvm1.4.From RC2 onwards, hsqldb has an error on startup if thedatabase is on an nfs file system and jvm 1.4 is used.Hsqldb starts OK using jvm 1.3, or with RC1, or if thedatabase file is on the local disk.
1.7.1 client hangs trying to connect to 1.7.2 server.I accidentally had an older 1.7.1 hsqldb jar in theclasspath (before the 1.7.2RC5 one).The client was just hanging for ever when trying toconnect to a 1.7.2 server.It would be helpful if some exception was thrown like "Ahsqldb 1.7.1 client cannot connect to a hsqldb 1.7.2server"
1.7.2RC5 - CALL IDENTITY() broken?I tried out 1.7.2RC5 today and was unable to use myapplication to insert data into tables that use IDENTITYcolumns.MY application uses prepared statements of the form:In this case there is a CUSTOMER_ID column of typeIDENTITY. My program fails on the this line after theSQL INSERT has successfully executed:The error message is "function not supported"I've reverted to 1.7.1 and my program is working again.I didn't perform any 'upgrade' on the database itself, asfar as I can tell this isn't required.RegardsIain
CREATE VIEW and USER() function problem.Hi,I'm currently doing an evaluation of databases to selectone for a new project. Whilst evaluating your veryimpressive database I have noticed a problem.When creating a view such as ;When connecting using SA and performing the SELECTstatement used in the VIEW command I got the SA rowas expected. When I CREATE the VIEW and do aSELECT * from the VIEW I get no rows at all. Afterfurther investigration I found that the SELECT withinCREATE VIEW is run as user SYS. Which means I can'tcreate a VIEW based on the currently connected USER.This causes me a problem and is different to every otherdatabase I have seen which runs the CREATE VIEWcommand within the context of the connection.Is there a workaround to this or can it be fixed ?Thanks in advanced for your help.Matt Shaw
National characters in text table.Hi,I tried hsqldb text table but nationalCzech characters are stored as '?'.In other tables are stored in <database>.scriptas escape constant.-- for the same non-text tableUfak
ResultSet.first() throws exception...A call to ResultSet.first() throws the following exceptionwhen the ResultSet is positioned before first row:I can see why a call to ResultSet.first() should result inan exception if the ResultSet is positioned AFTER thefirst row. But not while it is positioned either before, orat the first row.This is clearly a bug, and I'll need to change quite a bitof ResultSet.first() to ResultSet.next() to get my codeto work. Well, it's doable I admit :-) But hey, I shouldn'thave to :
Compatibility issues from Linux to Windows?Using 1.7.1:I have created a DB instance on Linux. I checked in to CVS (asbinary) the .data and .script files. A co-worker on Windows (using thesame commandline) gets an error (see attachment) when trying tostart the DB and then the .data file is zero'ed out. I have spentseveral hours combing through the web, but couldn't find anything.What are we doing wrong?What's interesting is that if we delete the index creation lines from the.script file (which produces the output seen in the attachment) theerror doesn't occur, but the .data file still gets zero'ed out.Any help would really be appreciated!Thanks.Jason Rogers
Setting a byte[] of zero length throws exception.If I use a blob datatype with zero length size of thearray an exception is thrown.
*.data and *.backup not deleted.I had one cached table in my database but eventuallydropped it.I noticed that the data and backup file aren'tdeleted or at least set to zero size even aftercheckpoint and proper shutdown.
Test file for the "NOT unknown" issue.This file contains tests in the TestSelf format.These tests are not complete and may be improved.RegardsMassimo
server not starting.i'm starting a database and i get the following output:System.exit() is called nexti already restored the .data file from the .backup andthe error persists.i'll upload the database
buildJDK12.bat fails to include some files in jar.The buildJDK12.bat script that comes with RC5 fails toinclude the following directories (from /classes) in theresulting hsqldb.jar file:
Nightly tarball contains files with weird names (on Windows)All the files in the nightly tarball available from thehomepage have ",v" appended to the end of their names. Example:I'm using winrar 3.30 (latest version released on 2004)on WindowsXp to uncompress the .bz2 file.
"create view" fails when having identical column-names.the statement above works with DB2 und Oracleit works as well, if you only do the SELECT:Workaround :
Trigger fire callback data is incorrect.Hi,I've been doing some work with triggers. The BEFOREUPDATE FOR EACH ROW and AFTER UPDATE FOR EACHROW don't seem to be passing the correct data.According to the documentation Row1 and Row2 shouldcontain the before and after data but Row1 seems to bethe data to be updated with and Row2 is null.I tested this in my own code and also with theTriggerSample class and got the same result.I need both sets of data to make a decision in theTrigger.If this is a bug could the other trigger types be checked.ThanksMatt
Updated trigger data violates table constraints.Hi,When using Triggers I noticed something which I believeis a bug.If you use one of the BEFORE FOR EACH ROW triggersand modify the data that is about to be inserted into thedatabase the data that is inserted isn't checked againstthe table constraints i.e. NOT NULL or similiar.I found this while trying to acheive a veto of a changerequest. I basically nulled the data and expected thedatabase not to insert the new data or throw anexception or something instread it quite happily inserteda null row even though all the columns were NOT NULL.CheersMatt
ArrayIndexOutOfBoundsException when creating indices.I get the following exception when running the SQLstatement:in my HyperSonic database.
EBCDIC platforms not supported.The hypersonic engine is not handling character setsother than ascii. Running on the z/OS platform causesinvalid characters to be written to the script file. Thereare places in the codebase where ascii-to-unicode, andvise versa, conversions are being done. I believe noneof this should be necessary if using Reader/Writers. Anexample would be in the java.util.Properties source,which reads and writes to a text file and is platformindependent.The log reading is correctly using a "BufferedReader(newInputStreamReader(dataStreamIn))", but the same is nottrue for writing - and is directly using aFileOutputStream instead of a "new BufferedWriter( newOutputStreamWriter(fos, "8859_1") )" as is done in thebase Java Properties class.
CREATE TABLE with integer DEFAULT seems to fail.The latest CVS code produces an error for the following
Default column value of 'now' no longer work in create table.In 1.7.2_RC6 the following syntax no longer works in acreate table statement:This did work in 1.7.2_RC5. In RC6 I had to update mysql scripts to remove the single quotes from around 'now'.Not sure what is expected behavior, I just wanted toreport it in case using 'now' in a default column valueshould work.
RC6: switchtojdk12.bat followed by buildjdk12.bat fails.I downloaded/unzipped rc6, and immediately did a swtichtojdk12.bat (successful), followed by abuildjdk12.bat (fails). I am running jdk1.4.2_04 on this machine to build it.Output from buildjdk12 below:HSQLDB build file for jdk 1.2.x and 1.3.x*** we recommend the use of the ANT build.xml insteadof this method for all jdk's include the path to jdk1.x.x\bin in yoursystem path statement
Database won't shutdown after creating Triggers.Hi,If you create triggers using statements such as;and issue the SHUTDOWN command, from anotherconnection, with no or any of the SHUTDOWNarguments the command hangs the Server and doesn'tshutdown.I have tracked the problem down.In Server.java, the code;is looping forever as the activeCount is always equal tonumber of triggers that you have created.Unfortunately I'm not sure how to fix it.I have removed all my code from the fire() method onthe trigger to eliminate that.This is obviously fairly serious as it means you can'tcleanly shutdown the database if you use triggers.CheersMatt
java.sql.SQLException: File input/output error: saveSorted.I use hsqldb_1_7_1. It happend only once during soaktest and i don't know why.
Unexpected results using LEFT JOIN.I've tested the SQL below on several other databasesand got the 'Expected Results' (see below). HSQLreturns an unusual row containing NULL values (see'Actual Results').
SELECT NEXT VALUE FOR <seq>.select next value for <sequnce> does not work. Returnthe following error. Also there is not a NEXT_VALUEcolumn in the SYSTEM_SEQUENCES table for the sequencethat I created.
Wrong handling of non HSQL URLs.Try the following code (alone in a main, do not try toinclude the Oracle driver to the classpath):I get an exception:This is erroneous since the URL is not a HSQL URLanyway (you can put anything you like in the url, suchas real urls of other database drivers, except validHSQL URLs of course). Other drivers (Oracle, mySql,MSSQL) do not throw an exception in that case becausethe URL is not valid for them. With all these drivers,I get this exception:which seems much more normal.To my mind, this is an important issue since it canmask other (real!) exceptions from other drivers.Actually, my initial problem was while trying toconnect to an oracle database, I had made a mistake inmy oracle URL but got the HSQL exception instead of theoracle one because the DriverManager tried HSQL first(and I understand that the DriverManager cannot choosebetween two drivers which raise an exception)!
setObject and setBoolean don't map a Boolean to a int field.According to JDBC (table 8.9.5 on pagesetObject and setBoolean should map a java Boolean toan int field. But HSQL's JDBC driver seems to simplyoutput the boolean into a literal "TRUE" or "FALSE" andwill trigger an error when trying to insert such valuesinto a int field.The following test shows the error:
NPE in ServerConnection.signalClose()When multi-threaded connections, the runnerThreadvariable may be null.Perhaps can we swith the test to avoid this case likethis :
insert..into..select..from..group..by bug(?)There are no rows in tbl1, but a row with null valuesgets inserted into tbl2 anyway. Not sure if it makes adifference, but the jdbc url is "jdbc:hsqldb:."This is with 1.7.2 rc6b. Please let me know if furtherinfo is needed.Thanks,Ron
7.1.1 can't create table name matching keyword :-(.Can't use this SQL to create a new table.
getPrimaryKeys maybe broken.Hi,if I callfor this tablenothing is reported.I do not know if this is correct or not.ByeLorenzo
Wrong results if combining COALESCE, CAST and BETWEEN.Hi,if I submit the following query as PreparedStatement itwill always return all rows of Table1. The statementalways ignores the passed java.util.Date parameters.
Bad tmp directory for DatabaseManager.On Linux when I run as a non-root account and try tostart the DatabaseManager without any options:After some investigation it seems there is a bug inSince I'm not root, I can't write in the root dir (/)and it fails. Need to change everywhere getTempDir()result is use to create a file name to add a directoryseparator in the ConnectionDialogCommon class.
Can't compile with sun jdk 1.3.1_09 under windows 2000.Please,I am obtaining the log above when a try to compileBUILD FAILEDfailed; see the compiler error output for details.Total time: 14 seconds
Integrity constraint violation when delete all rows.It is not possible to delete all rows from tables where acolumn references the primary id of the same table (treestructure stored in the table). Problems occurs with thelatest release candidate: hsqldb_1_7_2_RC_6bExample of the table:
INSERT trigger does not fire.Hi,I tried to register an insert trigger with hibernate usingcreate trigger i_role before INSERT on role for eachrow call 'InsertTrigger'This trigger (which currently only consists of anWhen I create an UPDATE or a DELETE trigger, thetrigger method fires. The InsertTrigger class existsand can be found in the classpath.Any help is appreciated!Sincerely,Sven Herschel
IndexOutOfBoundsException after crash.The following error occured when tried to open adatabase that was open when we turned off the machineit was running on.We are running on Linux Java Desktop and accessing thedatabase through a java application through the JDBCconnection in hsqldb.jar from RC6 (30 may).
connection in stored proc. doesn't know URL.I have a stored procedure that makes use of theautomatically passed java.sql.Connection.Trying to call getURL() on the MetaData results in aNullPointerException.add something like to org.hsqldb.Libraryand execute call "org.hsqldb.Library.testProc"()to reproduce the problem.
jdbcDatabaseMetaData getTables bug.The problem is that when something creates a table whose name isNOT all upper case and then uses getTables to check for it'sexistencethe result will fail even if the name is correctjdbcDatabaseMetaData needs to call toUpperCase on all tablenames before adding them to the SQL.The whole point of JDBC being that you don't have to know thepeculiarities of a given db.An even better solution would be to support lower case db namesbut I'm assuming that won't happen any time soon.
SELECT EXCEPT EXCEPT problem.I have query which contains two EXCEPTS, the examplelooks silly but it is simplification of our real world query.The query returns different results in hsqldb and insapdb and it seems that it is because of order ofevaluation.THe idea of the last select is (123) - (12) - (23) so Iwould expect empty set. Thats what I get in sapdb. Inhsql rc6c I get 2,3. Is this a problem?
dbvis shows ghost hsqldbs.This is against 1.7.2Rc6c, dbvis 4.1.1 on JDK 1.4.2_031. Create a connection to a pre-existing embedded HSQLDBdatabase.2. Look around (open some tables)3. Disconnect from the database.4. On file system, in location of DB, note that the DB.lck file is stillthere. This should have been deleted by hsqldb.5. Delete the database files (DB.lck, DB.log, DB.script,DB.properties)6. Go back to DBVIS and Connect to the database.7. Look at the previously-viewed tables. You will see the old viewsfrom the deleted database, rather than an empty table list.
bit column does not work with "in" operator.Against hsqldb 1.7.1:I have a column that's of type "bit":the following SQL statement does not work:It also does not work with a prepared statement withsetBoolean:ThanksMoh
Error in script file line: 13 out of memory.Strange message, on DB starting i got an exceptionMy db files are not to big, db.script looks good also,what happend i don't know. The same problem afterswitching to RC6d.
IndexOutOfBoundsException while creating index.I have a database running in my application that I useto store about 2 million records in. My table iscreated with the following command:The table is created successfully, and is fullypopulated with data after some time passes. After itis done populating, I do a commit, then want to indexthe table, using:The first time I run it, it crashes with an index outof bounds exception ( below ). If I run it again, itfails. If I index the table before adding records toit, it works, but is slow. If I use a smaller dataset,it succeeds.I've looked through the issues in the bug reports, andit looks like a similiar bug was reported back in May (well, maybe not a bug, just a dain-bramaged user ).I'm using the default configuration for hsqldb... nospecial parameters or anything. As a lark, I broke mydatabase in half ( each with the same tables defined inthem ). Again, the indexing fails on the firstdatabase, but succeeds on the second. I figured itmight be a timing issue with records not being fullywritten, but even blocking the code for 10 minutesbefore attempting to index doesn't seem to help.Ideas?
java.sql.SQLException: File input/output error: d.backup.Hi there.I m getting File input/output error. Right now I mhaving 4 files in my database i.e. d.backup, d.data,d.properties and d.script. Last time when I started mydatabase it was running successfully. but when I wasshutting it down at that time, the power goes off, and itgot corrupted. Right now d.data file is of 0 KB. (Zero KB)and d.backup if of 11 MB. 'modified=yes' in d.propertiesfile and 'hsqldb.cache_version=1.7.0'. To my wonder,d.script file is also containing d.properties file'sstatement at the beginning with one exceptionis 'modified=no' and after that it shows some non-ASCIIcharacters. I think that non-ASCII character isconverted by hsql for my CREATE table statementscause I can not see first 3 CREATE TABLE statements ind.script and after non-ASCII characters it shows rest ofthe CREATE TABLE statements.Please help me out to recover the data from thedatabase as it contains almost 300000 records.Thanx and Regards,Heet Patel
cannot open database in jar when compressed.I tried to open a database which is inside a jar file.When the scriptformat is in regular text mode, it worksfine, but when I set the scriptformat to compressed, thedatabase cannot be opened.
setFetchSize.Hello, my email is fulvio.biondi@ingeniumtech.it.I'm waiting for registration confirmation but, in themeantimeI wish to submit a small problem with the 1.7.2 rev.RegardsFulvioThe setFetchSize() method throws NO_DATA_EXCEPTION.I believe the fix should be :
Sub-select in WHERE clause of DELETE broke after 1.7.2RC6b.The following statement executes just fine in 1.7.2RC6b,but throws an exception in 1.7.2RC6d and 1.7.2 Release:The exception I get is:JRE version is 1.4.2_05.I'll apologize in advance for wasting your time if thisturns out to be a "stupid user" bug.
column name become uppercase.execute the following code :you can get column name from rsmd ,but the columnname bacome "A"(uppercase),not "a",is this a bug?
Unnamed constraint causes error.The following queries produce a "Constrain alreadyexists" error in the latest CVS:
hsqldb.files_readonly=true broken in final release ?Hello,just updated from 1.7.2 RC4 to the final release(1.7.2.2) and HSQL doesn't work as I was used to.I have a database, just defined by the two filestest.script and test.properties.test.properties is the default properties-file, that isgenerated, in addition there's the linehsqldb.files_readonly=trueWhen I now connect to the database as usual:both files test.script and test.properties areoverwritten, the line hsqldb.file_readonly vanishes.When I insert new data they get added to the test.script.This is not the behaviour that appeared in RC4 !All my junit-test don't work any more, because theyalways need a prepared database, when a new connectionis established, but all changes should only be done inmemoryI checked the behaviour again with SquirrelSQL justswitching jars, not changing anything else.In RC4 everthing worked fine, in the final Versionscript and property files are changed.Here are the files in use:
CURRENT_TIMESTAMP SQL function generate a NullPointerExcepti.Version of hSQLdb is from zip file hsqldb_1_7_2_2.zipavailable on sourceforge.and SQLTool does not respond anymoreThanks !david
v.1.7.2.2: Error while creating more than 1 CACHED table.When I try to create two CHACHED tables in your SimpleCode Example testdb, following code:Only table "sample_table" is created in database,sample_table2 code generates this exception.
small typo error in html user guide.Chapter 2. SQL Issues->Sequences and Identity ->SequencesThe table name for the sequence is missing an s.
1.7.2.2: HSQL can't read its own script files.to reproduce on a fresh database:then reconnect to your database, and you'll get theso the leading 0 of the timestamp is missing.You should either be more strict when saving timestampsor not as strict when reading them.I know that this is a quite uncommon timestamp, but Ihave a database where timestamps are used asprimary-keys thus heaving no other special meaning ...
INSERT INTO SessionInfo VALUES (NULL, ?); CALL IDENTITY()Is this a bug? I'm using 1.7.2.2 In 1.7.1 this worked.
Server can't start after special CREATE statement.The bug is reported against the current HSQL-DB release 1.7.2.2.Start a new database server i.e. by an windows batchfile containing:The database abc is now generated.Then connect to the database using the Database Managerand execute the statement:No error is reported. Then shutdown the database viaSHUTDOWN.Now the server can't be restarted via the upper windowsbatch file. The error message is identical to the uppererror message thrown during the first shutdown.I would expect:1. If the CREATE statement is wrong, it should not beaccepted! An error should be thrown on client side.2. Otherwise the server MUST be able to correct anerror in the database definition itself. It MUST bepossible to start the server.
hsqldb.files_readonly=true dioesn't have any effect.According to 1.7.2 documentation,I'm settingin my default.properties (before starting the DB of course)and observing that this has no effect.After debugging this problem a little bit,I discovered that in classorg.hsqldb.HsqlDatabasePropertiesat the biginning there in the static section thereseveral sets of allowed properties defined, andfiles_readonly is not one of them.So, what happenes is that insideorg.hsqldb.HsqlDatabaseProperties.filterLoadedProperties ()this property (along with quite a few others) getsfiltered out before seeing the light of day.I don't really care about the property. I just want torun the database in such a way that all the changes tothe DB are not logged to .log file and are lost whenthe databse is closed. Is this possible?Thank you,Yuri
avg() returns integer value for integer columns.Creating a tableand inserting valuesavga is returned as BIGINT therefore the correct result2.333333 is casted from double to integer giving 2.Also the avg of integer-type columns should be returnedas float-type.
Concatenating strings in query.Concatenating strings in SQL-query results in output nullIF one of the strings is null.Ex select (STRING_DATA1 || STRING_DATA1 2) from...if either STRING_DATA1 or STRING_DATA2 is null, theresulting output will be null.This problem didn't occur in 1.7.1
Temp tables.If you have many connections, it is possible to create temp tablesfor each session (with the same name) without any conflict.How-ever, if you close one connection, then all of the temp tablesare dropped for all of the sessions.
left outer join - bug with index.left outer joint breaks as soon as an index is createdon a column in the where clause.-- the query doens' return a single row (ok)--now we create an index and run the same query again-- this time the query erroneously returns rows !
1.7.2.4 cannot read script files from 1.7.1.I create a table using:In the script file, 1.7.1. renders this asShutdown sequence completed in 0 ms.It seems that older versions generate a script file withattributes in an order that the newer version does notsupport. This makes it impossible to upgrade.
Error when using functions in ORDER BY.I am testing Cayenne ORM with HSQLDB. The followingquery runs fine on 1.7.1/Linux/JDK 1.4.1, but fails on1.7.2/Mac OS X/JDK 1.4.2:
jdk1.3+hsqldb 1.7.2.4, DatabaseManager StreamCorruptedExcept.we use jdk1.3.1+hsqldb1.7.2.4, if we run command :
problem with ResultSet.getMetaData.When trying to callI get a NullPointerException, when working in a Libraryfunction (1.7.2.4).add the following procedure to org.hsqldb.Library andexecute call "org.hsqldb.Library.test"();to reproduce.
Statement.setMaxRows(int) restricts inner queries.Statement.setMaxRows(int) restricts the number of rowsreturned by a select statement in inner queries like'INSERT INTO test1 SELECT * FROM test2'.The JDBC documentation says: "Sets the limit for themaximum number of rows that any ResultSet object cancontain to the given number. If the limit is exceeded,the excess rows are silently dropped." Therefore onlythe queries that return a ResultSet should be affected.My release number is 1.7.2.
hsqldb startup problem.I try to startup the db in code. (In a new Thread) Mosttimes it starts up ok but sometimes it startsup butdoesn't listen on the port it's supposed to listen.Below is the code i use to start the server.Hope you can help me out.Regards,Wim Heijboer
HAVING missing into the documentation.HAVING works fine but doesnt appear in thedocumentation :
jdk 1.4 requirement due to java.sql.Savepoint.Has a dependency on JDK 1.4 been introduced?specifically, the class java.sql.Savepoint is new to JDK 1.4.for additional details, see bullet [1] at
1.7.2.4 LEFT OUTER JOIN joins to many rows.Hi,the LEFT OUTER JOIN on a column joins also rows of thejoined table if its column is null.Example:
Unexpected token with "ORDER BY".Hi,I've got a small table with 3 columns. When I use the commandI've received the errorIf I remove the ORDER BY-part, everything works fine.Here's the create-command:At the moment, there is only one row in this table.Michael
NullPointerException after restarting of HSQLDB.After some restarting of my server which uses HSQLDBinternally I got an error when I try to start server
Function not supported.Hi.Following code lead to SQLException :"Function is notsupported":Btw, this code works on Hypersomic 1.7.2 alpha M release.Test example attached.
connection (not really) broken - memory problems.When trying to retrieve a rather large resultSet (about 500.000) from a 1.7.2.4 database, I get ajava.sql.SQLException:However, the connection wasn't completely broken.Executing another select with a small resultSet workedjust fine.Instead the cause of the problem was insufficientmemory.Assigning some more memory with -Xmx caused theproblem to disappear.I did this on my SuSe Linux 9 (512MB RAM), my WindowsXP computer with (768MB) didn't need a higher memoryassignment.It took me quite a while to figure this out.If the memory use is justfied and not the bug itself anoutOfMemory-Error or at leastwould be helpful.If you need more details - let me know.Thanks,Meikel
1.7.2 failed to restore DB after the application crashed.hi all,I have this message in my error.log.extra:
fails to add foreign key on quoted column.This problem shows in 1.7.2.A message appears saying that a token is not expected.It seems that quoted column names are not fullysupported. I also had a problem where the columnnames in the scripts written by HSQLDB did not quotethe column name even when the column name was areserved word or case sensitive (eg 'check').We are creating columns to represent fields with case-sensitive names over which we have no control, sosticking with upper case names and avoiding key wordsis awkward.
first values are used for all formula in select.all computed columns have the same value as the first oneassuming a table tbldesc:
Metadata.getColumns gets very slow after a while.Hi all,I discovered a bug which seems not so critical butwhich is critical for me...Try this algorithm:After a while, the getColumns() call gets slower andslower. You have a code example joined to this bugreport. Actually, it seems that the getColumnsindirectly forces the recreation of the SYSTEM_COLUMNStable, and that this recreation is slower and slower,just as if it was following back all actions that haveoccurred on tables since we connected.I'd really like this bug to be corrected since the onlysolution for now is to relaunch my app each time toreset everything is HSQL... or go back to version 1.7.1which doesn't have this bug.Thanks!
HAVING clause doesn't work properly with particular case.Engine doesn't return result if HAVING clause containsexpression about aggregated value and non-aggregatedvalue.this is sample SQL occurs this phoenomenon.
jdbcUtil.notSupported is broken.whenever hsqldb wants to report a "not supported" condition, it throws a prefabricated exception instance, known as "jdbcUtil.notSupported".However, the stack trace reported by it is the stacktrace when the jdbcUtil.<clinit> executed and not the stack trace of the call that throws the exception.Therefore, it is completely useless for locating the place of the exception.I'd recommend you to remove jdbcUtil.notSupported and replace all occurrences of "throw jdbcUtil.notSupported" throughout the code with so that correct stack traces are being generated.
Error in reflection class name in 1.7.2.4.In RowInputBase.javaI found a non existing class reference:This should be corrected to:
text tables not completely honoring database location.This test creates two databases, one in /tmp named foo,the other in /tmp/bar/ with no extra naming information.Database files for the second test appear as/tmp/bar/.properties, etc...The second test should create the test.csv file as/tmp/bar/test.csv, but it creates the table as/tmp/test.csv. This confilcts with the schema createdin /tmp named foo, which also has a test.csv file.Discovered in 1.7.2.7
TOP does not work with UNION.The TOP selection in a select statement does not workwhen connection two selects with UNION.I am using the latest stable version 1.7.2.7.To reproduce the bug, use the following SQL-statements:
select with group-by no longer works.I have a select that was worknig on 2003.12.28 RC_1/1.7.2but when I upgraded to 1.7.2.7 it reports an error.More detail on new version: 'Oct 2004 zip named -1.7.2.7'aka "latest release 5 of HSQLDB 1.7.2" from readme fileThe SQL:I do not know of another way to form the sql. It looksvalid to me.SUGGESTIONS? HELP!
NIO IndexOutOfBoundsException thrown from NIOScaledRAFile.I'm not really sure how to reproduce it. But today wegot the following exception trying to connect to brandnew (all db files have been removed) database.About this db, it's using 1.7.2 with cached tables.Any ideas why would this happen?
can't run on jdk 1.1 NoSuchMethodError java/io/File.deleteO.Hi ,I try to run the HSQL engine Version 1_7_2_[7/8] on azaurus with the evm JVM (JDK 1.1).To build the hsqldbz.jar I use ant with switchtojdk11and jarzaurus.If I try to run hsqldb I got this exception :
getTime/getDate/getTimestamp problems with Calendar.getTime(int, Calendar) does not work.getDate(int, Calendar) does not work.getTimestamp(int, Calendar) ignores Calendar all together.
parsing of user defined function args.I have a user defined function with a String constant arg.Example:parsing the function args causes an IOException inwhen it hits StringConverter.hexToByte(String).If I change this toreturn (String)o;everything seems to work as expected.
conversion from Float to int.The method Column.convertToInt(Object) is failing forObjects of type Float.The resulting problem can be experienced with thissample code :Results in :java.sql.SQLException: Type Conversion not supported
curdate trailing space.curdate() seems to be returning a string with a trailingspace.This doesn't return any rowsThe result looks okay e.g. "2004-11-30"I'm using version 1.7.1 but I've not seen this mentionedin the change log as a fix.email address alan@terapin.f9.co.uk
Nullable column rendered non nullable by check constraints.-- num_code is rendered non nullable by the checkconstraint applied to table KEN
java.lang.IllegalMonitorStateException.Java Corporate Post Office is starting...I developed a class that extends TimerTask. This classhas a "begin()" method that initialize an internalhsqldb instance. The code can be found herehttp:This code uses a server instance of hsqldb, so I havemy personal database and tables structure and data issaved on filesystemWhen starting the application, I have to create theempty db structure, BUT, with version 1.7.3 (and even1.7.2.9) i receive the following error:I saw the error comes from line 1260 of Server.java that isand, at a first glance, it is working fineHope this helps
Error closing db.data (IOException)Hi,I am using HSQLDB embedded within JBoss 3.2.6(Windows 2000, JRE 1.5.0), which is, I think, 1.7.2.4.I got a strange error while running the server:I really do not have any idea where this error comesfrom.Cheers,J-F
Wrong database file version.A database created with java 1.4 can't be accessed byjava 1.5:java.sql.SQLException: Wrong database file versionchecked on HSQLDB 1.7.2 and 1.7.3
java 1.5 compatibility.A database created with jre 1.4 can't be open with jre 1.5
update test set id=1, id=2.This is currently allowed.An error should be thrown, similar to Oracle:This is a low priority bug, I suggest I fix it myself.Thomas
Value for a Numeric column is not checked.Hi,when doing the following (extraction from the logscript) (HSQLDB version 1.7.2.4)It is possible to insert a value which is greater thanthe allowed ones.Best regards,PS: For another description see
can't login as another user during DB creation.The behaviour I will describe is new to 1.7.2.9-1.7.3 -it never happened in 1.7.1 (I didn't check all theversions in between).Let's create testLogin.script with the following line:Then let's try to connect to this new database with urlWe will get the following error message while trying tobut files testLogin.lck.lck and testLogin.propertieswill be created.If you try to connect as TEST second time - everythingwill work !!!After some additional testing I found that iftestLogin.properties exists - database is created andeverything is ok, otherwise - we get the error message.Workaround: precreate properties file before making newdatabase.Note: I opened the same bug in tools section by error,you can delete the duplicate there. Sorry.
Uses undefined com.sun classes.From the hsqldb gump run on Kaffe:It would be nice if we could build hsqldb with Kaffe,but using unspecified Sun classes that are not part ofthe Java APIs prevents that.cheers,dalibor topic
Crash evaluating a function in a subselect.Core function evaluation fails when the function isused in a subselect.Reproduced on 1.7.2 and 1.7.3 :Smallest test case i could get :
outofmemory error.We have multithreded application and many thread useDB at the same time (I know that HSLQ does notsupport this.Each one have to wait).They are using SQLstatements likeinsert into x (y) values ('a')then I have got java.lang.outofmemory.
SQL error.We have tried this sql statement on MYSQL and MSSQLit is okey.But HSLQ does not execute it.What is the problem.
NPE in subselect.When we use the following query, we get a NPE when noresults can be found in the subquery:doesn't give a NPE.
complex calculation cause exception error.In an attempt to calcuate standard deviation of data.Below is the select statement.
Unable to use WebRowSet.acceptChanges()This is not actually a hsqldb bug, but it's currently notpossible to use the new JDBC RowSet's acceptChanges() method to update the database with data from aRowSet.Here's some sample code that shows the problem:The last line results in this exception:The real problem seems to be that sun's WebRowSetImplis trying to set a transaction isolation level that hsqldbdoes not support. It would be nice if something couldbe done to allow the method to continue on with afallback isolation level, so that the acceptChangesmethod can be used. The way it is currently,CachedRowSets are extremely hampered by the factthat they cannot be used to update the hsqldbdatabase.Anyway, like I said, this is not a hsqldb bug, more of anice to have, especially since RowSet is part of the newJDK1.5. (but my testing was done using JDK1.4 inconjunction with Sun's rowset.jar).Thank you.
column not found in correlated IN subquery.When I try to run the attached sql script I get thefollowing error:Column not found: B_ID (ANSI Code: S0022)The same SQL runs fine on postgresql. Interestinglyenough the problem only occurs if there are rows in thetables. When the tables are empty the query executeswithout error and returns zero rows.I have verified that the bug occurs in the 1_8_0_RC1release candidate as well as the 1.7.3 stable version.
lockfile and mac osx.We have mac osx server where users home directories aremounted by several clients. On the client, hsqldb failsto start due to a problem in the locking system. Hereis an example with hsqldb logging turned on. Noticethat the directory is empty, and hence the databasecannot exist yet, and hence is not being accessed byany other process. However, hsqldb fails to start sayingorg.hsqldb.HsqlException: The database is already inuse by another process:It runs fine if I use a local disk. I presume this issome incompatibility between the hsqldb file lockingsystem and apple's afp disk mounting system???
NullPointerException with recursive constraints.Hi,if executingZal
Was: "Not equals (<>) excludes null", is now "Bug in LIKE".The following queryAs expected returns all rows where col1 has text notequal to 'xxxx' but does not return rows where col1 isnull. I would expect the null valued col1 rows to beincluded.This query returns all rows correctlyRegardsAlan
SUBSTR(myfield, 0, 1) returns Java exception error.The second argument in the SUBSTR() SQL clause acceptsthe offset of the string to extract, offset 1 for beingthe first character. If you erroneously put 0 as theoffset, HSQL returns the cryptic error message "Stringindex out of range: -1". I believe this comes from aJava exception thrown inside HSQL (it has the same textas a common Java exception) It would be nice if thedatabase returned a more friendly error message.I'm running HSQL in Server mode, and accessing itthrough a JDBC interface. I'm using v1.7.3.
Command line parsing errors.Running HSQL from the command line throws Javaexceptions on bad arguments:
OUTER JOIN WITH IS NULL.From Open Discussion Forum, posted by rainfun@users...I have two table a(a1,a2),b(b1,b2).there are three rows in table a. different is in the first row)so ,i change the sql into 'select a.A1,a.A2,b.b1,b.b2from a left outer join b on ((ifnull(a.a1,'')=ifnull(b.b1,''))',the hsql say this sql is not supported.but i execute thussql in microsoft sql server ,the returned result is what iwant.then , i change the sql into 'select a.A1,a.A2,b.b1,b.b2from a left outer join b on ((a.a1=b.b1) or (a.a1 is nulland b.b1 isnull))' again,the hsql returned result is not what i want either,theresult is but i execute thus sql in microsoft sql server ,thereturned result is also what i want .what wrong with my sql syntax? thanks in advance.The last query should work but HSQLDB does notsupport it yet.
UPDATE fails in a no-primary-key table when any value is NUL.bug report for hsqldb SQL
select * into table no longer works.Its gives the error:Unexpected token: INTO in statement [into] / ErrorCode: -11
insert into texttable (select * ...) does not work.1) Create test tables2) create a text table identical to customer (call it test)3) set test source to "test.csv"4) Execute insert into test (select * from customer)Statement fails with a NullPointerException
select * from text table returns no rows.select * from text table returns no rows
SQL: problem on recursive constraints on single rows.tested on 1.8 RC6&7here is the step to reproduce:create table mytable(field1 int not null, field2 int);alter table mytable add constraint pk primary key(field1);alter table mytable add constraint pk foreign key (field2)references mytable(field1) ;now process the following statements:a) insert into mytable values (0,0); --> okb) insert into mytable values (1,1); --> okc) insert into mytable values (2,1); --> okd) delete from mytable where field1= 2; --> oke) delete from mytable where field1= 1; --> Integrityconstraint violation PK table: MYTABLEI don't know if it is truly sql99 but logicaly if you canprocess the statement b), you should be able to processthe statement e) ?In most of other database it is the case.This case is quite typical for a tree structure.The workaround I found is to have the rows (0,0) andupdate the row (1,1) to (1,0) before trying to delete it.
OutOfBoundException: reparsing logs after abrupt shutdown.this bug has been found on a 1.8RC7on a specific case I got a OutOfBoundException duringreparsing the .log file at the restart of a server abruptlyshutdown.It seems that it is linked to an Update statement on atable with a foreign key or an index.note2: If I do a checkpoint, or a clean shutdown itworks fine.
Please remove profanity.In a recent source scan the following profanity was detected.Can you please have it removed for our internlacompliance.Package HSQLDBProfanity to remove: shitFiles affected:Thank you in advance.
Server putPropertiesFromFile wrong result.Trying to setup a server by loading the properties from anot existing file using themethod 'putPropertiesFromString' returns 'true'. TheJavadoc says: "Returns:true if the indicated file was read sucessfully, elsefalse". So I think the returned result is wrong.Example:
Error with CompiledStatementManager.freeStatement.I am running a stand-alone application with Hsqldb inserver mode. I amusing Hibernate and get the above exception whenHibernate executes aprepared statement. It looks as though Hsqldb isattempting to remove thecompiled statement from the Hsqldb session but throwsthe execption. If Irun this same code using file access and not serveraccess, I do not get theexception.Please let me know if I can provide any furtherinformation.Logging Statements
create user.Statement <create user a- password ''> is valid. you canlog on with user a- . After you shutdown hsqld andrestart you get an errorSystem.exit() is called nextunexpected token -it should be both possible to create a user a- via jdbcand to restart hsqldb with that user;or it should be both **not** possible for having aconsistent db. The actuell behavior could cause strongproblems after restarting, think about much users thatare allowed to create new logins !
PDF version of User Guide truncates lines in"Example Blocks".In PDF version, on page 4; "Example 1.1" shows:The Web version shows complete correct statement:This problem is not limited to this one occurance.Truncated examples occur further down page 4 and onpage 5.This problem affects the usability of the PDF version.The Web version of the user guide does not have thisproblem.
create user !Sorry for sending again:I test it once again:First of all :create user '8' password ''via jdbc!!!Look at the system user table: that user 8 is availableconnect user '8' password '' works fine !you run into an exception (same problem with user a- etc.)System.exit() is called nextchange manually create user 8 password"" tocreate user '8' password""in the .script file fix that problem!Thanx!
Creating table with a foreign key in self throws NullPointer.Version 1.7.3.3 has a bug that was not in 1.7.3.0.try:
ORDER BY in SELECT for CREATE VIEWs.I can´t create a view using the ORDER BY clausule inSELECT statement.Is it a bug or a feature not implemented ?See the example:
Race condition in Server.start() [1.8.0RC8].The javadoc comment of "org.hsqldb.Server.start()"states:This method waits for current state to changefrom SERVER_STATE_OPENNING.But the implementation of Server.java 1.8.0RC8 does notalways hold that condition. The code reads:The problem is that if the newly started ServerThread isnot (or too late) activated by the OS. Therefore it cannotset the state field to SERVER_STATE_OPENING andthe while-loop is never entered. To fix the race condition,make sure the state equals SERVER_STATE_OPENINGbefore entering the wait loop. I cut&pasted line 1973 fromServer.run() and now it looks like:Regards,Christian
Issue with Sequence nextvalue.Next Value in a sequence is returningcurrent Value + Number of Sequences in the databaseIf you have 3 sequences Seq1, Seq2 and Seq3 in thedatabse, following query returns 3 values eachselect next value for Seq1 fromSYSTEM_SEQUENCES
Don't support hibernate 3rc1.Got the following exception on the server side whenexecute application that uses hibernate3rc1:Comments:1) The same application works fine with hibernate 2.1.82) Don't work with hibernate3 and hsql 1.7.2, .1.7.3and 1.8.0rc9It seems like hsqldb (not hibernate) error because hsql_server_ (not jdbc driver) hung.
Restart of engine fails due to spurious locking issue.I have noticed that despite closing all connections andexiting a standalone database, at least one connectionstill remains.The defect is manifested in HSQLDB 1.7.3 and HSQLDB1.8.0 RC 8.If you compile and run the sample code below, it willrun fine for the first time. Second time (if it is runimmediately after the first time say within 2-3 secondsafter completion of first execution) it fails everytimeciting a database locked exception!The only workaround I could think of was to use theun-documented function:Angsuman Chakraborty
LIMIT and TOP cannot be used in subqueries.The changelog for 1.7.0 states that "SELECT LIMIT <n><m> ... is now treated as a complete SELECTstatement and can be used anywhere a SELECT isused".However LIMIT and TOP cannot be used in a subquery
select ... where varcharColumn in ('abc')  case sensitive.I'm using 1.7.3.3.Columns of type VARCHAR_IGNORE case can beselected ignoring case. This works only withvarcharColumn = 'abc'which matches values like ABC, abc, Abc ...But the IN clause always reflects the case of thecharacters.I expected to worl this too, likevarcharColumn in ( 'abc', 'def')
zip file for RC8 and RC9 does not have bin directory.Hi,I am trying to package a RC9 (or RC8 at least) RPM forhsqldb in JPackage.org devel area (we have a 1.7.3.3already in the production area) but I encountered thefollowing problems:1) The zip files for RC8 and RC9 do not have the bindirectory anymore, so no 'hsqldb' command, for instance.2) The RC9 zip file has the compiled .class files in it(I can just ignore it but it makes the src.rpm muchlarger unecessarily)Regards,Fernandofnasser@redhat.com
Out by one in jdbcClob.position.Found an out-by-one bug in jdbcClob.position(Clob,long).Have commited patch to hsqldb-dev1.Should be:
Error in Order By.Table: Test(ID:Integer, Cost:Float)SQL: SELECT ID, ' kr' + Cost FROM Test ORDER BYCost;In this scenario HSQLDB sorts the resultset by using aString comperator instead of a float-comperator. Thiserror-case is also true when doing descendent orderingand for double types. I have not tried this scenario for adisk-based HSQLDB.A possible work-around is to insert the Cost-field withoutconcating strings around, before the concated cost-fieldSQL: SELECT ID, Cost, ' kr' + Cost FROM Test ORDERBY Cost;This select-statement yields correct results but theextra Cost-field is not an option for my project
Empty resultset with quote in string.This SQL statement gives empty resultset:select * from customer where last_name='O''Connor60'I would have expected 1 record in the resultset.The following SQL statement gives 1 record in resultset:select * from customer where last_name like '%O''Connor60%'Can someone explain why the first SQL statement does notreturn a record ?
Select doesn't contain all rows in the rusult.Select doesn't contain all rows in the rusult. It happens forbig tables only. Some rows are lost.Example:If A and B is big enough, the result doesn't contain somerows.
getColumnDisplaySize returns huge number for a float.hsqldb 1.73Here is the simplest sql:select 1.0 from ...then getColumnDisplaySize will return 646456995.On the other hand,select 1 from ...then getColumnDisplaySize will return 11 which isreasonable.Binh
How to start server.Haii need a small help how to start HSQLDB server. ityped the following command in command prompt.Iinstalled my HSQLDB 7.1.3.3.zip flle in c:\HSQLDB3folder i tryied this command ini tryied as per your specification but it shows thefollowing errorexception thread "main" NoClassDefFoundError.and what is xdb please provide some elabration.so What is wrong please give me some suggestion.Thank you for reading this message.withregards,Baburao.
java.sql.SQLException: socket creation error.I`m geting this error message when trying to connect tohsqldb engine Server.I`m starting the server andmannager normally but cant connect to the bank.the commands I using are
Error: java.sql.SQLException: Unexpected token ORDER, requir.I got a error when use hsqldb_1_7_3_3, Error:
StoredProcedure - rset.getMetaData() causes Null Pointer.Calling getMetaData() after a query using a Connectionpassed into a stored procedure causes a null pointerexception.Stack Trace:e-mail: marc.smith@bi-uk.com
Too many open cursor.The method SQLFile.processSQL doesn't close thecreate Statement.So when it is used many times the error"Too many open cursor" comes from Oracle.It's easy to fix only insert the linestatement.close();at line 1717
jdbcResultSet does not properly adjust timestamps w/calendar.In general, the internal Hypersonic handling ofTimezones is flawed since the conversion done inColumn.java initially occurs without reference to anyTimeZone supplied on entry through PreparedStatement.This creates date objects violating the java.util.Datecontract that the enclosed fastTime field representmilliseconds since UTC epoch.This problem is largely corrected by adjustmentsperformed in jdbcResultSet, however these cannot becompletely correct since they use the supplied time asthe basis for daylight savings adjustments. As a resultdaylight savings times for retrieved dates will occurat a time offset by the current timezone, and not forexample at the local midnight.However, a more serious problem is that Timestampobjects are not corrected at all by jdbcResultSet, withthe result that Timestamps will be corrupted by storageand retrieval through Hypersonic, even if the sameCalendar object is supplied to ResultSet andPreparedStatement.This problem(s) are exhibited by HEAD as well ashistorical versions of Hypersonic stretching back atleast 2 years.A patch is enclosed against jdbcResultSet to illustratea partial solution of the more serious problem. This isagainst hsql 1.7.3.3 (rev 1.6 of jdbcResultSet)although the relevant code has not changed since then.
Update on TEXT TABLE do not work.If a update on a Text-Table is executed only the firstcharacters of the old row will be replaced by linefeed.Reason is the method remove in classorg.hsqldb.persist.TextCache. Calling ofr.getStorageSize() returns 0.To fix the problem I r eplaced r.getStorageSize() withr.getRealSize(rowOut).Karl-Heinzmailto:Karl-Heinz.Fleck@subito.de
Get java.sql.SQLException: error in script file line: 8 out.HSQLDB 1.8.0RC9:I get the following exception when trying to connect tothe database on startup:java.sql.SQLException: error in script file line: 8 out ofmemoryThe relevant line from the script is:It appears that the script is trying to set the table indexat a point in the data file that is well beyond the end ofthe data file (which is only 4,194,304 bytes long).This probably occurred because there was a non-cleanshutdown.Let me know if you want me to attach the database asI'll have to get permission from my customer.
hsql doesn't check length of text field.hsql doesn't check length of text fieldthe text field can save text out of the length .it has no errors. I found the problem until I move toOracle
arithmetic operation on bind variables fails.The attached code attempts to add two bind variables.Preparing the statement fails withThe same error resulted.This was tested on 1.8.0-rc9.
non-null bind variable evaluates as null.Executing the statement "select count(*) from testwhere ? is null" with 'hello' set as the bind variabledoes not return 0. A test case is attached. This wastested on 1.8.0-rc9.
bind variable in limit clause causes NPE in parser.Calling prepareStatement with "select limit ? 0 id fromfoo" causes an NPE in the parser which results in aS1000 general error SQLException thrown to the client.A test case (run on 1.8.0-rc9) is attached. The NPEthat is printed to the console is:
Integrity constraint violation.simple example:Lets say there is a row such as:1,1,1you can not delete this row..(btw, it is working inPostGre)
Script command vs Unicode.Hello!I have HSQLDB 1.7.2 with Russian characters inside. Iwish to export DB via script command and a bit laterimport it to another copy of DB.If I script DB I'll have something like INSERT INTO TTTVALUES('ID','RU','\u0423'). If I execute such script atthe DB, I'll get value \u0423 in the column instead ofRussian letters.Elias Ross (genman) said that it looks like a bug andask me for good test/example for it (see attahced fileand
getColumnDisplaySize different between hsqldb:file & server.The result returned by getColumnDisplaySize is differentwhen connecting to the database as a file and whenconnecting through the server. The hsqldb:file resultsare correct but the hsqldb:hsql are not.eg:lightware@mailbox.co.za
null exception in script file (Windows only)Procedure to reproduce:to conform with HSQLDB naming conventions- HSQLDB fails connecting when reading first line of theoo.script- that line is a CREATE CACHED TABLE (...) instruction- you get aerror in script file line: 1 null exception message- the exception comes from DatabaseManager.newSession()call, line 2449 of jdbcConnection.javaWorkarounds:- Removing the first line of the script removes the exception- That happens only under Windows.It works perfectly under Linux (!!!)Environment:- HSQLDB Release Candidate 10 for 1.8.0(but same with 1.7.3)- OpenOffice.org 2.0 beta m104(but same with m100)- SDK 1.4
SET Password => sqlException(Unknown Source)I wanna set Password via MD5 but this causes Exception.Looking more detailed I think it's due to somemisshandling of the input stream. e.g.??? why it fails in the one case, while in the othernot ???
NPE if sql.compare_in_locale=true in 1.8.0 RC 10.Opening a DB with sql.compare_in_locale=true cause aNPE inin org.hsqldb.Database.reopen() has do be placed beforthe call ofdatabaseProperties.load();to fix the bug.Mit freundlichen GrьяenKarl-Heinzmailto:Karl-Heinz.Fleck@subito.de
Duplicate row after uptade in 1.8.0 RC10.After update of a text table and closing the db without calling SHUTDOWN COMPACT, I get duplicate row in db.Mit freundlichen GrьяenKarl-Heinzmailto:Karl-Heinz.Fleck@subito.de
General error when attempting to getConnection.I got the following error:Every time I run my application i get this error. Theonly way i can fix it is to delete mydatabase.properties file which was mysteriously empty.then it works fine (created a new database.propertiesfile). But then it happens again after a while. (occursquite rarely).I can only think it became empty because of a strangesequence of events in the previous execution of myapplication.Thanks,richardk@carbontwelve.com
missing ends of lines.PDF doc for 1.8.0 RC10Long lines, formated using non-proportional font, arestripped.Screenshot from AcrobatReader 7 included.
Isolation Level not supported but no error or warning.In latest 1_8_0 RC10 version Transaction Isolation Levelsare still not supported. Method setTransactionIsolation injdbcConnection looks like ready for this feature, but methodsetIsolation (which is called by jdbcConnection) is stillempty:public void setIsolation(int level) throws HsqlException {}so, now I can set Isolation Level and hsql driver doesn'tthrow any Exception, but when I try get current level I stillreceive of course 0...I think, that If this functionality is not implemented yet, itshouldn't be possible to set any custom transaction isolationlevels without any errors or warnings.
incorrect row size in 1.8.0 RC11.Hello Fred,the class TextCache generates a incorrect row size, ifthe row before is empty. The size of the empty rowwhile be included.Line 508 in TextCache:int length = (int) dataFile.getFilePointer() - firstPos;firstPos contains the start position of the empty row.If you will use pos instead of firstPos, you get theright size.Mit freundlichen GrьяenKarl-Heinzmailto:Karl-Heinz.Fleck@subito.de
Cannot open DB inside of jar in 1.8.0 RC10.I have a in-memory database which opens fine in 1.7.3.I upgraded the DB to 1.8.0 RC10 and re-jared it. I nowget this error:
SELECT INTO does not use "hsqldb.default_table_type".Existing default in parser switch is:default :However, to be consistent withother "hsqldb.default_table_type" handling, it likelyshould be (roughly) the equivalent of:perhaps getDefaultTableType can be factored out ofDatabaseCommandInterpreter and placed in Session.I don't think Database is the best place to put this,because we may eventually want to implement sessionscope equivalents for some database properties, e.g.
Incorrect calculation for var_samp and stddev_samp.not using (n-1) divisor:patch follows:Index: SetFunction.java
DATEDIFF function returns incorrect results.I have a simple database and get incorrect results fromthe following query - between 23:00 and midnight localtime:This normally works as expected, and returns eventsreceived within the current day, but between 23:00 andmidnight it returns no results at all. "time_received" isdefined to be a TIMESTAMP.After midnight, the select statement works as expectedagain. I am wondering if this has something to do withday light savings processing or something?HSQLDB version 1.7.3 running under JRE 1.4.2 and1.5.0 on Windows XP Pro (all service applied). Systemclock is running day light savings time adjusted localtime.
CONVERT not working.CONVERT doesn't seem to be working and throwsan "Unexpected token in statement" error in 1.8.0-RC11.Examples I've tried:I've used CAST to work around this.
Random ArrayIndexOutOfBoundsException.running 1.7.3.3 built with JDK1.3 running in 1.1Doing some load testing we have 30 clients running hsqldatabase, we frequently are getting anArrayIndexOutOfBoundsException inHsqlByteArrayOutputStream.write() method. The clientthat fails and the location of the failure varies from run torun but we consistenly get this same exception.This was the failure on the last test run:
SET PROPERTY "hsqldb.default_table_type" does not work.'SET PROPERTY "hsqldb.default_table_type" cached'throws and access denied error in 1.8.0-RC12--Access is denied: hsqldb.default_table_type instatement [SET PROPERTY "hsqldb.default_table_type"] /Error Code: -33 / State: S1000--1.8.0-RC12 documentation clearly states thathsqldb.default_table_type can be set using SET PROPERTY:-- cut --The CREATE TABLE command results in a MEMORY table bydefault. Setting the value "cached" for this propertywill result in a cached table by default. The qualifiedforms such as CREATE MEMORY TABLE or CREATE CACHEDTABLE are not affected at all by this property. (SETPROPERTY)-- cut --
<column> IN ('value1',...) requires trailing spaces on value.When doing a SELECT * FROM <table> WHERE <column> IN('value') with sql.enforce_size=true set in the<Database>.properties file value needs the trailingspaces up to the field size in order to match.For example:Table Def:
Invalid username's.Hi Fred,I've just tried to create a user in RC12 with a name ofTEST-USERIt didn't like the dash (-). What are the valid charactersfor a username ? What is wrong with a dash in ausername ? If this isn't a bug but a feature where is thecode that I could change to allow dash's in usernames ?CheersMatt
ResultSet.getObject() returns wrong value type.version: 1.8.0.RC12I created a table with a column of type smallint; themanual (section 8) says that columns of that type aretreated as short/java.lang.Short values. However, whenI call ResultSet.getObject() on that column, i got anInteger value.I queried the SYSTEM_COLUMNS table and found out thatinteger and smallint values have the same buffer size,so it seems that short values are handled as intvalues. I think it's not the expected behavior.
jdbcConnection(Session) -> jdbcConnection(SessionInteface)in jdbcConnectionthe methodpublic jdbcConnection(Session c)should change interface topublic jdbcConnection(SessionInterface c)
ArrayIndexOutOfBoundsException from BaseHashMap.stacktrace from 1.7.3.3Our application has a lot of agents which collect dataand then senda copy of their database to a central server where thedatabases are openned and their data is copied into anOracle database.After openning and closing a number of Hypersonicdatabases, westart getting this exception on every database we open.I first noticed this problem in 1.7.2 RC 6b and thoughtI should upgrade to 1.7.3.3 and test it before Ireported it.Unfortunately, I do not have a good isolated test caseto attach to this. I have only reproduced it with ourapplication running for an hour after I shutdown theOracle database; it's openning/closing new Hypersonicdatabases the whole time.
database grows unlimitedly.Here is bug scenario:1) I have database with cached tables.2) I delete some LARGE rows with data3) These rows disappeared from table - but table sizeis NOT reduced. As a result, now I have 100M databasewithout ANY data!Database version 1.7.2
Significant performance optimisation in SetFunction.java.In SetFunction.java, function addDataPoint, thefunction uses Math.pow to square sk - (double) (n-1) * xi.This is vastly less efficient than simply multiplyingthe number by itself. the pow function is based on logswhich is why it is so inefficient.
Use of variable N very inefficient in SetFunction.java.In SetFunction.java, we have:private long n;However, every time we use n, we cast it to a double.So we may as well haveprivate double n;instead. Casting is inefficient and as functionaddDataPoint will be called many times if thestatistical functions are used, this is a big weaknessin the algorithm.
SOME returns null instead of false.In SetFunction.java, line 250, the function is meant toreturn false if count==0. However, line 183 returnsNULL if count==0 and is in front of this line.Hence the SOME operator will never return false. Itreturns NULL instead.INcidentally, the expression:return count == 0 ? Boolean.FALSE: Boolean.TRUE;can be optimised to:return(count != 0)
non-null doesn't work properly in TEXT tables.Using hsql 1.8.0.0, I got the following error:error in script file line: 17 bad TEXT table sourcefile - line number: 1 Attempt to insert null into anon-nullable column: column: DESCRIPTION table:MM_OALIAS.txt looks something like this:where DESCRIPTION is the 5th collumn.According to the documentation ,"", should beinterprted as empty string, and ,, as NULL. The errormessage makes me think that it interpreted ,"", as NULLany way, which it cannot be.
Aggregate function requiring group by clause check bypassed.If you use a function such as "left" on a column in aselect statement with aggregates, the checking that allcolumns not aggregated are in a "group by" is bypassedresulting in a garbage result. Here is my example:I have this table:name datatype width no-nullsNow, issuing this statement gives the correct error:select sale_date, sum(sales_price) from salestable;SQL Error at 'stdin' line 60:"select sale_date, sum(sales_price) from salestable"Not in aggregate function or group by clause:However, if I now wrap a "left" around the sale_date column, no error. Garbage result:
The "DISTINCT" command is redundant in the MINUS statement.It seems that the DISTINCT command is either notimplemented or is redundant, in the MINUS statement(select ... MINUS select).Not sure if this is a bug because some functionality ismissing, or if this is functionining as designed.
Error restoring attached log file.Version: 7.1.3.3Tonight I encountered an interesting problem with theattached database. The attached database fails to loadall data from the *.log file when you start up thedatabase. No error is generated, the data is just missing.I traced through with a debugger to find out what wasgoing on.The problem seems to be when a delete statementreferences a column named position. Looking throughthe documentation I see position is a valid functioncall so I suspect that is what has caused the problem.Unfortunately the way the system handles this is not good:1. It reports the eror using the Trace function.Unfortunately all tracing seems to be off by default.2. It stops trying to load any more data and truncatesthe log file.The net effect of those two things is that the data isjust gone.To get around this I'll probably have a go at renamingthat column but in the mean time I suggest thefunctionality should be correct:1. Position should be a reserved word and you shouldn'tbe able to use it in a table in the first place.2. Always log that an error has occured.3. Stop all processing and leave the database in aconsistent state.
DESC keyword is sometimes ignored.For some queries, if a DESC keyword is supplied it isignored and the result set is returned in ascendingorder. This phenomenon appears to be a function of howthe order-by column is referenced in the SELECTstatement. There may be other factors involved as well,as some attempts to design a minimal example did notexhibit the problem. I have encountered a number ofindependent instances of this problem, all of whichhave involved ordering on a DATETIME column.The attached file provides an example of the problem.For two variants of a SELECT statement the records arecorrectly returned in descending order. For two othervariants, the records are incorrectly returned sortedinto ascending order.Note that the phenomenon occurs with queriesauto-generated by Hibernate (http://www.hibernate.org/)when operating via its HSQLDB dialect. Therefore, it isnot feasible to simply avoid the problematic way ofreferencing the order-by column (unless the Hibernatedialect is changed).
Null Pointer Exception from using version 1.8.0.Using HSQLDB v1.8.0 in conjuction with JPOX, I receive
Error using JPOX query with HSQLDB.Note this error does not occur with using the samequery on a different database.Here is the error message reveived:
ArrayIndexOutOfBoundsException in jdbcDriver.java.I get an ArrayIndexOutOfBoundsException injdbcDriver.java:java.lang.ArrayIndexOutOfBoundsException: 4atorg.hsqldb.jdbcDriver.getPropertyInfo(Unknown Source)The DriverPropertyInfo array is initalized to a size of4. The method then makes assignments toDriverPropertyInfo at indices 1 through 5. TheDriverPropertyInfo array should be initialized to asize of 6 to prevent this error.
COALESCE/NVL/IFNULL(MAX(...), ...) returns NULL.If I create an empty table with hsqldb 1.8.0.1 byCREATE TABLE TEST_TABLE(VALUE DECIMAL);thenSELECT MAX(VALUE) FROM TEST_TABLE;correctly returns one record with a NULL value.But if I execute one of the queriesSELECT COALESCE(MAX(VALUE), 42) FROM TEST_TABLE;SELECT NVL(MAX(VALUE), 42) FROM TEST_TABLE;SELECT IFNULL(MAX(VALUE), 42) FROM TEST_TABLE;then the result is the same, although 42 should bereturned instead.
hibernate-generated SQL runs *very* slowly.I'm trying to use HSQL v1.8.0.1 with Hibernate, andhave come across a problem that appears to cause thedatabase server to hang and/or enter an infitite loop(CPU usage stays 100%).The attached file contains the database, which consistsof some tables, with some sample data.With debugging etc, I've obtained the SQL thatHibernate generates, that causes the problem:This version works, returning the expected 0 rowsalmost immediately.Unfortunately, I dont have control over the SQL thatHibernate is generating, so havent found a way to usethis (working) version of the select.No additional messages appear on the console. Also, ifI repeat the test with an empty database (ie tablescreated, but no rows inserted) then the problem doesnot appear.
Misleading exception in trigger handling.Hello,I wasted a fairly long time trying to find the error in the sqlstatement i used to create a trigger. The exception, that wasthrown had message "Unexpected token while parsing triggercommand". I thought something is wrong with the sql query, istarted. But after a time, i started debugging into your code, andfound out, that the error occurred, while hsqldb tried to instanciatethe trigger class, that unfortunately had no default constructor.I would appreciate finding a hint in the documentation about thatindispensible default constructor in a trigger class. In addition, theexception has in fact nothing to do with the problem. Could youplease fix it, too?Best regardsChristoph
Unique Constraint Violation with autoincrement on Text Table.When using generated keys on text tables, the engineadds ALTER COLUMN RESTART WITH statements in the scriptfile. If, after adding new records to the table the dbshuts down incorrectly, these values may not beupdated. If the db is then restarted, future insertsinto the table cause a unique constraint violation.If the ALTER COLUMN statements are removed, thedatabase oprates correctly and continues with the nextnumber.
Under 1.8.0.1 the getTables() method doesn\'t work.Using the below code snippet, under 1.8.0.1 the firstset of results (below the snippet) does not return thetable requested. When this same snippet was used uner1.7. 1 the second results are provided. This appearsto be a bug in the current implementation. My onlywork around is to go back to 1.7.1.that can't be rewound.
global temp tables with preserve rows not working.If I run the below script via the HSQLDB DatabaseManager the select returns no results.If the "on commit preserve rows" is removed then theselect returns results.
COT implementation should call ATAN.Most of the trig functions in Library.java call theunderlying Java code directly. But for some reason theCOT implementation doesn't call ATAN() in java.lang.Math.I am guessing it's because the coder didn't know thatCOT is actually ATAN, being 1/tan().The problem with is being implemented as 1/tan() isthat the Java specifications are very clear that theresult must be within 1 ulp of the correctly roundedresult. Results must also be semi-monotonic.This is guaranteed in the java.lang.Math library but isnot when you do the maths yourself as in 1/tan().A simple test is to play around with select statementswhere you select multiples of cot(+-PI()). They do notgive Infinity. Select cot(0) and it does.Of course, this is also because of the resolution ofPI() which can only approximate it, so this test isn'treally fair but it does make the point.
DELETE query with JOIN under 1.8.0.1.Executing a DELETE query with a JOIN throws anerror. Trying to work around it with:DELETE tblChequeDetail FROM tblChequeDetailWHERE EXISTS (SELECT chequeMasterID FROMtblChequeMaster WHEREtblChequeDetail.chequeMasterID=tblChequeMaster.chequeMasterID AND tblChequeMaster.CustomerID=1)also throws an error:Unexpected token TBLCHEQUEDETAIL, requiresFROM in statement [DELETE tblChequeDetail]
In the MOD function, a divisor of zero aborts entire dataset.If you use mod(number,divisor), with divisor zero, theentire result set is aborted on the divide by zero error.It SHOULD return NaN for that instance.This is very much needed when MOD is used across anindeterminate dataset (i.e. rows in a table where thevalues in those rows cannot be predicted).
CONCAT doesn\'t handle a single null value correctly.This is really bizarre because looking in Library.javaBut it returns NULL.Likewise CONCAT('ABC',null) doesn't return 'ABC'.I have a table DUAL defined that allows me to select a single row (yes, I know, it's an Oracle thing, sorry!).
CONVERT statement syntax is wrong. Comma causes error.The CONVERT statement syntax should be:However, this produces an error in the latest version of HSQL:However, this works:Which is the syntax for the CAST statement.Looking in Parser.java line 2785 there is this statement:It seems that isConvert is not behaving correctly tothe syntax is changing to that of CAST instead.
type-conversion error when using COALESCE with dates.COALESCE does not seem to work correctly when dealingwith dates or timestamps in some situations. Forexample, if I have a table "foo" with a DATE column"foo_date", this statement causes an exception:The error is:Using CAST in this case will also fix the problem, butit seems less reasonable to require it, since the valueis unambiguously a DATE.
SQLTool -> NullPointerException on Timestamp-columns.SQLTool fails if a select is done on a null timestamp column. Example:
SELECT statement behave different in different platform.I'm using hsqlDB version 1.8.0. I've re-compiled itfor Java 1.1 for the iPAQ platform. It was runningfine, except when I test a SELECT statement, I noticednot all the records are returned from the result. Butif I run the same statement on the Linux/Windows usingthe 1.8.0 for java 1.4.2. All the records will bereturned.Here is the select statement:The problem is:Any records that has the from_date='2005-09-02' willnot be returned on the iPAQ platform (hsqldb for Java1.1), but they are returned if I run on Linux/Windows(hsqldb for java 1.4.2).The database table (cut down version):
java.sql.SQLException: User not found :SA.I have lost two databases randomly from this and thedata is lost too. It appears to occur at shutdown thatthe files are not being shutodwn properly. When theapplication is restarted, the files become corrupted. Ihave lost both a tomcat user database and an ApacheMail database. I have also received copies of thecorrupt database from end users who are using anapplication which has HSQLDB embedded.The only thing in the script file is:
java.sql.SQLException: Unexpected token: GROUP in statement.I have just upgraded to 1.8.0.2, from 1.7.2 and my codethrew this error, when I was attempting to create atable. I have distilled it down to the attached example:What seems to be happening is that the SQL statementis being truncated after the word group. I have an easyworkaround by changing the name of that field. As faras I am aware the word GROUP is valid in this context,as it is just a field name but I am no SQL expertReverting back to 1.7.2 or cfhanging the name works fine
Create table failes after the table rename operation.The following code returnsBest,Ali Salehi
Failed to upgrade database.Data Crow uses the database in byte mode(hsqldb.script_format=3) as it can grow quite large(images are stored in the database, etc).It is virtually impossible for Data Crow to pick up anewer version (1.8) as we have to explain the user torun a SQL statement on their (as can be read in thedocumentation) old database / data crow version beforeinstalling a newer version of Data Crow.Is there a way to upgrade a "byte" database to 1.8without having the user to run sql scripts ? Can wesolve this in the code ?
Script reading in Windows 98.When using hsqldb 1.7.2 or 1.8.0.1 on Windows 98 withSun JDK v 1.4.2, whenever a script has a line breakwithin an SQL statement, the reading of the scriptfails with the message that there is an unexpectedtoken ' '. That is, it is stumbling on a non-printingcharacter. If I remove all the line breaks from withineach statement, it runs fine, so I figure it must bechoking on either the presence or lack thereof of theCR in the newlines on Windows.
1.8.0.1: NullPointerException in Index.child.We have a NullPointerException in the HSQLDB 1.8.0.1engine during an INSERT. The problem always producesthe same stack trace but doesn't necessarily happen onthe same data when we re-run our program (hence, wecan't provide a concrete test case). The problem onlyhappens on Linux (we have a Red Hat 8.0), whether weuse 1.4.2 or 1.5 (SUN VM).Here is the stack trace:We have an index on two columns of that table.We don't have the problem with 1.7.3.3.
Ant does not build corret hsqldbmin.jar.For release 1.8.0.2, if build is exectuted with "anthsqldbmin" for the non-server jar, the resultant jarfile does not contain any class files.The other jar targets build fine.Thanks.
columnDefinition disallows NOT NULL DEFAULT value.It appears that <columnDefinition> makes it either-orchoise, which is... unexpected and somewhat inconvenient.
OOM when deleting from tables with a lot of  rows.create cached table articlesall records have:There was 1983 "batches" 100 "articles" each, i.e.
Cannot rollback to named savepoint.Creating a named savepoint and attempting to rollbackto it after issuing a single SQL command fails with thefollowing error:Attached is a small example that demonstrates the problem.
Scalar functions X Distinct.for any scalar function used then left (ex. substr...)
how IFNULL work?Not really undestand why this dont work,for examle, in engine in memoryfor execute use HSQL database manager,Specification-Version: 1.8.0give errorAttempt to insert null a non-nullable column: column:IDtable Yhow i may do that in one statement?
HSQLDB will not load after a restart.I am having a problem where I have to reboot my appserver anytime there is a problem or I make an appserver change. This is because if I stop and start justthe Cocoon application the HSQLDB does not start. Oninitial boot of the app server everything works just fine. Iam running WebSphere 6, but I've also deployed thiscocoon application on Tomcat and experience the sameresults. Things I have tried so far to resolve:1) Upgraded to latest version of HSQLDB 1.8.0.12) Modified web.xml to use the ParanoidCocoonServlet3) Changed the init-classloader parameter to trueHas anyone experienced similar problems withHSQLDB? I've done a netstat before trying to restartand the HSQLDB port (9002 in my case) had beensuccessfully released. I can get around this byrebooting my app server every time, but it wouldcertainly be a lot easier to just restart the cocoonapplication.Relevant section of web.xml
TriggerSample doesn\'t work in Server mode.In the 1.8.0 release, I found the TriggerSampleexample which run perfectly in Mem mode.When I change the url forI found two issues :1) impossible to create audit table due to the factthat the server needs an argument for tn VARCHAR2) once the audit table created with tnlongvarchar, the server hang during the audit phase -impossible to insert values in audit table. If I skipthis audit phase all run OK, but it is the auditfunctionality that I want to use in an OOBase document.Best Regards
timestamp format bug.hello,it seems like timestamps are stored in a notjdbc-typical way which causes the system to actuallystore another value than the one provided. the problemis the representation of the nano seconds: thejava.sql.Timestamp class likes to represent them in away where you can cut the ending zeros. so for example:has 46000000 nano seconds. hsql likes to cut the firstzeros and preserve the ending ones. the bad thing aboutthat is, that it seems to be mixed up in the code sothe result is flawed. because has 460000000 nanos in jdbc representation (10 timesmore than it should have).the problem occurs when the db is shut down andrestarted. after that the values are flawed. i'veattached a testcase to reproduce the problem.i'm using hsql 1.8.0_2 and it seems to work with cachedand memory tables. actually, when using memory tablesyou can see the following line in the script:
build for JDK1.3.Have any one successful build project for JDK 1.3?It keep complaint aboutjava.lang.NoClassDefFoundError: java/sql/Savepoint,which I believe it is JDK 1.4 thingsThanks
can not make a remote jdbc connection.Hi,I am trying to make a remote connection to a hsqldbserver running on another windows xp desktop from mylatop, but got a java.sql.SQLException: socket creationthe local connection on the desktop was ok, the'netstat -a' shows that the hsqldb server is listeningon the default port 9001, and the firewall on thedesktop was disabled.Not sure it is a bug (I don't beleive), but anysuggestion will be appericated.Thanks,Marlin
ArrayIndexOutOfBoundsException on index creating.Hello, hsql team!The next exceptions happens very often when someindexes are created.If I restart the hsql server, the indexes are createdwithout problems. But, after sql statements describedbeneath, creating of indexes causes this exception:
NFS not supported anymore.We are using HSQLDB with JBoss 3.2.7. When we useHSQLDB version 1.8.0.2 we can't start the databasewhen the files are on a NFS mount. With 1.8.0.0 (default JBoss) it worked fine.Vincent de Weger
NullPointerException.I am getting this null pointer in the middle of a verylarge transaction ~45000 records over 121 tables. Theversion is 1.8.0.2And one of my tables becomes corrupted though I am notsure if it is the cause or result of this exception.While I can't send you the database due to securityissues, I can run instrumented code to test a fix. Iwill also see if I can narrow it down over the weekend.
JOIN on columns fail if alias with same name exists.The following select statementHello 2but returns an empty set.Testing the following query you'll get a SQL Exception:which is odd, since you won't get one with this statement:but still an empty result which is wrong.RegardsStefan
Desc order by doesn\'t work with alias columns.Hsqldb 1.8.0_2 has a bug in desc order by when usingcolumns aliases: it doesn't order data in descendingorder. I found out this bug using Hibernate 3.0.5generated queries.The following commands are able to reproduce the bugcondition:
Mac OS X service instructions incomplete.Mac OS X does not have a useradd command; instead, one needsto run the following to create an hsqldb group and user.Unfortunately, the commands below do not autogenerate a uid/gid,so one has to be selected. I chose 101.Doing this eliminates the need to create a full-fledged System user, with it's own (fat) home directory while maintaining the security of an hsqldb user. For a home dir for hsqldb, create /Library/Hsqldb/ and store your data there. This is where OS X has other services keep their local files.
null value as boolean error.create table test (state char(1));The same problem occurs if instead of false a subselectof the form 'id in (select id from othertable)' is used.Release 1.8.1 and 1.8.2, not yet tested with earlierrelease.
PreparedStatement: setInt() does not work.If i have created a Column with Type OTHER I cannotsave an Integer as Integer.If I try to setInt I get an Exception which say cannotconvert from Long to ??? (since I already applied myown workaround, don't know the EXACT ExceptionType -but I remember clearly it has to do with conversin intoLong)
PreparedStatement: setObject fails.I have created a Column with Type OTHER and I want tosave PageFormat I get an Exception.Is it now supported or not?
Error with the \'LIMIT\' at the and of \'SELECT\' statement.Good day.When i execute 'SELECT' statement without anythingbetween table name and 'LIMIT' at the end of statement,for example:then it executed successfully.Thank you for a great work (and sorry for my English).Alexei.
Built-in functions NOW, CURDATE, CURTIME return null.The built-in functions NOW, CURDATE, CURTIME returnnull. See the related functions in org.hsqldb.Library.In earlier releases (e.g. 1.7.1) the functionsreturned a valid Date, Time ir Timestamp.So for instanceresults in a null value i.s.o. the current timestampin the LASTMODIFIED column of the newly createdMYTABLE record.
UNION fails.I have a table called "sta_authentication", thistable has >40000 rows.When I tested UNION and got some strange results. Tryand execute the following query:This results in 10000 rows, it's WRONG!The correct should be 20000 rows.
Criteria order on date/time, setMaxResults/setFirstResult.With Hibernate (3.0.5) and HSQL (1.8.0.2) when I'mtrying to get the latest object with Date/Time fields,I get unexpected results which seems to point to off byone errors.With 10 objects, this returns unexpectedly the next tolast:I'll attach my testcase to demonstrate. Note that I'vefound this at work and the same code with Microsoft SQLworked.
Transfer and QueryTool missing from standard jar.The Transfer and QueryTool utilities are now missingfrom the standard jar (target "hsqldb"). I see thischange was the result of revision 1.69 of build.xml,which has as log message only "post 1_8_0 RC11",which I cannot interpret. The documentationcontinues to claim that these utlities are included,so I don't know if this was an intentional change.
Can not have filed with "#" in filed name.fails due to use of "PROGRAM_LINE#" field. Table iscreated automatically by using metadata from otherRDBMS.Error: Unexpected Token: # in statement [...]
data not fully loading in 1.8.0 with hibernate.We have an application that uses hibernate 2.1.8. Weare preloading data into the db with a small java app.We have been loading this data into a postgresqldatabase for a while with out issue. Wanted to createa portable version so we moved the database over tohsql 1.8.0. The data loader would not load all datacompletely and often varied in which data was beingloaded for certain tables. The majority of data wasthere but a few rows were missing. Switching to 1.7.3everything seems to work normally.Using the hsql standalone engine.Feel free to contact me for additional information.
\"Order by <column_alias>\" causes floating error.Issue:1. hsqldb would not issue streight SQL error duringparsing2. Error is floating - Order by works in one case andfailes in another
Name of constraint in case of vilolation not available.Submitted by Michael CodiniWhen running the following script a primary keyviolation is produced.
Synchronize problem with small .log.The NPE occurs when the .log file reaches its limitof 10 MB, while in the process of removing many rowsin chunks of 1000 rows for each commit.Using .log default size, 200 MB the NPE never occurs,my work-around for now.I have tested both latest release and (module hsqldb-dev) CVS-tags: hsqldb_1_8_0_3 and HEAD, same problem.
Wrong error message (alter table)I had a create table intruction:The problem I am reporting:After runningI received this error message:although I should receive column already exists error.Not a big thing, but I was looking for it for some time.
Exception caching gives incorrect stack traces.Exceptions for features not supported are cached.For example; in Connection.getTypeMap() rather thancreating a new exception, it returns a reference to astatic final exception (stored in Util) that isinitialised when first refereneced, hence stack traceis frozen to be the stack trace when exception is firstcreated.The exception thrown from point YYY has the stack traceof exception thrown from XXX! Even though 'Foo' isprinted to the console!Fix - throw new UnsupportedException rather than usingstatic finals to cache.
ResultSetMetaData.getTableName(int col)Hiwhen doing a select with an alias as follows you don't get the alias but getthe table name insteadselect name as n from company as c;ResultSetMetaData.getTableName(1) returns company not c like expected.This happens in the latest 1.8.02 version of hsldb..Thanks!
Multiple Sequences Cause Multirow Return with Next Value.I tested this under 1.7.2.2 and 1.8.0.2Create multiple Sequences:Retrieve the next value for sequence test1:This will return 3 rows instead of just one with thevalues:Repeating the SELECT will produce a result of:If you change the SELECT to a different sequence liketest2, it will return a rowset of 3 as follows:So each sequence maintains individual counts butinstead of a single row being returned, the rowset isbased on the total number of system sequences created.This makes it difficult to maintain multiple sequenceswith the expected increment.submitted by:
Inserts if some variables not bound.Code:Executed successfully, however value for column c is not bound.SQLException should be thrown.
DISTINCT does`nt work for functions.DISTINCT does`nt work for functions in version 1.8.0.2The bug is described inwas added to the specified version.
Add note that text tables not supported with res proto.Per thread:Since text tables are not supported via the resprotocol it would be good to have a note stating suchin the documentation for the sections describing texttables and the res protocol.Bob
Batch updates lose the original error message.I am using HSQLDB 1.8.0.2 and am noticing batch updatesdon't return detailed error messages. For example, ifan underlying update fails because of a uniqueconstraint violation, HSQLDB only reports "failedbatch" to the client. Here is a specific example:I'm stepping through the code in theSession.sqlExecuteBatch(Result) method.Line 1093 looks like this:This results in a unique constraint violation, so the"in" Result object represents an error. Here are someof the fields from that object:So at this point, the "in" Result looks correct. Butthe last few lines of the Session.sqlExecuteBatchmethod seem to discard the error information:So the "in" object that contains the error details isnever sent to the client, making it very difficult todetermine the true source of the problem.Instead, clients see something likeAlso see this forum posting:
multi-column index not always used.hsqldb 1.8.0.2 does not seem to be using multi-columnindexes for multi-column queries if a single-columnindex matches and was created earlier. Example:If I drop index1, the explain plan will then showindexMultiColumn as being used, so it is a valid index,it's just not being chosen when it would be the mostappropriate index...--Erich
PreparedStatement run as Admin.All PreparedStatements are run with Admin privs. Givingaccess to all tables for any user. This is a bigsecurity problem.
Connection is broken: org/hsqldb/lib/ArrayCounter.I am using version 1.8.0.2I execute this query:from the HSQL Database Manager and I get the titled error.I execute this query:and the result is returned fine.I call script <script_file>and all records are present. The table is a memorytable containing two columns: id and ref_count. id is aprimary key.Within my code, I'm fairly sure something happened withthe write for this record and although JDBC reported asuccessful update, the next call to identity() cameback with the previous written record's id.Please let me know if I need to be concerned about thisbehaviour.
concat(round(xxx, 0), \' yy\') appends unwanted .0.Hello there, I observed the following behaviour with hsqldb distributed with OpenOffice Base 2.0 (with Button "Run SQL command directly" toggled):(thickness being a float column). This is what I expect. Now, trying to append a string to the result, I tryselect concat(round("thickness",0), ' mm') as "thickness"which produces "3.0 mm" instead of "3 mm". Same behaviour with "||". Is this intended?
Assert failed: beginNestedTransaction.Version 1.8.0.2 HSQL, JBoss 4.0.3The following was thrown by JBossMQ when commiting atransaction:
IndexOutOfBounds on delete table.am using Tomcat 5.0.28, jdk 1.5, HSQLDB 1.8.0_02 andaccess HSQLDB using a datasource. When executing:The table mentioned is existing.This exact code runs without any problems in 1.7.2HSQLDB version.
The database is already in use by another process (embedded.I run the following simple skript per jdbc in hsqldb1.8.0.2 embedded mode twice. (The bug does not appear in server mode).The output of the 1st run is OK.In the 2nd run i become an error.If i wait 10 seconds i become in the 3rd run the OK output.The output of the 2nd run:
Adding column to table before a column with an index.I am using 1.8.0.1. Consider the following SQL:The addition of col_one works fine, but the addition ofcol_three fails with the error "There is an index onthe column to be removed". It appears that the code ischecking erroneously for indexes on the "BEFORE" column.I glanced at the source and there does seem to becommon code that deals with addition, modification andremoval of columns, so you can imagine the removalchecking code being confused by the "BEFORE" column.
HSQL WebServer.Hi,We are using hsql webserver to provide a java Appletthrough the network.It seems there is something wrong with requestprocessing since our applet cannot be downloaded to theweb browser. After a lot of debug and trace into theprocessGet method of the webserver it seems thatflushing the output stream doesn't end and the streamis closed before the applet jar is sent to the browser...Very strange isn't it ?To strange bug, we have found an odd (and dirty) fix:we added a sleep(2000) between the flush and the closeof the stream. Even if we know that this fix is reallydirty, it works in all cases for us. You shouldprobably investigate further to find the "real" fixbecause all this looks like a thread problem.NL.
NegativeArraySizeException from readUTF method.I have the database file, if interested. It is quitelarge.
English collation is not supported.I ran the following commandbut I got an exception. All the other collation namesare working exceptin 'English'.
NullPointerException while reading a text table.I get a NPE when I try to set the table source (SETI traced it down into the code and it looks like hsqldbdoesn't count the leading quote as a quote andtherefore misses the end of the first data line (itassumes it's still inside a quotation and therefore thenewline is part of the value. The NPE is due to theparser reaching the end of the file and skipping thelast (empty) line. This leads to not reading a realline of data which causes the NPE inside theDataFileCache#get (the object got from the store is null).
allow double args for modulo.Currently mod() only allows ints, so you get weirdresults if you try to use it on a table with doubles.For example:gives you 0 when you would expect .4.I think the mod function should be expended to allowdouble arguments. This might be as simple as changingBut if mod should only be used with integer argumentsfor some other reason, then mod(4.4, 2) should cause anerror instead of converting the arguments to integers.
Failing NULL value checks with complex expressions.There are still problems with complex expressionsevaluating to NULL in hsqldb 1.8.0.2, as I've alreadymentioned inSuggestion: The evaluation error for NULL values shouldbe fixed somewhere in the object comparison code as itaffects some more functions and expressions.
NULL Pointer Exception from DatabaseMetaData.A NULL pointer exception is thrown if thejdbcDatabaseMetaData class is instantiated from astored procedure. This occurs if the getMetaData methodof the Connection object passed into the procedure bythe database server is used.The problem appears to be that the connPropertiesmember of jdbcConnection is accessed directly from thejdbcDatabaseMetaData constructor. The Connection thatis passed to stored procedures as an automatic firstargument has connProperties set to NULL.I have added a check to jdbcDatabaseMetaData to checkfor NULL, and setting the useSchemaDefault to true bydefault. I have noticed no adverse effects; allDatabaseMetaData functionality seems to be fine.However, this is just a work-around.
Query failures/syntax errors.The following have been tried on 1.7.3.3 and 1.8.0.2and the results were the same. 1.8.0.4 failed as wecould not get the server started.We are looking to find versions of the queries thatwill work across HSQL, Oracle and SQL Server.Example 1This query works as written:This doesThis does work:A strategy similar to Example 1 works.
IndexOutOfBoundsException, SHUTDOWN deleted .data file.HSQLDB 1.8.0.1 ... The DB was probably nearing the 1GBmark.
SCHEMA and reloading server make tables public.These are the steps I am performing:- Define my schema and nest all of the tables andindexes with that definitions. These are CACHED tables.Run with no problem- I insert some data into a couple of maintenancetables that I just created.- I can select the table data by using the schema name.It is running as designed.- I then take the server down cold and restart it I seethe following. The schema that I created is stillthere.but the tables that I defined to that schema arenow not associated with it. The tables are now public.I am running the current 1.8.0.4
Erroneous rejection of input sql?I am using HSQLDB 1.8.0.The following query:fails with the following error:Since RA and DEC are valid columns in the SampleStarstable, I would expect this query to work - it certainlydoes on the other DBMSs that I've tried.Is this a bug or a feature request from your point of view?NB The query :is fine.Thanks,AstroGrid project
docs for SQL features of TEXT tables erroneous.I think HSQL is a great application and I love the texttable feature, but would you please change thedocumentation on Text Tables to indicate that (as fredtstated in April 2005) "Alterations to the tablestructure are not supported for TEXT tables," even inversion 1.8.0.4As was pointed out in the thread below, the docserroneously indicate that full SQL is supported by texttables. The cryptic, "This operation is not supportedin statement <alter statement>" does little to disabusethe user of that misconception.Alterations to the table structure are not supportedfor TEXT tables.Hi,I tried adding a column to a TEXT table throughthe HsqlDbManager, itgave the following error-Cant we add column"s in TEXT tables as we do in normaltables? As described in the documentation "The full range of SQL queriescan be performed on these files", we should be able to alter the texttable. Am i missingsomething?please reply,thanking in advance,sudhakar.
Possible bug causing exception in subselect.The following code throws an exception with a message"Column not found: MY_VALUE in statement". Note thevery similar query in the comment that happens to dothe same thing, but does not throw an exception:This is on version 1.8.0.4, binary release.
NullPointerException while calling Server.shutdown() method.Hi,i'm starting and stopping a hsqldb server (1.8.0.4)from my application.If i want to stop the hsqldb server i use the shutdown() from the org.hsqldb.Server class. While executingthe shutdown() method it came to the followingNullPointerExceptionIt seems that the "protected void shutdown(booleanerror)" method called two times. One time from me andanother time from the finally statement at the end ofthe run() method in the Server class which is calledafter closing the socket from the first runningshutdown() method. I think both methods runs at thesame time and without synchronize this error occurs.So I found a solution for that problem. Ichanged "protected void shutdown(boolean error)"to "protected synchronized void shutdown(booleanerror)". This change make sure that only one shutdown() method is executed and not two or more.
hoe to get next value of sequence.i want next value of sequence to store this as astudent ID. for example the rows of table are studentID (integer),name (String) and Data of join(Date).inapplication i called sequence.nextval to getting uniqueID for student to store student information. when icall this statement like seq_student.nextval which isshowing syntex error.how can i solve thisproblem.please give a solution.while inserting how toget seq_student.nextval.my query is "insert into studentvalues(seq_student.nextval,name,12-03-2003)";it is showing syntex error.please tell me how to solvethis solution.sorry for my bad english.
Column Alias Incompatibility.HSQLDB supports this:Other databases don't support it. I think HSQLDBshouldn't support it as well, as it leads toincompatibilities: the same query means something elsedepending on the database used. Example:HSQLDB returns 1 row, all other databases 0 rows. It isa valid query for all databases, but the result isdifferent. This is really bad if you want to write anapplication that runs on multiple databases.I suggest the behaviour should be changed in HSQLDB soit is compatible to all other databases.Thomas(P.S. this is a forum post, but as I didn't get anyfeedback there I create a bug entry for it).
Column Alias Incompatibility.HSQLDB supports this:Other databases don't support it. I think HSQLDBshouldn't support it as well, as it leads toincompatibilities: the same query means something elsedepending on the database used. Example:HSQLDB returns 1 row, all other databases 0 rows. It isa valid query for all databases, but the result isdifferent. This is really bad if you want to write anapplication that runs on multiple databases.I suggest the behaviour should be changed in HSQLDB soit is compatible to all other databases.Thomas(P.S. this is a forum post, but as I didn't get anyfeedback there I create a bug entry for it).
NullPointerException in jdbcConnection.close()hsqldb v1.8.0.4When I use Eclipse to turn on a break point exception forNullPointerException I see that the Finalizer thread isthrowing a NullPointerException injdbcConnection.close() if the Connection object hasalready been closed.According to the source code there can be only one culprit:should beThanks for HSQLDB !Tony.
Expression.toString makes debugging difficult.ERROR hibernate.util.JDBCExceptionReporter - Not inaggregate function or group by clause: org.hsqldb.Expression@182ef6b in statement [select top ?Note the Expression.toString() does not return anythingof any use so it is impossible to know exactly whichpart of this query is causing a problem. I had to plugit into mysql to get more helpful info.
Delete with unknown column.Having a table 'foo' with one column 'bar', thefollowing query returns an update count of '0' (zero):"delete from foo where xyz = 'bla'". I would haveexpected an exception, like "column 'xyz' not found fortable 'bla'" (at least Oracle behaves like that).Did I miss something or is it a bug?Rob
Not a condition error when alias=real name.using the sample database,leads to the errorNot a condition/Error Code: -106After changing the alias from TOTAL to TOTAL1(something different from the real name), the erroris evaded.The software I'm using needs to set an alias with thesame name as the real column name. Needs to have itfixed.
HSQL startup too slowly.Now I use HSQL text DB to store data which are savedinto .CSV files. In the HSQL text DB, there are fivetext tables, one of the tables is much larger thanothers, called [table A].I do a performance test for my application, made theHSQL DB be about 500M Bytes. I think there are about 1million records in [table A]. Then I restart theapplication, it cost nearly 1 hour to startup the HSQLtext DB, too slowly. And after the HSQL text DBstartup, almost any operation could not be processed.How to resolve the problems? thanks very much!
SELECT: S1000 General error java.util.NoSuchElementException.Unable to get row count for table PUBLIC.SENDJOBS.Using value '0': java.sql.SQLException: S1000 GeneralDatabase seems corrupted. Files are available.Are there any tools available to repair hsqldb files?
Refer to constants by name in Server.getState() javadoc.Clarify javadoc of Server.getState():from:I'm reporting this because I had to look at the sourceto find out the symbolic name of the constants.
Max Aggregate function does not work for me.Hi,I have this table schema:- When i run the following query:I get an exception:"Not in aggregate function or group by clause"The same query in posgrees and MySQL works fine.Regards, PabloPS: I've tried this with hsqdb v 1.8.0.5 and 1.8.0.1
getColumnClassName returns "double" for function columns.The Java API forResultSetMetaData.getColumnClassName(int i) says thatit should return the "fully-qualified name of the Javaclass" type that will be returned by getObject for acolumn.However, when it is called for a column that is theresult of a function returning a double, the result isthe String "double". Since this is not a class name,it cannot be used to get a Class object throughClass.forName. It also does not follow the descriptionquoted above.This can be most easily demonstrated by opening aconnection to an existing database (server or local),choosing a table from that database, and running thequery: "select pi() from TABLE_NAME", replacing thetable name. This will need to be done in code, so thatyou can call getResultSetMetaData() on the ResultSet,and then call getColumnClassName(1) on the meta dataobject. It will return "double".This does not only happen with pi, however. I firstnoticed it with floor, but have tested it with acosand abs as well.For, example in an table called EXAMPLE with a columna of type bigint, and data:a = (100, 150, 200) Each item is a record.Execute the query "SELECT floor(A/5) from EXAMPLE" andyou will get the same results from above.One workaround is to nest the select statement insideanother statement, such as "select * from (selectfloor(a/5) from example)" This fixes the problem,causing getColumnClassName to return"java.lang.Double," but this isn't feasible for ourapplication.
When adding a primary two column in one table.Error When adding a primary, two column in one table.find HSQL1.8.0rc1 ~ HSQL1.8.0rc5error message :
PK constraint picking up name of FK constraint.Run the ant build file in the attached archive. Itcreates a small db in /tmp/bugdb The script willexecute successfully. Run it again. It will remove thecontents of the existing db and recreate it - againsuccessfully. Run the script a third time and it breakswith the following error:The constraint FK_QUESTIONS_1_FROM_N_UQID was given toa foreign key constraint and yet the script fileassigns it to a primary key constraint. This is verywierd and very wrong.Possibly related to 1387237 ?
Add OSX-friendly path to search for hsqldb.cfg.OS X likes to have non-system daemon configs stored in(Yes, Hsqld is capitalized on purpose).
Tables/Views not found after db restart.After running the attaced build set (similar to thatused to identify bug #1547479), I reconnect to thedatabase and a large number of tables and views aremissing. No trace of them exists in either the .scriptor .log file and no data can be selected.There appears to be a cut-off point after which alltable creation statements, data entries and viewcreations are lost. No SQL error is reported in theschema creation.
Correct HSQL version number.hi there,is the result ofYet I'm using 1.8.0 version 5.I suppose there were fixes between 1.8.0.1 and xxx.5 ?For correctness, I believe the version number should bethe full one.cheers,Geert
The .script got corrupted!When connecting the following NPE occurs:What has happened, why is my .script file corrupted?Please test the attached database to reproduce theproblem.How can I restore the database?Best Regards,Krister
Version Number out of date.HSQL Version Numberis out of date: 1.8.0.5 (needs to be 1.8.0.7).
Negative SQLException error code.Current behavior:The method org.hsqldb.Trace.error(int, int,final Object[]) has the lastExpected behavior: SQLException.getErrorCode() returnsint value which could be compared to Trace.XXXX withoutMath.abs()
NullPointerException on Tomcat 5.5 at org.hsqldb.lib.HsqlTim.We are experiencing a persistent NPE after databaseshutdown with an application running in Tomcat 5.5.Stack track from catalina.out follows:HSQLDB version is 1.8.0.7Tomcat version is 5.5.20.The error does not seem to manifest on Tomcat 5.0.28.We do an explicit SQL SHUTDOWN call from theapplication when the application is shutdown.With "hsqldb.applog=1" we see "Database closed" inthe .app.log file. A few seconds later the abovestack dump is generated in catalina.out.
patch 1329486 is not merged with latest release.I have just downloaded the hsqldb1_8_0_7, however I donot see patch 1329486 "ensure HsqlTimer thread quits".Moreover I checked the references oforg.hsqldb.lib.HsqlTimer.shutDown() and it has appearedthere is no call of this method within hsqldb sources.Is that expeced?I use hsqldb with webapp: without mentioned patch eachwebapp server's shutdown results in following exception:
Read-Only setting is ignored.Just to follow the discussion at the Help-Forum:I include the Log from my application which shows, thatthe update is executed without any problems. Noexceptions, nothing.I would expect, that an SQL-Update would either resultin an Exception AND the values are not stored in theDB. I get neither an Exception NOR a rejected update ofthe DB (=values remain the same).Either I have missed an option or ...????
can't create view with aggregate extract select.this fails in 1.5 Java with 1.8 hsqldbthrown:Have managed to get this operating with the 1.4 JVM.It's the "extract" that is not liked.
Order by is not working correctly?First create table:Am I missing something?
Inner select with union returns bad results.Hi,bellow is a sample SQL script to demonstrate theproblem. The last select should show two rows, the rowwith event_id=100 should show value=100, but the valueis empty (or null). When I change thethe value for event_id=100 is shown correctlyTested with HSQL 1.8.0.7 (in memory).Thanks for your support, Jan
ClassCastException with union query.A ClassCastException is thrown by the server whenexecuting an union query with constants.Here is a simple example:An SQLException, wrapping the ClassCastException is thrown.With a more complex query the ClassCastException is notthrown by the JDBC driver within an SQLException butonly logged in hsql trace. After that the serverdoesn't work anymore.Regards
SHUTDOWN COMPACT aborts at a TEXT table.Since my DB.data file continued to grow I discovered"SHUTDOWN ABORT". Result (embedded DB driver):Couldn't shutdown DB.The lines of the respective table in the script filelooks as follows:Maybe HSQLDB has a problem with TEXT tables with onlyone column?
length of binary is wrong by factor 2.Hi!The length function on columns of type "binary"returns a wrong value, its two times of the value itshould be:create table hallo (zack binary)insert into hallo (zack) values ('0004ff')select length(zack) from hallothe last query returns a single row of 6, but itshould return 3.From the docs:Binary data starts and ends with ' (singlequote), theformat is hexadecimal. '0004ff' for example is 3bytes, first 0, second 4 and last 255 (0xff).Apart from the wrong length, storing and fetching thebinary data works well. So a "select zack from hallo"returns the correct 3 bytes. The behaviour does notchange when using prepared statements. The lengthfunction is wrong in the same way when using it in acheck constraint. Using varbinary or longvarbinaryshows the same results. Using function "octet_length"instead of "length" returns 12 instead of 6.The documentation specifies function "length" and"octet_length" for strings only - nothing is saidabout binary. I think, both functions should return 3here.Ralf.
buildJDK12.bat: ant jar building for Java 1.3 won't compile.Since 1.8.0.5 - "NIOScaledRAFile.java" is missed in thesrc-persist directory.
Bug in org.hsqldb.Servlet.I found a minor bug but a show stopper within org.hsqldb.Servlet class.InYou need to add forward slash before WEB-INF, otherwise if the real path will return C:\myproject\WebContent, dbStr will be C:\myproject\WebContentWEB-INF/database
Wrong Information in your guide documentation.The following section written like this:Hsqldb ServletThis uses the same protocol as the Web Server. It is used when a separate servlet engine (or applicationserver) such as Tomcat or Resin provides access to the database. The Servlet Mode cannot be started independentlyfrom the servlet engine. The hsqlServlet class, in the HSQLDB jar, should be installedon the application server to provide the connection. The database is specified using an application serverproperty. Refer to the source file hsqlServlet.java to see the details.Correction:It's not hsqlServlet.java but org/hsqldb/Servlet.java. There are no details in hsqlServlet.java because it's a dummy servlet class.Also, could you add how to make connection to hsqldb servlet like putting the following line of code:I have to trace & debug the source code just to figure-out the correct connection string for hsqldb servlet.
Not in aggregate function or group by clause.this statement work in every other dbms I use (PostgreSQL, Ingres, Oracle):
Inner select not working.The inner select is not working properly.e.g. if we have a 1 column table: -and we populate with some example data and do:select * from test where exists (select * from test limit 0 2)... does not work. I think its a problem with the limit 0 2 inside the inner select.
Locate function not working.Locate function to search for the index for particular string in any string is not working and returning 0 in all cases.
Trigger Issue.Hi,I have created a trigger on insert in the table and also define proper java file for trigger.Now after inserting a row in a table db is calling fire() method implemented in my java file. My problem is when i am trying to execute an statement in java file after trigger is fired, my database is getting hang.i can't do anything. After going through my trace i found that some problem is coming while calling DriverManager.getConnection(url,login,pw).I am attaching the code to make it more clear.ThanksAslam
TEXT(cvs) tables does not work well with identity column.In any case that the db had a unsafe shutdown. or reopen a modified CSV file.auto increment identity does not reset itself to a correct value. And duplicate key exception happen on next insert statement.
Not in aggregate function or group by clause.Hi,i've a problem with group by and having clause in inner queries, when the having clause references aliases from the outer select. This works fine in DerbyDB.I get the following error:Not in aggregate function or group by clause:Here is the script to recreate the problem:drop table PROCESSDETAIL if exists;
forgets primary key constraint name.In an empty database I create a new table with a named primary key constraint:Then I ask for the name of this constraint:With hsqldb_1_8_0_2 this correctly returns "BLAH", but with hsqldb_1_8_0_7 it returns "SYS_IDX_46".This does not happen for check/unique/foreignkey constraints, there the name is ok in both hsqldb versions.
Data loss when on rapid startup -> shutdown sequence.The attached sample application does the following:First it registers a shutdown handler for itself. Then it calls startDatabase() to start a network-capable HSQLDB server using the Server class, and opens a JDBC connection to the server. Next it calls accessDatabase() to prepare, execute, close and null some PreparedStatements, which are:OPTIONALLY it then calls Thread.sleep()to avoid the bug. Currently that is commented out.Having accessed the database, it calls System.exit(0) to trigger the shutdown thread. The shutdown thread calls stopDatabase() which closes and nulls the JDBC connection, issues Server.stop() then Server.shutdown(), and nulls the server.Bug:If the above process runs without calling Thread.sleep(), the database engine shuts down without data getting flushed to disk. Data loss occurs, but when Thread.sleep() is called, it doesn't and "db.log" contains the right data.Tested:On 1.5 and 1.6 series Sun JDK in a Gentoo Linux environment. Tested on different computers. The 1.6 JDK on one computer was installed from a Sun binary, the 1.5 JDK on the other computer from Portage.Recreating:Grab the attached Demo.java, copy hsqldb.jar into the same directory. Check sources and having ascertained their safety, issue:I stumbled upon this by accident, while chasing another bug. For me it's non-critical, I can let it sleep. It however seemed like capable of biting someone, and I'mnot proficient enough with HSQLDB to fix it myself.Best regards, lots of thanks for a neat database to play with, and good luck hunting those bugs! :)Complication / fooException.
German '' character breaks "like" operations.Found a bug in the German language / HSQLDB. HSQLDB does case insensitive "like" operations by making the comparison string upper case. Unfortunately, the upper case of "ß" is "SS". I was able to patch HSQLDB to resolve this issue, but I'm not comfortable that the fix is appropriate.Here is a diff of src/org/hsqldb/Like.java that fixes the problem (and probably introduces others):
Out of memory when manipulating indexes.When a database with approximately 350 tables is manipulated by using either CREATE INDEX or the DROP INDEX statement, then it starts taking insane amounts of time to complete on tables with less than 10 records in them. This eventually runs the JVM out of memory. The JVM is already using the maximum amount of memory that will work cross platform. We are using the JDBC connection for communication.
hsqldbmin target doesn't produce jar.HelloRegarding build target hsqldbmin:"ant hsqldbmin" doesn't produce the related jar file in the lib directory but produces a manifest-only jar file without classes nor resources.I think this is due to a <include > tag present in the "hsqldbmin" target in the build.xml that override all.Removing this "include" tag - and including all *.properties files in the build process - produce the correct and working jar file hsqldbmin.jarbyethanks for this great product anywaybye
Explicitly calling shutdown() causes low-probability hangs.Attached is a demo program which starts an HSQLDB server using the Server class.It tries to terminate the server by calling stop() and then shutdown(). With a rather low but still real probability (about a once per 100 runs) the shutdown() call hangs.I have observed that omitting the explicit shutdown() call and nulling the Server object instead works more reliably, perhaps even 100% reliably. It seems like some race condition or threading issue, but I'm not qualified to dig deeper.You can compile the sample using:Best regards and good luck!
A duplicate of bug 1400344 (almost)My query is virtually identical to bug 1400344,except that the column is of type DateTime, and I wish to discard the Time part.Because convert is not treated as a function it fails in the same manner a functions did.I fixed the problem by adding CONVERT to the iscolumnI am not convinced this is the correct fix, but is probably no worse than treating ADD etc in this manner.
org.hsqldb.jdbc.* can not be compiled with jdk 1.6.As some interfaces (java.sql.*) have changed since Java 5, several files in org.hsqldb.jdbc can not be compiled any more with javac 1.6.0.This is a stopper for using Java 6 in Openoffice. Please make hsqldb compatible with Java 6.
No support for reading data from older version using 1.8 jar.If I try to read from older version of HSQLDB( in my case 1.7.2) using version 1.8 JDBC driver i get the following error:-SQLException: java.sql.SQLException: Connection is broken: java.lang.OutOfMemoryError: Requested array size exceeds VM limitI think newer version of JDBC driver should support reading from older database version.
Database URL of type res: is converted to lowercase.A Database URL of type res: is converted to lowercasewhile parsing it (DatabaseURL.java:238). Thus it is impossible to open a database contained in a package hierarchy whose name contains uppercase characters. Java class loading is case sensitive with respect to both Class and Package names.Package names containing uppercase characters are discouraged but not forbidden, so converting a database URL to lowercase should not take place, at least not for database type S_RES.
Throwing Exception: Starting Server using J9 in Windows CE.
Exception: Starting Server in J9 under Windows CE.Throwing Exception: Starting Server using J9 in Windows CE Private: (?)No
SELECT LIST Does not allow literal 'ALL' as first column.Does not all 'ALL' (uppercase) as first column in the SELECT list.Query works fine.This happens only when 'ALL' is the first literal in the select field list.Understand that ALL is a reserved keyword but it is not same as literal 'ALL' or is it?
select(select... union select...) broken (!!)Hi,on (at least) the latest hsqldb release (1.8.0.7) there's a bug in union when it's the source of a select. There's an older report of this which is filed as "feature request":The problem is that these queries are not as uncommon as one might assume. E.g. when using hibernate for relational persistence and using union-subclassing, these queries are used often.So i would consider this as a bug with high relevance rather than a feature request.I've attached a test case that shows this bug.Michael.
java.sql.Connection#createBlob() not implemented.do it ASAP, i do not want to introduce HSQLDB-specific code like "new org.hsqldb.jdbc.jdbcBlob(byte_array_var)" into my app, as it SHOULD be DB invariant.
STUCT typo.In table INFORMATION_SCHEMA.SYSTEM_ALLTYPEINFO the record for the STRUCT type has "STUCT" as the value for the TYPE_NAME field.
Temporary Tables lose ON COMMIT PRESERVE ROWS.If you create a temporary table with option ON COMMIT PRESERVE ROWS, then you add columns with ALTER TABLE ... ADD COLUMN... the attribute ON COMMIT PRESERVE ROWS gets lost.Using the second form, the attribute ON COMMIT PRESERVE ROWS gets lost (as you can see in the database script file)It seems that this problem exists with any subsequent ALTER TABLE command, not only ALTER TABLE ... ADD COLUMN...Greetings,Alex
ORDER BY item should not be in the SELECT DISTINCT list.Here is the script to create the test data:When I now execute the following statement:I get following error message:The spec of SQL does not require an ORDER BY item to be in the SELECT DISTINCT list.
Critical Date bug in latest version (1.8.0_7)Suppose you insert a Date in a Date field (not a long representing an UTC for that Date) from a hsqldb table.Then, when you read the date inserted it's not the same as the original date.The 2 dates differ by a day or two. Even if you use TimeZone and Calendar and proper formating of the dates this still doesn't work.This bug was not present in 1.7.3.3 version.
Session Class Swallowing Stacktrace.The sqlExecuteBatch method in the Session class calls into the execute(CompiledStatement cs, Object[] paramValues) method of CompiledStateExecutor, which contains this code:But when control returns to the Session.sqlExecuteBatch method, the result is not checked for errors.Adding the following code to the org.hsqldb.Session class:Results in the actual SQL exception being displayed. This is much better than what you now see, which is "Failed Batch".
SQL: CALL TRUE; failes in 1.8.0.7.If you enter the statementcall true;in the DataBaseManager connected to a HSQLDB server you will get an exception.I stumbled on it while running the JUnit tests. Is a test case in testSQL.java, in particular testX1(). It will affect any stored procedure returning a boolean.It does not occur when using when using the in memory engine.Attached is a JUnit test.The problem is in Expression.java.A patch for 1.8.0.7 is attached.In the repository it has already been fixed as I have seen. I filed this bug only for users of the current version. It will go away with 1.8.1.RegardsWalter
Exception using "sum" function in "case when" else clause.An exception is thrown for the following query:selectHowever the following query succeeds executing:The only difference is in the position of the aggregation function.Both queries work on Oracle,DB2 and MSSQL.
RESTART WITH on text tables.Issue 1251640 needs to be reopened for 1.8.0.7.The description was as follows:"When using generated keys on text tables, the engineadds ALTER COLUMN RESTART WITH statements in the scriptfile. If, after adding new records to the table the dbshuts down incorrectly, these values may not beupdated. If the db is then restarted, future insertsinto the table cause a unique constraint violation.If the ALTER COLUMN statements are removed, thedatabase oprates correctly and continues with the nextnumber."This issue was reportedly fixed in 1.8.0.2, but we are still experiencing the problem in 1.8.0.7.
Exception while using any of the Transfer Tool.Hi,There is a exception that occurs when using the Transfer,Dump,Restore Tools under the DB Manager(Below). This occurs for the version above 1.8.0.
identity() doesn't work with preparedStatement.If I create a new record using a prepared statement and then, with the same connection, create a new preparedStatement and execute "CALL IDENTITY();" the ResultSet contains an Integer '0', not the ID of the IDENTITY column.If I do the same thing, but use a standard Statement to call IDENTITY(), I get back the expected result.I would expect to get the correct value of the new ID with either a Statement or a PreparedStatement.
ON UPDATE CASCADE does not work.Using hsqldb version 1.8.0.7.A virgin in-memory db, connecting with: jdbc:hsqldb:file:<path to folder + dbName> (nothing else touched and no configs altered).While defining the following tables i get: error code: -11, state 37000... it says UPDATE from the fk cascade definition is an unexpected token - no matter if defined with constraint <name> or if i do it in table definition itself.Here is a simple script that shows the problem:great job done guys and hopefully this is easy to fix...
Unsupported parenthesis on JOIN.The following query doesn't work:It throws a SQLException with the message:If I remove the parenthesis, then the query works perfectly.The problem is that, even if for this query the parenthesis aren't needed, for queries with several outer and inner join you have to use parenthesis to manage the "join priority".In other words, it isn't possibile to execute many real-world queries.
unsupported NUMERIC(precision,scale)The engine does not understand the numeric type like standard SQL dictates.Like DECIMAL NUMERIC can get a precision AND also a scale. But it looks like scales are not allowed today.
Incorrect right outer join result.Right join output incorrect result, when using after inner join.
Constructor of org.hsqldb.test.TestBase has wrong assignment.The power of the Eclipse syntax check reveals:"Assignment has no effect":Probably has to be changed to:
org.hsqldb.ServerConnection close()es incorrectly in run.In org.hsqldb.ServerConnection.run(), the close() is called outside of try/catch, which sometimes leads to non-closure (in this case observed in TestSql, which throws due to ClassCastException and does not stop correctly)The close() has to be called inside a finally, like
org.hsqldb.test.TestSql.tearDown should call super.tearDown.Instead of:
org.hsqldb.test.TestSql.testX1() fails with ClassCastExcep..See Bug #1737389, which is the same with another title, this is just a duplicate in case someone looks for "ClassCastException".Problems occurs in the code:This will cause the server to end
setNull(..) in preparedStatement behaves strange.I use the follwing code:the code does not cause any errors or SQLExceptions, but the result set is empty after the call, though it shouldn't be.If I replace the statement witheverything works fine.
ArrayIndexOutOfBoundsException on condition of type char.I'm using the latest code from svn (https), but when I use a condition on a character column, and include a subquery in the from clause, I receive the error:
NPE in Database.connect.I am getting this wierd error and not able to figure this out. Also, If I try to perform the action in debug mode, I do not get this error.Help?
Error casewhen in condition.Error occurs when in condition use casewhen for example:thanksDanilo
umlaut not working with text tables.After inserting a "" into a text table via jdbc, the text file contains corrupt characters. Reading the file via jdbc returns "?".
Empty rows in text tables.Deleted rows in a text table are not reused.Insert a row into a text table. Delete the row from the text table. Insert the row again.The result is a file like this:Do not know if this is documented somewhere but for sure not the behaviour expected.
Using database as file, no exception for unwritable file.I am attempting to validate that the choise the user does, when selecting the database output file, is valid.So forHowever no RuntimeException is thrown, and I seem not to be able to detect this condition and warn the user.
Dates are written wrong with hsqldb-server.I found a bug in the Server code or the JDBC Driver Client code.If I write a Date via a PreparedStatement into a database via network (with a "j"-URL) the date in the database is one day before the right date.I am using hsqldb.jar 1.8.0-9 (the newest one) with Sun Java6 on the client and the Debian Etch package with Sun Java6 on the Server (Version 1.8.0.7-1).
TEXT tbl - source file is locked until restarting the engine.Hello, hsql team!TEXT table - after making it READONLY the source file is still locked and cannot be changed until restarting the DB-engine.It happens only when the table is switched from read-write to read-only mode. When the table has already been READONLY, the source file is not locked.I hope, that the source file should be unlocked after setting READONLY and/or DESC mode.Regards,Yarick.
TEXT tables with DESC attribute are not re-read on select.Hello, hsql team!I tried the "re-reading" TEXT tables functionality via runManagerSwing.bat:From the documentation I have understood, that when option "DESC" is specified in 'SET TABLE my_text_table SOURCE "my_text_table_file" DESC', then the source file must be reread on every 'select'.(Doc: "This feature provides functionality similar to the Unix tail command, by re-reading the file each time a select is executed").Regards,Yarick.
javadoc on jdbcDataSource is unhelpful.The class level javadoc on jdbcDataSource is just copied from javax.sql.DataSource. This is highly unuseful as it doesn't say anything about the implementation such as if this datasource supports pooling or not. If you're just going to copy the documentation, then you should just put an @see reference.D
Infinite loop.Hello.I recently downloaded 1.8.0.9 and ran our JUnit test suite for our app. on it. A simple query produces an infinite loop in the Select.buildResult(Session, in) method.In the while loop on line 873:the loop terminates if nontempty is false or level is less than 0. notempty is set on 869 and, in my case, remains true. level, on the other hand, never gets a value less than 4. It alternates between 4 and 5 infinitely.One iteration decrements level to 4, but then the next iteration increments it to 5 and back again. It goes on forever.Here is the query that is being executed. Table names have been changed to protect the innocent:All of the id fields are indexed, but someColumn is not. Yes, it is a six way join but there are only a hundred records in each table. The query runs fine on MySQL, PostgreSQL, Oracle, and SQL server.The funny thing is, almost an identical query executes in our test suite prior to this one without any problems. The only difference with the previous query is that it participates in a UNION ALL with another SELECT statement and criteria is specified on a different column.I dug a little deeper and noticed TableFilter.findFirst(session) method on line 525:Since the tables involved in my query only have a hundred rows, I put a break point on this line and looked at the value of "value". Turns out the same result set from the query is being iterated over again and again.Let me know if you need anymore contextual information.I would like to use HsqlDB for unit testing, as it is very fast.Thanks!-Nathan
HsqlTimer$Task.cancel() hangs on shutdown in 1.8.0.9.Hi, I'm getting a deadlock when doing a database shutdown. The deadlock is easier to reproduce on slower system.It appears that HsqlTimer$Task first locks the cancel_mutex and then inside HsqlTimer$TaskQueue.signalTaskCancelled, a task queue.The HsqlTimer.nextTask first locks the queue, and then inside HsqlTimer$Task.isCancelled, the cancel_mutex.Thank you,
getMetaData().getPrimaryKeys is not working in v1.8.0.9.Here is what my SQL used to create the table:When running the following code it does not return any rows.I am running the latest version of hsqldb v1.8.0.9Here my java version running on Windows 2000:
Servlet NullPointerException guaranteed.
Rollback is not performed, leaving an inconsistent state.Problem: When executeUpdate throws an exception, a rollback should be performed on the database to prevent the inconsistent state.Solution: The below code snippet in the function should be modified:
Allocated resources are not released properly in ZaurusEdito.Problem:The function getPrimaryKeys of DatabaseMetaData can throw exception and a close() function on its return should be invoked to close the corresponding resource.Solution:The below code snippet in the function getAllTables
Prepared Statement is not closed in ZaurusTableForm.java.Problem: PreparedStatement.close() should be executed when an exception occurs while executing Connection.prepareStatement()Solution:The code snippets such as the one shown below in those functions should be modified to close the corresponding resource. For example:The same case applies to other methods saveNewRow, saveChanges, deleteRow
Prepared Statement is not closed in ZaurusTableForm.java.Problem: PreparedStatement.close() should be executed when an exception occurs while executing Connection.prepareStatement()Solution:The code snippets such as the one shown below in those functions should be modified to close the corresponding resource. For example:The same case applies to other methods saveNewRow, saveChanges, deleteRow
SQL CHECK constraints with CASE statement fail.Like the post at suggests, HSQL CHECK constraints can not be used together with CASE WHEN statements.If you try to insert/update, you will receive a non-informative "S1000 General error java.lang.ClassCastException", followed by the whole SQL statement. (here I have HSQL 1.8.0.9).If you have something like:I'd liked to add that information to the post, however I don't know how to access it.
Multiple servlets does not work.If you deploy two org.hsqldb.Servlet in the same JVM they will not work.Servlet.doPost() has a lineBut the dbId is always zero so it can't find the right database, hence can't find the right session hence throws a NullPointerException when the session is attempted to be used
HsqlTimer.TaskRunner thread must nullify contextClassLoader.Upon shutdown, the HsqlTimer.TaskRunner needs to nullify the thread "taskRunnerThread" contextClassLoader property via a setContextClassloader(null) on shutdown()By not doing this, if hsql is used in a hot-deployed environment, such as in Tomcat. When the context is destroyed and if shutdown() is called on the database, this thread retains a reference to the WebappClassloader, which will never be cleaned up out of the heap because a JVM thread group retains a reference to this thread. Over time this will lead to a permgen out of memory exception
Literal null in subquery overrides subsequent values.Given this temp table:However, the last query returns null as the value for both rows.This causes grief when using Hibernate with a table-per-subclass strategy.This is in HSQLDB 1.8.0.9.
TIMESATMP in UTC and CEST/CET change (Daylightsavingtime)When adding values at(28.10.2007) 2:30 CEST and 2:30 CET both will yield after hard storing/retrieving into db as 2:30 CET.this is due because the given calendar is not hounored properly.when changing this to store proper UTC values you have to look for the opposite change (at 25.03.2007 CET-> CEST) because time jumps 1 hour forward....This problem exists in other jdbc drivers (jaybird-jdbc from firebird) also. So I don't know if this is a bug in hsqldb or in jdbc...see attached junit-test.Thanks in advanceArne Plöse
Simple inserts / updates take randomly more than a minute.We use the hsqldb in a process oriented system where process and store records in the database within a few milliseconds.The hsqldb performs great most of the time, but randomly after inserting data @ 3000 records per minute, the database randomly takes a very long time to execute even a simple update query on a table less than 25 records.I am currently on a trial and error mode to create and try to fix the problem.How the current implementation is.1. HSQLDB version 1.7.2 I it also happens in the current release), running in Server mode.2. Tables definitions are Cached.3. updating through Java prepared statements (JDK 1.5).4. Rate of data input 3000 records per minute.output from my logs
OutOfMemory if telnet to port and enter two times enter key.I played around with HSQLDB which comes with Spring Framework 2.5.3, the MANIFEST says it is version 1.8.0.When I start the server and telnet to the port it started on and press the ENTER key twice I get an OutOfMemoryError. It is reproducible. The stacktrace is:
DatabaseMetaData.getTypeInfo.caseSensitive flag is incorrect.The JDBC DatabaseMetaData method getTypeInfo() describe the database types. There is a boolean column"CASE_SENSITIVE".With HSQLDB 1.8.0.1 it returns "false" (case-insensitive)for VARCHAR and "true" (case-sensitive) for VARCHAR_IGNORECASE.It should be the other way around.
more than one tab in CREATE VIEW STMT leads to a failure.I have formated my code with more than one tab. The statement looked like:create view x as select a.* from a union all select b.* from bThis is only a simple example.I have formatted the code like the following:This doesn´t work. HSQLDB allows only one [tab].More tabs are generally used within "more complex" querries.
Union Query returns different results with/without params.The following SQL statement (with parameters values inlined), returns the correct (expected) number of records:select count(*) from location where id in ((select location_id from stop where job_id = 0) union (select 9550 from job))If, however, I run the query as a PreparedStatement with parameters, it returns only the results from the first part of the UNION (ignoring the row from the secondary table-- job):The first query returns 136 records (the expected number); the second returns only 135. If the problem is with the query itself, I would expect a SQLException trying to create the PreparedStatement (which is the behavior I get when running the same query using H2). Instead, the query seems to work (i.e, no exceptions are raised), but returns the wrong number of records.
Problem for operations with ifnull HSQL1.8.0.9.I think of having to find a problem in HSQL 1.8.0.9Here the query
NPE on  jdbcPreparedStatement.executeQuer(String)Hi we're getting the following exception:
Insert trigger not working Version 1.8.Hello,Can someone test to see if they are getting the same result. I wrote a trigger and the insert action is not populating the old and new objects.As a test I ran the TriggerSample.java supplied with the project, and for the insert statements I get:These is the output following the test inserts into the trig_test table as outlined in the bottom of the TriggerSample.java example file.I tried version 1.8.0.9 and 1.8.0.10 with the same result.I am curretly running Java 1.6.0_03.Thanks,Scott
Missing StringComparator.java from (1.8.0.10) release.The StringComparator.java is missing from (1.8.0.10) release.It should be in the org.hsqldb.lib package.It's referenced in the TestSelf.java test.Looking in the source repository, I can see that org.hsqldb.lib.Sort has the StringComparator as an inner class - the org.hsqldb.lib.Sort in the source distribution does not.I've tried to build using the source repository version for Sort, but it fails (which in hindsight is no surprise). The test builds and works if I extract the StringComparator from Sort and put it in its own file.
DATE in a HAVING clause gives wrong datatype error.Seems that the text to date conversion in SQL statements is not handled when in a HAVING clause.See the following example:Seems specific to DATES. The same test with INTEGER for example works fine.
Index conflicts for multiple schemas.I have attached an SQL scripts that create two schemas: BOOKS and SONGS. Each schema has a table named PUBLISHER. Each table creates an index and constraint with name PK_PUBLISHER. The DDL succeeds but the SYSTEM_INDEXINFO becomes corrupted. This can detected by using the \di command in the SqlTool browser. Dropping the second occurance fixes the corruption. The bug is that two indexes of the same name but in separate schemas should be allowed. Another example occurs for the UK01_PUBLISHER example. (FYI, UK is my abbreviation for User Key).A second bug is schemas cannot be created using a database user as the owner / grantee.
casting bigint to numeric or decimal type does not work.Hello,I have a table with bigint datatype columns and I need to perform some division operations between them, and for that I apply a cast operation to decimal (or numeric).To my surprise, that cast seems to have zero or fuzzy effect, because the casted values still behave like integers (division gives no decimals). This should be something related to the bigint datatype itself, if I cast to double for example or if the column is just int then I get the expected result (worth to mention that in my samples, the bigint values were not even very big really).I picked up decimal/numeric cause they offer exact precision, but with this problem the workaround for me will be using double cast, which is just approximation but looks more stable.I just read the documentation and it tells that decimal divisions will have the larger scale of the operands ... in this case, both have no decimal part ... mmm, could that be the cause? Anyway, the result seems counterintuitive for me ... I would expect full precision in division as well (although maybe, that is not implemented yet).Regards.
Testdb throws NullPointerException.A trivial problem.member variable conn is not initialized.My email is bench_wang@hotmail.com
Bug in org.hsqldb.persist.ScaledRAFi.In my opinion there's a bug in org.hsqldb.persist.ScaledRAFile in all write methods.Instdead of:In void writeInt(int i) it should be:In void writeLong(long i) it should be:
Database shutdown closes System.out (log problem)Whenever a process database is shut down, the System.out is being closed by SimpleLog.close(). No other output (e.g. further logging in the calling application) can then be sent to the console.Call Stack:Thx for fixing this....Markus
1.9.0 - 'Numeric' boolean/bit columns.Hi,According to the HSQLDB documentation on bit and boolean types:'This type of column can also be initialised using values of any numeric type. In this case 0 is translated to false and any other value such as 1 is translated to true.'On attempting to use numeric values during an INSERT, this was stopped by method convertToType in the BooleanType.class (otherType.Type was Numeric, which resulted in the 'default' case being invoked, and a consequent cryptic message 'Value too long').Some background: I am planning on migrating to 1.9.0 from MySQL community edition, which uses 1 and 0 representing true and false respectively in its boolean columns. This is for the SourceForge project Kangas Sound Editor (http).In anticipation of your help, thank you!Paul
1.9.0: RETURN_GENERATED_KEYS.Hi,In 1.9.0, the behaviour to return generated keys from method calls such as executeUpdate(String sql,int[] columnIndexes) followed by getGeneratedKeys() doesn't appear to work - is it implemented yet? A quick look at the source code (in Session.java) indicates that this might be implemented for prepared statements (there is a call to cs.setGeneratedColumnInfo() which looks relevant), but not yet for direct statements.In anticipation of your help, thank you!Paul
Text tables with FK to memory tables produce an FK violation.I have a database that uses a text table that has a foreign key to a memory table. I insert data into both tables and shut down the applicaiton.The data for the text table is persisted correctly in the .csv file, and the data for the schema and the memory tables is persisted in the .script file.However, when the application starts again a FK violation is thrown.I suspect that this happens because the engine initializes the text table first, and then add the constraint without first populating the memory table (the INSERT statements are below the ALTER TABLE statements in the .script file).
documentation not uptodate and missleading.Hi there,when trying to configure my server using the server.properties, I noticed, that the documentation of the possible properties is not consistent. Unfortunately I read the section shortly after table 4.1 in "Advanced Topics"(URL: http:), which still shows the old property names like "database.i" and dbname.i" instead of "server.database.i" and server.dbname.I". Although the correct property names are noted somewhere else in the same webpage, it is still confusing and personally took me a long time to sort it out.The server itself also doesn't help, since it does not show an error or hint when using wrong or old property names. It just says "Properties read from..." even, if the server.properties file doesn't exist. It would save newbies a lot of time, if the docs would be updated and the server would tell the user about wrong configurations.
precision on DOUBLE unsupported, contradicting docs.According to:It seems that DOUBLE should support precision (although the precision is ignored by default). However, as of hsqldb 1.8.0.10 (also affecting earlier version), a table creation of the form:Either the engine needs to be fixed to reflect the documentation, or the documentation needs to be fixed to remove DOUBLE as supporting precision.
"checkpoint compact" causes server.shutdown to block.In version 1.8.0.10 having a database connection issue the command "checkpoint compact" causes the shutdown method in the server (when run from within an existing process, ie. using server.start()) to block. When calling server.stop() and checking for the server's state, the state never changes to shutdown.It worked fine in 1.8.0.9.Also, in the documentation, the getState() return values are referred to as in ServerProperties where they are in ServerConstants.
(1.8.0.5) S1000 General error java.lang.NullPointerException.Hi,I am using HSQL v1.8.0.5 and I found a bug in statements execution resulting in the following error:I understand that this bug was fixed in HSQL 1.8.0.7 but I didn't find the root cause or scenario causing this problem.This information is important to me for the following reasons:Any help would be appreciated...Thanks!
CALL IDENTITY()The example use of CALL IDENTITY() in Chapter 9. SQL Syntax doesn't work as a prepared statement.This implies that the correct way is to use multiple statements in a single statement which is not allowed in prepared statements.Clearer guidance on the use of CALL IDENTITY() especially in prepared statements is needed.It is not clear what happens if multiple threads are adding records. If CALL IDENTITY() is used in a separate statement what guarantees are there that the correct value is returned to each thread?
bug in BitType.convertToDefaultType()The code involved is from the svn trunk (I wanted to test HSQLDB with connection.prepareStatement(String sql, int autoGeneratedKeys)).I think the BitType.convertToDefaultType() has a bug. When I try to convert a Boolean to sybase BIT, it throw an error:
Lost data in temp table from union select.I have three tables (think table per subclass from hibernate) they all have two of the same columns, two tables have two additional fields each. I'm going to union select the three tables.
1.9: Delete trigger does not work.Delete SQL triggers doesn't seem to work in 1.9 (svn 22. Sep 2008).Here's a script to test (deletion should trigger an entry in log table):
SELECT DISTINCT (exp) ORDER BY 1.If a non-trivial expression is used in an ORDER BY clause in a SELECT DISTINCT, a variety of inappropriate error messages get triggered.For example: SELECT DISTINCT (base.Ref IS NULL) FROM Base base ORDER BY 1 gives "ORDER BY item should be in the SELECT DISTINCT list"; obviously, item #1 from the SELECT DISTINCT list is in that list.This error can be avoided by putting the column used in the SELECT DISTINCT list, but I've been getting problems with a "Wrong Data Type" exception in some circumstances (which I haven't been able to characterize) even then.I can provide schemas and detailed examples, but it seems to happen with all of the commands of this form that I've tried.
SQLC has been renamed to jIncarnate.Hello,On your web site (http) you reference SQLC tool. I'd like to inform you that the name of the tool was changed to jIncarnate.On a similar note, you may want to add Hammurapi code review tool (http) to the list of software which uses HSQLDB. Hammurapi stores code review information into HSQLDB.Best regards, Pavel.
Incorrect Wrong Date Type from "is null" as column.If you have a schema like:create table tasks(done timestamp)and you've got a row with a non-null done,select (done is null) from tasks;will give a Wrong Date Type error when it tries (done).getValue(session, Types.BOOLEAN) on line 3339 of Expression.java. It looks to me like that section should only run for an exprType of ADD, SUBTRACT, etc. (the non-default branches of the case statement following).
Foreign keys between schemas don't work.You can't make a foreign key between tables in different schemas.These few lines of sql set it up:All three of the following options incorrectly produce errors:
Typo on home page.There is a typo at http"In it's current version" should be "In its current version"
Incorrect result with statement.setMaxRows(1)Hi,please have a look at this code:The select statement always returns just one row.But when I define statement.setMaxRows(1) I always get as result "1" (for other sql statements as well) instead of the correct result.CiaoHolger
Function call syntax.jdbcConnection requires using exactly "?= call" for function call.I'd prefer less strong check, because simply using "? = call" causes much time loss to find out why it doesn't work.
cancel trigger action.i tried to throw an RuntimeException from a triggers fire method expecting the corresponding data not to be written to the database. instead it was.could/should be a way to cancel a triggers action.
1.8.0.10: Deadlock when using setWriteDelay.hi,while executing "SET WRITE DELAY" I get a deadlock (as usual not every time)between the Timer thread and the thread executing the SQL. Here's the threaddump:Java stack information for the threads listed above:best regards,Bernd.
trigger acitions executed after commit!the acions of a before-update-trigger are executed after commit! in the example i provided you read different values in two consecutive selects after a commit!the example prodces:this shouldn't happen, especially not after a commit!
HSQL jdbcConnection has no socket timeout?If something bad happens (like a rogue firewall rule that drops packets) to a jdbcConnection to an HSQLDB after it's already been opened, operations on the connection will hang for a long time. There's appears to be no socket.setSoTimeout() call in the connection setup to allow this to be controlled.
General SQL Error/NullPointerException in cascading deletes.I have a schema with two tables METRIC and SLICE. SLICE references METRIC with ON DELETE CASCADE foreign key. METRIC has hierarchical structure, i.e. it has PARENT column.When I issue delete in METRIC I get General SQL Exception / NullPointerException. Once it happens other connections start getting NullPointerException for no reason. The database server has to be restarted to fix this.I had this error in some other case with three tables connected with FK with ON DELETE CASCADE.I'm not privy to HSQLDB internals, my speculation is that it happens when some particular record has two cascading deletion paths, when the first path is executed it sets something to null. When the second path is executed, it dereference that something without checking for null and it results in NullPointerException.
Types.getTypeString returns NULL for BIT.According to the JavaDoc Types.getTypeString should return the SQL type string usable in HSQLDB for a given java.sql.Types int. Since BIT is one of the supported types in HSQLDB this method should return either "BIT" or "BOOLEAN" for it.I suppose a simple "typeNames.put(Types.BIT, "BOOLEAN");" in the static initialization should be enough.Affects: HSQLDB 1.8.0.10
DatabaseMetaData getColumns doesn't include IS_AUTOINCREMENT.According to the Java API for DatabaseMetaData the ResultSet retrieved by getColumns(...) should include a column which states whether the table column is autoincrement. HSQLDBs method does not return this information.getColumnsRetrieves a description of table columns available in the specified catalog.Each column description has the following columns:PS: Is there any other way to get my hands on that piece of information right now?
Documentation: SET LOGSIZE.In the documentation on the web site http Chapter 4, Table 4.8 it saysyou have to issue "SET LOG_SIZE ..." to set the log file max size.It should be "SET LOGSIZE" instead.
1.8.0.10 Lock File Does Not Work.In the latest release the Database in use exception is no longer thrown. I have tracked this down to substantial changes in the lock file functionality. I turned on the new hsqldb.lock_file property.In this new version instead of getting a SQL State 08001 with a nice Database in use message you getFile input/output error XXXX.backup java.io.FileNotFoundException: XXXX.data (The requested operation cannot be performed on a file with a user-mapped section open)In some cases during my testing my database got corrupted and I had to restore a backup in order to continue testing.
"ALTER USER SET PASSWORD" fails unconditionally.I was exploring your svn head yesterday and I noticed that ALTER USER SET PASSWORD="..." fails unconditionally. I'd see things like:Internal errorNaturally I looked at StatementCommand.java and it looks like a really simple fix. ParserDDL.compileAlterUser is compiling a list of Expressions instead of a list of Objects. (Why that distinction exists I'm not sure.) So StatementCommand overloaded for Expressions fails unconditionally when receiving a SET_PASSWORD type, since there's just no code to handle it. StatementCommand overloaded for Objects on the other hand already has code to handle receiving a SET_PASSWORD type. Just switching Object in place of Expression in compileAlterUser seems to fix the problem, though I'm no veteran of this project. I attached a patch against the SVN HEAD though, so do take a look and please apply if I haven't horribly misunderstood the situation.
get_column_name defaults false in 1.8.0.10?The documentation at httpstates that get_column_name defaults to TRUE (so that getColumnName and getColumnLabel will return the values I would expect them to)However after a quick test, it would seem that this is not the case, and it is actually defaulting to FALSE :-/Not sure if this is an issue with the documentation, or the engine itself, my guess would be the latter...Here's the code to demonstrate the problem:
primary key on varchar does not work.with the example below the HSQLDB says there is a unique constraint violdation in the column FIRSTFIELD
prepared Statement with subselect doesn't work.I tested it with folloing statement:I did a quickfix in the constructor of CompiledStatement line 312 (version 1.8.0.9)This solved the problem for me.
NullPointerException in HSQL engine.NullPointerException in HSQL engineWhile running HSQLDB 1.8.0.10 in-process during a day with multiple insertions (more than 20 000 in a day), some insertions are rejected with a NullPointerException.The VM Xmx parameter is set to 2048m.I have modified the Result(Throwable t, String statement) constructor in order to trace the Full Stack of the exception. Here are the logs:ThanksRomain
Union in subselect yields incorrect results.The following scenario:Running just the inner query does generate the expected result.This also appears to be the cause of the issue 2102123.
NullPointerException on shutdown.I start up my HSQL Database and want to connect to it and shutdown properly. I wrote a simple class to make the connection and issue the shutdown statement. The code looks like this:System.out.println("The database was shutdown successfully.");When I call this code I see an exception on the server console (I built with Javac debug so the stack trace has useful line numbers):The exception doesn't cause any trouble. The ServerConnection is trying to close a socket and the variable was never initialized.It would be nice to have this fixed. I have tried this on Windows XP and OpenSUSE 11 with the same results.
patch for avoiding recursive call on ConnectionPool.setDatab.Current setDatabase(String) in org/hsqldb/jdbc/pool/JDBCConnectionPoolDataSource.java is erroneously a recursive function. This patch fixes the problem.The patch has been checked against 1.9.0-alpha1Bye,Giuseppe
Hard to find how to set server IP address.It would be helpful if you mentioned the "server.address" configuration option in the "Server and Web Server Properties" section of the "Advanced Topics" section of the documentation (http).The existence of this option is implied in the java docs for org.hsqldb.Server (http), but it's not obvious from the "guide" (http): The "Server Modes" section of chapter 1 (http) says "Server modes can use preset properties or command line arguments as detailed in the Advanced Topics chapter", but the relevant section of the "Advanced Topics" chapter (http) doesn't include the "server.address" option. Chapter 1 does mention that org.hsqldb.Server takes '-?' to give a usage summary (why not '-h' or '--help' or '-help' ?), which does mention the '-address' arg from which the 'server.address' config can be inferred, but it would be better if it was mentioned explicitly in chapter 4.
JDBC driver does not respect nested Properties objects.Creation of a connection using DriverManager.getConnection(url, props) does not read the properties correctly if the Properties object passed in was created using the Properties(Properties defaults) constructor. It treats values in the nested Properties object as though they do not exist. I'm sure there is a simpler demonstration, but below is code approximating what is used. The shutdown property is not respected. When the line "props = new Properties(props);" is removed, the shutdown property is respected as it should be. With the code as is, the result is 42 printed twice. The expected result (and what is seen if the Properties object is not nested) is a single print out of 42, and then a SQL exception caused by "org.hsqldb.HsqlException: user lacks privilege or object not found: FOO". This is expected because the database should have been shutdown and cleared between connections. This was tested in versions 1.8.0.7 and 1.9.0-alpha2
create table fails.Using alpha2.BTW. alpha2 distribution goes with only one hsqldb.jar compiled with java 1.6, so in order to use it for older javas recompilation is needed.
timestampdiff does not work.Trying use timestampdiff.
Deadlock in 1.9a2.Using hsqldb 1.9 alpha2, I encountered a deadlock, wherein one thread was attempting to get a new connection to the db, while another was in the middle of checkpoint.I'm using a mixture of cached and memory tables.Relevant bits from the stack dump below.Thank you!
missing changelog of 1.8.10.There is only a changelog up to 1.8.0 but 1.8.1-1.8.10 are not documented.
HSQLDB doesn't complain about, but others do...selectThe problem: the field "F_id" can be found in both tables. HSQLDB doesn't complain about this, but other DB do.
Clob:  SetClobParamter : Invalidad argument.I have added support for HSQLDB inSun's OpenESB (BPEL-SE). It seem to be working fine except Clob data.JDBCPrepareStatement.java: setCharacterStream() : When java.io.Reader is type of CharacterArray, it goes into else condition of (reader instanceof java.io.StringReader) where it's calling setParamter(paramterIndex, sb.toString()). Here sb is StringBuffer.setPatameter() calles setClobParamter() which throws invalid argument exception because sb (StringBuffer) is not instance of Clob.I have tried following things:writeClob tries to convert into ClobData and throws exception.I this case, in JDBCPrepareStatement.java:performPreExecute() function, it throws exception when it type class to Clob.I would really appreciate if you can give some hint.NOTE: I have fixed one bug in TIMESTAMPDIFF function which I will submit a patch.
transaction rollback: serialization failure" error.Fred,Today when I started the loadtest, I am get transaction rollback: serialization failure" error so couldn't continue load test. If I run single test, It doesn't happen but if I run same test in loop for let's say 10 times, I was able to reproduce it every time and out of 10, it could happen 2-3 times.Please find attached compressed log file. See the ThreadID=41.
Randomly "Table not found: SYSTEM_TABLES".occures randomly in our junit load tests using multiple threads simultanously.each thread opens his own connection to his own database file via "jdb"if this error occures once, all following attempts to read the system table (of newly created databases) dying with the same error. the jvm has to be terminated in order to successfully read table names again.used version: HSQLDB 1.8.0.10
Alter table resets identity.I work with hsqldb 1.8.0.8.Altering a table with an identity results in a reset of the identity.Example:The object inserted after the "alter table" statement is created with ID 1, altough objects with ID 1 and 2 have already existed.
Regression from 1.8 upon COALESCE and COUNT with GROUP BY.Versions 1.8 and 1.9 alpha 2 (latest build as of 2009-05-22) behave differentlyupon doing the following experiment. I would appreciate if you could tellif this is by design, a bug which can be fixed, or something I should work around.You can recreate my results like this:
LOCK TABLE <TABLE> WRITE causes NullPointerException.When you perform a "LOCK TABLE <TABLENAME> WRITE" the following exception is thrown.
Duplicate constraint name generated.When using liquibase to generate the schema for a particular db, the generated .script file for a file-based database contains duplicate constraint names.The db properties being use are:After executing the above change sets, the generated .script file contains an entry for the AUTHORITIES table that looks like this:Note the duplicate name CONSTRAINT FK_AUTHORITIES_USER_ACCOUNT where the primary key constraint should be AUTHORITIES_PKEY. Also note that in the liquibase change sets, the primary key constraint is added, then removed, then added again (with an additional column name added).This error is observed in versions 1.8.0.9 and 1.8.0.10 but not in 1.8.0.7
Regression: poor execution plans for SELECT with LEFT JOIN..This bug causes HSQLDB 1.9 build 2999 to form very poor execution plans for SELECT queries featuring LEFT JOIN and WHERE statements.You can recreate it this way:1) Create a test database with the following tables both under 1.8 and 1.9Also, OpenOffice puts automatically added WHERE statementsat the end of SQL queries, and isn't smart enough to check for JOIN statementsand automatically build subqueries. I've already observed this causing problemswith OO 3.1 when I attempted to use an external HSQLDB 1.9 database.
Deadlock in b3.hsqldb.b3Circular dependency between SessionManager and Logger causes thread deadlocks (see attachment). However, it seems to be easily avoided in this instance by removing line Log.java:430 in addition to the code commented out below it.There's a second reference to database.sessionManager on 780, but it seems safe.thanks!
hsqldb.b3 locks up.I ran a multithreaded test and had several threads lock up in this state:I'm running on 1.6.0_03-b05/RHEL 2.6.9thank you.
1.9 Beta 3 Bugs.While using v 1.9 beta3 . . . noted a few items for your consideration.1, I too, had problems with Shutdown Compact problem.
java.sql.SQLException: not allowed in OUTER JOIN condition.Creating a view I get an unexpected java.sql.SQLException:No problem with this statement (well, the equivalent statement as of the different DDL syntax and data types) in other data bases (Oracle, Ingres). Complete data model of the underlying tables see below:
build.xml don't allow calling from other ant task.I have a "parent" build.xml that build a few other project, including hsqldb.The structure is:Starting from 1.9.0beta, this ant command no longer works:I have created a patch, please check the attachment.
SELECT causes NullPointerException at ExpressionLogical.java.When running this query with HSQL 1.9 b3, the following NullPointerException occurs. This is working with HSQL 1.8Thanks
incompatible data type in conversion when binding a boolean.When binding a boolean object to a numeric parameter in a PreparedStatement with the stm.setObject command, it fails with the following exception :This is a regression, works perfectly with HSQL 1.8
INSERT not working correctly with DECIMAL columns.Consider the following sql tool session:The result should be 3.3 not 3When retrieving the value from within a Java program using getDouble() as printl() also prints 3.0The above script was run against a newly created empty 1.9b3 database.The generated .log file of the database contains the following content:As you can see no fractions in the INSERT statements.Running a SELECT against the table displays the following:
SELECT .. INTO foo does not work in trunk - r3012.SELECT * INTO newtab FROM oldtabgives ErrorCode.X_42581 on INTO token.
1.9beta3 identity generator.I tried to access a 1.8 database with the new 1.9 beta3.I got the following exception. The bean that is mapped with Hibernateuses "native" as id generator.
Must use fully qualified names to use PUBLIC tables.It seems that tables that are created in the PUBLIC schema are not accessible unless you fully qualify the name of the table. In previous versions, tables in the PUBLIC schema did not need to be fully qualified to access them. It seems that any object that is in the PUBLIC schema should be accessible if it is not in the current schema.
JDBC Connections opened with the :res: option fail to open.Changing a jdbc url from jdbc:hsqldb:file:<path to db> to jdbc:hsqldb:res:<db on classpath> the following exception is always thrown (with 1.9.0-beta-3):This makes it impossible to package a database in a jar (which is very useful for unit testing).
sqltool cannot SELECT varbinary column.incompatible data type in conversion: from SQL type VARBINARY to java.lang.String, value: instance of org.hsqldb.types.BinaryDataIt should be possible to select rows which contain VARBINARY columns. Handling of String conversion from BinaryData seems to be broken in sqltool.
readonly fails in 1.9b3.I'm creating a simple file: database. Creating and using it works fine both in 1.8 and 1.9, but in 1.9 I can't use it when it is readonly. Setting readonly to true in either the properties file or the jdbc url fails and gives me this error message (from SqlTool):Failed to get a connection to 'jdbc:hsqldb:file:Database/foo;readonly=true' as user "SA".Cause: invalid schema name: SYSTEM_LOBSThis seems to work fine in 1.8. My database has no CLOB or BLOB columns, in case it is relevant. Shutting down with 'shutdown compact' does not help.
setting UNIQUE constraint on a column fails.I tried to create a table with a column having UNIQUE constraint. This works in 1.8.0, but fails with 1.9.0 beta3.Here is the SQL statement:
DROP TABLE IF EXISTS does not work.I tried to execute a DROP TABLE sql statement but it fails. Said error at EXISTS keyword.It works in 1.8.0 but fails in 1.9.0 beta3.My SQL:DROP TABLE IF EXISTS table_name;
Regression: SET LOGSIZE (and other settings) refused.Threre is an error in trunk revision r3023, r3006 works well.
SET SESSION CHARACTERISTICS R/W does not work.I migrated from version 8 to beta 3 version 9 recently and it does not permits table modifications in local transactions.The tables are cached tables. When I made the first tests and tryed to modify any table I got the errorSQL state [25006]; error code [-3706]; invalid transaction state: read-only SQL-transaction;Then I tried to execute at the begining SET SESSION CHARACTERISTICS AS READ WRITE and it worked only forthe very first transaction. Then I tried excecuting this statement at the beginning of every transactionand it seemed to work until the same error came back again. I gave up and decided it might be a bug.Sincerly, gerardo.leon@cablevision.net.mx
sql state for  foreign key violation is incorrest.On foreign key according to SQL-92 standard have to be 23503. The 1.9beta3 returns 23502 which is an insert or update a value to null , but the column cannot contain null values. The patch which fixes it is attached.
Timezone and Timezones off by a factor of 1000.In DateTimeType, the following code adjusts the date by one day, not one hour. This is because session.getZoneSeconds is subtracted *before* the multiplicaton by 1000, not after.I believe the below code fixes this:
Issues with DATEDIFF in 1.9.0-beta3.I am having a problem with the DATEDIFF function in 1.9.0-beta3. Below are reproduction steps. These worked in 1.8.0.10 (although the DATEDIFF function has changed it's parameter order)gives error - user lacks privilege or object not found: D1 / Error Code: -5501 / State: 42501
java.lang.NullPointerException in ExpressionColumn.getValue.I am upgrading our unit tests from using 1.8.0.10 to 1.9.0-beta3. I have quite a complex piece of SQL which is now causing a java.lang.NullPointerException in the ExpressionColumn.getValue method. I have also tried with the latest SVN code (revision 3031) and get the same error. I have managed to extract the part of the SQL which is causing the issue and put the statements required to reproduce below along with the stack trace.
user lacks privilege & create alias error  in 1.9.0 beta 3.Code works well in 1,8.x release, but two errors I gotuser lacks privilegesee attachment.Really bad feeling for the updates
Multiple start possible - lock file does not work [patch].The lock file does not work - at least in NON NIO case.The attached patch improves the situation for me.The issue #2547727 may be related.
1.9rc4: Deadlock.Hello,hsqldb went into a deadlock (please see attachment stack_trace.txt for stack trace).Beginning of the script file is at the end of the above attachment.Scenario:multiple, concurrent read threads, setup usingsingle write thread, executing concurrently with the reads.db is a mixture of memory and cached tables, cached table has blobs, total db size ~1GBThank you!
JDBC Stored Procedure calls don't work with null parameters.If I use a Spring org.springframework.jdbc.object.StoredProcedure to call a stored procedure that has at least one java.sql.Date parameter, and pass a null value for that parameter (via StoredProcedure's execute(Map) method) then a NullPointerException is thrown by org.hsqldb.types.DateTimeType line 806 (of 1.9.0rc4).Note that org.hsqldb.FunctionSQLInvoked's this.routine.parameterNullable[i] field (line 113) correctly detects this parameter as being nullable.Possible fix: org.hsqldb.FunctionSQLInvoked line 118 "if (this.routine.isPSM())" should be "if (this.routine.isPSM() || value == null)" - this would prevent a conversion to a java type even being attempted if the value was null.
re-sourcing a text table doesn't work.When using SET TABLE .... SOURCE a second time on a text table, the new contents are not immediately reflected.I continue to see the old, original data when executing selects until I restart my application. Closing and re-opening the connection does not help. Somewhere in memory, independent of the connection, it appears that my data is being cached.
1.9rc4: rollback handling.Looks like a similar issue to comment #2 to 2828178.Transaction failed with index constraint violation (which shouldn't be possible, but I'm investigating), and an attempt to rollback caused a series of calamities (please see attached stack trace).Another unfortunate consequence was the fact that the CountUpDownLatch was left in locked state:
Meta data COLUMN_SIZE returns 0 in 1.9.0-rc4.While testing the new 1.9.0-rc4 release, I ran into a situation where the JDBC meta data doesn't return the correct COLUMN_SIZE for string types. The attached code, has the following output for 1.9.0-rc4:Column TESTTABLE.SOMESTRING VARCHAR(0)In contrast, 1.8.0.10 returned the following:Column TESTTABLE.SOMESTRING VARCHAR(64).This seems like a regression.
UPDATE statement fails.For version: HSQL Database Engine, version: 1.8.0I am using the follwing native SQL query from withign hibernate:This fails on error:It seems like HSQL is choking on the ENGINE_TOKEN.ID part of "WHERE tmap.TOKEN_ID = ENGINE_TOKEN.ID". As HSQL doesn't support UPDATE ... FROM ..., there is no other way to transfer the ID to the inner statement.The very same SQL query works fine on MySQL 5.1, and Microsoft SQL Server 2005, and is only a problem on HSQL.
fail restart server after shutdown.2) open DB Managerexecute in the menu <Options>/Insert Test Dataexecute the command "SHUTDOWN"3) 1) start the serverRegardsAdolf Rieger
1.9rc4: Index NPE, locks.apologies, enountered an issue when re-running the tests using the trunk/svn (rev 3114).During delete, this exception was generated...thanks!
bitand function not same as Oracle.Hi,A table with a bitmap column like :I need to count the rows for each bit of the bitmap like :What do you think ?Thanks,Steve
MERGE ... WHEN MATCHED clause column reference.The MERGE ... WHEN MATCHED THEN UPDATE clause does not recognize new cursor rows during update operations. Instead, the entire target table of the merge is updated with uniform values across all rows.This behavior appears to be constrained only to this portion of the clause. The attached script shows that the WHEN NOT MATCHED THEN clause behaves as expected.
Cannot add a foreign key with existing data.If a table has a text primary key then a foreign key can be created to that table fine.However if the table already has existing data it will fail. This works fine if the key is of type integer.Here's a simple example which shows the problem:
1.9rc4  Interval Bug?Why is it that when executing the below SQL using JdbcTemplate.queryForInt(..) Oracle returns 14421 but HsqlDB returns 1245974400? Clearly, Oracle is returning the days between the two dates and hsqldb is returning the number of seconds...who is right? (note: for the above to work on hsqldb you need to create a table called 'dual')
Some comments NOT ignored by some JDK versions...While building revision 3158 locally, I found a quite odd problemwhich I tracked down to comment syntax in "JDBCConnection.java".If I check out an unmodified copy of revision 3158 from SVN,and try building it on my Debian / OpenJDK / Ant based system,it fails to compile with the following error message:The source of the problem appears to be in the comment syntax:For some reason, my JDK apparently refuses to treat this as a comment,and only compiles the code if I alter the commented-out "ifdef" directivesby inserting a space between the comment tag // and the "ifdef" directiveI realize that strictly speaking, this is not an HSQLDB bug,but since it might confuse others too, I thought I'd mention it.used to comment out
incorrect empty results from select on indexed cached table.i have a table built from various bits of Java code which seems to have got itself into an inconsistent state.This is using the patched 1.9 build from 27th August on the support page.Running a select statement matching the PK does not return any rows but doing certain other queries does return a row which the original query should have found.So for example:I have attached a copy of the db chopped down to the the smallest I can get it to be.It only has the problematic table remaining.The table is defintely in an inconsistent state.Running deletes against it will apparently delete rows but then after exiting and restarting the JVM the rows are no longer all deleted but the number of rows is not necessarily the same as before the delete either.Certain deletes will cause the missing row to reappear.Dropping columns also seems to make it reappear.I'm guessing it rebuilds the table somehow and that's what "fixes" things.I can probably provide the inserts that got the table into that state if that's helpful but will take a bit of work.
1.9.0-rc4: PreparedStatement failed.I use Sun's JRE v1.6.0_16.Attached file show a simple Java program for testing.
Table never unlocked after select with autoCommit off.Seems to me this is another aspect to bug 2805121 but I couldn't attach to that so here's a new bug. This is against the latest support snapshot (3rd Sep)Simply doing a select statement in a session with autoCommit off will mean the referenced table(s) NEVER get unlocked. Obviously this is bad.The statement in bug 2805121 that the latch count does not increase for select statmeents seems to be false. I originally hit this with 3 sessions doing selects from a table and another trying to do an insert (each in separate threads). The count in the CountUpDownLatch was 3 and never changed causing the program to lock up.This can be easily reproduced with the code attached.
1.9.0-rc4 HEAD: Problem with foreign key constraint + (a,b)I have been trying out hsqldb-1.9.0-rc4. I've found a problem with both the released jar and the latest trunk for 1.9.0.Consider the following sequence of SQL statements:I expect only one result to be returned in the select statement, but I'm getting two. Now, if I rerun the same code but remove the foreign key constraint, I get the expected result. I'm not sure if this is a bug in my understanding of SQL, but this code executes correctly on MySQL 5.0, so I think the problem is with HSQLDB and the interaction between foreign key constraints and multi-column IN statements.
count(distinct *) always returns 1.See the following example.Run with latest 1.9 snapshot using a file based database.
1.9: Different date/datetime after migration from 1.8.Problem: Different date/datetime in cached tables after migration from 1.8.0.7 to RCI migrated a HSQLDb database from 1.8.0.7 to 1.9 (RC from 10. Sept 2009) by shuting down the database under 1.8 and starting it up on 1.9. I did nothing special. On the first look everything went well - but when I did take a closer look on tables with date and datetime columns, I have recognized that the date content was wrong (e.g.).Further it seems to be that this is only a migration problem for cached tables. With memory tables this problem does not occur (may be due to the fact that the data is "stored" as script).In the following I provide you with some steps to reproduce the problem:As you can see the dates where changed/shifted.Now I did the creation of the table in the insert of the table compoletly with version 1.9x
res: databases with text tables.This item includes a jar containing a small database. This is a demonstration of packaging a database with text tables into a jar. Note the SET TABLE SOURCE commands and how the text files are referenced there.
Sequence not incrementing.There seems to be a problem getting the next sequence value when multiple "call next" statements are executed in the same HSQLDB session. Verified using Hibernate 3.3.2.GA and SQuirreL SQL Client.It seems as if the problem occurs only in the same HSQLDB session (found when debugging the problem in context of Hibernate 3.3.2.GA). When a new HSQLDB session is used then a new sequence value is returned, but succeeding calls to "call next" will then return the then-new value again without incrementation (until a new HSQLDB session is used).Steps to reproduce (using in-memory HSQLDB from SQuirreL SQL Client):create sequence myseq as bigint
Scale not respected for numeric (BigDecimal)It seems as if the scale of numerics are not respected when inserting and retrieving BigDecimal objects using the "snaphot jar of HSQLDB 1.9 Release Candidate compiled on or after 16 Sept 2009 ".ResultSet.getObject(String) returns the right value, but both ResultSet.getBigDecimal(String) and ResultSet.getBigDecimal(String, int) rounds the value prior to returning it. I have little experience with the inner workings of HSQLDB, but it may originate from JDBCResultSet.getColumnInType(int, Type) as it seems as if the source type lookup in "resultMetaData.columnTypes" is offset by one.I have attached a small java program that creates a table with a "numeric(32,16)" column, inserts a BigDecimal and retrieves it. Retrieved values are output to the console. When I run it with the "snaphot jar of HSQLDB 1.9 Release Candidate compiled on or after 16 Sept 2009 " I get the following output:Inserting: insert into testtable (testcolumn) values (?)
1.9: Different date after migration from 1.8 (reopen)1.9: Different date/datetime after migration from 1.8 (refer to ID: 2857537)The problem described in bug ID 2857537 is still occurring:When I migrate from a database on version 1.8.0.7 to 1.9 the date/datetime values are changed.I took the jar from the support page as requested by you in your lastcomment of the bug 2857537 (source:Unfortunately I got the same results as explained in in the last bug request(means the date/datetime values are changed).I get it with the JAR file from the 10th September as well as with the actual jar file (I took them both from the support page!!)Then I tried the jar from the RC Package:Using this package everything works as expected - the dates are migratedproperly from 1.8x to 1.9x RC.For me it seems to be that there is a regression which was already in the JAR file of 10th september.
1.9: Different date after migration from 1.8 (reopen)1.9: Different date/datetime after migration from 1.8 (refer to ID: 2857537)The problem described in bug ID 2857537 is still occurring:When I migrate from a database on version 1.8.0.7 to 1.9 the date/datetime values are changed.I took the jar from the support page as requested by you in your lastcomment of the bug 2857537 (source:Unfortunately I got the same results as explained in in the last bug request(means the date/datetime values are changed).I get it with the JAR file from the 10th September as well as with the actual jar file (I took them both from the support page!!)Then I tried the jar from the RC Package:Using this package everything works as expected - the dates are migratedproperly from 1.8x to 1.9x RC.For me it seems to be that there is a regression which was already in the JAR file of 10th september.
Ordering a "SELECT DISTINCT" by a "CASE WHEN".HSQLDB 1.8.1.1 fails to execute a "SELECT DISTINCT" if it is ordered by a "CASE WHEN" even though the "CASE WHEN" is also part of the SELECT list.Example reproduced using SQuirreL SQL Client:
Hard-to-pinpoint regression: unsupported internal operation.While making preparations to transfer a database which is in production useunder HSQLDB 1.8 to HSQLDB 1.9, I encountered several querieswhich 1.8 executes successfully, but which cause 1.9 to freeze the threadservicing the JDBC connection, so that from a client's perspective,the query seems to take forever, while the server reports:However, when I tried generating a minimal data set to attach to this report,I encountered difficulties. No data set of a convenient number of records,no matter how deviously I crafted it, was able to cause this crash.However, real-world data from a customer's database, most probably error-freebut containing 240'000 articles and nearly 100'000 warehouse saldos,do realiably cause this crash, and I'm still working to pinpoint how.Thus, despite my current inability to accompany my bug report with any solutionbeyond a crude work-around, I decided to submit it anyway, in hopethat someone might figure it out.The structure of the tables involved in my scenario is like this:
Defrag failure.Hit this problem during a long-running load test (multiple inserts/deletes over a long time).After the error the app seemed to have recovered, however. Haven't been able to reproduce this yet (I've been running the , but I thought it may be useful.Here're the settings for the db (from the script):
select count returns wrong number of rows.Found this bug in the latest version, but also appears to be in 1.9The below code should be self-explanatory, but in a nutshell, it doesn't appear to deal with the same column appearing twice in the predicate list for a select count
invalid ORDER BY expression error when sorting on aggregate.When sorting on an aggregate the following exception is thrown:Rob
SQLException when using upper(?) in query.When we use the upper function on query parameters, prepareStatement fails with this exception:This works fine in Hsql 1.8.See attached sample program.Rob
limit with offset works different when selecting PK or not.I have 2 similar tables, when selecting with limit and offset parameters, the results are different if the table has a PK or not.When the table has a PK the behaviour is not compatible hsql 1.8.In HSQL 1.8 both queries return 2 rows.Rob
invalid HAVING expression error when using query parameters.When using query parameters in the having clause the following error is thrown:See attached sample program.Rob
Suggestion: add more classes to the "hsqljdbc" build target?My use case: a HSQL JDBC client is installed on a Windows CE handheld computer, and it connects to a HSQL server on a Debian Linux box. The handheld computer has rather limited RAM and Flash memory, so minimizing the disk footprint of .jar files is important.My concern: the build target "hsqldbmain" generates .jar files of about 1.5 MB, which also contain server classes. However, when I tried using "hsqljdbc" instead (it produced packages of about 380 KB), they didn't contain enough classes for JDBC client functionality to actually work - right as I tried loading the driver, I got a crash since the VM couldn't load necessary classes.It thus appears that the "hsqljdbc" build target is too compact to support a functioning JDBC client. Perhaps it's compete enough when considered from some other aspect, but I found that I needed to add about 20 classes to it, increasing the .jar size to slightly above 500 KB.I'm attaching a diff of "build.xml" to this message.
validateSpecifiedUserAndPassword has to be improved.tried JDBCConnectionPo#olDataSourcevalidateSpecifiedUserAndPassword with 1.9 version. Implementation could be completely fine if it need to compare two string objects, but since it should compare username and password, implementation needs to be improved.From pure technical point of view null reference to string is not equal to zero length string, but from semantic point of view its one and the same thing. So if for example user input argument is null reference and configuredUser local variable is zero lenght string, function should not throw exception.
SYSTEM_COLUMNS difference betw. 1.8 / 1.9: bug or by design?I'm currently trying to discover why OpenOffice form filters breakwhen run against HSQL 1.9.Among the possible reasons for breakage are different results which 1.9 giveswhen OpenOffice queries "INFORMATION_SCHEMA.SYSTEM_COLUMNS"to determine table structure.I have the following table and index:Please don't take my report too seriously, I'm not sure yet whether this differenceis actually involved in breakage. I am currently testing this behaviourwith the 1.9 RC6 .jar file obtained from "http".If testing with an SVN build would likely help, I can try that too - I picked the binaryfor the convenience of OO folks, so they could easier obtain the same conditionswhich I tested in.If you wish to discover more about the context of my situation,the bug report I've filed about form filter breakage in OpenOfficecan be found at:
wrong package name in documentation and runServer.bat.The package name is wrong. It must be: org.hsqldb.server.Server (read this exactly!)The same bug is in the start script runServer.bat.
Select keeps readlock even if resultset is processed.It seems that a select issued in 1 connection (autoCommit=false) keeps a lock on the table even if the select is completely processed (it does not have any results in our case).An insert executed from another connection blocks on the select statement.See attached sample program, this program completes using hsql 1.8 but hangs using version 1.9.Rob
UPDATE statement with IN criterion recently broken.Hello,I suspect that some fairly recent change to the codebase has broken
Documentation update needed.The current documentation reflects old paths to HSQLDB server mode startup. the startup command should be:java -classpath hsqldb.jar org.hsqldb.server.Server instead of just org.hsqldb.Server ... should be easy to modify and update.RegardsVyas, Anirudh
PreparedStatement did not return generated keys.I tried to retrieve an auto-generated key from an INSERT statement, but the generated keys result set is empty. See my test case below. The assert statement at the end fails. I am using 1.9.0-rc6. The code works fine with MySQL, PostgreSQL and Oracle.
Suspecting a memory leak (OOM after day's work)While stress-testing an installation of HSQLDB 1.9 in real usewith about 30 database clients of various sorts performing warehouse transactions,I obtained an OOM by the evening, despite having allowed 1.2 GB of Java heap space.Maximum log size is about 200 MB, and 1.8 never required nearly as much,yet 1.9 seems to quite reliably exhaust any amount of memory given to it.Before the crash, about 3.79 million statements were processed.I unfortunately only obtained a thread dump, not knowing how to obtain more.I had internal event monitoring running on level 2, but its log shows nothing of interest.The thread dump however indicates a massive amount of objects in the "Old" generation.I suspect this is a result of their handles remaining in memory, and garbage collectionbeing unable to collect them... that is assuming that garbage collection *tries*to do that, which I sort of assume it *must* try without any extra encouragement.I have not, however, tried enabling explicit GC calls.Any ideas about what might be happening are very welcome.
Apparent deadlock with r 3281.While running an application against a HSQL server which imports and exportsXML files, I found that after upgrading from HSQL 1.9 revision 3271 (or perhaps 3274)to revision 3281, situations which resemble a deadlock started occurring.They involve the affected client only - other clients connected to the same servercan continue working undisturbed, and the server still responds to them.Basing on the method in which the client hangs, it could be attemptingto execute something like:...but I am not sure if this is always the method which hangs.Others might be involved, simultaneous activities by other clientsmight be involved, and the SQL involved might vary.A thread dump from the client looks like this:Heap
"Integrity constraint violation" after prolonged work.While attempting to track the reasons of great memory use (which I mentioned in another report),with revision 3282, I also observed an effect which I believe might be separate from it,but might be worth reporting.It occurs after an HSQL server has operated and serviced clients for a notable time,often as long as 6 hours. Out of the multitude of clients this server services,it *seems* to be occurring with one particular client -- a client which frequentlydisconnects from the server and reconnects to it, since its network linkis unstable and it's been designed this way to gracefully resume operation.I have never seen it with the same database and nearly the same clientpreviously on HSQL 1.8.The error message the server issues, implies that a problem with indexeswas encountered while inserting a value into an index, but surprisinglythe call stack suggests that the call actually originated from a rollback operation.I am unsure what to think about it:When this happens, it does seem to effectively guarantee that a SHUTDOWN COMPACTstatement won't execute correctly, while an onling backup with the BLOCKING option,followed by a SHUTDOWN IMMEDIATELY (my usual way of recoveringfrom this situation) generally does execute correctly.I have no reason to suspct that at the time of this error ocurring,an actual integrity constraint violation would occur, since the data this program processesis repetitive in nature, and then I'd be getting these errors multiple times per day.What is meanwhile ocurring on the client (in case it provides any insight into the problem),is typically a saldo import operation, whereby a lot (usually about 40'000) warehouse saldosare read from an XML file, which has been supplied by a separate program.In the below excerpt from my logs, the client has successfully imported 19'000 saldos,then suddenly seems to pause for several minutes, reports the error, and proceeds to skip the rest,since its ability to find article records from the article table has apparently been impairedby something:I can additionally certify that no network connectivity problems could have been involved,since the HSQL server and client were operating on the same host.
"unique constraint or index violation" inadequate message.I have a table with two foreign key constraints and two unique constraints with specific different names. I am using Spring Framework's JDBC tools to add data to the table. If I add a row to the table in violation of one of the foreign keys, HSQL throws an error like this:org.hsqldb.HsqlException: integrity constraint violation: foreign key no parent; CODE_MAP_ENTRIES_FKCODE table: LOOKUP_CODESSpring then wraps this with a DataIntegrityViolationException from which I can extract the name of the foreign key constraint to determine what kind of error to throw of my own.However, if I insert a row in violation of one of the unique keys, HSQL throws an error like this:org.hsqldb.HsqlException: integrity constraint violation: unique constraint or index violationSpring appropriately wraps this in a DuplicateKeyException, however, since HSQL provides no constraint names in this error like it does with foreign key errors, I have no way of telling which unique constraint was violated. To make troubleshooting easier, the error should be changed to be:org.hsqldb.HsqlException: integrity constraint violation: unique constraint or index violation; CODE_MAP_ENTRIES_TABLEOLDCODE table: LOOKUP_CODESOr something similar.I've tracked down at least where a change needs to be made to org/hsqldb/index/IndexAVL.java line 541:However, I am simply not familiar enough with HSQLDB source code to be comfortable contributing a change like this to it because the table name and/or violated constraint name are not readily available within the body of that method from what I can tell. The table name isn't totally necessary, but the constraint name is definitely necessary. Every other major SQL vendor supplies the violated constraint name in the JDBC exception.
1.9 rc 6: database.data file has no up-to-date last-modify.I have a database with a cached table in it.For reasons of doing a catalogue file backup, I looked to the timestamps of the various catalogue files.Thereby observing that the last modify date of the .data file was several weeks in the past although updates to the tablehad taken place more recently.Is this a feature or a bug?
poor query performance 1.9.I have used v 1.8 for the last year and performance was great. Thought I'd try out 1.9 so I downloaded it last week and converted my database. The following query runs in less than one sec in 1.8 but over 15 seconds in 1.9.I can provide 27MB zip of data on request. Tried to attach but got failure message.
1.8 Script stops working in 1.9 rc.I have no problem to execute the SQL statement above in one JDBC statement or on the SWING Manager from HSQLDB. Now it stops working on 1.9.0-rc6. This is error message I got - "user lacks privilege or object not found: T1 / Error Code: -5501 / State: 42501"Does anyone know what have changed in 1.9.0-XX which made it not working?Thanks
set ignorecase true doesn't work.In 1.9.0.RC6, set ignorecase true doesn't work. I looked at the code and I see that Database.setIgnoreCase() is called when processing the command, but I couldn't find anywhere that Database.getIgnoreCase() was used when setting the column type. Perhaps that should be passed to the constructor of ColumnSchema so the data type can be changed to VARCHAR_IGNORECASE?Here is some test sql.The data_type in the last query shows name as 'CHARACTER VARYING' not VARCHAR_IGNORECASE as one would expect. Defining the column type explicitly as VARCHAR_IGNORECASE works.
ClassNotFoundException while testing r3310.While trying to gather data about the deadlock problem which I described previously,I attempted to start testing with SVN revision 3310. However, transitioning to this revisionin regular manner failed, producing ClassNotFoundExceptions.After issuing these exceptions, the server utilized a lot of CPU for 7 minutes(sorry, couldn't wait longer), and didn't manage to reach readiness for work.That's when I sent it the "-QUIT" signal to produce a thread dump.1) Starting up and log extractHeap
.Net Provider Connection Times out.In System.Data.HSQL.Client assembly, file HSqlConnection.Api.cs, in the following method, the milliseconds is converted from seconds by doing a binary "and" with 1000. Shouldnt that be multiplying by 1000 ? As a result no connection is getting opened because of the low timeout value
Database corrupted.Embledded mode, cache table, 1.9 b6. After restart software -
Procedures - declarations for more than one variable.i tried to implement a procedure which inserts data and also uses the internal keys:the application throws no error and hangs himself.i'm using the current RC6 from HSQLDB 1.9.0 and jdk-1.6.0_14
New release should be compiled for Java5, not Java6 only.The RC6 is compiled for Java6 only (i get an java.lang.UnsupportedClassVersionError: Bad version number in .class file loading the JDBC driver)
LIKE behavior 1.9.0_RC7.LIKE statements aren"t working as expected.I seem to have the following behavior.In a LIKE statment the '%' matches on a single character, so the '%' has the same result as an '_'.
Script file error in RC7.After moving from RC6 to RC7, application runs only once, on second run I got exception "java.sql.SQLException: error in script file line: 8 unexpected end of statement". Statement on line 8 is really incomplete: "SET DATABASE DEFAULT ISOLATION LEVEL ".Here is the first lines of script file:
Hibernate and use of getColumnName() for column mapping.I have migrated our Hibernate 3.2 application to HSQLDB 2.0 RC7 and certain code started to fail.Investigation showed that queries where we are inner joining to the same table caused this issue (since column names were duplicated)The following QUERYfrom Awould fail if it was through hibernate, since getColumnName for Ba.B_VALUE and Bb.B_VALUE causes hibernate looks up column names for each column. getColumnName(1) -> "B_CD" and getColumnName(3) -> "B_CD". Then when hibernate runs the query, it looks up by "B_CD" and gets the first one both times.I have been looking at ways to get the JDBC Metadata getColumnName() to return the aliases, and have explored "get_column_name=false" parameter, but this has not worked.I think this bug issued for mySql actually summarizes the issue better than I can: http
user-defined nested function call fails RC7.setup:The error message I get back is "user lacks privilege or object not found".
UnsupportedEncodingException for existing encoding.In SqlFile class in setEncoding method is this:It raise exception on existing encoding.Related to 2.0.0 RC8 version
NPE when passing null to a date argument of a Java SP.If you create a stored procedure in Java with a java.sql.Date as the type of one of the parameters then when you pass a null to that parameter HSQLDB throws a NPE. This is in 2.0rc8.The FunctionSQLInvoked class has the following starting at line 111:This will ensure all parameter values given as null will not be converted - they will be passed to the SP as null.
hsqldb_2_0_0_rc8: syntax error saving view to .script.I have created the following view
Deadlock in 2.0.0 RC8.Concurrent transactions frequently cause deadlock. Downgrade to 1.8 fixes the issues
Execute default & unrevokable.It appears (in 2.0.0 RC 8) that accounts have execute access to procedures by default, and it cannot be revoked.Accounts should only be able to call procedures that they have been granted access to.
Parameter before "IN (SELECT..)" throws NPE.Version: 2.0.0 RC8When executing a SELECT containing a parameter before a subselect an NPE is thrown.Workaround: Don't use a parameter at this point.
Wrong select result in hsqldb 1.8.1.1.Hi all,i created the following table:
build.xml target bug.In order to build hsqldb and sqltool jars with jdk15, it's necessary to edit the target store in the following way. Instead of:the depends list must be changed to: depends="s"
sqltool.jar has dependency on hsqldb.jar.attempts to use sqltool fail in 2.00 rc8 because org.hsqldb.lib.RefCapableRBInterface is not present in sqltool.jar. Works if put hsqldb.jar on the classpathbut this is not consistent with the documentation
Error upon indexing a DateTime field.Testing with a fairly recent (but not assuredly latest) SVN version, I noticed the following:1) I have the following table:3) The following error occurs:
view does not work dep. where it is defined.I have an application which creates several tables and views and then populates the database with some data.I observed that one view did not work after the database had been shutdown and restarted again.I was able to track the situation down to the following observation:if the respective view is defined after the create table statements (as is done in the script file), it does not work afterwards.If it is defined after the tables have been populated, it works.I think, it should work independently of where it is defined, hence this incident.I add the sql file with which the problem is reproducable (see the comments in it).
2.0.0-rc8 - Merge does not work.I am using the version 2.0.0-rc8 to test the merge insert update but it seems that there is some error being thrown from hsqldb.I have Oracle Merge in my application code and I wanted to use HSQLDB to be be able to do some good standalone testing.If this issue has been fixed already for some reason, could you let me know which version i can use?If it will be fixed, then could you also let know when it will be available for release?The following is the error:
tree style data in single table,delete all failure.Test code :
hsqldb does not work on java <6.Does HSQL really require Java 6, or will it work on Java 5? I suspect it would. In that case can it please be compiled using target Java version 5. Otherwise we can't use it in websphere 6.1.
HsqlException: incompatible data type in operation.Error in 2.0.0-rc8 with Hibernate, works fine in 1.8.0.9 and Hibernate.The SQL statement below fails to compile with the following Exception :If I change the SQL Statement to the following (by removing the parameter from the CASE WHEN, it works fine (except the behaviour is now different obviously :)).So looks like parameters within a 'CASE WHEN' bulk update statement are not working.
create schema v2.0-rc8.I try to use my hsql script which works fine in v1.8 with the current 2.0-rc8 release
NullPointerException getting column for sub-query.HSQLDB Version : Latest develpment build dates 19th Feb. 2010.The SQL statement below (generated by Hibernate) results in a NullPointerException:and lower(rollup1_.C_ACC_CODE) like ?)
HsqlException : incompatible data types in combination.Found in latest development build of 2.0.0-rc8 (dated Feb. 19th).Getting an "HsqlException : incompatible data types in combination" when attempting to run a bulk INSERT statement. The statement runs without issue on version 1.8.0.9 of HSQLDB and also other RDBMSes.Script for table creation and failing INSERT statement are attached. The scripts are SQL Server scripts as I do not have HSQLDB equivalents (Hibernate creates the tables automatically when using HSQLDB).Stack Trace :
Incorrect calc when using an Alias in a group by expression.When using a column alias which matches the name of the original column in a GROUP BY clause. The GROUP BY clause appears to pass the value calculated in the SELECT statement back into the function in the GROUP BY clause which can result in duplicate rows for example:This is the expected (correct) result!
DatabaseManager.removeDatabase must be synchronized.DatabaseManager.removeDatabase method changes fields like memDatabaseMap and databaseIDMap w/o proper synchronization. Other methods that change the fields (e.g. addDatabaseObject) are synchronized.
getUpdateCount should return -1 on second call.In RC 8, the following will cause an infinite loop:ps.getUpdateCount() should be returning -1, but is always returning 0. This appears to happen for INSERTs as well
outer join result null or 0.on making an outer join to a table with "not null" columns you get in the query result a REALLY ZERO in case of an integer instead of NULLresults in case of all columns in the table t2 definition are not null allowed
Differences in date after conversion from 1.8 to 2.0.I tested OOo with hsqldb 2.0 latest (and earlier) snapshot version 2010.02.21, and found a bug with it, I tried to test it with standalone hsqldb server.I'm not java developer only tested with scripts.I used test database for conversion testing and found, that not all date, time and timstamp values converted vell, in date I get minus 1 day, in time minus one hour, in timestamp, somtimes both changed sometimes only date, another times correct conversions.I used for testing standalone hsqldb servers, too. I created a table with test data in 1.8.0.10, stopped server. copied all files (test.script etc,) from 1.8 data folder to 2.0 data folder. Sstarted 2.0 server, the conversion went through without error message.I saved scripts to file system, I attach both version scripts, 1.8 with original data, and 2.0 with erroneous one.
\'getBinaryStream\' returns null over BLOB type.Executing \'ResultSet.getBinaryStream()\' over a BLOB field returns null, even if the variable has been stored correctly.The code works fine for BINARY fields.Sample code attached.The code creates a new table (either BLOB or BINARY type), stores a file (RampartSample01), and tries to read it from the DB and store the content to a new file.Using BLOB throws NullPointerException.Using BINARY works properly.
More complex SQL scripts stopped working in with 2.0.After migrating from 1.8 to 2.0rc8 my sql scripts stopped working. Apparently with 2.0 its no longer possible to create an object and refer to the new object in a later statement within the same script.Please see attached unit test for details.
Row not found when it does exists.I have many cases where existing rows are not found by SELECT statements when they do match.I have narrowed down the problem and have created a simple example that creates 2 tables T1 and T2. T1 has a foreign key to T2. There is one row in each table.Executing a select from T1 joined to T2 does not return the existing row using the WHERE clause defined in the example.In the example, I am using a parameterised query to obtain the data. 2 parameters are on T1 (alias 'a'), and a third parameter on T2 (alias 'b'). The query in the example fails. However, if I remove *either* of the WHERE clause clauses for T1, the query works! It's only when both clauses from T1 are used that the query fails. The query also works if you remove the clause for T2 but include both clauses for T1.
Row not found when it does exists.I have many cases where existing rows are not found by SELECT statements when they do match.I have narrowed down the problem and have created a simple example that creates 2 tables T1 and T2. T1 has a foreign key to T2. There is one row in each table.Executing a select from T1 joined to T2 does not return the existing row using the WHERE clause defined in the example.In the example, I am using a parameterised query to obtain the data. 2 parameters are on T1 (alias 'a'), and a third parameter on T2 (alias 'b'). The query in the example fails. However, if I remove *either* of the WHERE clause clauses for T1, the query works! It's only when both clauses from T1 are used that the query fails. The query also works if you remove the clause for T2 but include both clauses for T1.
NullPointerException in BitType.compare().
PreparedStatement TYPE_SCROLL_INSENSITIVE is broken.TYPE_SCROLL_INSENSITIVE queries are not supported for PreparedStatements in 2.0rc8It looks like the Result.rsProperties isn't getting propagated correctly somewhere along the way.
NPE on RC8.I get this while trying to compile my schema using sqltool:It is caused by the following view definition in the attached schema:
OOM Truncating a cached table.I created one simple cached table:and filled if with 5 million rows.When i preform a DELETE FROM TABLE1 a java.lang.OutOfMemoryError: Java heap space occurs. I'm expecting this as a rollback segment must be used. But the sames occurs when trying to truncate: TRUNCATE TABLE TABLE1.This I wasn't expecting as no rollback segment is used. Is this a bug, or am I assuming something wrong?A work around is to drop-create the table. Is this advisable?Thanks in advance.
NullPointerException at updateRow()I'm calling updateRow() on a "SELECT * from singleTable" ResultSet. The singleTable has a private key two other tables depend on (FOREIGN KEY constraints with ON DELETE CASCADE).When I call updateRow() (after updating some insignificant fields, not the private key), I get the following stack trace:after removing the FOREIGN KEY constraints - all works fine.I'm using 2.0.0 rc8, jdk1.6.0_11.
Incorrect query result.I wish I could find a more concise way of reproducing this bug but here goes:Please run the attached schema.Then please run the attached test data script.The following query incorrectly returns one row:test allTo make it even more clear that this result is incorrect, we can change the query to the following: here, the 'clause1' and 'clause2' columns are exactly the same as the two parts of the 'where' clause which are ANDed together: test all FALSE TRUESo effectively FALSE and TRUE is evaluating to TRUE...I've been staring at this all afternoon to see if there's something I'm doing wrong, but I can't find anything.
Exception in RC9.When testing RC9, a query which worked in RC8 is giving a runtime exception in RC9Please see my schema attached
Table alias doesn't work is ResultSet.getString()Hi,I have the following query:When trying to access the column value with table alias I get Column not found SQL exception.
Memory issues with HSQL DB.We are using HSQL db as an in memory engine for our data processing. We do fire large set of sql insert and select statements during data processing. Once the processing is complete, we are deleting the rows inserted initially. These operations are done using JDBC connection. Once the deletion is completed, we see that the inserted rows are actually deleted from database successfully. But the additional memory taken by HSQL db at the time of insertion of rows is found not to be released even after deletion. This is creating problem for us as the used memory of the product keeps on increasing over a period of continuous usage. We need to know if there is some way to address this issue or if this is a bug with HSQL db, we would like to get a solution to this.
Testdb example not working in RC 9.The testdb sample does not work any longer - throws "resource not found" exception in class Thread(when run in debugger, tested in Eclipse and IntelliJ)
data exception: string data, right truncation in select stat.works perfectly with version 1.8, but gives "java.sql.SQLException: data exception: string data, right truncation" at the first "rs.next()" on the resultset with version 2.0 RC9. The db is too big to upload
WRITE DELAY needs underscore.My env. : "JDK 1.6 , windows, hibernate 3.5.0 CR2, Netbeans latest version, HSQLDB 2.0 RC9"I lost many hours testing and looking the source code of HSQLDB and finally found the bug.In the documentation "guide.pdf", table 12.3, the property hsqldb.write_delay informs that we have to change/set the property "WRITE DELAY", but it needs an underscore to work correctly, i.e. "WRITE_DELAY".After that there is a mention about "SET FILES WRITE DELAY". I think it is also wrong . It should be "SET WRITE_DELAY".Furthermore other properties had worked as part of my URL connection, but "hsqldb.write_delay" NOT. I think it is a bug related to the Engine 2.0. Part of my URL isBut the database.script shows always the default value "SET FILES WRITE DELAY 500 MILLIS" instead of "SET FILES WRITE DELAY 2" when I create the db in the first time.It works only when I explicitly execute the statement below.check_params does not seem to work also. I changed "hsqldb.write_delay" in the previous URL to "hsqldb.write_delaz" but no error is returned. In the documentation informs :"If the property is true, every database property that is specified on the URL or in connection properties is checkedand if it is not used correctly, an error is returned"Well, thanks to hear me!Best regards,Jocafi
getColumnClassName returns "Integer" for bigint field.I was using apache common beanutils RowSetDynaClass to process the result set. It throws an exception about not being able to convert Long to Integer.BeanUtils creates properties based on the types returned from ResultSetMetaData.getColumnClassName(). It returns "java.lang.Integer" for bigint fields. Later when BeanUtils tries to populate the property value, it calls ResultSet.getObject(columnName) which returns an object of java.lang.Long. Therefore, BeanUtils throws out the abovementioned exception.From the documentation, my understanding is bigint is mapped as java.lang.Long in HSSQLDB. Isn't the returned column data's type be the same as what is returned from the ResultSetMetaData.getColumnClassName()?
order by on aggregate no longer works with latest snapshot.I downloaded the latest snapshot (April 9, java 1.5 version), in this snapshot the order by on count-aggregate throws Error: invalid ORDER BY expressionSample sql:This worked with hsql1.8 and with earlier snapshots of hsql 2.0Rob
name of the constraint is different between CREATE and ALTER.We use Apache DDLutils to manage HSQL database and we have a problem with the name of the constraints.thanks for your response and sorry for my vocabulary
ArrayIndexOutOfBoundsException: 2 2 while creating function.I'm trying to create function:language java parameter style javaI have 3 overloaded methods in StoredProcedures class:Functions with varchar parameters works well. The one with int parameter does not. I'm getting java.lang.ArrayIndexOutOfBoundsException: 2 2.
Dropped function is still dependent object.In RC9, When I drop a function F that reads from a view V, and then drop V, it tells me that it cannot drop V because of dependent object F, even though F has already been dropped.This gives me...
NPE on RC9 and latest snapshot.Please run my schema below.Then enter the following test data:Then doBut when it is part of a view, it doesn't.
Query returns inconsistent results.I adapted my schema to work around issue 2987677 that I raised a couple of days ago.Now I get another issue (which could be a manifestation of the same issue)...Run my schema on the latest snapshot and insert the following test data:Then try the following query:This returns 0 rows, which is incorrect.Then run:Then try that first query again...So the same query has returned different results even though the intermediate query does not update any data.
order by null desc.Try:which is correct.Butwhich is not correct. It should return as it did with 1.8.0.8.BTW, the new behaviour would be ok, if DatabaseMetaData.nullsAreSortedAtStart would return true,but nullsAreSortedLow returns true, bout in 1.8.0.8 and 2.0.0 rc9
2.0.0-rc9 MERGE bug.SEVERE Rolling back SQL transaction.
ata exception: string data, right truncation (26.April snap)This all happens with rc9 as well as with the snapshot I downloaded yesterday...
Unique constraint messes up select.I am trying to upgrade from 1.8.0.7 to 2.0.0-rc9. I have a problem with a unique constraint with multiple columns. The simplest test case that I can manage is this:The select does return no rows, although of course the second row should match. This used to work in 1.8.0.7. I reproduce this using the HSQL Database Manager.
servlet mode not in the ROOT.Hi,I had tried to use hsqldb in servlet mode:I have this in my web.xmlThe servlet is running.The database is also running.There is nothing in the tomcat access log, so it looks like it had not reached the servlet at all.I was desperately trying to debug the org.hsql.jdbcDriver source but my Eclipse cound not build it with Java 6 nor Java 1.4 nor Java 1.1 - main problems about missing some methods implementation in teh jdbc driver classes - so I give up, but it looks like the answer lies somewhere in the DatabaseURL.parseURL.zdenek
CASE WHEN space-pads results.I have this kind of CASE WHEN expression (this is a Hibernate subclassdiscriminator):This has so far worked as expected in 1.8.0.7, and it works withoutpadding in Postgres and Oracle.I find that I can add TRIM to fix the code for now, but I wonder ifthis is intentional or a bug? It seems to me that the branches of theCASE WHEN should be independent of each other and so there is no goodreason to pad the result.
data truncation error in WHERE clause.Using a too long string in a WHERE clause I get a data truncation error, when I use a PreparedStatement and a placeholder. Rejecting too long data in INSERT/UPDATE is really o.k., but in my understanding of SQL using a too long string value as parameter in a WHERE clause I should get an empty result set (or so, depending of what was selected, of cause), and not a SQLException.When I use a "Statement" instead of a "PreparedStatement" the behavior of HSQLDB is o.k.
MINUS operator doesn't work.I performed the following queries:It seems that MINUS always returns the second argument.I can provide my schema if you can't reproduce it.
Foreign Key problem.I have two tables like so:It seems to be because this order of attributes doesn't match the order in the primary key clause for the first table ieWhen I changed the foreign key clause to the configuration shown at the top, with the attributes in the same order as the primary key, then it worked.
Docs: read_only > readonly property.Please change the docs for chapter 12 for property 'read_only' to 'readonly'. The underscore version won't work for 2.0 (and I think 1.8 neither). Thanks!
Missing artifactId in pom for release 2.0.0.When using maven, builds fail with this error :This artifact might be in your project's POM, or it might have been included transitively during the resolution process. Here is the information we do have for this artifact:It seems that artifactId is missing from the 2.0.0 release.It can be fixed by adding this to the pom :
NullPointerException when using remote_open=true.Test case:Actual result:Database manager reports a NullPointerException.My analysis:The exception originates at the server. It happens in situations when the server loads without any databases, such as when running with remote_open=true and without additional database.x/dbname.x parameters.The reason is circularity in static initialization of org.hsqldb.Collation. During its static initialization, it performs: defaultCollation = new Collation(). This, in turn, causes the constructor of CharacterType to call Collation.getDefaultInstance(). Since this happens during the construction of the default instance, the getDefaultInstance() method returns null.This doesn't happen when the server loads with a database, since the classes are loaded in a different order.To reproduce, put breakpoints at Collation.java:156 (final static Collation defaultCollation = new Collation();) and Collation.java:177 (getDefaultInstance()) and compare running the server with remote_open=true vs. false.
UNION CORRESPONDING causes npe.I tried changing a view from union to union corresponding and I get a NPE.Please see the attached schemaIf you run the scripts domains.sql then templates.sql that should be enough.The view is all_node_format in templates.sql
TABLE T with view causes NPE.The expression "TABLE T" causes an NPE if T is a view.
Dead lock with Hibernate test suite.Hi,I tried to update Hibernate test suite to use hsqldb 2.0 but it seems there is a dead lock. You can get the code from http. Simply update parent/pom.xml to use org.hsqldb:hsqldb:2.0.0 instead of hsqldb:hsqldb:1.8.0.2 and run mvn clean test -PhsqldbThe build is stuck on test org.hibernate.test.jpa.lock.JPALockTest.Here is the thread dump: httpDo you have an idea of the cause of the issue.Thanks
SqlFile pass error - create function.Execute a SQL file with SqlFile.execute() that contains create function failed. Reported error is as following:This happend when migrating unit test based on HSQLDB from 1.8.0 to 2.0.0 to replace the deprecated CREATE ALIAS ... FOR HsqlDB SQL.
When execute query : incompatible data types in combination.if the 'outdate' filed is Integer type, I use "select * from user where outdate=0 " execute query , that is fine. but when use "select * from user where outdate='0' " will throw exception...see:
INTERVAL Constant '0:0:0' Not Support.Interval constant '0:0:0' (HOUR TO SECOND) not supported. Only '00:00:00' can be recognized. It is too restrict and it is not easy for the calling application to format the interval string.Oracle supports '0:0:0' interval constant. HsqlDB should support it also.
When execute query : incompatible data types in combination.if the 'outdate' filed is Integer type, I use "select * from user where outdate=0 " execute query , that is fine. but when use "select * from user where outdate='0' " will throw exception...int the HSQLDB 1.8 and mysql , it's fine.Developers is not easy to judge the “outdate” data type。see:
select null throws exception.select null reports following error:data type cast needed for parameter or null literalfor example,
hsqldb2.0 has a bug, about fetchsize.Use hsqldb2.0 database, when the implementation of the query, PreparedStatement set fetchSize value, query the value of the number of records than fetchsize, hsqldb there will be a mistake. Here is test code:
Uncommitted records in COUNT aggregate.Hello,Not sure if this is fixed on trunk.Uncommitted records get included in following statement,-thanks
Committed data lost if no SHUTDOWN issued.Committed data for CACHED tables lost if no SHUTDOWN issued.Steps to reproduce:Result - commited changes was lost.Expected result - commited data never lost, even if no SHUTDOWN command issued.
Transaction broken in 2.0.1?Hi,I downloaded the latest version from June 26 (this is 2.0.1, I think), the java 1.5 version.Following sql gives me unexpected results:The insert was not rolled back.Rob
left outer join on temporary table.Hi,One of our tests with the latest 2.0.1 version fails, (June 26 version, java 1.5).Data setup:A left outer join on b works fine, 1 row is returned as expected:However, the same on the temporary table does not return the single row:Rob
COUNT gives wrong results when using aliased table names.This is a regression. The following code performs correctly on 1.8.0.7, but fails on 2.0.0.
ch09.html bad compression.Navigating to http in Firefox 3.6.6 on Windows XP SP3 yields an error:Content Encoding ErrorThe page you are trying to view cannot be shown because it uses an invalid or unsupported form of compression.
ArrayIndexOutOfBoundsException.In the Class of org.hsqldb.util.ZaurusTableForm, Version 1.8.1.3.In the function of "private void fetchColumns() ":
IDENTITY increase even shouldn't.Hi,I noticed that the Identity id will be increased even if insert statements fail because of primary key violation.Now each time the Identity id will be increase:But just the first statement inserted a value to the database!Testet with V1.8.0 and 1.8.1.3
Table meta-data for tables created in quotes is wrong case.The following class demonstrates the problem. When the table user is created using quotes then the meta-data for the table name is "user" when the table is created without the name in quotes the meta-data for the table name is "USER". Liquibase automatically quotes the table when it is called user.
wrong query result wth Multi-column (A,B) IN (,,)The version 2.0 provides new expression types as "Multi-column (A,B,C) IN ((,,), (,,), ) both with literals and queries" but returns unfortunately wrong results. I've tried the following request with Hibernate (which is working with MySQL) and get 10 rows back instead of 2 rows as it should. In fact it seems that the constraint "IN" isn't taking into account.The queryreturns 10 rows where the sub-queryreturns only 2 rows.
INSERT INTO texttable (SELECT * ...) does not work.Only reproduced with 2.0.0 instead of 1.8.0.I didn't find any way to reopen that, so copying:I get this ex:Thanks, Ondra
JDBCResultSetMetaData.getScale() doesn't check column.JDBCResultSetMetaData.getScale() does not check to make sure that the column that is being accessed actually exists as the other get*() methods in this class. Instead it throws an ArrayIndexOutOfBoundsException when accessing data for a column off the end of the type array. I expect to get a SQLException like the other methods.This behavior exists in the current 2.0.0 GA as well as the current development tree. It is reproducible by examining the code for JDBCResultSetMetaData.getScale() or by calling the method with an out-of-bounds column number (eg. -1 or Integer.MAX_VALUE).
JDBCArray.getResultSet(JI) doesn't report all data.When calling the getResult() methods of JDBCArray with the position and count parameters not all the data is retrieved. For example, if the retrieved array has 3 values and getResult(2, 2) is invoked then only one value (at position 2) is returned instead of the expected values at 2 and 3. See the attached Java program that reproduces the problem.The probable cause is JDBCArray.newColumnResult() at around line 545 in the current work branch. At that line the for loop iterates from 'position' to 'count' instead of 'position' to 'count + position'.This problem is observable in both 2.0.0 and the current work branch.
java.lang.ArrayIndexOutOfBoundsException.Hello, I use hsqbdb 1.8 and I have no problem. I downloaded the 2.0 distribution and found that the following query fails in 2.0 (was working in 1.8) :unfortunately, as the query is generated, i cannot change it...Any idea ?
NPE when referencing a table.See the attached Java program which will throw a NPE.If you remove the "REFERENCES file(id)" on line 19, the NPE goes away.
NPE when trying to drop a column.This bug looks similar to the one I reported yesterday (thanks for the quick turn-around btw!!).See the attached program.
Wrong union select result.When doing select with union subselect like following:on any table (contract is irrelevant) values of test field are all null but should not. For first select in union should be null but for second should be 1.Without sorrounding select like this:query result is proper.The problem is only with null values, if I change column definiotion from null test to 0 test result is right.
HSQLDB 2.0 and Eclipselink errors.I just updated from 1.8.0.10 to 2.0 and suddenly my tests stopped working. I'm using this config:and I'm getting these errors (none of which appeared before):
lock java process.Hi,When I use the latest version of hsqldb, after insert data with unitils-dbunit, I have a lock of java process.Below, the tread dump.
Duplicate table aliases in SELECT do not cause an error.I would expect a query such as the following to generate a parse error along the lines of "table alias 't' used twice":This is not the case in HSQL 2.0 - instead, the alias appears to be bound to both table names, which is unexpected and presumably not the correct behaviour according to the SQL standard.
to_date() function missing.When I try and call the to_date() function I get: user lacks privilege or object not found: TO_DATEto_char() works fine. Other functions also don't exist, e.g. to_timestamp.
Java function syntax doesn't work.The syntax for creating a Java function given in the documentation doesn't work:It complains that the JAVA keyword should not be present.
array comparison doesn't work.i wanted to compare arrays in tables, but the result is always true. example:which can't be. all arrays are different, even the number of elements doesn't match. my understanding of the documentation is that comparison of whole arrays is possible.i'm using a current stable version 2.0.0
NPE in LobManager.presumably some entry in the data array is null and this wasn't anticipated, or the count is incorrect. Unfortunately this error seems to be intermittent and happens deep inside quite a complicated application, so I can't give precise reproduction steps.
SET FILES SCALE not migrated from 1.8.When upgrading a 1.8 HSQL database the SET FILES SCALE setting isn't getting migrated properly. It appears that its by design (from what I can tell) that this can only be set on a fresh database with no data. In my testing my 1.8 database has a scale of 8, after upgrade it is changed to 1; which limits my upgraded db to 2GB (if its being honored, since it's not listed as a valid setting). If it's not being honored, the setting should be set to 8 rather than 1 (in the .script file).I'm using 2.0.0.3754
Joins with parenthesis.When I create the following tables:The I get this error messageI tried making it work using aliases for both tables and the joined table, but nothing did work. The same code works for MySQL, Oracle and PostgreSQL.This bug is related to #1763757 , which applied to 1.8.x.
ISO Year Format Incorrect Implementation.Version of HSQLDB 2.0to_char function using IYYY returns incorrect year.
it is failed that connect to DB.it is failed that connect to DB when exclamation mark in the full path of hsqldb.jar .if running the following source, error occurred .
"in" clause in case or if statement not working.group by product;As you can see from the results of the select, the "in" clauses in the "casewhen"s never match, but equals does. This is a regression from v1.8, where "in" worked in a "casewhen".
Java driver does not handle fractions for TIME data type.The TIME data type discards fraction of second when storing to database as well as when getting from database. Note that in JAVA VM, all temporal data is managed in millis since epoch. Thus when TIME(6) is used, it must be possible to retain the millis and round-trip to database must retain Date that has same millis since epoch. This is not the case in current implementation - HSQL 2.0.This stores 10:20:30 in database and 450 millis are lost.I do have following recommendation to fix the code:The culprits are following conversion methods in org.hsqldb.types.DateTimeType class:In convertJavaToSQL for TIME data type switch the code must be as follows:
Nullpointer in hsqldb-2.0.0 TransactionManager.I am getting a nullpointer when banging the same tables with multiple queries and inserts from different threads. The exception seems to be happend in hsqldb's internal TransactionManager.
Deadlock between LobManager and TransactionManager2PL.I'm using HSQLDB 2.0.0 (in-memory) with Hibernate and am experiencing a deadlock when multiple threads persist lobs concurrently. I've replicated the problem in a very simple test case, and it happens immediately. See below for stack traces from deadlocked threads.
RAWTOHEX NullPointerException.I do the following:I use one of the latest jars from the support page. It declared itself as "HSQL Database Engine 2.0.1". I used in-memory database: jdbc:hsqldb:mem:test
Low performance in CREATE TABLE statements.After having upgraded from HSQLDB v1.8.x to HSQLDB v.2.0.0 the Performance of "CREATE TABLE" statement decreased remarkably (I feel it take ten times longer, maybe measured exactly could show a five times longer durance.)We use an in-memory-instance, very small tables with check-, foreign key- and primary key constraints, and every table is created with default, what should mean "in memory".Has there been added any new feature in v2.0.0, which is responsible for this low performance, and how should I deal with it?
is null stop working in HSQLDB 2.0.The following sql works fine in HSQLDB 1.8, but the query return nothing after the 2.0 upgrade.If I change the query to display "is not null", it returns correct number of rows.ThanksJacklty
Power() doesnt work for negative arguments.Power(2,-1) turns out with "invalid argument for power function". This is not normal behaviour in standard SQL. Negative number is a legal argument to Power,
ad-hoc resultsets not supported.select 1 as ngivesunexpected end of statement
One prepareStatement method does not support generated keys.When using version 2.0, I found that calling this method:results in a statement that when executed with executeUpdate, does not return any auto generated keys. However by simply replacing that line with this one:then the query starts to return the generated keys. This seems like a bug to me. The javadoc (http:) indicates that the first method *should* return a statement capable of returning auto generated keys:Creates a default PreparedStatement object capable of returning the auto-generated keys designated by the given array.
duplicate column name in derived table.I receive an error if I mix * with derived column.If I list out all individual columns, it runs fine.Thanks
database engine fails.I am using HSQL database to replace Oracle in a web application.My connection is currently stored as an application attribute in Tomcat.I am not using a connection pool, but just this one connection.To test the web application I am using JMeter to hit multiple pages with 8 users.The web application works fine with Oracle, but when I use HSQL I get the following error:Then the server dies.And I don't get any errors in Tomcat.
Problem setting transaction level.I tested latest snapshot jar (2010/10/04) from http.Setting transaction level to Connection.TRANSACTION_READ_UNCOMMITTED sets connection into read-only-transaction mode. This behavior is different to 2.0.0 GA.I can't beleave that this is defined in SQL standard.
Cannot create table containing column "filter".I get a SQL exception when I try to create a table containing column "filter":Escaping this column name does not help.This is new with latest snapshot jar (2010/10/04), but was not in 2.0.0 GA.
substring omits last character.After preparation:I used latest bugfix jar (revision 3808) for java 1.5. This problem was not present in 1.8.0.8
rawtohex and empty blob.After preparationI used latest bugfix jar (revision 3808) for java 1.5 and in-memory database. This problem was not present in 1.8.0.8.
Round() - Inconsistent behavior.The build-in function - round() doesn't give consistent result.Can you please take a look?Thank you so muchfrom test
Memory Leak when using Java Language Routines.If I use any JRT functions in sql query, somehow the statement object creates an extra connection.Even though I close my own connection with "Shutdowm" then JDBC close(), I could not get rid of both connections.JProfiler shows that both connections are holding the entire database in memory which causing a leak.The version I used is 2.0.1 RC1, and 2.0.0 doesn't have this problem.Can you take a look? thanksHere is my JRT example
Don't work Native L&F on start in DatabaseManagerSwing.When start DatabaseManagerSwing, native L&F don't work (checkbox enabled), when choose Native L&F directly, then work.
Error message duplicate.and testdb not exists, catching exception java.sql.SQLException: java.lang.RuntimeException: database alias does not exist database alias does not exist.So, don't work "... a new, empty database is created if no database exists at the given path".
NullPointerException in Swing JTree.Stopping
Command line wrong input not checked.
redundant parenthesis in check constraints.When I create a check constraint like this:then the information schema (INFORMATION_SCHEMA.CHECK_CONSTRAINTS) reports a check clause ofThe parenthesis around PUBLIC.PRIMES.PRIM and the numbers are redundant, and should be removed.I do use one of the latest releases fromm the support page for jdk1.5.
ArrayIndexOutOfBoundsException With Array Out Parameters.We're using HSQLDB to do the unit testing for MyBatis (formerly iBATIS). We found an issue with stored procedures output parameters that are arrays. Calling CallableStatement.getArray() returns ArrayIndexOutOfBoundsException. Here's a test case. I'm using version 2.0.1 rc2.Thanks!
Loading Binary File Hangs.Java 1.6The table is properly created, the row is properly added, the binary data is properly load. When I attempt to update the table I end up in a recursive loop here.Not sure if this comes into play as I am just getting familiar with the HSQLDB code base but the txManager is TransactionManager2PL. Please let me know if this is an error or bug or a PEBKAC issue.Sincerely,Tim
PSM (PL/SQL) routines do not see variables in MERGE statemen.When I try to use variables as arguments in MERGE statement, I get 'user lacks' error.There is a script in attachement that creates database schema.And here is a procedure that can not be compiled but probably is correct ('lack' on 'vstrTrunc' and 'vnID'):
Perfectly invalid date/time truncation in TRUNC() function.Simple test case:So I get :Also, my time zone is GMT+3And function TRUNC() does not know anything about 'SS' specificator.
Invalid sequence number generation on UPDATE in MERGE stmt.Script to create test schema is in attachement.When there is no data in TM_VOICE_MENU_STAT table, values for nID column are generated sequentially and correctly.So this MERGE statement works:But when I execute it again, it fails on 'UNIQUE constraint or index violation'.That can only be when value for update ST.nID is generated once.Tested on revision 3889 from subversion repository.
In JTree of DatabaseManagerSwing view and data is the same.When choose View->Show row counts, And right-click on table (for example, "AUTHORIZATIONS ( 5 )"), and choose SELECT * from AUT..., then created wrong query SELECT * FROM INFORMATION_SCHEMA."AUTHORIZATIONS ( 5 )"
'set database sql syntax ORA' statement.In documentation:Use <set database sql syntax ORA statement> to enable support for DUAL, ROWNUM, CURRVAL, NEXTVAL and non-standard data types.But in fact 'set database sql syntax ORA;' does not work: 'unexpected token ;'
convert for double returns exponent 0.When I do the following:the this statementselect x, convert(x,varchar(40)) from tabreturns the following result:I think, that all the trailing "E0" should be ommitted. As in MySQL, Oracle, PostgreSQL and hsqldb 1.8x. I use one of the latest releases from the support page.
Invalid database restoration using log file.1. Create database using hsqldb.sql file.2. Execute test from Tm_HSQLDBTransactionTest.java.Test case does simple: it inserts data into memory table (TM_MENU_ITEM_IMP), then executes procedure (PR_UPD_MENU_ITEM_STAT). This procedure:After procedure call it commits a transaction.3. When test finishes normally, cached data is written to binary data file, but database log looks like:So there is:4. Connect to database with DatabaseManagerSwing and perform 'SELECT * TM_MENU_ITEM_IMP': There are records in memory table!Do similar but terminate test case abnormally (by killing process or java machine) when it reaches instruction 'System.out.println("Not terminated abnormally");'Now you can see that there are records in memory table and no committed data in a cached table!
Deadlock between LobManager and TransactionManager2PL.Similar to the bug 3072706, i can reproduce this problem with hsql in-memory (14-Nov-2011,2.0.1-rc3SNAPSHOT) and hibernate 3.6.I got a deadlock when multiple threads persist lobs concurrently.One thread got a lock on the database, but have to wait before a synchronized method (LobManager.adjustUsageCount)The other thread wants the lock too, but is in the synchronized method LobManager.setCharsForNewClob.See below for stack traces from deadlocked threads.
SQLException with NullPointerException in cause.Database creation scipt (sql), empty database snapshot (tar.gz) will provide.Tested under jdk 1.5.0.12. For tests used latest snasphot from Subversion.Also, test case is in attachement, too.
Embeded Blocks in Multithreaded environment.I'm usgin v2.0.1RC2 embeded with my application.It get blocked arbitrarily when two threads that share the same connection executes two statements (one each).Is not possible to share connections?Thanks a lot...Good work!
HSQL can't read it's own timestamps.If I want to transfer some data from one database to the next I would select the columns from one database connection and then insert into the other database connection. This works fine for strings and numbers, but when it comes to times and timestamps, the output format of the select is incompatible with the input format of the insert. It would be really nice if HSQL could reads it's own output. The error is: Wrong data type: java.lang.IllegalArgumentException: Timestamp format must be y.I've seen this in both 1.8.x and 2.0.1-rc2
NullPointerException in changeToDiskTable (session==null)I got a NullPointerException on an Select () on a View which has more than 10000 items and following prev. statement set:I use the the newest hsqldb-2.0 version.
OutOfMemory.After updating to hsqldb (02 December 2010. HyperSQL 2.0.1 RC3 ) my previous problem is fixed, thanks.But now, my whole TestSuite doesn't work in the in memory-variant. The server-standalone is still okay, in the last stable version the test was okay with heapspace 512m, now with a lot more heapspace (1568m) I get a OutOfMemory at all.The attached stacktrace only tell us the part where the memory is called, but not where the other memory is hold.If you tell me what you need, I will give your extra information.GreetingsChristian
USING keyword not accepted.We normally run our application with a Oracle 10g R2 database.For unit testing reasons we'd like to use HSQLDB (we downloaded hsqldb-2.0.0).We setup a JUnit test environment were we read in our DB scripts to create the DB.We adapted current scripts by converting VARCHAR2 --> VARCHAR, NUMBER ---> INTEGER or NUMERIC or similar.But we thought, the USING keyword is allowed since it is on the feature list.But we got following error
Query with result errors when mixing subquery and group by.to view the error, try:prepare data with this querry:
SYSDATE not accepted.At http we can read that SYSDATE can be used:
datediff 'ms' returns nanoseconds.It seems that in hsqldb-2.0.0, the following returns units in nanoseconds.According to the documentation, it should return 1000 (milliseconds). But it returns 1000000000 (nanoseconds).
wrong result set for query.When i run the following query on the attached database (2.0.1-rc3 version) i get 2 results instead of one.You can see that the join does not work correctly:Checked the same on 2.0.0 version and it was fine
CountUpDownLatch seems insufficiently concurrent.In a highly threaded environment (64-256 simultaneous connections all accessing an embedded db with a mix of read/write, mostly read), I get stuck at the latch.await() call in Session.executeCompiledStatement(); various others have reported this on the forum. It is a bear to replicate, but seems more prone to happen with more cores (my machine is a quad-core).In looking at the code, CountUpDownLatch seems problematic; the filed 'count' is not volaitle, which means under concurrent access, different threads can increment incorrectly. FOr example:Thread 1 calls countDown(), in its memory picture 3-1 becomes 2.at the same timeThread 2 call countUp(); in its memory picture it has it's own copy of count, no volatile, so 3+1 becomes 4, when it should have been 3.In fact, while volatile will help, it should probably be an AtomicInteger, or similar structure. Volatile would however be enough if the CountUpDownLatch is accessed by separate threads under an exclusive lock; a surface look indicates this is the case. Exclusive locking however does not guarantee the memory barrier effect of volatile.Without doing more looking in TransactionManagerCommon et al, I can't tell if the methods within CountUpDownLatch are meant to be atomic; setCount() in particular seems like it should execute synchronized from all other CountUpDownLatch methods, but the usage pattern of CountUpDownLatch may protect against this.
Case/When unsupported internal operation: ExpressionOp.I had a query that used to work with V1.8.1 but now fails in V2.0.0 with ArrayIndexOutOfBounds exception and now in V2.0.1RC3 with 'unsupported internal operation: ExpressionOp'.
Uncaught Exception.I have downloaded the latest driver for 1.6, today, and the problem still exists:We have a DB-connection monitoring, which catch Exceptions due to connection-lost. This works quite fine. Since we have implemented a generic UncaughtExceptionHandler for all running Threads in the app the Exceptions from HSQLDB are also caught:java.lang.RuntimeExceptionat org.hsqldb.jdbc.JDBCConnection$1.run(JDBCConnection.java:2829)Little bit annoying is, that this exception cannot be handled in our app. Anyway, is there a chance that this exception is caught within HSQLDB-driver?
 #1094 INTERVAL Constant '0:0:0' Not Support (oringal Id  3019349)I have report the same bug (Id 3019349 ) before but it is closed as invalid. But when I check ANSI SQL-92 standard, your comment is incorrect. '0:0:0' is a valid hour to send interval according to ANSI SQL 92 standard:Values in interval fields other than SECOND are integers. SECOND,however, can be defined to have an <interval fractional seconds precision> that indicates the number of decimal digits maintainedfollowing the decimal point in the seconds value.Leveling RulesBecause I can't reopen the original bug, I create it again.
NPE in RowStoreAVLDisk.I am using hsqldb 2.0.1-rc3 compiled for JDK 1.5 with hsqldb.default_table_type=cachedThe problem occurs when 2 threads are both deleting rows from the same table.I get this exception :
OutOfMemoryError when using cached tables.I am using hsqldb 2.0.1-rc3 compiled for JDK 1.5 with hsqldb.default_table_type=cachedI added 50000 items in my table while using cached table (As expected I get an OutOfMemoryError when I use memory tables)When I try to delete these items , I get an OutOfMemoryError :
missing syncronized block for time conversion.The following error occurs on HSQL version 1.8.0 & 1.8.1:Problem is in class: HsqlDateTimethe following method should be fixed - to add syncronized block on the calendar object:
incompatible data type in conversion with java.lang.Boolean.When adding a java.lang.Boolean as an Argument of a PreparedStatement viajava.sql.PreparedStatement.setObject(int, Object)im getting a Stacktrace like this:The Query looks like this:I tried 2.x rc2 and rc3 and it seemed to be no problem in 1.8.x
'incompatible data types in combination' with timestamps.I'm getting an SQLException, running an arithmetic operation on a Timestamp.My java code looks like:This query happened to be no problem in hsql1.8.x. I already tried hsql2 rc3
'LIMIT 0' broken.'select * from anytable limit 0' is a valid query (I agree, doesn't make a lot of sense) and HSQLDB 1.8 correctly returned zero rows. Release 2.0 (including 2.0.1 RC3) throws an error: 'Data exception: invalid row count in fetch first clause, Sql state: 2201W, Error Code: -3452'.The bogus part is in org.hsqldb.QuerySpecification, lines 1178-1187:Line 1178 checks for <= 0. Line 1182 allows 0 as a valid value, but asigns 'no limit'(!) which again would be wrong, if line 1178 were fixed.In my opinion, 'LIMIT 0' should, as in the earlier release, return a result with zero rows. All other rdbms behave like this.
invalid results for queries on indexed columns.Those 2 examples demonstrate strange behaviour relating to queries on indexed columns.
Discrepancy between getObject(int) and getArray(int)I have found a discrepancy between the two PreparedStatement methods getObject(int) and getArray(int) for DATE ARRAY columns.It can be reproduced as follows:The getArray(1).getArray() returns an array containing java.sql.Date classes, which is the expected mapping. This also happens when selecting getObject(2). But getObject(1) returns an array holding a HSQLDB-internal class. I guess the automatic mapping was forgotten for datetime types? It seems to work for numeric or string types...
NullPointerException in insert into INTERVAL Type.I have found a NullPointerException on insert into INTERVAL Type.It can be reproduced as follows:Usage on INTERVAL Type is correct?I use by default as VARCHAR.I guess the problem is in the call to IntervalType.convertToDefaultType method here (IntervalType.convertToType(SessionInterface session, Object a, Type otherType) line: 620):
hsqldb.init & SERVER_ADDL_CLASSPATH.Starting from line 400 variables are being exported because the jvm is started in a new shell with eval exec.But variable SERVER_ADDL_CLASSPATH has been forgotten.And thus user defined classpath is not given to jvm.So line 401 should read: export SERVER_ADDL_CLASSPATH
Parameterization of days number causes NullPointerException.Note: The query "select current_date - 20 day from document" works fine.
dead lock when checkpoint.When hsqldb execute a checkpoint, the entry point is org.hsqldb.persist.Logger.checkpoint, at here it will get a lock of logger, Then it will go to session.commit, in here, it will try to get a write lock of transaction, that's ok. But when we execute a select sequence statement, the execute order of updating of sequence is: get a write lock of transaction,then try to get a lock of logger, that's dead lock.Note: I am running on a non-English environment, so I translate some key-word to English by myself, maybe some words are different.
FrameworkLogger resets application log configuration.it seems very odd to me that an embedded database would feel free to reset the logging configuration of the entire application. as it is, our application does programmatic configuration of the java.util.logging framework upon startup. however, when we attempt to open an hsqldb database, the FrameworkLogger class resets the jdk LogManager to its original configuration.i'm surprised that this is not the default behavior, but at the very least there should be a configuration setting for telling hsqldb to leave the logmanager alone.
hsqldbmin build target does not seem to work.i built the 2.1.0-rc4 release using the ant targets "switchtojdk16 hsqldbmin". however, the resulting jar file would not work in my test code (using a simple, single threaded, embedded db).
jdk Logger leak in FrameworkLogger.when using the jdk logging system, each new database adds a logger to loggerInstances, but these loggers are never cleaned out. they should be removed when a database is "shutdown". (in our application, databases tend to be transient, and we may open many different dbs while the app is running).using hsqldb version 2.1.0-rc4.
Query with DISTINCT erroneously returns no results.As you can see when running the attached SQL, some queries using DISTINCT return no results,but correctly return repeated results when DISTINCT is omitted.This bug is in all of the 2.1.0/2.0.1 release candidates, but not 2.0.0GA, nor 1.8.1.3.
Failed to use Hibernate StatelessSession with version 2.1.It seems there is an issue when you try to get a result from an Hibernate query using a StatelessSession, no result is returned and it causes a dead lock. When using version 1.8 everything works fine.
wrong property name in docs for max memory rows.the database property for the max number of rows in memory is "result_max_memory_rows", but the (2.0) documentation refers to the property as "max_result_memory_rows".
Can't delete db files after shutdown with NIO.If HSQLDB uses NIO to access data files, I can't delete the database data files after the database is shutdown. This looks like a symptom of long standing JDK Bug 4724038 (http). When calling FileChannel.map(), the returned MappedByteBuffer will hold a handle to the underlying file until it is garbage collected. Windows can't delete files with open handles.I've attached a test case that demonstrates this problem and a patch to ScaledRAFileNIO that implements the workaround described in JDK Bug 4724038. I believe this workaround should be safe for HSQLDB since the buffer is unmapped immediately before removing all references to it. The patch has only been tested with Sun JDK 1.6.23 on Windows x64.It looks like the folks at H2 hit a similar issue: http
Throwing Exception: Running an HTTP server to use batch file.I couldn't have run an HTTP server by ClassNotFoundException when starting to use runWebServer.bat.The package name mistakes?
Exception while upgrading to version 2.1 from working 1.8.7.Hi,I did upgrade from version 1.8.7 to the latest 2.1.0 and I am getting following exception for a code which was working before. I am trying to inserta PDF binary file into a table like thisfollowing is the java code which was working on 1.8.7 and is failing on 2.1.0
"database does not exist" opening jdbc:hsqldb:res: catalog.In revision 4124, org.hsqldb.lib.FileUtil.FileAccessRes.openInputStreamElement(...) was updated to use the thread context classloader if the current classloader was unable to load the requested resource.However, the isStreamElement(...) method - which is used to verify that the resource exists before calling openInputStreamElement(...) - uses only the current classloader.This prevents a jdbc:hsqldb:res: catalog from being opened in situations where the use of the thread context classloader is called for, and results in an exception like the following:Method org.hsqldb.lib.FileUtil.FileAccessRes.isStreamElement(...) should be updated to use the thread context classloader in the same manner as openInputStreamElement(...); a proposed SVN patch for base/trunk is attached.
databasemetadata not showing 2.1 info.Database product version still at: 2.0.0
index and ordering by multiple columns.I have a database with about 500k user PROFILES. There is an index on LAST_LOGIN column. Because there are sometimes multiple rows for same values of LAST_LOGIN for queries I use ordering by LAST_LOGIN and ID. This is very useful when using queries for paginating results. For example when I have last previously received LAST_LOGIN and ID, I create query like " select * from PROFILES where LAST_LOGIN > ? or (LAST_LOGIN = ? and ID > ?) order by LAST_LOGIN asc, ID asc". For reversed direction query looks like " select * from PROFILES where LAST_LOGIN < ? or (LAST_LOGIN = ? and ID < ?) order by LAST_LOGIN desc, ID desc". The same query ordered by single column takes 15 ms, ordered by both columns takes 15 seconds, so I suspect index is ignored when ordered by additional column despite the fact second column in order by clause have small impact of returned results.
NullPointerException using MINUS with large tables.When executing a minus statement such as "SELECT item_id FROM TABLE1 MINUS SELECT item_id FROM TABLE2" with tables with many rows I get a null pointer exception in RowSetNavigatorDataTable (see below). Attached is a test to reproduce this. It happens when I populate the tables with at least 100000 rows but not when less than 10000 rows. I'm seeing this in hsqldb 2.1.
Util.sqlException for Result throws base SQLException.org.hsqldb.jdbc.Util.sqlException(Result r) does NOT delegate to the sqlException function that throws the correct SQLException depending on the sqlState.This means you can't catch any of the SQLException hierarchy from the client code.
sql.enforce_size property does not work.Whilst upgrading from 1.8 to 2.1 ran into the problem of the change in VARCHAR length behavior that is well described in the documentation. However, one can't work around this with properties after all.Setting the sql.enforce_size property to FALSE (before creating tables) does NOT prevent exceptions from exceeding specified VARCHAR lengths in version 2.1.Checking the .script file shows that the statement "SET DATABASE SQL SIZE TRUE" is always present, regardless of whether the property is set to false or not.Also, using the "older" property described in the documentation, "sql.enforce_strict_size" triggers an invalid property exception.David
Adding support of org.hsqldb.types.Types.DATE as a Timestamp.We are using HSQL as an Oracle DB emulation and needed this fix to support Dates as timetamps.The attached patch fix this issue from 2.1RC3.
Adding support of Inserting boolean in number(1)We are using HSQL as an Oracle DB emulation. Oracle supports inserting a boolean in a number(1) column. The attached patch adds this functionality.
Adding support of NVARCHAR2 & dotted selects.We are using HSQL as an Oracle DB emulation. The attached patches adds support of NVARCHAR2 and dotted queries like this :select table.col1 from table
deadlock in ScriptWriterBase (checkpoint)sync order against BufferedOutputStream and ScriptWriterText are inconsistent; checkpoint causes deadlock:
Using ARRAY in with recursive.If you create the following table 'RECUR' and execute the provided 'with recursive' statement the error
Concurrent write while backup.Hi,sorry if this issue was already discussed in another thread that I didn't find.We're currently implementing a solution where the backup is performed while the server is running. The SQL statements are executed using the JDBC connection. As you know, while the backup is performed, the database is locked. This means all reading/writing processes are blocked.Here comes the bug description:After the backup is complete, all writing processes are unblocked, thus a new .log file is being created. And it starts with the INSERT statement (for table XXX). If you close the Java program without closing the database (e.g. process got killed, power failure,..), the log file continues to exist. On next startup, you get an exception that the table XXX was not found and the rest of the log file is being ignored. Finally, the log file is deleted so it's not even obvious WHY the table XXX was not found.And here comes the workaround:if you perform a checkpoint right after the backup, everything seems to be fine (was not able to reproduce this error) - but I won't bet ..Attached, you have a cropped version of the source code to reproduce the problem (~80% of executions). You may need to adjust the iterations and backup waiting time. The idea is that the backup starts WHILE the thread is writing data.
Upload 2.1.0 jar to maven repository.Please upload the "Latest stable version" (i.e. 2.1.0) release artifact(s) to the Maven central repository.I have some unit test scripts that use nvarchar, which work with 2.1.0 but give an "unknown data type" with the latest version currently available there (2.0.0).
Allow column defaults of form "(1)".A table definition I extracted from a MS SQLServer database had columns specified with the formbut when I try to run these into an in-memory hsql database, it gives an "unexpected token" error at the opening brackets.I assume the "literal" definition in
ClassCastException when casting to longvarchar.I'm getting a ClassCastException from the hsqldb driver when executing this SQL statement:This doesn't work anymore with the newly released version 2.1.0. It worked with 2.0.0. The stacktrace from the HSQL Database Manager:
Cannot have procedure parameters of type longvarchar array.This used to work with version 2.0.0.With version 2.1.0 it doesn't anymore, I get an error:
SQL DATA access clause is now mandatory.I'm not sure if this is wrong now in 2.1.0 or if it was wrong in 2.0.0 and fixed now. But it's not really documented here:I didn't find a comment about that in the release notes either.This used to work in 2.0.0:
Cannot create CHAR[ACTER] LARGE OBJECT type.According to the documentation, I can use CHAR[ACTER] LARGE OBJECT as synonyms for CLOB when creating tables:This doesn't work in 2.1.0, though:
LONGVARCHAR seems to default to LOB now.The newly added setting seems to be defaulted to TRUE (maybe after upgrading from 2.0.0 to 2.1.0? I'm not quite sure...):SET DATABASE SQL LONGVAR IS LOB TRUEIt would be more backwards compatible, if it were set to FALSE by default.
SessionManager.closeAllSessions() can cause deadlock.I am experiencing deadlock when two different threads attempt to close the database with hsqldb 2.0.0 and 2.1.0. The issue is that Thread-1 acquires a lock on SessionManager@58a983 when SessionManager.closeAllSession() is called. Thread-1 is also attempting to invoke Session.close() the active sessions (i.e. Session@e107d9) which requires a lock on the session. Meanwhile, Thread-2 has already acquired a lock on Session@e107d9 when it called Session.execute(). Thread-2 is also attempting to acquire a lock on SessionManager@58a983 for SessionManager.closeAllSessions, but the lock was already obtained by Thread-1. I have posted a more concise summary and the relevant thread dumps below.Deadlock summary
LIMIT 0 returns one record.These two queries return the same record:I would expect "LIMIT 0" to return nothing (like MySQL, Postgres. SQLite, H2) or raise an error (like Derby). Is this the expected behaviour or is it a bug?
DatabaseManagerSwing won't start with -noexit.won't start and throw exception "No value for argument". throws exception when there is no arg for -noexit.This will fix the issue:
DatabaseManagerSwing throws exception.In Rev 4201,This will also check for the case DatabaseManagerSwing --user --password. The addition won't take --password as the argument of --user.
rolling back to unnamed savepoint rolls back entire txn.i'm using hsqldb 2.1.0GA. in testing savepoint functionality, i found out that rolling back to an unnamed savepoint (created via Connection.setSavepoint()) seems to roll back the entire transaction. when i run my test with a named savepoint it works as expected.my test is essentially:
Clarify LOCK TABLE behavior.The behavior of LOCK TABLE statement as described in the documentation does not specify whether READ lock is shared and WRITE lock is exclusive. Is it an implementation of "readers-writer lock" as exists in Oracle/PostgreSQL "lock table {table_name} in share|exclusive mode" statement?If not, please adjust the documentation, if yes, there is a problem with taking locks (assume 2 concurrent transactions):
Array and wasNull-Call.I figured out that the resultSet.wasNull() does not work correctly while using SQL arrays.example:
The SQLSyntaxErrorException while createArrayOf in 2.2.Any call of the createArrayOf() method for a JDBCConnection in HSQLDB 2.2 throws an exception.The same thing for HSQLDB 2.1 is OK.My systems were:
Table and Schema information missing from metadata at random.It seems that under certain conditions, Hypersonic will return empty schema and tableName metadata even when such data should be available. For example, this query:Results in metadata only for the invoice_invoice, prod_product, and invoice_element tables. The rest have schemaName and tableName values that are left blank. Shuffling the joins around does affect which tables are missing metadata, but not in a predictable way. For instance, sticking the two outer joins in the query above at the very end of the list of joins results in all tables except prod_type having metadata. I can provide a database for examination upon request.
NullPointerException when ordering by NULL.This is a minor issue. When I run this:I get a NullPointerException:This works:This doesn'tI think the NPE should also have an associated error message. On the other hand, why is 1 permitted, and no other value is?
offset/limit broken with unique-index.It looks like, a unique-constraint breaks the behavior of offset/limit. I attached a sample db, which was stripped down from our production table. Decoupled from our project, it doesn't make a lot of sense, but it shows the bug.The following query lists the rows I'm interested in:Now using offset/limit, I would expect to be able to get the same result piece by piece. For example, the following query should return the rows with rid 82 and 83, but it returns 88 and 89:Or from offset 4, I would expect rows 86 and 87, but I get 90 and 91:With offsets 6, I get the same result as with 4. Same for 2 and 8. Same problem with other offsets.
Comparing DATE column to DATETIME produces error in 2.2.2.Comparing a column of type DATE to DATETIME values no longer works in HSQLDB 2.2.2. The build made on May 17, 2011 to address the metadata issue does not have this problem. The expected results for the below queries that produce errors are the same as the results of the previous query.Sample script:
JDBCClobFile length() bug for fixed width enc > 1 byte.I'm just posting this here so that it is a known bug between releases 2.1 and 2.2.2.Basically, the bug results from failing to provide a sufficiently rigorous unit test, togther with an inadertent typo where the file length is multipled (*) by the fixed character byte width, where it should be divided (/).This will only manifest for truely fixed width encodings of over 1 byte per character, such as "UTF-16BE" and UTF-16LE" (which are hopefully rather uncommon)This will not manifest for UTF8 or UTF16, since they are not fixed width encodings, and will not manifest for latinxxx or any other single byte encoding, since multiplication and division by one both yeild the same value.The fix and updated unit tests will be commited today.
Exception getting connection.org.hsqldb.jdbc.JDBCDataSource.getConnection(String, String) checks field user for not being null instead of corresponding accepted argument.It leads to exception "invalid argument: user" if user was not set previously explicitly with setUser(String)
Create Temporary Table as select WITH DATA.if you create a table from a select statement, and the data is to be published into the created table, doesnt work.This only solution is to create with no data and then insert the the rows.
session hangs with invalid use of table function.This can be reproduced most easily with the HSQL DatabaseManager. Create this function (or probably any function returning a table):The session hangs. The database server is not affected, i.e. new connections are possible. Also, it doesn't seem to matter whether the database is run in in-memory mode, or server-mode. I have observed this with both versions 2.2.1 and 2.2.4. Here's a thread-dump of the hanging thread:
INFORMATION_SCHEMA.COLUMNS regression or new feature?There seems to be a regression between versions 2.2.1 and 2.2.3/2.2.4 in the INFORMATION_SCHEMA.COLUMNS view (I didn't check 2.2.2). If it's intended, then I didn't see it in the release notes:I think this is quite an important change between such minor releases for it not to be mentioned, that's why I thought it might be a regression. Here's what I observed. For this table:I used to get these values in 2.2.1:Now I get these values in 2.2.4:What do you think about this?CheersLukas
INFORMATION_SCHEMA.ELEMENT_TYPES doesn't work.In your release notes, I found that you have added this new INFORMATION_SCHEMA.ELEMENT_TYPES view in 2.2.3:I have tried selecting from it and got an unhandled exception:
java.lang.Bug on query handling.java.lang.ArrayIndexOutOfBoundsException encountered on a queries to a particular view structured as demonstrated by the attached test program
Error in handing update/insert/delete on a view.Thanks for the prompt response. However, it looks as though the fix for 3354244 had introduced new bugs. It is no longer possible to prepare statements to update/insert/delete on that particular structured view.This is demonstrated by the attached test program
union and character padding.When I do the following:I used
RuntimeException with ORDER BY CASE...This is how to reproduce it (with 2.2.5):
ClassCastException with < ALL operator.Here's another one of those highly unlikely queries that I tend to come up with for my own integration tests :-)This doesn't
NullPointerException when calling char_length.Casting again.This works fine:
Statement.RETURN_GENERATED_KEYS in Batch broken sine 2.2.We have Batch insert operations that works with generated keysThe flow that used to work in hsqldb 2.1.0 is now broken in 2.2.5 (and 2.2.4) (BTW the same code is on in Oracle and MySQL)The error I'm getting now is:" java.sql.SQLException: invalid cursor state: identifier cursor not positioned on row in UPDATE, DELETE, SET, or GET statement: ; ResultSet is empty"JDB code is as flowing:
incompatible data type in operation for call parameter.adding a cast for the parameter eliminates the error, but should not be required because the LHS of the catenation is unambiguous (binary type)
Doubts about new ELEMENT_TYPES table.Hi Fred,I'm trying to get a hang of all the new equijoins between dictionary views that you impose on me :-) I have found an inconsistency in version 2.2.5 (or maybe I'm misunderstanding something?). Consider these three simple stored procedures:I can use the DISTINCT keyword as a workaround, for now... What should be the correct behaviour? Because if duplication is correct (due to explicit matching by parameter ordinal), then I'd be missing the ordinal information from the INFORMATION_SCHEMA.PARAMETERS view
Bad link on hsqlUsing.html.On this page here:...the link to ObJectRelationalBridge - OJB is "broken", i.e. the OJB project has been retired in favour of Apache's OpenJPA implementation:
Duplicate Column Names even with Alias.Select both fields and a third using substring of one of them with an Alias.HSQL throws an exception "Duplicate Column name in derived table"I think it doesn't take the alias into consideration as the new name of the field.To reproduce the bug: execute the following 2 statements
Aggregate Function - unsupported internal operation: Type.After updating HSQLDB from 2.1rc4 to 2.2.5, I can no longer perform the following SQL query anymore (calculate weighted average with 2 columns)Could you take a look of it?Thank youjacklty
NullPointerException when dropping schema.Hsqldb 2.2.5
subselect doesn't work correctly with a view.when using a view in an inner select as described in the following example, no results are returned.when the view usage is replaced with the table or tvo.val in the where clause is replaced by a hard-coded string, results are returned as expected.The query is a simplified example of SQL generated by Hibernate-Envers so modifying the SQL is no option for us. We use a database view to support legacy code.
Identity colum: Inconsistency between documentation and code.The documentation suggests at http states the following syntax for column definitionThe key (for this issue) is the comma (,) between START WITH <n> and INCREMENT BY <m>. When I do this I get an exception "saying unexpected token: , required: )". Basically saying it is expecting a space instead of a comma. If I remove the comma between start with and increment by it works. So it would seem that the documentation needs updating, right?
BooleanType.convertToDefaultType() does not support numbers.BooleanType.convertToDefaultType() does not properly convert a number object to a boolean for insert/update into a database. It seems to only handle Boolean and String types.
Exception over an HTTPConnection on huge records insertion.The Java test file is uploaded here.The test results are below:My systems were:The results are same.
Create table hangs after writing to another table.Using HSQLDB 2.2.5, if I do the following:The call to create the 2nd table hangs. Is this expected behavior? See the attached test case.Using HSQLDB 2.1.0, the attached test case passes.
parameter of type char(1) in merge takes 32K of memory.After upgrading from HSQDBL 2.2.4 to 2.2.5 we noticed a dramatic increase in HSQLDB's cache's memory consumption. After some investigation we discovered that a parameter on a CHAR(1) value in a MERGE statement was being padded out to CHAR(32K). For a cache size of 50,000 rows this translates into roughly 1.5GB of additional memory usage.Here's the table definition and the merge statement:The problem does not reproduce if we change the data type in the merge statement to a varchar. I've also attached a JUnit test that shows the problem and will lead to OutOfMemoryErrors when run with a max heap size of 1GB.It looks like this behavior was introduced in r4345.
NPE when data fiel is locked on disk.HSQL Database Engine 1.8.1I think, HSQLDB should throw a meaningful exception that cane be recognized as "datafile is locked".
error parsing a parameterised SQL.The following query is legalThe above SQL is accepted by both Oracle and DB2.Attached is a test program for this
Missing caused-by exception.When an IOException occurs during the JDBCPreparedStatement.setBinaryStream() the causing exception is lost because not given as cause to Util.sqlException().should become:
VARCHAR is space padded or trims trailing spaces.VARCHAR appears to be padded with trailing spaces (or trailing spaces are trimmed), which means that VARCHAR columns with a unique constraint can't have 2 entries differing only by trailing spaces. I would expect this behavior from CHARACTER but not VARCHAR. See the attached test case.
NPE at ServerConnection thread.We had been using HSQLDB for a long time and some time ago have switched to 2.x version. Unfortunately, recently we have got freezing of our application in our old and reliable DB related code.The reason is NPE in HSQLDB's ServerConnection thread. The problem is stable reproduced on the latest HSQLDB 2.2.5 and looks like thisException in thread "HSQLDB Connection @1ebd75b" java.lang.NullPointerExceptionThis NPE brings to opening new server socket without closing the old one. As result, client code doesn't know anything about server side problem and waiting answer on the old socket forever:I've attached java example for the problem reproducing. Just start it and NPE will appear.For now, I've found temp. workaround for the problem: set FETCH_SIZE const in the example to zero. Another known workaround is to use separate connection per table access via ResultSet.
DISTINCT crashes in 2.2.6-SNAPSHOT.Attached test case blows up on SVN 4417 + 4421(HEAD)
2.2.5 Memory Leak on 'MERGE INTO' with sample code.Scenario:1) I start with no existing database on the file system2) After 'INSERT INTO' 10000 records in a table using an prepared statement, and closing down the connection, about 10MB is in use in the Java VM after Garbage Collecting 3x with 2 second sleeps in between.3) I remove the database files from the file system, and change the prepared statement to use 'MERGE INTO', and shoot the same 10000 records into the database. Result: about 700MB(!) are in use after 3x GCOther trial run scenarios:- I executed on both Java 1.7 and 1.6 and the results are similar.- I executed the prepared statement in batch mode, as described in the manual: Still same results.- I changed the scenario to 5000 records, and the 'in use memory' after closing down the connection varies significantly (to me this denotes a second kind of memory leak, as it applies both to the INSERT and MERGE scenarios.Here are the numbers.Attached is the sample code.
JDBC 2.0 ResultSet updateRow is not working as expected.I have simple ResultSet with update of current row (if required by application).It works in MySQL and Oracle. But Breaks in HSQLDB.Can you please be so kind to look at it?Environment tested hsqldb v 2.2.5 and any before. Java 7 or Java 6
Upload 2.2.5 jar to maven repository.please deploy the latest version to central maven repository
Integrity constraint violation.Summary how to represent situation is in attached SQL script.First we create schema with 3 tables (dictionary, temporary table, storage table) and 1 view to select data.Then we create procedure that merges data from temporary table into storage table.When there is data in a temporary table, all is ok.But when there is no data in a temporary table, call statement:Fails with:
ORA compatibility:rownum misunderstood in DELETE query.In a DELETE query, ROWNUM can be used to restrict the number of records to delete in one query, like for example:The above statement should delete 1000 rows from 'hugetable'. However, in HSQLDB this statement has no effect if the total number of rows in the table exceeds 999 rows (0 rows deleted). ROWNUM seems to be interpreted as the total number of rows in 'hugetable', which is not correct. ROWNUM (in Oracle) means the current row it is acting upon, meaning it will run from 1 to the maximum rows in the table.
SQL Routine NOT FOUND handler not work.From the doc, it said whenever update affected 0, should go to not found handler, but it did not do that.In below example, you can see table B, msg is empty always.Example:
Trigger+Merge do not see variables in Merge statment.Similar to an old bug:routines do not see variables in MERGE statement.This time is a trigger. The trigger cannot compile, it said cannot see newRow pointer for the NEW data.Thanks Fred!
Allow for omitting parentheses when calling procedures.According to the Javadoc of CallableStatement (and to some SQL dialects, especially that of Oracle), stored procedures without any arguments can be called without parentheses, e.g. these two should be the same
Calling org.hsqldb.Server.main with the argument  "--props".Whensoever you call "java -cp ../lib/hsqldb.jar org.hsqldb.Server --props ../bin/config/server.properties" following exception is thrown:But the argProps has still the property named system.props=../bin/config/server.properties and this property is for the server an invalid property, so in the method Server.setProperties(HsqlProperties) the calling of HsqlProperties.validate is thrown the org.hsqldb.HsqlException.The patch removes the server.props property from the argProps if the propsPath is not null.
MVCC+READ_COMMITTED: sql in SQL routine fail to acquire lock.Please see attached doc file for description and related ready-to-run files.In a normal SQL, if we use MVCC+Read_Committed, and setAutoCommit(false), then when issue SQL like "Update xx", we will get the row lock until commit.In SQL routine, we cannot acquire row lock when issue SQL like "Update xx".However, it will be able to detect the lock acquired by other transactions. [Will pause if lock acquired by other transactions]Below is a simple example to simulate the case:1. A Java program called Locker to acquired a row lock on a row on FIX.LOCK_TBL table;2. A Java program called SPRunner to run a SQL routine.The SQL routine will run below.Note that when the SQL routine run to 2.2, it will pause because a open transaction by 1.This is to simulate a "Sleep" inside the SQL routine.3. A Java program called Attacker to runIf the row lock of BB table execId='100' has been taken by SPRunner, then Attacker should wait until SPRunner release.However, the result is thatAttacker can run immediately, check the table, found the f_2 value changed to 6. It proves sql statement in SQL routine fail to acquire row lock.
Trigger "Instead of update" fails.Update is not working on views with "instead of update" trigger.
Can't drop view if any table is being locked.Even though the view and table are unrelated
bug in parsing create table statment.As diescribed in the doc a create table statment with auto incremented key should have following syntax:
bug in parsing create table statment.As diescribed in the doc a create table statment with auto incremented key should have following syntax:
Cascaded Views + Sub-Select » ArrayIndexOutOfBoundsException.The following schema cannot be imported into 2.2.6-SNAPSHOTI'll keep my fingers crossed, that you'll find a solution to this problem. ;)Cheers,Andy
getGeneratedKeys() multiple row inserts does not work.Inserting multiple rows with PreparedStatement (sql, "generatedColumnName") and addBatch()/executeBatch does not return generatedkeys with HSQLDB 2.2.5, 2.0.0.0 works fine with no code changes, just changing the HSQLDB jar.
DbBackup missed command line option for AbortUponModify.I saw DbBackup has the setter/getter for AbortUponModify, but don't know how to change it's value from just command line.When backup a database, will do below.But if I want to AbortUponModify=false, i cannot pass value in command line, Seems have to write code.
Referenced views are absent in VIEW_TABLE_USAGE.It stated that VIEW_TABLE_USAGE should provide information on TABLE and VIEW objects that have been referenced in the query expressions of the VIEW objects, but it provides only tables:
One SqlTool function definition variant broken.Needs to be verified, but I think that creating functions from buffer fails if an "appendage" string is not given.
doc mistake re. raw mode terminator.I think that online docs (and maybe Util guide) state the wrong characters to terminate raw input. The examples or user guide fragments must be correct, because I know some people are using the feature successfully. Another possibility is that the incorrectly documented usage applies only to either interactive or non-interactive usage so that not all users are affected.
INFORMATION_SCHEMA.SYSTEM_COLUMNS field name typo.In the table INFORMATION_SCHEMA.SYSTEM_COLUMNS field header for "table_schema" is missing trailing "a" so it stands as "table_schem".See query:
HSQLDB 2.1 fails with a core dump.Please see the attached core dumps.
statement.execute executes multiple sql statements.The statement.execute(String) method executes multiple sql statements separated by semicolon. This might allow sql code to be injected into a sadly programmed application.Please do not understand me wrong: There might be some space for interpretation in the jdbc specification of the Statement interface. So this behavior might be ok in the sense of the specs. BUT: an app that uses code like this:is vulnerable for sql-injection if the user inputs some thing like this:As this is bad programming it might not be the problem of hsqldb either!BUT: for example the oracle jdbc driver does not allow mutliple statements in the Statement.execute method. This adds an additional level of security that hsqldb is not having.I stumbled across this behavior when working with owasp's webgoat intrusion example webapp and was quite shocked to find a way to add update/insert statements into a read-only application. I had not thought that this was possible.So if this is intentional behavior, please think about its usefulness in comparison to the security impact. If it is a bug, please fix it :-)
Failing NULL value check with decode in ORA SYNTAX mode.Hi,Detected in versionsDecode function fails to identify null value in ORA SYNTAX mode.Thanks for your help.
Table / column aliasing doubts in nested selects.I have found some weird behaviour when aliasing tables and fields. This here is pretty clear:
NullPointerException when unnesting empty array literal.These statements result in a NullPointerException:These statements worIs this a syntax error? According to the documentation, it seems to be. At least one value expression has to be provided between the brackets. But then how to construct empty arrays?
object not found when fully qualifying it in nested JOINs.Here's a funny thing I have stumbled upon. Create this database:Now, this query with a somewhat odd syntax works well:It looks like the tables b and c are somehow implicitly renamed and no longer form a part of the "PUBLIC" schema. I'm guessing this is a bug, as I couldn't find any explicit reason in the documentation around this definition that would justify this behaviour:Also, HSQLDB is the only database I know that has this behaviour.
HSQLDB breaks my logs.When I establish a connection to HSQLDB, logging no longer works.
current value for sequence is null !!!
NOT IN predicate and NULL values not SQL standard compliant.Maybe I have not grasped some subtlety in how this really *should* be according to the SQL standards... In my understanding, the following should return an empty result set:The rationale taken from the SQL 1992 standard chapter 8.4 <in predicate>:And then, further down:In the case of my example:
Regression in TRUNCATE statement after upgrade to 2.2.8.I have detected a regression in my jOOQ integration tests for the TRUNCATE TABLE statement after upgrading from 2.2.6 to 2.2.8. The following is specified in the documentation:"If the table is referenced in a FOREIGN KEY constraint defined on another table, the statement causes an exception"Most other databases also behave this way. But HSQLDB 2.2.8 seems to silently execute such table truncations. Note, I'm not using the NO CHECK clause
Cannot unnest arrays resulting from nested selects.I seem to have a regression when unnesting arrays that result from nested selects. Create the following schema:Run this query:I have observed the issue in HSQLDB 2.2.6 and 2.2.8. I think I had seen this working before, but maybe it's just a syntax confusion?
Error when unnesting arrays from "preceding tablereferences".See also possibly related issue here:I'm running a test against this schema:The test query looks like this:According to the documentation of UNNEST the above should work:The documentation reads:"The array expression can contain references to any column of the table references preceding the current table reference."In the example, "STRING_ARRAY" is a column of "T_ARRAYS", which has been referenced precedingly. Nevertheless, I get the following exception:It does work like this, however:I think I had seen this working in a previous version of HSQLDB, but I'm not 100% sure.
select distinct * from ( select...) doesn't work any more.The following select worked until 2.2.6-snapshot (2.2.6 pre-release). Since then, it returns:Error: user lacks privilege or object not found: C8I think it's something with the 'distinct': if we ommit him, it works.Thank you,Lucio I.P.
DECODE fails as of 2.2.7.Starting with 2.2.7, this statement started failing for me:I've tracked the change that broke it to SVN revision 4878 in ParserDQL. With OpTypes.MATCH_FULL passesd in, flow ends up going into case "OpTypes.MATCH_FULL" in ExpressionLogical.getValue(). This results in a call to ExpressionLogical.testMatchCondition(), which throws an exception of "row column count mismatch". Prior to 2.2.7, flow goes to case "OpTypes.EQUAL" in ExpressionLogical.getValue(). This results in a correct evaluation of the data.
update LOCAL TEMPORARY TABLE leave COMMIT in *.log.I used an local temp table. Then I frequently insert/delete record from it. Yes, it will not write those SQL into *.log, however, it left many COMMIT in the log and cause it huge. In fact, I've disable the auto check point, because I found that the auto check point will cause HSQLDB hung. So the *.log file will be very big and full of only "COMMIT". Any idea?
Unnecesary SQLWarning:cursor updatability mismatch.prepareStatement for update created unnecessary warning "cursor updatability mismatch" W_36502The code example is in attachment, All executed just fine in HSQL, Oracle and MySQL.Only warning are annoying when executing Unit tests using HSQL.
EOFException when database grows past ~5GB.Running 2.2.8, we are randomly hitting an EOFException when our database size goes over ~5GB. We run our database with the settings:I poked around a little bit in ScaledRAFile, specifically looking at how the fileLength member is maintained. It seems like the logic in the write() method "if(!extendLength" might not be correct. I ran some test with the logic reversed "if(extendLength" and that may clear up the problem (although, i can't guarantee that since the issue is not 100% reproducible).
Pathological Query Performance in 2.2.8.My company is trying to integrate hsqldb into our product and while trying it out with some test data, we hit a class of queries that result in pathological query performance -- about 5 minutes on my machine. For comparison, the same query runs against MySQL in about 300ms. Here's the query:An "explain plan" showed that some joins used some indices, but at some point, it did a full table scan of the ec_job table. The MySQL explain resulted in no full scans and a very different plan. See attached file.I've also attached a zip file of the hsqldb we were testing with. How to connect to it:I was running on an 8GB laptop with 64-bit IntelliJ IDEA with 2GB heap. I used the database console to issue the query.
NullPointerException concatenating empty blob.Precondition:Table containg an empty blob valueAttachment:The attachment contains a maven project with a junit-test reprocuding the error.The test can be executed using "mvn test" in the project root directory (assuming maven bin-directory on the path)
Double.NaN equals any DOUBLE.HSQLDB supports NaN, INF and -INF in its DOUBLE datatype. Equality for NaN appears to be broken.The result is one row one column containing NaN. It appears that (NaN=x) is TRUE for any x, including NaN. I believe that's exactly the wrong way around. (NaN=x) should be FALSE for any x, including NaN itself.HSQLDB 2.2.8 release, Java 6, OS X, observed on in-memory database.
Exception when comparing empty (zero-length) BLOB or CLOB.
IllegalArgumentException in multi-threaded application.The current version 2.2.8 is not completely thread safe. Under heavy load the method org.hsqldb.HsqlDateTime.convertMillisFromCalendar may fail. You get an IllegalArgumentException, if this happens.
OutOfMemory error.Revision # 4531In heap dump (512 megabytes allocated for java machine):OS: Linux, 32-bitProblem didn't happen instantly. System worked for some days then this situation happened.
OutOfMemory error.Problem has been too quickly closed but I think resolution is not correct.Revision # 4531In heap dump (512 megabytes allocated for java machine):Problem didn't happen instantly. System worked for some days then this situation happened.Last resolution:Well, this dump indicates you have one million rows in MEMORY tables. Thesetables are stored in memory and quickly fill up large memory allocations.If you can manage with a larger heap, you can continue using MEMORY tables,otherwise you need to convert some of these tables to CACHED tables.But that's not right. That's initial script in attachement of database scheme.Application (3 threads) does insert in *_IMP tables and then calls PR_UPD_*_STAT(). Then an insert in TM_DATAPROCJOURNAL is made and then commit.Also 3 threads perform select of all rows from *_STAT tables ordered by date to export into text file.
BINARY field display as [B@12345 in Database Manager.Other data types are represented in roughly the same syntax as their literals. The current display of Binary types is unusable.
Server fails with ClassCastException.Create custom function with declared result NUMERIC, but actual result is TABLE. When function is called, server fails.Example:
Inaccurate documentation on the datetime TRUNC() function.I've tried using the TRUNC() function as specified here:It saysThe <char value expr> is a format string for YEAR, MONTH, WEEK OF YEAR, DAY, HOUR, MINUTE or SECOND as listed in the table for TO_CHAR and TO_DATE format elements (see above).But that's not correct. I've tried using 'DAY' as a literal, but that doesn't work:select trunc(current_timestamp, 'DAY')This works, though:The same seems to apply for ROUND()I'm not sure if this is an engine bug, or a documentation bug
Datetime TRUNC() truncates to UTC, not to local timezone.This query here:The same applies for ROUND()
NPE in CharacterType.substring.Getting a null pointer exception in CharacterType.substringHere's the SQL to reproduce, the error and the stack trace:Not very convenient but does the trick
missing hsqldb.init.The hsqldb.init script is not to be found at locations given in Appendix D: those are dead links.Also, FWIW, it seems arbitrary to paste the hsqldb.cfg and hsqldb.rc scripts verbatim into the docs but not hsqldb.init.
foreign key constraint name not shown in GUI db manager.If I create a named foreign key constraint, say with name FK1, in the left pane under indices I can see, e.g., SYS_IDX_10037 instead of SYS_IDX_FK1_10037 as expected but in INFORMATION_SCHEMA.TABLE_CONSTRAINTS I do see my FK1. It looks like the GUI tool has wrongly used "" as the constraint name.
procedure returns updateCount even with READS SQL DATA.A CallableStatement's execute() method will always return false when calling a stored procedure; that is, the first result will always be the update count and getMoreResults() must be called to obtain the first ResultSet, if it exists.While this is expected behavior for a procedure capable of modifying data (e.g. when the procedure has the parameter MODIFIES SQL DATA), the update count should not be returned when the procedure has the parameter READS SQL DATA; such a read-only stored procedure will always return an update count of 0 and is therefore redundant and non-standard API.Currently, statementRetType in JDBCPreparedStatement is always set to StatementTypes.RETURN_COUNT regardless of whether the stored procedure is MODIFIES SQL DATA or READS SQL DATA. Solution: when READS SQL DATA is specified, statementRetType should be changed to StatementTypes.RETURN_RESULT so that getMoreResults() inside the JDBCPreparedStatement.fetchResult() method is automatically called (on line 4667).
ClassCastException when doing simple select.We have a table definition:Where the sql is:resuting in the following error:Why do we get this ClassCastException?
Servlet server mode fixes for 2.2.8.For me the Servlet server mode operation was not working, and Iooking at some postings on the net it has been broken for quite a while. There were 3 distinct issues causing servlet more to fail:1) The servlet as is would only work in the root of the webserver2) The client-code would not correctly set the content-length of the post-request, causing an EOFexcpetion on the server when reading the payload3) A similar issue to 2) on the reponse being generated on the server: The response content-length was not set correctly by the server, causing EOFEXceptions on the client
HSQLDB 2.2.8 server not shutting down cleanly.HSQLDB 2.2.8 server is not shutting down cleanly when given the "shutdown compact" command. The server begins the shutdown sequence, but never exits. I have a small sample database that I'm using (I can make this database available if necessary).The process I'm following is:I have also used a java class to create a JDBC connection (rather than using DBVisualizer) and get the same results.I have attached the output from the server process on the command-line. Let me know if there's anything more you need.Thanks.
WITH RECURSIVE returns only first level children.Query using WITH RECURSIVE returns only first level children, even for query in docs:As I see union/unionAll methods in RowSetNavigatorData cleans result which is used later.
2.2.8 Hangs with select.I'm having trouble with an update where I have the following:The initial state of the database is a charge with a decision attached.The action perform is a replacement of the decision on the charge with a new decision.I've attached full logs of update, and result of "SELECT* FROM INFORMATION_SCHEMA.SYSTEM_SESSIONS"
Unsupported WITH clause in subselect.Usage of WITH works fine in HSQLDB 8.2, but apparently not in a subselect.
COUNT(DISTINCT(ID)) returns 1 instead 0 for VARCHAR NULLs.Given the table:Reproduced on 2.2.6, also reproducible with 2.2.8 and latest snapshot.
Caused by: org.hsqldb.HsqlException: expression not in aggre.Hello,The simple request below doesn't work whith HSQLDB 2.2.8 but works fine with MySQL.Is this a bug in HSQLDB ?Anyone knows a workaround ?Here is the stack trace :
"set table source ..." fails since 2.2.6.It seems there was a bug introduced in release 2.2.6 in the area of text tables. Up until 2.2.5 it was possible to set the java system property textdb.allow_full_path=true and then attach CSV files using the SET TABLE statement as follows:Note the path in the SET TABLE statement differs from the path actually to be opened. I checked the docs and it seems the behavior of release 2.2.5 and earlier is consistent with the docs.
Incorrect result sets when using WITH and aggregates.I think the following 3 queries should be equivalent and return the sameresults, however, only the 1st is correct. I originally found this asqueries referencing a CTE in a WHERE clause were giving incorrect results.PostgreSQL returns the correct result for all 3.Returns empty result setps. I was going to submit this several months ago :( Anyway, findingHSQLDB fantastic so far.
JDBCCommonDataSource isn't Serializable.Since JDBCCommonDataSource isn't serializable and the subclass is, Java doesn't store the values from the class JDBCCommonDataSource when the datasource is serializaed. Therefore when deserializing the url is null.
incorrect results for subqueries within a view.It appears that hsqldb (v2.2.8) is botching queries against viewsdefined with more than one subquery. The following SQL test casewill explain this far more clearly than English:In general, the first subselect in the view is evaluated correctly,and the rest are not.
DDL session is never freed by TransactionManagerMVCC.version 2.2.8The problem is probably in MVCC and in the following piece of code:So txManager.commitTransaction - never happens in the session A and cannot release TransactionManagerMVCC.catalogWriteSession
PreparedStatement keeps references even after closed.JDBCPreparedStatment.close() does not nullify the session variable. The session variable hangs on to a cache object. This means that PreparedStatements take up much more memory than needed after they are closed. In my application, this is adding up to about 42 megabytes of RAM. I know that I can fix the problem by nullifying my PreparedStatements when I'm done (and that's what I'm doing now), but I thought it would be a good idea to fix this by nullifying the session variable in PreparedStatement.
Text table: Delimiters not encoding-aware.Using hsqldb 2.2.8.Text tables can be declared with a text encoding parameter, if the encoding of the underlying file is not ASCII. Unfortunately, this encoding is not applied to field delimiter and line separator characters. This fails with encodings that are not strict supersets of ASCII, most prominently UTF-16.Example:As you see, the fs (tab) and the CRLF at the end have not been properly encoded as UTF-16.Attempting to configure a text table with a properly encoded text file which already contains data also fails because HSQL does not recognize the delimiter/separator characters.The manual states that "[t]he default is encoding=ASCII and the option encoding=UTF-8 or other supported encodings can be used". I have not been able to find a list of "supported encodings".
a UNIQUE constraint does not exist on referenced columns.Tested on: v2.2.8, and the latest snapshot of 2.2.9 posted on the hsqldb homepageAlso tested on MySQL, and works correctly there.Minimal SQL to reproduce error:The add foreign key works as expected.If you need more info please let me know.ThanksChris
Select for varchar with new line does not work [2.2.x].Example col in DB with following content:attempt to query like this:NOTE: on hsqldb family 1.8 such selects worked perfeclty - on 2.2.x they are not working
The precision of BLOB column types is ignored.Trying to save a BLOB value longer than the maximum length allowed for a column will always succeed, effectively ignoring the specified column maximum length. A check similar to what's done in {{BinaryType.castOrConvertToType}} should be used here as well.
Exception when a value exceeds the precision of CLOB column.Normally, CLOB values should be truncated to the maximum allowed length (precision) of the target column. However, because org.hsqldb.Session.performLOBOperation(ResultLob) doesn't have a switch case for REQUEST_GET_TRUNCATE_LENGTH, an exception is thrown, causing the transaction to fail.The solution would be to add a switch case for REQUEST_GET_TRUNCATE_LENGTH which would call database.lobManager.getTruncateLength(id)
Cannot create a VARCHAR type.After I've created a type with:in an instance of hsqldb server, I shutdown that instance with SHUTDOWN command. When I try to restart I got the following exception:The guilty line is this:If I modify the line removing the information_ schema part or removing the collate part, the script seem to work, bringing up instance
NullPointerException on subquery with group by.Given the following definition:I am using the latest version (2.2.9) as an in-process, in-memory database.
Unquoted identifiers handled differently from PostgreSQL.I am using HSQLDB in PostgreSQL compatibility mode and it appears that unquoted identifiers are handled differently between PostgreSQL and HSQLDB.In PostgreSQL unquoted identifiers are converted to lower case whereas in HSQLDB unquoted identifiers are converted to upper case.This seems like it should be a relatively simple configuration option to include and would help improve compatibility between HSQLDB and PostgreSQL.I am currently using version 2.2.8.
Defrag does not trigger properly at checkpoint.When I repeat the process of adding a million rows to a table, then truncating the table, the data file continues to increase in size when I have hsqldb.defrag_limit=5. My output is the following:After the first run, the size of the data file is 67108kb, which should be the max size needed at any time because I am only adding a million rows and deleting them. After the second run, the size of the data file is 134217kb - twice the size of my data, which means 50% of the db file is wasted, so a defrag should be triggered at the next checkpoint. However as you can see, the defrag is not triggered.When I reduce hsqldb.defrag_limit to 1, the defrag is triggered and the file size stays at 67108kb. But it should also trigger when the limit is 5.Test code is attached. This was run against hsqldb 2.2.5.
wrong shutdown from sqltool.The bug seems to be appeared at 2.2.9 release. It reports an error, when shutting down non-interactively from sqltool, i.e.Enter password for SA:Disconnected from JDBC Data Source
cannot attach text tables (CSV files) with absolute path.Hi thereI reported bug ID 3535299 against 2.2.6 on June 14. You reported the bug as fixed in 2.2.9 - thanks for paying attention to the bug report! However, I just upgraded to 2.2.9 and I still get the same error as I reported in 3535299. (I just copied the stack trace from bug report 3535299):
Cannot store strings with leading blanks in TEXT tables.This bug report applies to 2.2.9 and probably to earlier versions too.HSQLDB cannot store strings with leading or trailing blanks in TEXT tables. I do the following:When I look at the csv file, it contains one record:I conclude that HSQLDB can read Strings with leading and trailing blanks correctly from the csv file when they are quoted. Unfortunately HSQLDB does not quote strings when they contain leading or trailing blanks.I suggest the following bugfix
ORDER BY NULL Logic Not Consistent.We use HSQLDB for testing to mimic Oracle.. Just recently I upgraded HSQLDB and was surprised that our test cases were failing when checking if NULL was first or last.This is when I first learned about NULL FIRST/ NULL LAST. Unfortunately we use Hibernate which doesn't support those options.So then I wanted to verify the behavior for Oracle and I found this:In HSQLDB, by default it's either always first or always last. There isn't logic to have a best guess. I would recommend that by default it uses the "best guess" in order to prevent surprises on upgraders.
DbBackup overwrite not working.When DbBackup attempts to overwrite an existing file, it does not delete the file before renaming the -partial file to the desired file name.As a result, the rename fails and the -partial file persists.When another attempt to backup the database to the same file is performed, an IOException is thrown when the -parital file is found and the exception incorrectly suggests that something or someone may be writing to the file.The resolution to this is simple.If overwrite is specified, delete the pre-existing file prior to renaming the -partial file.If the delete fails or if the rename fails, an exception should be thrown.
Using Schemas doesn't seem to work with Connection Pools.Hi,We've been using HSQLDB on the XWiki (http) open source project for years now and it's great. Thank you for such a wonderful DB :)Now XWiki supports having one DB per wiki in a farm mode and I'm adding support for HSQLDB (this mode works with some other DBs already).My problem is that even though I set the schema correctly (SET SCHEMA "myschema") the statement is executed on the wrong schema. I've been debugging this and I think I've found the problem:However the problem is in recompileStatement(). It creates a new statement but uses the old schema in the cs as the session schema instead of using the current schema:I don't understand why the "session.setSchema(schema.name);" line is needed and this line seems to be causing my issue...So I see several solutions to my problem:WDYT?Is this something that could be fixed in HSQLDB?Thanks a lot
Inserting blob in a db with "res" connection string NPE.When calling an insert statement with a blob parameter: this exception is thrown (the same query is successful when connecting to the sam database using "file" url):
Type Coercion Needed.When running a query that coalesces a bit field, you should be able to supply a default value as follows:In the above example, if 'aTable.someBitField' is NULL, 1 should be returned in the result set. Currently, an exception is thrown with the message 'incompatible data types in combination'. In a similar vein, the following query should return the same result set:Both queries ran and failed against HSQLDB v2.2.9, running in memory with the following connection string:
Querying CHAR fields using MySql Syntax.If a table is created with of field of type CHAR of a defined length as follows:And the CHAR field is defined in a simple SELECT query as follows:Only the first character of the field value is returned. In essence, the field is treated as a CHAR, not a CHAR(36).
Versions 2.0.0 and higher fail on Sonar.When running Sonar analyzer with Maven (mvn sonar:sonar), JUnit tests using HSQLDB fail with segmentation fault.Regular Maven build (mvn clean install) pass without problems.My guess would be that Sonar's byte code manipulations somehow interfere with HSQLDB.When using HSQLDB version 1.8.0.10 the build passes both with Sonar and in regular mode.Please see dump log attached.
NullPointerException on shutdownWithCatalog.I looked into org.hsqldb.DatabaseManager.shutdownDatabases(Unknown Source) and I think following is the problem:
WHERE condition on ROW_NUMBER does not work.Where conditions on the generated row number generated by ROW_NUMBER() OVER() does not work for lower bounds > 0.Assuming 5 records matching the SELECT criteria...
UNION in ROW_NUMBER sub-select does not eliminate duplicates.Assuming 5 unique rows match the SELECT criteria of a ROW_NUMBER sub-select:The expected output is 5 rows. In the attached example I get 10, every row duplicated once.
SELECT with a subquery in WHERE sometimes returns nothing.Having a non-empty table Q, with ID as the primary column, running this query will return no rows:If ID is not a primary column the query would work. Replacing "WHERE ID = " with "WHERE ID IN " will also work.The bug is reproducible with 2.2.9 and with the latest snapshot. It is not reproducible with 2.2.8, so it seems to be a regression.Unit test attached.The query is actually of the type which is frequently generated by Hibernate Envers, so any project using Envers with HSQLDB 2.2.9 might have some problems doing so.
Error while performing connection to previous version of DB.Hello, Fred!I remember about your mail but had no time to perform database tests.Today I've checked out latest revision of source tree (5106) and tried to connect to database from 5106 build.So I'm very disappointed about trying to test engine because I get such error:This I get when I connect via Swing interface:The database dump is in attachement.
"incompatible data types in combination" with TRUNC function.Executing prepared statement including TRUNC function with timestamp parameter, HsqlException with "incompatible data types in combination" message is thown.For example, this prepared statement doesn't work: SELECT COUNT(ID) AS TOTAL_ROWS FROM TABLE1 WHERE OPERATION_DATE = TRUNC(?)Instead this prepared statement works: SELECT COUNT(ID) AS TOTAL_ROWS FROM TABLE1 WHERE OPERATION_DATE = TRUNC(TIMESTAMP'2012-11-01 01:00:00')In attach junit test for both cases.
strange behaviour of exit / continue handler.A procedure loops through a table and updates each record in a begin / end block. The update sometimes fails due to unique key violation. With having an exit or an continue handler the record to be updated is DELETED! With an undo handler everything is as expected.After my opinion deleting the record in such cases is unacceptable.
SQL / PSM: aggregate function do not see variables.The problem seems to be similar to 3107413.Find complete example in attached file, essence is:
Resource bundle name causes assertion failure in gwt-dev.Reproduction scenario: unzip the attached zip-file, and run "mvn test" in the folder which has the pom.xml file. This results in a test error: "Could not initialize class org.hsqldb.error.Error". (Alternatively, from the zip-file import the Eclipse project, with m2eclipse installed, and run the provided JUnit launch configuration.)The error only occurs when assertions are enabled during the unit test run.In gwt-test-utils (specifically in com.googlecode.gwt.test.internal.GwtClassLoader.GwtClassLoaderWithRewriter.GwtClassLoaderWithRewriter), a call is done to gwt-dev's com.google.gwt.dev.util.Name.BinaryName.toInternalName("org/hsqldb/resources/sql-state-messages"), which fails on an 'assert' which checks that there are no '/' characters in the name.As far as I can see, the cause is that org.hsqldb.resources.BundleHandler.prefix, which contains '/' characters, and org.hsqldb.error.Error.errPropsName, which contains '-' characters, together result in the call java.util.ResourceBundle.getBundle("org/hsqldb/resources/sql-state-messages", ...). HOWEVER, this method specifies that this String argument must be "the base name of the resource bundle, a fully qualified class name" (see htt).Therefore it seems to me that both BundleHandler.prefix and Error.errPropsName must be changed, so that ResourceBundle.getBundle() receives a funlly qualified class name; the 'assert' in gwt-dev will then automatically succeed.
clob AsciiStream read returns arg length everytime.in Clob typemethod read of InputStream returned by getAsciiStream evrytime returns this arguments array length
null pointer exception while executing stored procedure.Hi,the next example gives a null pointer exception (HSQLDB 2.2.8, server version):this occurrs only when the do_update block is run inside a loop.This error occurred inside a more complex procedure and was really hard to find. It would be much easier, if there was a print option as requested (by me) in 3584054. Is there already an internal / unofficial mechanism that helps debugging stored procedures?
exception handler problems with stored procedures.Hi Fred,I use latest HSQLDB snapshot from Dec. 2nd 2012 and have several problems with exception handlers. Find attached a file with some tests. Maybe some things are only due to misunderstanding of the documentation (which is quite brief)
Bad behaviour of the NULL predicate for row value expression.The NULL predicate is not implemented correctly for row value expressions. Both the HSQLDB documentation and the SQL 1992 standard specify the same behaviour as specified in §8.6 of the SQL standard documentation paper:However, HSQLDB 2.2.9 returns a value for this query here:It seems that IS NOT NULL always returns TRUE, whereas IS NULL always returns FALSE for row value expressions with degree > 1
Stored Procedures Can't Have NUMERIC Parameters.If I create a function with a BigDecimal argument and declare it as a stored procedure with a NUMERIC parameter then HSQLDB can't find the function - but if I declare the same static function as having a DECIMAL parameter then it works. I think the patch below fixes this:
upper() or lower() function limits.When using multiple upper() or lower() functions for comparisons, receive a "java.sql.SQLException: java.io.IOException: Access is denied" error.For instance, the following works:But this will throw the error:
MERGE with constant in <search condition> fails.Given a simple table like this:And trying to run this MERGE statement:I receive this error: "user lacks privilege or object not found: SYSTEM_SUBQUERY".Exactly same query used to work with HSQLDB 2.2.8 and before, but is not working both on 2.2.9 and latest 2.3.0 snapshot.
Wrong result for left outer join with subselect.We have a problem with a select statement containing a subselect for a left outer join (see attachment)It worked fine in version 2.0.1 (previous version we used). Since the upgrade to 2.2.9, this statement returns wrong results.I guess this is an error in the engine? Im not sure though in which category to put this issue.
No view results even though query has results.I have just upgraded from version 2.0.8 to 2.2.9, and I am having a problem with certain views not returning results. When I run the actual query that the view is defined as, it returns results, but as a view it does not.Please open the attached DB - there will be an error at startup about a missing Java stored procedure but this is not relevant.If you run the query:then it returns 18 rows.if you now doandthen 0 rows are returned.
No view results even though query has results.I have just upgraded from version 2.0.8 to 2.2.9, and I am having a problem with certain views not returning results. When I run the actual query that the view is defined as, it returns results, but as a view it does not.Please open the attached DB - there will be an error at startup about a missing Java stored procedure but this is not relevant.If you run the query:then it returns 18 rows.if you now doandthen 0 rows are returned.
UUID() built-in.Hi,It seems that the UUID() built-in function, called without parameter generates an UUID built with only 8 bytes which are really random.For example, here is an UUID generated with the function UUID() : 3ddf4f9e3ddf4f9e1bac4a331bac4a33If we look closer we can see that the first 8 bytes are repeated and the third 8 bytes are repeated.The same UUID printed differently :Would'nt it be better if the 16 bytes were randomly generated ?
Natural Join returns duplicate columns.As recommended in a previous issue I tried the latest snapshot jar. With the attached DB please try this query:The result has two columns called 'TEMPLATE_GROUP_ID', so I am unable to make a view out of this query.
More natural join problems.On the latest snapshot (26/2), please open the attached DB.gives several duplicate columns in the result.
JDBC ResultSet deleteRow problem.When deleting rows on a JDBC ResultSet any following rs.next() on that result set returns false.This is contrary to any other JDBC implementations (uploaded test code works on both MySQL and ORACLE). Currently, the ResultSet javadoc for HSQLDB does not state this difference from the JDBC standard explicitly.
expression not in aggregate or GROUP BY columns.Hello,I have defined 2 tables:This problem appears only on version 2.2.9, on 2.2.8 it works fine. Also, when I run similar query on mysql it also works correctly.Maybe this problem is somehow related to changes concerning bug with id 3534936.Regards,Adam
HTML export not XHTML compliant for sqltool.Perhaps as a future enhancement, it would be nice to have the tags used for this export/report externalized so I could pick my own tags for rows and columns.
Bug in sub-select in aggregated query.Hi,We migrated from version 1.8 to 2.2.9 and experienced bug described below.Look at the query below and notice NEWRATE sub-select query. This sub-query always returns no data and therefore I get nullas a result of this column. I checked this in latest snapshot and (as of 18-03-2013) and it doesn't work there either.If I remove SUM(...) and Group by query works fine.
Bug in Transaction manager causing NPE.Hi,I discovered bug in newest snapshot (as of 18.03.2013 revision 5210 of trunk. We experience NPE in some cases of LOB usage.NPE occurs when limit of 32 (or N * 32) is reached for size of rowAction.elementData.Scenario is given in execution flow and solution patch (tested and works) is attached.Please apply patch given or fix this bug in some different way in next release.If we have lob column and we reach limit in element data following scenario occurs.Therefore we need to copy array instead of making reference to it.Regards,Ognjen Milic
TRUNC function causing java.lang.IllegalArgumentException.Hello. I'm quite new to databases, so forgive me if I use the wrong words.I've a simple table with a column TIME_STAMP and a column COUNTER. TIME_STAMP contains a timestamp expressed in milliseconds.I need to group data by week and I use the following query:
data exception: string data, right truncation in CASE.Hi!I have two string columns with some 'compressed' data in following format:...Use-case is two extract some value by tag number that may by in any of two columns.Below is an example where time is retrieved from date value.Here delimiter is char 0x1, not displayed in browser unfortunately. I've attached the same in file just in case.I'd not be wondered if such exception occurred when columns of this size (Integer.MAX) are concatenated, even though size of their content is small.But concatenation is executed successfully.All these expressions are executed successfully individually, but not in this CASE together.Other two weird things I noticed playing:1. If in WHERE right argument in comparison is 0x1, then query is executed successfully2. If ELSE returns any explicit value instead of SUBSTRING function, query would is executed. I repeat, this SUBSTRING itself is executable successfully.And two related questions with our permission:1. Is it planned two support kind of VARCHAR(MAX) format to avoid explicit huge sizes defined?2. Is it planned to implement POSITION in CLOB?Thanks in advance!
NullPointerException.Example below is pretty senseless, but I cut off all insignificant data and expressions to ease debugging.
Starvation issues with LOCKS transaction mode.I'm seeing starvation problems with LOCKS transaction mode.Basically, in a single-writer/multiple-readers scenario, there seem tobe many reader threads hanging on the latch.await call, with verylittle reason, given the waited sessions committed already (whichshould count down the latch).I had some little time to look at the code and I believe it may be anissue in the transaction manager resetLocks and resetLatches methods:waited sets are computed by the former in session order, and thenlatches are released/updated in the *same* order; this may cause thefirst session (the one who got the locks) to terminate *before* thedependant sessions have inserted themselves as waiting sessions, hencecausing the waiting sessions (the ones who do not got the locks)hanging forever on the latch (as the session that should have countedthem down completed already).Here's attached a patch to "unlock" sessions after all waiting sets have been computed.
TIMESTAMP and AT LOCAL behavior.I'm puzzled by the results I get when using TIMESTAMP and AT LOCAL when it comes to time-zone/daylight saving conversions.I'm not sure if this is a bug or not. Maybe I'm just doing the wrong assumptions. In case please help me to better understand what is wrong.In one of the columns of the table I have to query there's a number representing a timestamp. For example: 1228086000I'm located in Italy, current timezone is GMT+2 (due to daylight saving, otherwise it would be GMT+1)According to website http: that timestamp corresponds to:GMT: Sun, 30 Nov 2008 23:00:00 GMTMy time zone: 01 dec 2008 00:00:00 CET GMT+1It is important to notice that the local time is GMT+1, because that date belongs to the range in which no daylight saving is applied.Now I tested the following statements with the corresponding results (-->):When "AT LOCAL" is not used, I get the same result for A,B,C.I would expect A1,B1,C1 to be different from A,B,C and all look the same, but it is not the case.As it regards A1 and C1 it seems that "AT LOCAL" has no effect.B1 is different, but still it is wrong. In fact I would expect B1 to return 2008-12-01 00:00:00.0, because on 1st december there's no daylight saving (GMT+1).Instead it seems that the timestamp is converted to the current time zone (GMT+2).Am I doing something wrong? If yes, what should I do to go from that number (1228086000) to the correct local date-time (2008-12-01 00:00:00.0) ?Thank you.
Jdbc Batch Selects doesn't work.When executing a batch of select queries, HSQLDB 2.2.9 reports an error:The problem can be reproduced with the Junit Test in the attachment, or with the
session leaks on initialize.I'm using hsqldb in combination with hibernate (3.6.8)I tried to upgrade from hsqldb 1.8 to 2.2.9 and ran into the problem that I could not change the transaction isolation level initially. This did work after I ran my first transaction. When digging a bit I found out that it seems that when reading the metadatadefaults somehow a stale transaction exists which prevents the change of isolation level. Also when checking the getAllSessions().length it still has a session open.When I put the property "hibernate.temp.use_jdbc_metadata_defaults" to false I do not encounter this issue. The change of isolation level works from the beginning and no session is open.I made a simple test to expose this problem. See code below:
NPE in StringConverter.byteArrayToSQLHexString.On version 2.2.9 with sqllog set to 2, HSQL tries to log an insert statement on a table with a BLOB column. For the logging, it tries to convert the BLOB to a hex string. At the time of logging, the field value is of type BlobDataID. As the BlobType.convertToSQLString calls BlobDataID.getBytes() which returns null, the following call to StringConverter.byteArrayToSQLHexString fails with a NPE.Table format as created by HSQLDB: create table SomeTable (id bigint not null, version varchar(32) not null, data BLOB not null, primary key (id));
LEFT JOIN (SELECT...)  <-> LEFT JOIN .... non-equivalence.Running the following script:This is extremely non-intuitive, to say the least.
subselect and indexes.We have a problem with subselects on same table. Table has indexes.It works fine in 2.2.8 but in 2.2.9 rusult is a empty list.Our initial analysis: For subselect is another plan used. In 2.2.8 'full table scan', in 2.2.9 'indexes' used
Create view based  on selection from another view.Failed to create view which based on selection from another already created view.If it is based on selection from existent table - there is no any problem, it works well.Environment:Script:
invalid transaction state: active SQL-transaction in stateme.HSQLDB: 2.2.9 (also checked for 2.3.0 but problem still exists)Auto-Commit mode: falseI have two methods. They have test porpouses.One method executes a lot of insertions and updates in a few concurrent threads for one table. For such concurrent case I'm using MVCC transactional control mode. So, I set such mode before test will do any action.As soon as first method finished - second method starts and tries to return transactional mode back to defualt (LOCKS).But it failed with such error:java.sql.SQLException: invalid transaction state: active SQL-transaction in statement [SET DATABASE TRANSACTION CONTROL LOCKS]What I've tried and checked:- I've checked that all statements were closed, all connections were commited.- I tried to alter session (<alter current session statement> with ALL argument) to release any transactions, reset current session.- I forced to commit used connection- I forced to close connection and create new oneNothing helped me.Could you check - is there any issues with switching between different transaction modes or I'm doing something totally wrong?Is it allowed to change such mode for one connection multiple times?
Get a Concurrent exception while close connection.
Error if JRE1.7 is installed.Doesn't matter which JRE you use to compile the code below, if you run it under JRE1.7 you will get the error.The code:
Implementation of java.sql.Statement is not conformant.Your implementation of the interface java.sql.Statement is not conformant to the contract.The JavaDoc reads:By default, only one ResultSet object per Statement object can be open at the same time. Therefore, if the reading of one ResultSet object is interleaved with the reading of another, each must have been generated by different Statement objects. All execution methods in the Statement interface implicitly close a statment's current ResultSet object if an open one existsBut with HSQLDB you can actually use two ResultSets from the same Statement concurrently without a problem. This almost made me report a bug against the MySQL Connector because there it didn't work, I tried with HSQLDB and it worked and thus thought it is a bug in the MySQL Connector until I found that piece of documentation which actually explains what the problem with my code was and that the MySQL Connector behaves exactly as expected.
Incompatible data type in conversion with EXTRACT function.We are getting an error "incompatible data type in conversion" when doing a setTimestamp on a PreparedStatement where the parameter value will be inside an Extract function call. Here is an example of the query and attached are a code sample to reproduce easily the problem:
SSL Server Doesn't Work On IBM JVM Implementation.Configuring HSQLDB Server to use SSL results in a java.lang.NoClassDefFoundError: sun.security.ec.ECParameters when running with IBM JVM 1.7.0 on AIX 6.1. I verified the missing class is not available in the IBM implementation. I am able to configure an SSL server using a Sun/Oracle JVM on other operating systems.I think the problem lies in the constructor for HsqlSocketFactorySecure. It looks like it is adding the SunJSSE security provider if it is not available. When I comment out the block of code, I am able to start an SSL server with what I assume is the IBM JSSE implementation.You should consider removing the code forcing the SunJSSE provider to be available and/or allow it to use other JVM implementation security providers.
3609454 reproduced on 2.3.I'm still getting NPE on 2.3 in this case https:
Datatype Not Resolved for Parameterized Escape Character.When specifying the escape char following a LIKE condition as a parameter, the data type is never resolved and results in exception "data type cast needed for parameter or null literal" when preparing the statement. This problem surfaced using HSQLDB 2.3 within a Spring-Data/Hibernate environment using JDK 1.7.From what I can tell, it appears that data types are resolved from their associated table columns. In this case, no table column applies to an escape character, so the data type is left null, thus failing the condition in StatementDMQL, line 559. I am able to build a patch with the following addition to ParserDQL following line 4083 that resolves the problem:
JDBCPool not supported in JDBCDataSourceFactory.From the documentation of the factory method JDBCDataSourceFactory#getObjectInstance(Object, Name, Context, Hashtable), it seems that the JDBCPool is one of the four supported data source class names:
Count Function not working as expected.Team,I am facing an issue with the following query.It is throwing following exception."Caused by: org.hsqldb.HsqlException: Column not found: COUNT"But when I visited the HSQL Documentation, it was mentioned that count was supported. Currently using HSQLDB 2.3.0Please help me to sort this out.
SET MESSAGE_TEXT cannot take expression.In a PSM I am trying to set the message text for exceptions. This works when I use a simple string constant, e.g.However if I want to elaborate this with specific information on the error using either a local variable or string concatentation, it doesn't work, e.g.There is a similar error when using local variables in the PSM.
Pessimitic lock is lost after changing a property using SQL.In our application we're synchronizing threads using pessimistic lock on a row in a revision tableWe have following scenario:ERROR:After changing a property in HSQLDB an another thread (with a another transaction) that is waiting in select for update gets the lock (the first transaction is not closed yet!) From this point both threads are thinking, they have the lock they and are doing their job simultaneously. This leads at the end to an inconsistency in our data.Environment:
READ COMMITTED isolation level and table locks.Insert new data to the table block other transactions on the same table.This does not happens in MySQL and PostgreSql.This behavior makes it hard to tests complex application using HSQLDB as in memory database.See example code in attachment.Is there a workaround for this compatibility problem
Wrong doc Chapter 8. SQL-Invoked Routines (JAVA static SP)The SQL signature composed from 2 'string' parameters, while the JAVA signature composed of 3.This will lead to 'unresolved method' SQL exception if one will try this code as a template for its SP
NullPointerException in getColumnNames if no columns defined.V.2.3.0:If you create a table without any columns, then simple "select * from <table-name>" would throw Null Pointer Exception.It was working in V.2.2.5The stack trace:
HSQL JDBC driver crashes when calling JAVA SP with Array arg.Issue observed under 2.2.9 & 2.3.00. Compile the following class and add it to the classpath of the DB (it contains JAVA stored procedure implementation)1. Create simple DB using the following script2. Call the get_data SP
HSQL JDBC driver crashes when calling JAVA SP with Array arg.Issue observed under 2.2.9 & 2.3.0
JDBCPreparedStatement.setParameter may throw HsqlException.The JDBCPreparedStatement.setParameter() method may throw HsqlException for columns of type VARCHAR if the parameter value is not convertible according to the definition of CharacterType.convertToDefaultType().It appears the intention of JDBCPreparedStatement.setParameter() is to catch any instances of HsqlException that may be thrown and re-throw them asPerforming a similar call on a non-VARCHAR column results in an SQLException being thrown, which I believe is the expected behavior.The attached patch (against 2.3.0) should fix the problem, although I haven't tested it.
No Result for SELECT with Comparison > and DESC order.This select statement will produce no result set, which is wrong:The data is attached as csv-file.
Server#handleConnection still called after #shutdown.After shutting down an instance of org.hsqldb.server.Server and creating a new one with the same connection settings, sometimes the old instance still tries to handle jdbc calls (and of course fails to do so). The problems does not occur always but only in rare case and on some of our test machines.Version is 2.2.9I'd guess the cause of the problem is that the change of field socket to null (via method #releaseServerSocket) is not visible in the thread that executes the #run method and the while loop condition "while (socket != null)" remains true. This is because there's no synchronization when accessing the value of field socket and field socket is not marked as volatile. I'd think the field should be made volatile.Log output (adapted to output System.identityHashCode of the server instance as well) attached.A new instance 2008761310 gets started immediately afterwards (at 01:22:04,162) on the same thread (main).When used via JDBC (again from same thread 'main') the #handleConnection method of the old instance 428822417 is called - and of course leads to an error because the database has been closed (database alias=testpersistence_alias does not exist)
Quoted CSV Import Merges Fields.There is an off by one error in SqlFile.preprocessCsvQuoting that causes it to lose commas and merge fields under certain circumstances. The attached SQL and CSV files demonstrate the issue, and the Java file fixes it.Specifically, if two quoted fields are separated by a comma with no surrounding whitespace, that comma disappears. That situation results in a segment of length 1 containing just the comma, but the condition tests for "segLen > 1" instead of "segLen >= 1".Example:
call database_version() returns wrong version.call database_version() still returns "2.3.0" - it should return "2.3.1"
driver hang after OutOfMeoryError.It look like that the hsql need to copy all data of a row in the memory multiple times.I have 26829272 bytes free before executeUpdate(). I want save a InputStream with 9170069. I think 26 MB should enough memory to save a single row with 9 MB,But the fatal error is that it hang after the OutOfMemoryError occur. executeUpdate() never return. See the both stacktraces for detailsBlocking Stacktrace:
Can`t use sysdate as default column value.When I tried to create table:It was created successfully, but then, after reconnect to database was throwed exception:
Cannot use table dual in stored procedure.I create a database like this:In the resulting script, the procedure is created as follows:Trying to connect to the database complaints about invalid schema SYSTEM_SCHEMA:
Oracle - Limiting rows with "order-by" and "where ROWNUM".This is with regard to oracle compatibility. Limiting the number of rows with "order by" and "where ROWNUM" is returning wrong result set.This is on Ubuntu 12.04 with Oracle JDK 1.7. Attached is the sql file with the DDL and DML statements required to create the test table.
Rollback issue v2.3.0.Hi, have some strange behaviour after upgrading to v2.3.0.When I insert a new record, then rollback and try to select it, it is gone as expected. But after shutdown and restart it is inserted into the table.This happens with MVCC and cached tables. Please see the attached example code.
Process hangs at 100% CPU usage in server mode.Hello,We are using HSQLDB as the primary database in server mode for an open source project (a RSS feed reader, here https).Sometimes, when no heavy task is performed on the database, the hsqldb-server process hangs and it takes 100% CPU. I've attached a jstack if it can helps you.The database is quite big, around 500Mo. You can find the structure here :Thank you for this great project :)
trigger execution problem after dropping column.Hello,i found this problem when trying to test my DAO implementation.ExampleWe have a create table statement in the first script:In the second script we create trigger to auto set modification time column:In the last script we have a drop column statement:Ita apears, that droping a column doesn't infulence on trigger definition (trigger sees 5 columns, insert statement sees 4 columns).After changing order of the second and third script it works just fine.Here's java stack:
DATEADD does not work as expected (documented)
ArrayIndexOutOfBoundsException [HSQLDB 2.3.1].Queries:Details:
Use NULL as DEFAULT for INSERTs.Assume the following table:When I use the following syntax:INSERT INTO t_identity DEFAULT VALUES;I usually get the following error message:DEFAULT keyword cannot be used as column has no DEFAULTThe same happens when I use the DEFAULT keyword for single columns that do not declare a DEFAULT in their DDL. E.gPretty much all other databases use NULL as a DEFAULT, when no explicit DEFAULT is defined. I'd say that this is correct according to the SQL-92 standard:2) The default value of a column isCase:a) If the column descriptor of a column includes a default valuederived from a <default option>, then the value of that <de-fault option>.b) If the column descriptor includes a domain name that iden-tifies a domain descriptor that includes a default valuederived from a <default option>, then the value of that <de-fault option>.c) Otherwise, the null value.
DBMS ignores redefining of already defined alias.Sample:We can expected errors in above query, but the db engine successfully fulfills the request.hsqldb.jar version 2.3.1
Excessive memory use with "Delete from table" & "Truncate table".I have recently upgraded hsql db from 1.8 to 2.3.1 and started having memory heap space issue.Before the upgrade max 500 mb memory needed and there was enough heap space available during the entire test.After the upgrade 6GB space was not enough so I tried it with every version from 2.0 to 2.3.1 and I had the same problem.Now I am dropping tables and recreating the database fresh from scratch and the issue disappeared.Using "Delete from table" also "Truncate table" cause the memory issue hsql cannot clear the memory. I can provide more info if needed.Tested with
"Duplicate column name in derived table" for non-derived, top-level tables.The following query raises a "duplicate column name in derived table" error:But there is no derived table, and pretty much every database I know of allows for such a query. For example, PostgreSQL:This query will produce the same error:These queries, however, are a workaround for the problem:
write_delay can lead to data-loss.I believe I have traced a problem in HSQLDB v2.3.1 which is arguablyeither poor documentation or a bug -- either way, I only discoveredwhat was happening by looking at the source-code.While using v1.2.8 of HikariCP with HSQLDB, I noticed my application(which makes changes to a database and exits quickly) was sufferingfrom data-loss: information added as committed transactions weremissing on subsequent runs.The problem seems to be a combination of two things: v1.2.8 ofHikariCP has a 'shutdown' that does nothing and that HSQLDB, bydefault, relies on an orderly shutdown to guarantee data integrity.I should point out that newer versions of HikariCP shutdown methodclose all open connections, which (along with 'shutdown=true' in thejdbc connection string) eliminates the data-loss problem.The HSQLDB documentation for WRITE DELAY states:If the property is true, the default WRITE DELAY property of thedatabase is used, which is 500 milliseconds. If the property isfalse, the WRITE DELAY is set to 0 seconds. The log is written tofile regardless of this property. The property controls the fsyncthat forces the written log to be persisted to disk. The SQLcommand for this property allows more precise control over theproperty.This strongly suggests that data is written into the OS' file-systemcache (VFS-layer, for Linux) after a COMMIT, and write_delay controlsthe periodic calls to fsync. Calling fsync is meant to guard againstcertain hardware failures (e.g., power-cut), if the data has beenwritten to the VFS layer then it will be written to disk after theapplication closes (with extremely high likelihood, if not actuallyguaranteed), so committed transactions are safe from softwarefailures.In practise, org.hsqldb.scriptio.ScriptWriterBase shows that output iswritten through a BufferedOutputStream. The forceSync method firstflushes this buffer prior to calling fsync(). This behaviour is notat all described above.There are two issues here:It seems that HSQLDB requires applications to close any openConnection (and, perhaps shutdown the database) beforeguaranteeing transactions have been processed. This doesn'tappear to be mentioned in HSQLDB documentation and IMHO isn't partof the JDBC spec.The documentation for WRITE DELAY is misleading: it suggests thatit is limited to delaying calls to fsync and neglects to mentionthat there is an internal buffer that is also flushed.I cannot say whether the performance benefits outweighs the risksassociated with buffering the output in Java; I suspect this is adecision that can only be made on an application-by-application bases.If I may, I would suggest two actions:a. update the WRITE DELAY documentation to better reflect currentbehaviour,b. consider adding an option that removes the write buffer so thatHSQLDB can write data on commit but continue to support delayedcalling fsync.
Silent corruption.I am running a simple HSqlDB (v. 2.3.1) application on top of ext3 file system (write-back mode). My application just inserts 100 rows into a memory table. I see that HSqlDB writes the data to a log file before checkpointing the data to the actual script file. In ext3 write back mode, a system crash while writing to the log can result in a state where some part of the log file contains garbage data. In some cases, when the database is reopened from such a crashed state, HSqlDb returns garbage data to the application without detecting the corruption. Please note that this does not happen always - i.e., from most crashed states, HSqlDb can realize a corruption and recover to the old state of the database.
Regression in 2.3.2: Trigger introduces false object dependencies.The following leads to an error:I would expect the rename to succeed since the trigger does not refer to the column being renamed and is still valid afterwards. Yet HSQLDB 2.3.2 fails with:The problem does not exist in version 2.3.1.
unique index behavior change in 2.3.2.creates unexpected "integrity constraint violation: unique constraint or index violation"the behavior was different in hsqldb version 2.3.1. (was working fine)As well in PostgreSql and MySQLIt is not exactly specified here httpBut I think this breaks the SQL standardsTest:
Recursive query regression in 2.3.2.The example from the docs for recursive queries (with a slight modification) causes an infinite loop in 2.3.2. The same query works fine in 2.3.1. The key difference from the documentation is using "UNION ALL" instead of just "UNION".
NullPointerException org.hsqldb.index.IndexAVL.delete.We have seen a null pointer in the IndexAVL.delete method which occurs infrequently but with different types of SQL (always update or delete SQL). We cannot replicate it. At the time of running the SQL there may be multiple threads performing reads or writes on the DB. We also have some large varchar fields, in this case one that was abount 380,000 characters long.
GROUP BY does not support parameters.Then you can do:What does not work with HSQLDB that however does work with for example MySQL is using a prepared statement likewhere both parameters use the same value.That will produce org.hsqldb.HsqlException "expression not in aggregate or GROUP BY columns"
HSQLDB server mode limited to 2GB ResultSets.When working with large data sets I noticed that if the ResultSet returned was over a certain amount of rows the server would go into an infinite loop and never return the ResultSet. Upon further investigation the problem was tracked down to the HsqlByteArrayOutputStream class. In server mode HSQLDB creates the ResultSet and passes it over the network as a large byte array. Unfortunately the code in HsqlByteArrayOutputStream uses System.arraycopy() to resize arrays which is limited to using int for the length of the array. The code that ends up getting into an infinite loop is:In the while loop above newsize overflows and eventually went to 0 causing an infinite loop in the while loop.
HSQLDB hangs forever on a dead lock case.HSQL version 2.3.2.Get a table with two rows and a primary key:Then, in two connections:I expect an exception "deadlock" on query 4.However, HSQL hangs forever yet on query 2 :(Is there a workaround? How can I detect a dead lock?My application can work with several different RDBMS, and with other systems I can detect a deadlock, roll the current transaction back and re-try my queries a bit later.With HSQL DB in this case my application hangs forever :(Thanks in advance!
Servlet mode with WEB-INF=true does only work with Tomcat prior to Version 8.Hi!Using hsqldb-svn trunk.I'm using HSQLDB's Servlet mode in a JavaEE Webapp with Tomcat 8.0.3.0 and hsqldb.server.use_web-inf_path=true.The problem with this is, Tomcat 8's output of getServletContext().getRealPath("/") is without a trailing slash (/), so the path where our database is saved is not blabla-1.0-SNAPSHOT/WEB-INF/database/db but instead blabla-1.0-SNAPSHOTWEB-INF/database/db ...With any version prior to Tomcat 8 it runs flawless, but since Tomcat 8 it doesn't. Also other application servers like WebSphere do handle this like Tomcat 8, as this is a correct behavior (see http) ).It might be better to change this according to the API.I attached a working (but probably dirty) patch.Thanks in advance!
Foreign Key constraint issue.Foreign key constraint should not be applied if parent table don't have ref data but HSQLDB is applying the constraint and didn't throw any exception. Below is the sample script.Thanks,
JDBC compliance SOURCE_DATA_TYPE in getColumns() result set.In v2.3.2 the 'getColumns' metadata method documented here:returns a string in the penultimate column SOURCE_DATA_TYPE instead of a short, as documented both in the HSQLDB spec, and the JDBC interface it inherits from. Currently it returns the literal name of the data type.
HSQLDB not working with some IBM Codepages, HSQLDB is not binary compatible between different plattforms.Because in the Class ScriptWriterText the platform (System.getProperty("line.separator") specific line separator is taken, the files are not portable and the database don't start anymore.The real problem at the end is, that the LineReader Class only detect 0x0A and 0x0D.On IBM Code Page 500 for example, the line separator is 0x0F.Resolution:Define a permanent Hex Code for the line.separator (platform independent).I have changed the code in the ScriptWriterText Class which resolves the problem.This version runs now on our system (Linux and IBM USS)
Unique constaint does not work correctly if the nullable column is first in the list.The following example should throw an exception, but does not:
SYSTEM_TEXTTABLES id_quoted difference.In the SYSTEM_TEXTTABLES routine of DatabaseInformationFull, when sysTables[SYSTEM_TEXTTABLES] returns null, IS_ALL_QUOTED is created as column 10, IS_QUOTED as 11. If not null, textFileSettings.isQuoted is stored in row[10] and textFileSettings.isAllQuoted is stored in row[11] (through the index variables iiq and iiaq). The Javadoc comments indicate the latter is correct.
Results being overridden.In the 2-line for loop at line 270 of ArrayType.java, the result of the first line's call to convertJavaToSQL() is being overridden by the result of the second line's call to convertToTypeLimits(). Possibly the result of the first line s/b passed as a parameter to convertToTypeLimits()?
exception on union.executing the queries below, hsql crash :
Unable to use decode function in order to transform datatype.In Oracle database, I can use the decode command to transform the return datatype. For example, I can use in my PreparedStatement decode(:myVar, 'toto', 1, myColumnInNumber). When myVar equals toto, then it returns 1 otherwise, it returns the value of myColumnInNumber.This syntax is not allowed in hsqldb 2.2.8I tried to convert myColumnInNumber in String using the to_char function but it doesn't work too.The stack trace for the decode fucntion :
Prepared statement with placeholders: SQLSyntaxErrorException: incompatible data types in combination.Create a table:and try to prepare the following statement via JDBC:This only seems to happen when the columns in the SET clause belong to different types, here SMALLINT vs. VARCHAR. The following statement compiles without problem.
Problem with JDBCPreparedStatement when using "with" clause that include a recursive subquery.Hi, I am putting a DB2 application on HSQLDB, but I have a strange behavior. (I am using Hsqldb2.3.2)When I run a statement with all the values in it (in squirrel or in a java statement), the result set is feed with all the expected values.ButWhen I run it with a preparedStatement with the same values, the resultSet is emptySo, if I execute this statement with all value set in a sql client, records are returned:with produit_adhesion asBUT,If I use it in a prepare statement with the same values, the result set is empty.After debugging a lot, I found that the block in bold below is the problem. If I set it with fix values, the prepared statement will return expected values otherwise, no value will come back from the database…The cause seems to be in the pre-compilation of the prepared statement.HSQLDB get mixed up with the subquery using the previous one (folio_non_retire_cons using value from folio_non_retire)So, if I remove the ? in that block and put fix values, the prepared statement will work just fine :
Corruption during system crash and power failure scenarios.This issue is about what happens during a sudden power failure, if a SHUTDOWN statement is being executed. It is hard to reproduce this scenario normally, but we found it by using a tool that can reproduce such scenarios (we believe the chance of it occurring in a real world is small).When the SHUTDOWN command is executed, HSQLDB updates the properties file finally, using an unlink(properties) call followed by a rename(properties.new, properties). Before this, HSQLDB unlinks the log file, and updates the script file using an unlink and a rename.File systems such as btrfs can buffer directory operations, and send them to disk out-of-order. Consider that a file system buffers the unlink(log) call, and instead sends the unlink(properties) call to disk first. In this case, if a system crash happens immediately after the unlink(properties) call, trying to read the database after reboot reveals a corrupted database. Similarly, if the rename(script) call is buffered instead, trying to read the database results in an error.A slight disclaimer: I am involved more in file-system research than in using databases, so there is a chance that I did not use HSQLDB properly. Please let me know if you suspect that is the case. Also, the exact problematic buffering (sending out-of-order) discussed above might not happen with btrfs; I am not sure. I am, however, sure that btrfs does buffer and send some directory operations out-of-order [1], and it is possible future file systems (or other current file systems I do not know about) will do the problematic buffering.More details: HSQLDB version is 2.3.1.
Class cast exception with FOR Select.Using 2.3.2 as a server engine, within a stored procedure I am receiving class cast exceptions "String cannot be cast to Number". The example below will fail when trying to execute. If you remove the two varchar's (, VP_PATTERN, VP_CODE) from the select clause of the FOR statement, the code executes.The example is cluttered because I was trying to reproduce a problem in my development code where the chkpts table showed that in the course of entering the for loop, the variable your_counter jumped in value between chkpts yourCounter 1 and 2 by the number of records that should be returned by the select statement. Thus the VP_LOOP never executed a second time since your_counter exceeded howMany. Very bizarre. If you need this demonstrated I can provide an even more complex example. So two problems here.
Modulus function does not return decimal result.The HyperSQL User Guide says of the Modulus function:But mod(8.5,3.00) yields '2' not '2.50'.
Column names are case sensitive when returning Generated Keys.Hi,I'm new to using HSQLDB. I've found what may or may not be a bug, depending on your point of view, but I do know that this behavior is inconsistent relative to SQLite, Oracle, and Postgres.When you execute an insert that will return generated keys, if the String array of column names is not capitalized, HSQLDB will fail to find the columns for that table and will fail to execute the statement (and return the new primary keys).I've tried toBy making "FolderId" upper-case, it works fine, aka:
Invalid HAVING expression when having a parameter.I saw an old bug where having a parameter in a having expression generates an invalid HAVING expression exception. It's marked as fixed but I'm having the exact same issue on 2.3.2
ArrayIndexOutOfBoundsException in UNION ALL.The query:It works fine if the 'ALL' option is removed from the UNION and also when the two clauses being unioned are swapped. On its own, the first clause with the GROUP BY returns an empty result set; the second clause does not.
problem with materialising subquery in exists-Clause when view is involved.HSQLDB version 2.3.2.problem with materialising subquery in exists-Clause when view is involved.It seems the join-column-expression is not evaluated if it is not in the from-clause of the select.It was working with hsqldb version 1.8.0.10 and earlier :-)table setup-- not working (gives no result, should return the view-record)-- working (gives expected result)
The NPE raised if there's a subquery in the where cluase.I have a query with a subquery in the where clause,say:but I got the following NPE when executed:
Query with filter of NaN characters failed.Hi,I have an hsqldb table with -Inf, Inf, NaN and null. Using a select statement to filter using that value is confused. E.g. if using where sqrt(0), it returns 0 and NaN. Using where -Infinity, it returns -Inf and NaN etc. Use these samples to test:Thanks.-Aston
PostgreSQL Style Syntax fails on rename column.Greetings.With HSQLDB 2.3.2, the following "postgres syntax" doesn't seem to work.alter table eat_arch_status rename LAST_PACKAGED_DATE TO LAST_DIGITAL_PACKAGED_DATE;FWIW
User defined function. Exception when hsql is starting.Hi,I have the actual hsqldb running (2.3.2). I created a function via dbvisualize and tested it succesfully. After stopping hsqldb and starting it again, I got the following hsql exception.line 247 is exactley the function definition that should be executed.I attach the db script without data and the sql for creating the function.
Can't call callable with JDBC{?=call proc()} pattern.
SELECT query is not working if aggregated column have alias and that column also appear in ORDER BY clause.However above select query work fine if alias not give for aggregated column. e.g Select sum(id) from Sample order by sum(id).Please check and resolve the issue ASAP.Thanks,Tahir Akram
add_months in combination with extract loses bracket.I'm using version 2.3.2, the datasource has 'sql.syntax_ora=true'.When I'm using the query:However, when I make a combination:The recompiled SQL shows a missing part ',1)':I tried wrapping things with additional brackets but havent found a working solution yet. The query does run fine in Oracle.
Time zone change the date or hour in a database.I think the bug is in HSQL but I'm not shure.The bug comes up from LibreOffice or OpenOffice.(I'im sorry for my bad english)To reproduce it...1. create a new database in LibreOffice (or OpenOffice).2. create a table with tree fields: DATA, TIME and TIMESTAMP.3. put some datas in the table, save the file and quit LibreOffice4. change the time zone of your operating system with a farway zone from yours5. open again the tableThe date or/and hour changed
manual entry for constraint incorrect.I'm looking at the CONSTRAINT section of the manual (http).According to that information I should be able to doI'm currently getting "Error: unexpected token: INITIALLY".I've also triedI'm using hsqldb 2.3.1.
Trigger not fired on every single row when using “insert select” or “merge”.I defined a BEFORE INSERT trigger for a table and it works as expected for single INSERTstatements, but not for INSERT ... SELECT nor MERGE statements.These are my database objects (simplified):If single INSERTstatements are executed, everything works as expected, the ÌD is fetched from the sequence. But if I execute something likethe I get an error:integrity constraint violation: unique constraint or index violation: "EMPLOYEE_PK"which could propably mean that it tries to insert the same key from the sequence twice.I'm using the latests version 2.3.2 of HSQLDB.
DDL 'LIKE TABLE" does not copy NULLable property.In the documentation (Ch 4) it says:"All NOT NULL constraints are copied with the original columns, other constraints are not."However, this doesn't appear to be the case. All columns appear to have the nullable attribute set. Looks like it's down to this (ParserDDL.java:readLikeTable)The penultimate line overrides nullable indiscriminately.Is this part of the SQL 2008 spec? Either the docs or code should be changed, I think.I've tested this with 2.3.2, using a temporary table as the source table (though this shouldn't make a difference, I think).
Queries are not escaped with `.Hi there,I'm using hibernate and some of my entities have attributes like order, language or catalog. I noticed these are reserved words so having a query like this:will fail in HSQL but succeed in Mysql. The reason is that Hibernate will translate the query to something like this:and the same query gets translated like this when using HSQL:which fails. I believe the problem is in the hsql driver, so now I have to rename my datamodel and put some unintuitive attribute names, only because HSQL does not escape with.I hope you will fix that. Thanks a lot and keep up the good work :)
ScriptReaderDecode locks filehandle on exception.There is a problem in the ScriptReaderDecode constructor class. If the first constructor is called with a "String fileName", it creates an FileInputStream with the call to "openInputStreamElement(..) and then delegates to this(....)In our usecase the "new GZIPInputStream(...) throws an exception upon construction (because the DB File is corrupted). HSQLDB then holds on to the filehandle xxxx.script until the finalizer of FileInputStream finalizes that inputstream and closes the filehandle. During that time its not possible to delete the corrupted database.A solution is needed that frees up all resource if the HSQLDB cannot be started. Below is the current code of HSQLDB 2.3.2 that we use....
Incorrect results from query on temp-tables when spilled to disk.After upgragding to 2.3.2 I see a problem where I lose results in correlated sub-queries on temp tables that are spilled to disk. Here is the scenario:Connect and create a database : jdbc:hsqldb:file:C:\Users\DNICOD~1\AppData\Local\Temp\hsDNTst1\hsDNTst1SET SESSION RESULT MEMORY ROWS 1398 -- This causes the failure, but 1399 and above avoid the problem, presumably by not going to disk.I've attached a stand alone program (including data) that reproduces the problem. If invoked with an argument >=1399, then it returns the correct results1398 causes the query to return incorrect results. I can narrow it down further or provide more info if that will help.Thanks for your time,Dave N
NullPointerException when unnesting an array.The following SQL statement causes a NullPointerException to be thrown:Perhaps, the statement is invalid per se, but even if that's the case, there shouldn't be a NullPointerException. The full exception stacktrace is:
Wrong calculation of MEDIAN.HSQLDB calculates the MEDIAN() value as PERCENTILE_DISC(0.5), rather than PERCENTILE_CONT(0.5). For instance:The above yields 2, instead of 2.5.Consider for instance the Wikipedia article on the Median:If there is an even number of observations, then there is no single middle value; the median is then usually defined to be the mean of the two middle values [1] [2] (the median of {3, 5, 7, 9} is (5 + 7) / 2 = 6), which corresponds to interpreting the median as the fully trimmed mid-range. The median is of central importance in robust statistics, as it is the most resistant statistic, having a breakdown point of 50%: so long as no more than half the data is contaminated, the median will not give an arbitrarily large result.
MEDIAN() should ignore NULLs.The following query yields 1:This flaw is particularly interesting when emulating the SQL standard FILTER clause (as supported by PostgreSQL), e.g.In HSQLDB, the FILTER clause would be emulated as followsIn this emulation, again, NULLs are not ignored by HSQLDB, which leads to the MEDIAN() being wrong.
RuntimeException when using bind values in FILTER clause.I found another bug related to these aggregate functions. When using a bind variable in an aggregate function's FILTER clause:I'm getting:
sys_extract_utc not recognized in create table statements under Oracle syntax mode.Executing the following statement producesBut selects work just fine.Select sys_extract_utc(systimestamp) from dual;
read.Even though my connection string has readonly, sqltool tries to expand the data file and throws following exception:The connection string in question is:I should probably mention that the data file is in use in "read-write" mode in a separate jvm while i'm trying to open the file using sqltool. Any idea what could be going wrong here or if this is expected?
java.lang.ClassCastException: with count(*) and union.Hello,When the following SQL requests, a classcast exception occurs on the server side, for instance using sqltool:On the hsqldb server logs:I am using the last snapshot from svn, but it is reproducible with the 2.3.2.Best regards,
Oracle syntax mode, case statement datatype not resolved.Running the following set of sql statements against HSQL results in a stacktrace, while running them against Oracle successfully executes.SET DATABASE SQL SYNTAX ORA TRUE;It works in both HSQL and Oracle.
ArrayIndexOutOfBoundsException in org.hsqldb.DatabaseManager.getDatabaseObject.The application has 8 threads opening and closing connections to hundreds of HSQLDB databases. The application is running with the 2.2.9 hsqldb.jar.I suspect the issue is that the fileDatabaseMap isn't synchronized consistently.In addDatabaseObject, getDatabaseObject, and lookupDatabaseObject, the synchronization is on the DatabaseManager class. In removeDatabase, it's on the map.I glanced at the 2.3.2 code and it didn't seem to differ here.Thanks.
setObject with UUID throws excepton.We work with UUIDs. Every time when I call statement.setObject(parameterIndex, java.util.UUID.randumUUID().toString()); it throws an SQL exception. The column is generated with VarChar(100). Though there should be no Error. I solved it like this:I modified in method setObject of org hsqldb.jdbc at line 1055:It would be nice if Objects would be converted (when possible) to the Type of table. This may could be manged by an boolean.
Wrong results from inner join with subquery in join condition.The following code was extracted fromOn Hsqldb 2.8.2 it produces two rows ('a', 1) and ('c', 3). PostgreSQL, MySQL, H2, SQLite and Derby all agree with this result. Hsqldb 2.3.2 produces an empty result set.
Values scalar sub-query causes NullPointerException.A query that uses VALUES inside a scalar sub-query gives a NullPointerException.Here is the query:FYI, I am developing on Apache Calcite, on https.I have a workaround so I don't consider this problem to be urgent. The workaround is as follows:select (select null from (values 1) union all select null from (values 1)) from "foodmart"."department";(Yes, the desired effect is to produce a cardinality violation.)
Oracle syntax mode, update with sub query aggregation.The following query runs successfully on Oracle but fails on HSQL
Wrong constant used for indexing.In the TABLE_PRIVILEGES function of dbinfo.DatabaseInformationMain.java, the TABLE_PRIVILEGES constant is used to index into sysTables (line 3347) and sysTableHsqlNames (line 3350), but uses SEQUENCES to index into sysTableHsqlNames at line 3362/3.
"Error: Incompatible data types" thrown during CASE Statement with Sub-Query.Procedure to replicate,1) Run the DDL.sql to create the Schema and Tables.2) Run the DML.sql to populate data into the Tables.3) Run the SQL as decsribed above.Note,1) This may be related to https: as I am currently looking into the https, to rewrite queries and push it down to the underlying data source (in my case HSQLDB).Thanks!
Order by log(column) changes the type of column in select list.In the following example o_orderkey and o_customer_key are integers, but in the 2’nd query o_orderkey is returned as a double:This seems like a bug. It looks like the o_orderkey field in the select list received the type of the order by log(o_orderkey).Attached program to reproduce the problem, compile and run as followsOutput for me is :
Where exists using an temp table with join has no results.In a specific case, when using a 'where exists' clause the hsqldb should return results, but it doesn't. The next query is used:Strange thing is: when the 'left outer join' clause on TABLE2 is removed, the results are correct.
Cannot assign sequence value to a variable in a stored procedure.It is not possibile to assign the next value for a sequence to a variable, in a stored procedure.Below the example:the error is: "sequence expression cannot be used in this context"
closing and immediately opening a DB fails.After writing a medium sized DB (about 100MB) i experience the problem that opening the same DB immediately after closing it fails.Is there a way i can wait until the DB is finally closed so i can it open again?This is the sequence as seen in the log file:
Maven snapshot version numbering.Currently all snapshots arein a directory SNAPSHOT.I recommend naming this directory based on the version number. E.g. 2.3.3-SNAPSHOT
View using "with" clause cannot be selected.A view using a "with" clause can be created successfully but cannot be selected.The following runs successfully on 2.3.2 but not on SNAPSHOTSimply executing the select outside the view runs successfully with w_clause as (select * from a_table) select * from w_clause;
Grant examples fail.We have a project, where we need to invoke some Stored Procedures. Doing so via a Trigger is working, but when trying to access them directly, we got the error:As the Stored Procedure is working via the Trigger, we tried to look at the permissions, and from the documentation: httpWe can read how to do it. However, the example there:Is causing the following error:
Missing class 'StatementSignal'.Good day,I think the class 'StatementSignal' is currently missing on the trunk.The ParserRoutine is referring it on line 1988Kind regards,Richard
Table alias fails for INSERT INTO in Oracle syntax compatibility mode.When using an instance of HSQLDB started with Oracle syntax compatibility (sql.syntax_ora=true), the usage of table alias in INSERT INTO statements will fail with an unexpected token error.Example:-- create the example table# create table mytable (my_id varchar2(40 char) not null,my_name varchar2(1000 har),constraint my_id_pk primary key (my_id));-- this insert will work fineinsert into mytable (my_id,my_name) values ('item1','First item');-- but this will fail claiming unexpected token for mtinsert into mytable mt (mt.my_id,mt.my_name) values ('item2','Second item');
NPE when a unique constraint is violated.A null pointer exception is thrown in IndexAVLMemory when a unique constraint is violated:The old and correct behavior was to get a SQLIntegrityConstraintViolationException in such a case.Test case provided.
incompatible data types in combination when using COALESCE in case of DATE type.In case of DATE type this does not work:This workaround works:
Problem with column labeling in java ResultSet.Reading a db in locally from file to test a SQL query-generating API. I run the following Natural Join in java using the jdbc:where the ActorTeams join table includes an ActorID and a GroupIP, GroupBundles join table includes GroupID, BundleID, and a policy string, and BundleResources join table includes a BundleID, ResourceID, and ResourceType string. All fields are strings.I notice in the ResultSet that the columns are correctly matched to the data in the columns. However, the column labels are mixed up; instead of the columns "ActorID, ResourceID, and ResourceType" I get GroupID, policy, and ResourceID (which are not the columns that I selected). I'm thinking this is a bug.I ran the same query on the same schema in a different relation DB and it worked as expected.
unexpected duplicate rows in result of GROUP BY primary_key on implicit cross-join.commands issued on a new in-memory database:
General error since version 2.3.2.Since version 2.3.2 something is broken and I get a "General error":
index misses rows "where column < VERY_LARGE_VALUE order by column desc".-- querying without index matches the row.
index causes null values to match "column >= LARGE_NEGATIVE_VALUE".
Illegal SQL is persisted for table valued function.Consider the following table-valued function:When this function is created via jdbc:hsqldb:file:C:/data/hsqldb/test.db, it is effectively stored as
NullPointerException regression in 2.3.3 on INFORMATION_SCHEMA queries.I believe this is a regression in 2.3.3 as I can reproduce it only after upgrading. Consider the following table:And now this query against the INFORMATION_SCHEMA:
bug with queries with more than one "right outer join" since the version 2.2.9.It seems that there is a bug with queries with more than one "right outer join" since the version 2.2.9.It looks that the problem is not direct in the database but in the jdbc connector.I test them in the Server Mode and connect with SQuirrleL.
indexed null comparison gives wrong answer.Fetched 0 rows.-- same query gives wrong answer when using index:
Connection does not become invalid after HD loss.With HSQLDB 2.3.2 on Windows 7.Create/Connect to a db on a network drive (usb stick).Disconnect (I suspect a similar behavior occurs with a full hard disk)You can keep CIUDing without any problems and even close your db without running into any exceptions.It is very graceful behavior to be able to continue working even if the hd is lost (temporarily), but in my usecase too graceful (a user can work for hours against the database without realizing his changes are never saved).I'd expect the Connection to become invalid after encountering such a problem, or some driver specific way to detect/notify me of this?maybe Connection.getWarnings()?or a Connection.setNetworkTimeout ?(the attachment contains the exceptions that are printed by the sync thread)
Checkpoint deadlock in mvcc read_committed mode versions 2.2.6, 2.3.2, 2.3.3.I use HSQLDB for an image caching system. The images themselves are stored on disk but an image statistics (last access, usages etc) and location on disk are stored in HSQLDB. I experience deadlocks at the point the logfile is processed and emptied.Even though not sure this is because of my own code (it locks rows when updating statistics and when records are evicted, Spring and Hibernate should commit the sessions), I haven't experienced any deadlock issues with MYSQL so far.I have a unittest that reproduces this issue on my machine. It runs 10 concurrent threads that read from the database (read and update same record's stats) and 1 thread that inserts records. I tried both direct jdbc:hsqldb:file: connections and standalone instance with jdbc:hsqldb:hsql connections.My connection string (issue happens with both cached and normal table settings):Furthermore I use a 20 connection pool (dbcp2).I captured the session data together with a threaddump, see attachment.
executeUpdate does not return the correct number.Hi,I found a bug during the execution of executeUpdate() of CallableStatement.The return value of executeUpdate is equal of the number of row inserted/deleted/updated as written inI created a small test - the attached file - that creates a very simple scenario:a table with 2 columns, 4 store procedure for each operation and a test that:1) Insert a tuple (with data = value), select that tuple2) Update that tuple (with data = value2), select it3) Delete it, select it (result = null).As result of the test, the tuple is inserted, updated, selected and deleted correctly but the value of RowCount is always equal to ZERO!For this test I used the same types I used in my code to find this bug: CallableStatement, HikariDataSource.
Error on Cascade/No Action delete when I have 3 tables.Hi,I found a bug in the current release.I have 3 tables with these parameters (PGS Syntax):I use these alters:When I would like to delete from 'example_class_b3', I get constrain validation error as expected.But when I delete from 'example_class_a3' table, the result is 'updated count 1' and my expectation is a constrain validation error. This worked in 2.3.2 release.
"call current value for ..." returns null string, if called before "call next value for ..."."call current value for mycounter", if executed before "next value for mycounter" returns a null string. It should return the current value, I assume. This is through the DBManager GUI on 2.3.3.If executed after a 'next value for ...', in the same DBManager session, it appears to work correclty.
NullPointerException on add constraint.Hello,if I try to execute a alter table statement I receive an NPE. I used HSQLDB 2.3.3.My create statement:Please fix this error and use e.g. Sonar to detect NPE before a release is performed.
Concurrency problem with org.hsqldb.jdbc.JDBCResultSet.getTimestamp()Hello,I have noticed a thread locking problem when concurrently querying database for large results containing timestamps (calling org.hsqldb.jdbc.JDBCResultSet.getTimestamp() repeatedly from different threads).After some debugging I narrowed it down to this method: HsqlDateTime.convertMillisToCalendar()which contains synchronized block on a static Calendar field tempCalGMT:This obviously presents a bottleneck when getting timestamp results from ResultSet using multiple threads, so I am wondering if it can perhaps be refactored in order to be more suitable for multithreaded applications?
ArrayIndexOutOfBoundsException from XEvent in 2.3.3.ProblemReproduced with 2.3.0 and 2.3.3, but NOT 2.2.9. Running Java 1.8.0_60.When running an application with HSQL on the classpath I see the following error in the console now and then:After a lot of searching It turned out to be a problem with a xbindkeys mapping I'm using to map my scrollwheel to ALT+Left and ALT+Right (navigate back and forth in browsers and eclipse).Steps to reproduce1. Compile TesteFileChooser.java2. Run it with version 2.3.3 on classpath, e.g. rm -r DB_Test.* ; java -cp hsqldb-2.3.3.jar:./ TesteFileChooser (sometimes an existing database hides the error).3. Enter the following command in a different console: /usr/bin/xvkbd -xsendevent -text "\[Alt_L]\[Left]"CommentI have only been able to reproduce it with the xvkbd. If the -xsendevent argument is used the exception is not thrown.Potentially related issue:
Sequence generated only once during insert.I have a table using nextval('test_seq') as DEFAULT. It works, as long as I insert only 1 row. With more than one row it complains that the primary key contraint is violated. Is this behaviour intended or is this a bug? I'm attaching code to reproduce the problem, tested on HSQLDB 2.3.3. In PostgreSQL such sequence works as I expect - it generates a unique value for every inserted row.--this is ok
ENGINE getFromFile failed 10.Hello,we had this problem when we started up the HSQLDB database in server mode:Please take a look below to our database properties configuration:Do you believe this problem is related to the cryptography module or not?Can you help us giving a solution?Thanks for your attention.
BigDecimal precision is lost in NUMERIC(x.y) columns.HSQL seems to lose precision of the inserted BigDecimal values in NUMERIC(x,y) columns. Fractional part has always y digits - regardless of what the original value was or whether all these digits are zeros or not. For instance if I have NUMERIC(5,2) and insert 1, I get 1.00 back.Reproducible with 2.3.3. Seems to be a regression, works with 1.8.0.10.Test case attached.
Session.abortTransaction is set on InterruptedException, never cleared.I was trying to track down a random unit test failure that was associated with this stack trace:I finally tracked it down to the fact that some of the unit tests were testing corner cases around an interrupted thread, and that the interrupted exeption was picked up by hsqldb instead of my code it set Session.abortTransaction flag, which in turned caused the exception I was seeing. That is fine, but the flag is never cleared and subsequent commit/rollback operations on that connection will always fail, leaving that connection only semi-functional. Functional enough that connection pool validation still thinks it's a good connection, but make the connection useless for updates.See attached for code InterruptBug.java for sample code that duplicates the problem.
HsqlException: unexpected token: SELECT.Hi,I am using @Formula("select .....") annotation for property in the entity class.Calling the method with Query that returns my entity leads to following exception:Using @Formula annotation is working in 1.8.0.10 version but not in higher versions.
ClobInputStream.read(char[], int, int) does not comform to definition by Reader.The code will actually put "this is a " in ch[] from 2-11.basically when currentPos+len <= availableLength, the code will do wrong.Proper implementation should be something like below.
HSQLDB setting wrong input parameter name for procedure when preparing callablestatement.I am using HSQLDB as in memory database in one of my junit tests for a generic set of classes that I wrote for calling stored procedures.Then at some point inside the class that prepares the statement I use setObject method to register the input parameter:By using the debugger, I was able to find that there is a package private method in org.hsqldb.jdbc.JDBCCallableStatement class which is HSQLDB's implementation of CallableStatement, the method name is findParameterIndex which is called inside the setObject method, which checks if the provided parameter exists in the map of parameters from the procedure:by exploring that map using the debugger I was able to see that the parameter name is wrongly set by hsqldb, at least in this map:I was able to verify by changing the name in the setObject method call:After that it worked fine.The weird thing is that if I retrieve the metadata of that procedure using DatabaseMetaData.getProcedureColumns method, the name of the param is correct from the jdbc metadata perspective:Note that the name is coming in upper case, I already check that. I changed the registering of the parameter name to upper case in the setObject method to see if that helped, but didn't make a difference.
SessionManager <-> Session Dead Lock.Hi there!Please, find the attachment with the Bamboo report for the Dead Lock around Session and SessionManager.The synchronized Session.close() waits for the synchronized SessionManager.removeSession(), when the synchronized SessionManager.close() waits for the synchronized Session.close().Thank you in advance!
Wrong update when using subselects.Consider the following setup:Then run the following UPDATE statement to swap the two values in the column data:The row with ID = 1 is updated correctly, but the row with ID = 2 contains a NULL value in the data column.This happens with 2.3.3 and the 2.3.4 RC jar file
MVCC and deletes leaking RowActions.My version is 2.3.3. I'm experiencing unbounded memory growth using MVCC, cached=true, autocommit=true, and deletes. This is not a case of unclosed sessions or statements (AFAIK). What I am seeing is that the rowActionMap in TransactionManagerCommon has RowActions in it that are never cleaned up. I am determining this by looking at a YourKit memory dump. I see many RowActions in the rowActionMap that are for closed sessions. The RowActions are of type ACTION_DELETE_FINAL and deleteComplete is marked as false. The delete code I'm using is:As you can see the connection is called withing a try-with-resources statement which closes the connection. I have observed close being called. If I put the prepared statements in the try (and explicitly commit -- I have not verified that both changes are required), the issue still occurs.It is my understanding the all of the statements and associated results should be cleaned up when the connection is closed. There is a high degree of concurrency in my application. I can provide the YourKit snapshot if needed.
HyperSQL Database Engine (HSQLDB) / Feature Requests / #328 ROW_NUMBER() OVER(ORDER BY) Results in Error (HSQLDB 2.3.3)Hi,We are trying to execute the following SQL command in HSQLDB and are receiving the error below. Our understanding of 2.3.3 (our current HSQLDB version) is that it should honor SQL Server's ROW_NUMBER() OVER() syntax. It does, up until the point we add an ORDER BY clause.Can you please let us know what we are doing wrong?Thanks in advance,Chad
Current Statement not Canceled on ALTER SESSION.Looking for a way to cancel long running Statements on a HSQLDB Standalone Server,I stumbled upon this Stackoverflow Question and Freds Answer to it.Using the current Release Candidate and the svn version from the Date of Freds Answer, I tried to release or close a session in order to abort the Statement using another connection.I usedselect session_id from information_schema.system_sessions where current_statement='some_sql'to get the corresponding session id an then called ALTER SESSION <id> RELEASE.The Statement, however, is not canceled instantly. It seems that HSQL waits for the statement to finish and then returns an rollback:serialization sql error to the connected client.Is this the way hsql should behave in this case?If yes, is there another way to cancel a statement immediately?Thanks in Advance,Christian
JDBCPooledConnection with allow_empty_batch.JDBCPooledConnection uses constructor JDBCConnection(JDBCConnection, JDBCConnectionEventListener) to create its connections. This causes the property isEmptyBatchAllowed, and others, to be left on the default setting, thus ignoring the URL properties.I think you should add the following statement and its brethren in there as well:
Inconsistent case sensitivity in JDBCConnection.prepareStatement(String, String[])I am using the method JDBCConnection.prepareStatement(String, String[]). As you well know, the last String array argument tells the PreparedStatement which columns to return in the ResultSet from getGeneratedKeys().The column names in that array are case sensitive while in the previous queries, there is no case sensitivity: select id from users is valid, resultSet.getInt("id") is valid, but using new String[]{"id"} is not valid. I would have expected the same case-insensitive column names here.Here's an SSCCE that demonstrates the situation:The output shows the first two id's, but crashes at the prepareStatement:
Assignment to method parameter in JDBCPreparedStatement.Version: 2.3.4The result of c.nativeSQL(sql) is assigned to parameter sql instead of this.sql. In the end this.sql = sql is executed on line 3955 for toString() as the comment points out, so this might be intentional?
unexpected token: , required: (.This procedure worked in all previous versions of 2.3, it is objecting to the comma after Period
Deadlock when using HyperSQL 2.3.4 with Flyway migrations.When using the Flyway database migration system with HyperSQL 2.3.4, the attempted application of migrations results in deadlock.Version 2.3.3 works as expected and I found that the code change causing the deadlock is the following code added to TransactionManagerCommon.java line 558 in commit r5537:For some context, one of the first things that Flyway does when it starts is open up a connection to the database and lock its metadata table. The migrations are applied in a separate connection. The code pasted above gets run a few method calls below the executeCompiledStatement method in Session.java (this method is what is trying to execute my first migration).The getTransactionSessions method is adding the session that Flyway uses to lock its metadata table to the "tempSet" of the session that is executing the migration. This effectively causes the executeCompiledStatement method in Session.java (around line 1355) to wait forever -- the session that Flyway is using to lock its metadata table doesn't commit (and therefore release its lock) until all the migrations have run, so the count down latch will never decrement:The deadlock described above can be replicated by using Spring Boot's flyway sample and modifying the pom.xml so that the application uses HyperSQL 2.3.4 instead of H2. The unit tests for the sample show the deadlock occuring -- the build and units tests get run by running the following command:The output of the command will stop and lock up after outputting the following:
Bnary Data Type TableMetaData.Hello,First I would acknowledge the work that has been done with the HyperSQLdatabase. Being a fellow developer of a open source project I appreciatethe work involved.In reviewing changes between v2.2.9 and v2.3.4 my Application MyJSQLViewis reporting a change in Precision and Size for Binary types. Given thedefined table below v2.3.4 is now giving a zero precision and size fora standard Binary declaration with no length. The documenation indicatesthis should result in a single byte Binary field.Instead of being a single byte field, it appears to be cabable ofreceiving a unspecified number of bytes. I'm able to put a larger numberof bytes then one in the field. In additional this is causing an error inthe application output of defining the table, field as Binary(0).Dana M. Proctor
HSQL + Hibernate 5.1 (JDK 8) + JPA unable to insert due to column order and parameter order not aligned.Hello,I have a Spring 4.2, Hibernate 5.1 application which uses Liquibase to create a table. If I switch the application from MySQL 5.x to HSQLDB 2.3.4 it is unable to insert a row into a table (in the meantime it has inserted two rows into Liquibase control tables). The error is "Invalid argument in JDBC call" and the Hibernate-generated insert has the columns listed in alphabetical order but the parameters appear to be in the order that the table was created. If I switch back to MySQL all is fine but back to HSQLDB and it fails. I am not using Hibernate hibernate.hbm2ddl.auto by the way (which would cause the table columns to be created in alphabetical order). Apologies if this has nothing to do with HSQLDB but I can't think of what else it could be. I have also tried it with MS SQL Server and it works. The behavior seems to be Hibernate generates the insert statement with column names in alphabetical order. The parameters in the case of HSQLDB appear to be getting generated in the order the columns are in the table physically.Thank you
CallableStatement::prepareCall doesn't work in 2.3.4 for stored function with (at least) one parameter.I've just updated the version from 2.3.3 to 2.3.4 and I discovered a bug in 2.3.4 that was not in 2.3.3.The snippet below can be used to reproduce it.Basically, what happens in 2.3.4 is that there is an exception thrown in the call to connection.prepareCall("{call return_inparam(?)}"). If I replace the question mark with an actual value, and remove the statement.setString(1, "sometext"); line it works fine also in 2.3.4.The exception call stack is the following:
create table fails with exists error, but table does not exist.We are using HSQLDB in an in-process (Tomcat/WebSphere) multi-thread situation where tables are being created, populated, queried and dropped very rapidly -- usually less than 5s in total. Each table is named uniquely, guaranteed. Each table also has a single compound index applied, and each table has a primary key auto generated via identity.Infrequently, the create table fails with an "object already exists" error. In the catch block of that create, executing the identical create table script succeeds, in all cases.In a sample run of 900 table creations (being generated by 10 threads in the pool), this occurred only 3 times. However, we can find no programmatic reason for it to occur at all.
ResultSet#getObject not returning UUID.For a column of type UUID, a SELECT returns org.hsqldb.types.BinaryData as return type for ResultSet#getObject, instead of java.util.UUID.PreparedStatement#setObject() does accept an UUID as type, so ResultSet#getObject should also return one.See the attachment for a demo.
Joining table with BigDecimal/NUMBER as PK fails when value > MAX_LONG.Hi.Attached are three Java files that describe my simpel model. I use Hibernate to store the data. Later (using Hibernate or straight SQL over JDBC connection) I get a variable success when joining depending on the value I instansiate the model with (the column "parentkey"). Joining (using WHERE or JOIN) works OK if the value I give to the Java BigDecimal is small, but fails if it is over 9223372036854775807 (which is the MAX_LONG_VALUE).The actual SQL that silently fails is:So I think this is this a bug, or ?Regards.
DB appears corrupt after INDEX DROP/CREATE on column with a UNIQUE constraint.We had a schema creation script that drops and creates an index on a column with a unique constraint.The bug is reproducible with the HSQLDB GUI tool using an in-memory db. Affected are at least 2.2.9 and 2.3.4 versions.The script to reporduce the problem at the bottom of the post.After the script is executed, table CLIENT_DETAILS has three entries, however, they are onlyavailiable to an unrestricted select query:If one executes a query restricted on column CLIENT_ID, ony one entry is available:The entries inserted after DROP/CREATE INDEX are missing in the result set.The documentation menstions that one should not create custom indices on columns with UNIQUE constraint for performance reasons, since an index is created automatically on such columns. However, in this case the undesired effects seem to go far beyond poor performance.
DROP CONSTRAINT causes SQLIntegrityConstraintViolationException.We use hsqldb (2.3.4) inmemory mode for testing and all test uses the same db.When we start a full test at first we load data from xml to db as we drop constraints -> load data -> add constraints.It works properly but some tests load some data again and one of them (and following tests) failed when tried to drop constraints.It doesn't make sense because of a constraint (foreign key) dropping cannot cause "SQLIntegrityConstraintViolationException: integrity constraint violation: unique constraint or index violation"!I know whcih test methods cause the problem just I don't know why.Theese tests cointain failed transactions but other ones too and they don't cause any problem.I attached the log and in debug I found that "olddata" (RowStoreAVL.java:540) contains primary key twice but obviously I found just once in db (with select).
metadata for datetime types incorrect.In 2.3.3 The table INFORMATION_SCHEMA.SYSTEM_COLUMNS, which just shows the result of the jdbc introspection getColumns has some problems with 'DATA_TYPE' and 'TYPE_NAME' of datetime types. There are two issues I can see:2) When declaring a DOMAIN of TIMESTAMP WITH TIMEZONE CHECK VALUE IS NOT NULL, and then declaring a table column with this alias, 'DATA_TYPE' is again 93 as in issue #1, but also, the 'TYPE_NAME' is 'TIMESTAMP' (i.e. without time zone). Again, I suspect a similar problem with other date/time types but haven't checked.Here is the result of an example, query on SYSTEM_COLUMNS. The first row is declared directly as TIMESTAMP WITH TIME ZONE as in #1, whereas the others all use an alias DOMAIN as in #2 above.I guess that not many people care about this, but looking into rising populatrity of Java8 time, the driver should distinguish between these clearly to help the user to cast these as e.g. Time or OffsetTime.
HSQL under-relative JEE stress leads to a shower of SQLNonTransientConnectionException: connection exception: closed.While running weblogic 12.1.2 with NON-JTA (as the XA - JTA HSQL db driver seems to be quite problematic), our application systematically would go into connection closed errors "blood-bath" when runing agianst HSQL 2.3.4 stable release.The type of exceptions that were encountered are listed in the text file uploaded in attachment, with the stac trace with company related code removed.In this particular case, the HSQL DB 9001 server was running locally, on the exact same server running weblogic.Nor firewalls, no network communication going exernally.The connections to HSQL seemed reliable only while the system was not under stress.As soon as the the testing would create heavier load, suddenly many of the threads executing read or write queries would get pummeled by exceptions such as the one in the stack trac.eIn the end the HSQL in version 2.3.4 even without JTA transaciton was dimmed unsuable.We had to re-create the domain to run agains Oracle or Microsoft Sql server and all issues were gone.Of course now we have the network latency in a test server that could very well do with testing on local HSQL db.I did not try reverting back the HSQLDB JDBC driver and HSQLDB server to version 2.3.2, which is the current stable version of hsql we primarly use for integration tests, but I suspect the HSQLDB non JTA/typical jdbc driver under 2.3.2 as well as the server, is rather more stable.This situation of weblogic detecting closed connections I had never encountered before on HSQL.Weblogic will then reconnect and recreate new connects to the DB, but of course then many of the logically correct DB transactions have already be damanged by the previous errors ... so even if connections to HSQL will self-heal, this runtime exceptions are unacceptable, and the server/client driver combination for 2.3.4 had discarded as the only datbase giving us such trouble.
ArrayIndexOfBounds Exception in RowSetNavigatorClient.S2R:1. Create Statement with fetch size = 12. Execute select query from table which contains more than 3 rows.3. Call next() three times on result set4. Call resultSet.getObject(int)Expected:
NullPointerException parsing recursive CTE.This bug occurs reliably with HyperSQL 2.3.4. When parsing the following query, a Java NullPointerException is thrown:The stack trace is as follows:The problem appears to be that the recursive name ("foo" in the example) is referenced twice in the query. Although the minimal example query above does not really require require recursing twice, it's useful to be able to use a construction like this to halt the iteration based on some condition on the result of the previous iteration.
Null Pointer in CASEWHEN and CASE... WHEN use case.The last instruction of the script below results in a null pointer exception:FROM TestSame if CASEWHEN is replaced by CASE facet WHEN ...This is happening with hsqldb 2.3.3 (I'd like to test with 2.3.4, but it needs extra effort due to bug https://sourceforge.net/p/hsqldb/bugs/1441Thanks
PreparedStatement: setObject(..) throws SQLSyntaxErrorException when binding Arrays to MERGE statement.When I try to bind an Integer[] to a PreparedStatement that uses MERGE... I get a SQLSyntaxErrorException.INSERT/UPDATE works fine.I attached a test case that triggers that behaviour on my system with HSQLDB 2.3.4Is that a bug or faulty user?Harald
Silent option does not always prevent Server to write on stdout.I am starting a HSQLDB server programmatically. Everything is working well, except the silent option, which in despite of being the first method that is invoked on the Server object, one line is written on the standard output:A quick look at the code associated to the class org.hsqldb.server.Server let me think it is a bug. The field isSilent is initialized to false by default. Then, its value can be changed with a call to setSilent or setProperties. However, these last methods make use of printWithThread to print a few things before changing the value of the field isSilent. Since value passed to printWithThread is written on the standard output if isSilent not set, there is always at least one line displayed on the standard output.Is there any other solution to prevent output on standard output with the Server class?
org.hsqldb.HsqlException: incompatible data types in combination.I get following exception with v2.3.4:
unexpected token: SELECT.I'm using a formula to execute a select statement and I'm getting the following error: unexpected token: SELECTHere's the relvant part of the stack trace:
Commands work on embedded, not on server.I have a sequence of legal SQL commands that work fine on HSQLDB embedded, but fails when running HSQLDB in server mode. In server mode the last command in the attached file results in a java.sql.SQLException: statement is invalid.See attached file for SQL statements, including setting up the database and creating tables, server logs and config.
Parser error when RECURSIVE CTE contains parenthesised UNION query.This works:This doesn't:Only recursive queries seem to be affected. The following works:
colon not working as fs separator.A text table named hello.txt containing only "hello:world" returns "Access is denied" or "constraint violation" when
table created via subquery not like a view.http says"An <as subquery="" clause=""> used in table definition creates a table based on a . This kind of table definition is similar to a view definition." Yet after creating a (non-text) table from a text table via an as-subquery clause, and then DROPping the source (text) table, I still have my data in the newer, non-text table. So the latter table is not similar to a VIEW onto the former, dropped table.I don't know enough of HSQLDB's functionality to suggest fixed verbiage.
Error DELETE with referential integrity DELETE ON CASCADE.We use HSQLDB 2.3.3. We decided not to use 2.3.4 because of bug 1441 (Deadlock when using HyperSQL 2.3.4 with Flyway migrations).We had a problem trying to delete a record from a table woth referential constraint in DELETE CASCADE.Below you can find DDL to create some tables of our databaseThe row from table core.mainCols contains a columnMap that throws this exceptionbecause the number of elements of array is less than columnMap indexes.
using clob instead of varchar uses lots of memory with mem database.For junit tests in hibernate I use hsqldb mem database for performance. As soon as I switch a column to use @lob annotation in hibernate the junit tests persisting object graphs fail because out of memory. Obviously the clob type uses lots of memory for the mem database compared to varchar and exhausts available memory.
TO_CHAR not work into view.When I create a view on a table, if I use TO_CHAR into the view definition, HSQLDB doesn't find the column.With an example :I create a table MY_TABLEIf I create the view where I do a TO_CHAR on NUMBER_COLI have this error :But, if I create the view without TO_CHAR, it work :
java.util.UUID[] type cannot be used as bind variable.The java.util.UUID type is already supported as a valid bind variable type for HSQLDB's UUID type, but it cannot be used for arrays. For instance, the following code fails:The exception I'm getting is this:The logic in the failing method is this:There should also be a section like "if (a intanceof UUID[])".
Recursive query runs forever.This simple recursive query runs forever:Here are a few thread dumps from jstack:
CallableStatement cannot handle expressions containing bind variables.I have a procedure like this:I can call the procedure easily using a CallableStatement like this:I can also call the procedure using a constant expression for the IN parameter:However, I cannot use any expression that contains a bind variable, e.g.:This results in the following exception:
regression 2.3.4 ADD CHECK CONSTRAINT keyword handling problem.While upgrading to 2.3.4 from 2.3.3 a new error started to apper in our tests:Full error:the word period is not mentioned in reserved keywords. http://hsqldb.org/doc/guide/lists-app.htmlAlso when period is esaped (double quoted) the same statemt dod not work (with different error)
ArrayIndexOutOfBoundsException in RowStoreAVLHybrid#getAccessor()Attempting to upgrade from HSQL 2.3.2 to 2.3.4 we observed lots of our integration tests (more than 900) randomly failing with an ArrayIndexOutOfBoundsException in RowStoreAVLHybrid:If I add diagnostics to RowStoreAVL and RowStoreAVLHybrid and let the tests fail again, I see the actual length of accessorList was 1 at the moment the call was made, and the RowStoreAVLHybrid instance has been accessed by 40+ different threads.This looks like a inconsistent synchronization issue to me, despite all methods which change the array reference (not the array contents itself) seem to be synchronized.The exception is thrown during both SQL INSERTs and SELECTs, but always from the same (single) place.The issue is hard to reproduce in a lab, so I'm not providing any code here.
ArrayIndexOutOfBoundsException for array_agg(distinct col)This seems to occur because list.size() is used on line 343 instead of array.length. List size and array length can differ if distinct clause is used..
SELECT...FOR UPDATE locking unexpected behaviour.There is a thread about this that has some background info here:Basically, I'm trying to use SELECT...FOR UPDATE to coordinate access to a shared pool of tasks where each task is represented as a row. The goal is to ensure that each task is picked up by one thread only. Each thread queries for a "pending" task and then, while holding the update lock, changes that task from "pending" to "processing" so that no other "pending" query will return that task.This method has the expected behaviour on other DBs I've tried but not HSql.I've attached a test program showing the issue. You can just import it into Eclipse. I tried this program against a SAP HANA database and it works in the expected way.
Can't check for index existence by selecting from INFORMATION_SCHEMA.SYSTEM_INDEXINFO.As of r5720 (2.4.0-SNAPSHOT), I can no longer check whether a particular index exists.This is a regression compared to v2.3.4.I'm pretty sure this is a regression compared to r5711, too.The testcase which demonstrates the issue is attached.
Database Lock Acquisition Failure.Hello,We run hsqldb in a web environment, with Servlets under Jboss. Our stable version uses 2.3.2 but we encountered issues with query aggregates which were solved with a 2.3.4 upgrade. However upon restarting, we get a lock acquisition failure, which we have determined to be caused by the Database.reopen failing due to RuntimeException raised by LoggerFramework which is as it turns out because the name of the Database is empty.We have created a simple patch to change the database name check, but have not verified any other use cases in hsqldb aside from our own.The stacktraceApologies if this is a duplicate issue, we have compared against trunk and saw there are no similar changes.
SQL batch issue in concurrent  memory DB.I run the following code in servletwhen I do the performance test, there may be a batch error occur, the batch fail and the table will not be created. I wont get the exception if I remove the "mem" for connection.I also update my code, if I catch batch error, I will execute the SQL one by one, then the tables are created successfully.I think there may be some concurrent issue in HSQL, can you help fixing the issue?thank you!
OdbcPacketOutputStreamTest can't be compiled in some environments.If LANG=C and LC_ALL=C are exported, org.hsqldb.server.OdbcPacketOutputStreamTest can't be compiled:So
preprocessor.jar can't be built with gradle.Unlike the ant preprocessor command, gradlew preprocessor fails with:Note: Some input files use unchecked or unsafe operations.Note: Recompile with -Xlint:unchecked for details.FAILURE: Build failed with an exception.For some reason, Ant runtime (BuildException) can't be found on the class path during the Gradle build.
test.xml doesn't make any use of junit38.lib property.When building hsqldbtest.jar (declared in build.xml), it is possible to specify an external junit.jar location via -Djunit38.lib=... .This is not the case for make.test.suite and run.test.suite targets from test.xml, however, so one always needs to copy the junit.jar to lib/ first.
Provide support for dependency management.HSQLDB requires 3 external libraries:Gradle has been providing automatic dependency support for ages. Please add support for dependency management via Gradle, so one doesn't need to manually download junit.jar any longer.
HSQLDB can hang if the database is corrupted.HSQLDB can sometimes hang on start after unsuccessful shutdown (e.g.: power loss).We've observed this against 2.3.2 and subsequent versions.The stack trace is as follows (trunk). Apparently, if (length == 0) condition, under certain circumstances, can never be met:Since database corruption can't be avoided entirely, it makes sense to replace the while (true) loop with at least while (!Thread.interrupted()), so that the client can interrupt the thread and break out of an endless loop.
https connection problem.I'm trying to use hsqldb using https protocol. But I found a problem when the URL is generated for https.At this line the s variable receive an http urlat this line the https url is generated using the "s" variable with has a full http url.The attached diff shows one solution for this problem.
Docs Typo: Timstamp.Hi,while reading the docs on Java Language routines (http) I stumbled upon a typo in the table mapping SQL types to Java types. It says 'TIMSTAMP WITH TIME ZONE' but should say 'TIMESTAMP WITH TIME ZONE'Regards,Florian
Invalid character value for cast.Hi,Previously with HSQLDB 2.3.4 it was possible to execute an SQL query like this one:select cast(to_char(created, 'IYYYIW') as int) from TemporalEntityBut now with 2.4.0 we get this error:After some testing I found out that there seems to be a problem with the "to_char" function because if I test the same SQL query but without the casting part then I get this: 2017'18There is an apostrophe that gets inserted between the date and week values!Please let me know if you need more details and/or a test case...Thanks,Christian
TarGenerator.write outputs progress in stderr.We are using hsqldb to, among other things, periodically backup our hsql database. When doing so, our service produces log messages marked as ERRORs (since it is coming from stderr) that just show the progress of the backup. This introduces noise in our log monitoring system, and is also misinformative.The problem is located at src/org/hsqldb/lib/tar/TarGenerator.java and a patch fixing it is attached.
MVCC: write lock broken on savepoint rollback.Hello HSQLDB team. I've just encounter a bug on HSQLDB v 2.3.4. I've updated library to 2.4.0 but bug still exists.I will attach TestNG test case to illustrate a bug.Main scenario is (all performs in single transaction) :I think it is a bug, because:I'm using in-memory MVCC HSQLDB to test my application on a fast embedded DB.I know about "select ... for update" statement, but a "dummy update" should be tested too (some DB has bugs with "for update", like MariaDB)
StackOverflowError in Value Pool mechanism.StackOverflowError in Value Pool mechanismSince HSQLDB version 2.3.4 there is a bug in the area of the ValuePoolHashMap which will eventually cause HSQLDB to crash with a StackOverflowError. In our test environment the crash will reproducibly occur after 5 days of continuous operation. In real operational scenarios the occurrence may be more or less frequent depending of the frequency of updates performed on existing table records.Characteristics:The occurrence is characterized by a StackOverflowError, with a stack trace of the following constitution:Further, in theory, the bug may occur in the methods: org.hsqldb.map.ValuePoolHashMap.getOrAddDate, org.hsqldb.map.ValuePoolHashMap.getOrAddDouble.After the occurrence, HSQLDB will fail to execute any further query through JDBC with the following error:A restart of the HSQLDB is required to get it working again. No database corruption was observed after restart.Analysis:The ValuePoolHashmap serves as a mechanism of de-duplication to reduce memory usage when the database contains several entries with equal value. For this purpose it provides a number of type specific methods like getOrAddString() or getOrAddInteger() with accept a primitive type value or object value, respectively and returns a unique, singleton object instance with equal value. It’s implementation relies on the bespoke hash map implementation class BaseHashMap, which behavior is modified in ValuePoolHashmap to achieve a cache-like behavior in order to not endlessly keep value objects that are no longer part of the database entries. At the same time the implementation attempts to keep a balance between holding enough value objects for repeated equal values in the database but not waste memory by keeping value objects in the internal hash map that only occur once of few times in the database. This is realized by access counting.The typical logic of the de-duplication methods consist of computing a hash index based on the value and attempt to find a matching singleton instance, possibly after several re-hashes. If a matching object is found, the method returns that object right away. Otherwise, if no matching value object can be found in the hash map, a size check of the internal index data is performed:When this condition holds, an internal re-organization of the hash map is performed, after which the method invokes itself recursively in a repeated attempt to find a matching value object. When the bug occurs, the recursive invocation of the method does still not find a matching value object and the condition hashIndex.elementCount >= threshold still holds, which leads to an endless recursion.Related:On 2015-05-29 a similar bug was discovered and reported by Jesse Barnum in the SF forum, which affected the method getOrAddInteger of HSQLDB in the development trunk for version 2.3.4. That similar bug was then reported to be fixed on 2015-05-30 with commit r5476, which made it to the release of version 2.3.4. The commit however only affected the methods getOrAddInteger() and getOrAddLong(). The other methods like getOrAddString(), the culprit of this bug, was not changed.
File size increase with upper on clob.If you execute a select with in upper on a clob column in the where clause the size of the lobs-file increases. A upper copy of the clob will be created and stored. But if you execute the same statement again the already copied data won't be reused. Further the space is not freed again. Only if you manualy execute a CHECKPOINT the unused data in the lobs-file is removed and the space is available for other data.If you don't know this behavior the file increases until the disk is full. The size of the lobs-file cannot be shrinked as it was before the execution of the selects with an upper.It would be nice if this would be documented and that there is a possibility to shrink the size of a lobs file to the current used defragmented size.
NPE in ConnectionDialogSwing.actionPerformed.Launching the Swing GUI (via java -jar hsqldb.jar) and pressing the "Clear Names" button results in an NPE thrown in the AWT event thread. The backtrace is attached.
WHEN clause ignored using Java based triggers.Trigger:
hsqldbmain missing Main-Class in jar file.Build script for hsqldbmain is missing a main class in the mainfest like
Problem with database files initialization in volume of windows docker container.While running app in windows docker container with Oracle Java 1.8 within mounted volume HSQLDB library fails to rename files with ".new" prefixesWhen it's running in regular directory it succesfully rename files:According to the code in the org.hsqldb.lib.FileUtil#renameElement method result of org.hsqldb.lib.FileUtil#renameWithOverwrite method was not checked, so it silently ignores it.It seems that could be implemented workaround for cases when rename fails.
VALUES expression and TIMESTAMP WITH TIME ZONE literals not working.Potential bug with VALUES expression and TIMESTAMP WITH TIME ZONE literalsThe following highlights the bug.Is this a bug?
PreparedStatement#setObject with java.time.LocalDate saves incorrect values to DATE column.When using PreparedStatement#setObject with a java.time.LocalDate object to update a DATE column, the stored value appears to deviate from the actual value by 999 days for each day that the actual value differs from the epoch (1970-01-01). That is, a LocalDate of 1970-01-01 works, but 1970-01-02 is stored as 1972-09-27 (999 days after 1970-01-02) and 1970-01-03 is stored as 1975-06-24 (1998 days after 1970-01-03).Test code:
unique constraint or index violation: SYS_IDX_10094 when IN predicate contains array larger than 288 elements.When issuing SELECT (through JDBC with using technique described in HSQLDB guide) in which IN predicate value is an array of 299 lements or larger, exeption "(java.sql.SQLIntegrityConstraintViolationException) java.sql.SQLIntegrityConstraintViolationException: integrity constraint violation: unique constraint or index violation: SYS_IDX_10094" is thrown.Test-case code:
IndexOutOfBoundsException from Table.getColumn() while running recursive queries.Running of recursive query causes IndexOutOfBoundsException since 2.3.2. Works fine with 2.3.1 version.
Merge - Insert does not produce auto-generated keys."Merge-Insert" does not produce auto-generated keys.Java Code:Auto-generated keys will produced if it is not a merge statement. Only a If-Statement ist working fine.
TEXT table source parse issue.Fixed issue with incorrect parsing of text table data when the first field of the first line contains a quoted comma.
SELECT ... INTO issue with subquery.Inside a routine, a SELECT ... INTO statement that relies on a subquery does not work correctly. Example below was reported in the Open Discussion Forum
order by does not work in for loops in SQL-invoked routines.The order by clause does not work in for loops in SQL-invoked routines. It will be ignored.This issues exists since before version 2.3.1.My Example:A "get_test_vars()" call returns "ABC" but it should return "CBA".
CHECKPOINT DEFRAG raises IllegalArgumentException.Hello,I trying to migrate a table containing 140 millions rows using liquibase.
Delete with inner join not working.Delete with inner join is not working.For example:
How to reset identity column?I have many tables which will created and fully deleted from the user.I couldn't found a way to reset identity column, because the normal command:Thank youPS: Do you have a plan to release 2.4.1? There are already many bugfixes which are important for me.Thank you
"natural left outer join" bug.When I input following SQL statements:It's supposed to returnBut HSQLDB returns:
ALTER TABLE .. ALTER COLUMN doesn't adhere to the documentation.Try the following script:According to the documentation, the above should be perfectly fineThe relevant section is:This form of ALTER TABLE ALTER COLUMN accepts a columnDefinition as in a CREATE TABLE command, with the following restrictions.RestrictionsThe NOT NULL attribute will be that of the new definition (similar to previous item).However, the parser rejects the query with "unexpected token: NOT in statement". The same is true when adding a DEFAULT clause and other clauses.
DECLARE LOCAL in Stored Procedure.Using "declare local temporary table" within a stored procedure will not compile. In a simple statement it will, however. See proc below.If schemaless temp tables are not supported then perhaps the docs should be updated to clarify this as the documentation doesn't suggest such a limitation.Thanks.
SPs and Cursors : cannot be cast to org.hsqldb.result.Result.Exception thrown when executing a procedure that returns a cursor on an in-memory db. I have read anything I could find on the subject including this post and I am pretty sure I am following your lead as to how ref cursors are supported.Thanks in advance!MonteThe procedure:
Exception after altering a varchar to clob.The alter table command seems to execute properly, however on the next launch of the application, I see this stack trace. Any suggestestions would be greatly appreciated.
Exception when ordering distinct array_agg.
Collate clause from domains lost in DB script file.Using v2.4.0, I have created some domains with collate clauses as per the guide:However I discovered my SELECT queries were not working as expected as the collate clause was not being applied during table creation.Demonstration of issue using sqltool:Fetched 2 rows.Alternatively, shutting down the database then manually adding "COLLATE SQL_TEXT_UCC" to the "CREATE DOMAIN" definition in the DB's script file also works.
Discarding decimal places using Oracle syntax with column type NUMBER.We use hsqldb with sql.syntax_ora=true.Switching version from 2.3.4 to 2.3.5-2.4.1 datatype NUMBER shows different behaviour.With 2.3.4 storing a floating point value in column of type NUMBER the decimal places are preserved like in Oracle (3.141 -> 3.141).With version >=2.3.5 storing a floating point value in column of type NUMBER the decimal places are lost (3.141 -> 3).In the changelog appears a fix which may introduced this behavoir:
WHERE id IN ( UNNEST(?) ) only returns first matching row.only returns the first matching row when the column is NUMERIC(5) andthe array is int or smallint.However, if we change the column type to INT
TRANSACTION_SIZE() broken? Or at least doesn't track information_schema.
Case-insensitive English collation does not work with LIKE clause.The docs at http say (regarding collation strengths) "The value 0 indicates least sensitivity to differences. At this strength the collation is case-insensitive and ignores differences between accented letters." To me, this means that "English 0" should be a case-insensitive collation, and so equality or LIKE clauses should match case-insensitively.This works as I expect with SQL_TEXT_UCC collation, but with "English 0" collation an equality check is case-insensitive, but a LIKE clause is not. This is inconsistent between those two collations, because I would expect them to be the same in terms of case-insensitivity. I expect the collations to work the same whether it's an equality or a LIKE clause.
Handling of pos./neg. infinity values in HSQLDB 2.4.1.Hi,in an open-source project, quantile values of the F-statistic are calculated and stored to a HSQLDB (version 2.4.1). The F-distribution needs two degree of freedoms (dof). One of the dof can be +Infinity (in this case, the F-distribution is equal to the Chi2-distribution).The log file of HSQLDB contains the right value for +Infinity, i.e. 1E0/0If I close the database by shutdown, the sign of the infinity value is changed to -Infinity, i.e. -1E0/0. The corresponding script file containsFor validation of my problem, I create a database, insert one row to the TestStatistic table, and kill the application. Thus, the database is unclosed and the log file still exisits. You can take a look to the log file to validate the Infinity-value. If you open the database, HSQLDB flushs the entries of the log file to the script file. In script file, the sign is now negative. Why?What is the reason of the sign-change? You can download the short example here.Tested on Win7, Java 10 using HSQLDB 2.4.1.Thanks in advance.Micha
"incompatible data types in combination" for case when statement.Here are the tables I was creating:Here is the SQL query I need to execut:FROM CustomerOptions co INNER JOIN Customer c ONIt complains about "incompatible data types in combination / Error Code: -5562 / State: 42562"I think mainly because the PrimaryPhone column is bigint while others are varchar.a vast system is already built on the above mentioned tables, and changing the column definition isn't really an option.the same SQL query executes fine on MYSQL (production database).we are using hsqldb to run unit-testsso our unit-tests are not passing, but production is working fine.
13.28 "String comparison with padding" documention typos.This is a very minor ticket, but I ran into the 'silent character padding issue' referenced in ticket #1175.I found the documentation regarding setting "no pad" in section 13.28 but couldn't get it to work until I realised there was a typo!The corrections needed are:to become:andBy default, when two strings are compared, he shorter string is paddedto become:By default, when two strings are compared, the shorter string is paddedSet to priority 9 as I assume this is the lowest.Thanks!
In DB script file, CREATE COLLATION with CREATE TYPE broken.I have columns that use a custom defined TYPE via "CREATE TYPE" statements. These columns, in fact the whole database, needs "NO PAD" or "sql.pad_space=false" property.For non-custom-type columns I can use SET DATABASE COLLATION SQL_TEXT NO PAD and/or the connection property "sql.pad_space=false".For the custom-type columns, the corresponding CREATE TYPE statement ends with "COLLATE SQL_TEXT_UCC". However there's no way to specify "NO PAD" with "CREATE TYPE" so I had to create a new collation with CREATE COLLATION SQL_TEXT_UCC_NO_PAD FOR SQL_TEXT FROM SQL_TEXT_UCC NO PAD and use this new collation in my CREATE TYPE statements.This worked the first time I created/opened the database but after shutdown the database cannot be reopened.The first issue is that in the script file the "CREATE COLLATION" statement is placed after the "CREATE TYPE" statements that use it so I get a "user lacks privilege or object not found: SQL_TEXT_UCC_NO_PAD" error.If I edit the DB script file and move the CREATE COLLATION statement to just before the CREATE TYPE statements I still get "user lacks privilege or object not found: SQL_TEXT_UCC_NO_PAD" error.I noticed the script's version of CREATE COLLATION has "PUBLIC.SQL_TEXT_UCC_NO_PAD" so I changed one of script's CREATE TYPE statements so that the collation name was similarly qualified:But now I hit a new error: "unexpected token: PUBLIC" which suggests CREATE TYPE isn't able to deal with qualified collation names.I'm now stuck with no way to reopen my database or no way to perform non-padded, case-insensitive string comparisons.Any ideas for a workaround?
stored procedure with output parameter can't call another stored procedure directly.I have a stored procedure 'testDummy1' with output (or input/output) parameter.I can't create another stored procedure 'testDummy2' with output (or input/output) parameter. Calling 'testDummy1' passing the parameter directly, got error:Errore SQL [42603]: dynamic parameter or variable required as INOUT or OUT argumentBelow the sample code:
SqlFile throws error on first statement when script file has a BOM.I'm using SqlFile to execute a SQL script that was generated by SQL Server Management Studio (SSMS). My intention is to run the script against another instance of SQL Server to re-create an entire database.Because SqlFile does not seem to like the GO statements that SSMS intersperses through the file, I pre-process the file to replace the GO statements with semi-colons. However, I still get an error on the first statement because the file is encoded as UTF-16LE.SqlFile does not have a problem with subsequent USE ... statements, nor does it have a problem with USE [master] per se, as illustrated by the following test script:When I execute that script using SqlFile from SqlTool 2.4.1 viait producesFurther testing revealed that if I convert the file to UTF-8 with no BOM the error goes away. If I convert the file to UTF-8 with a BOM (as Windows seems to prefer) then the error comes back.So, it looks like SqlFile has a bit of a problem with Unicode files that have a BOM, even if the file really does need one (e.g., UTF-16LE).
Casting string to TIMETZ and back to VARCHAR yields wrong results.Running this query:I would expect to get the original value back, i.e. '00:00:00+02:00'. Instead, I'm getting '24:00:00+02:00', which cannot be parsed using java.time.OffsetTime.parse(). I'm not too skilled deciphering the SQL standard text, but in any case, the behaviour is inconsistent with this, which raises an error (as expected):
System generated constraint name breaks log file.Procedure:Server fails to rebuild from log file because create constraint statement with no name specified generated a different name (always or under specific circumstances?). When the drop constraint statement in the log file is reached, the name specified in the drop constraint statement does not exist and the entire log file is thrown out.Solution: include the system generated constaint names in create constraint statements recorded in the log file?Excerpted from broken log file:alter table cycle_counts drop constraint sys_fk_14655
Sequence next_value invalid after database restart (from scriptfile)When creating a table column with GENERATED BY DEFAULT AS SEQUENCE, while restarting the database using the scriptfile, any sequence automatically gets set to MAX() of the corresponding columns.If the sequence is defined with a MIN/MAXVALUE outside this MAX(), working with the sequence is not possible anymore. Also, another restart (scriptfile contains an invalid RESTART WITH now) is not possible (org.hsqldb.HsqlException: number out of the valid range for sequence generator).Expectation:The sequence must use the next-value given in the scriptfile. It should never automagically change these database definitions on restart.How-To-Reproduce:All correct so far, also the scriptfile is ok:As some can see, the NEXT_VALUE automagically got set to some value, which is max(id)+1.And, it's outside MINVALUE/MAXVALUE range now. This is what gets written to the scriptfile then:
Illegal reflective access warning on JDK11.From the warning emitted by the JDK:
Misleading error message when timestamp literal is illegal.Consider the following SQLselectfrom information_schema.system_users;It contains an illegal timestamp literal. The error message I'm getting, however, is:This is quite misleading
sql.sys_index_names doesn't seem to work.If I execute the statements below the index gets created as SYS_IDX_13915 (or something like this).I expected a different name, according to the docs.
Possible typo in  missing data impact clause error message.If execute this:I get:I would expect READS SQL DATA instead of only READS SQL.
Exception when creating foreign key.The last of these three statements:causes this exception:
ALTER TABLE loses ON UPDATE clause.The table works as expected after being created with:However after changing it with something like:the ON UPDATE clause stops working.If it's any help this also happens when adding a foreign key or dropping a column.I didn't try anything else but I suspect it's tied to ALTER TABLE, no matter what kind of change is done.
Can't change padding for string comparison.After executing these statements:sql.pad_space is still set to true.
Extra whitespace in .script file.When creating a new database specifying the connection property hsqldb.digest the .script file contains a line like this one:with an extra space between DATABASE and PASSWORD.Even if it's removed manually, a SHUTDOWN COMPACT puts it back in its place.
Data file size doesn't seem to be as expected after enabling files space.On a newly created database if I execute these statements:The .data file is 4 MB and I would have expected 2 MB since by default hsqldb.cache_file_scale is 32.The file size remains the same even if I change the first statement to SET FILES SPACE 1;, where I would have expected 1 MB.The size is still 4 MB even if before executing the statements above I set hsqldb.cache_file_scale to 256, in this case I would have expected 16 MB.Maybe this is not a bug but after reading the docs this isn't the behavior I would expect.
ClassCastException when using ora_syntax=true and Union ALL.Hi there!I'm getting an EOFException (connection closed) with some sqls, like the one below (ora_syntax = true):If you need more info, please let me know.Thanks!
CountUpDownLatch.java: String.format typo $d -> %d.
alter session close not working with sessions that have an open transaction.Steps to reproduce:I've tested another options (RELEASE and END STATEMENT), but the end result is the same.
Can't create java.sql.Array with type name TINYINT.The following test errors:But I think it should succeed just as this one:The exception thrown is:
SSL connections via hsqls not working on JDK 11.I've discovered a strange problem regarding SSL/TLS encrypted connections on JDK 11. I was able to reduce the problem to this short application:The program creates two connections to the database server via hsqls. Of course the server was configured properly and the truststore / truststore password is correct.Running this application on OpenJDK 8 & OpenJDK 10 leads to the expected output:First connection established...Second connection established...But running this application on OpenJDK 11 leads to an error on the second connection:First connection established...Second connection failed!Obviously the second connection attempt should not fail, if the first connection was properly established.I was able to reproduce this problem with HSQLDB 2.4.1 and SVN trunk on the following systems:I hope there is a solution before HSQLDB 2.5.0 is being released. Maybe you have an idea about this?
hypersql incompatible data type.can someone pls tell me why this error ?Derby shut down normally
Cannot connecto to the Database after renaming PUBLIC schema.Hi,I have discovered a strange behaviour of the database after a certain sequence of operation. I was able to reduce the problem with this code snippet:the program renames the PUBLIC schema and then creates a table and inserts into it a value. After the SHUTDOWN IMMEDIATELY I am not able to recreate a connection to the database again. The error that I have obtained is the following:The program was executed with the Oracle JDK8 on Ubuntu 18.04 using both 2.3.6 and 2.4.0 version of HSQLDB maven dependencies.If I execute a SET SCHEMA TESTSCHEMA immediately after the ALTER SCHEMA PUBLIC RENAME TO TESTSCHEMA everithing works, as well as if I do not insert values into the db between the table creation and the shutdown.
Interruption flag is cleared during statement execution.I encountered an issue with an application that was occasionally leaking active threads from thread pools that were shutdown. I traced this problem back to HSQLDB suppressing interruption flags during its statement execution. I saw this to be a pattern in for example the Session class where Thread.interrupted() is invoked after catching an interruption exception what clears the flag.As a consequence, a thread that is currently executing a statement will not be able to shut down as the interruption signal is only sent once. If the thread's event loop is checking for the flag to be set, it will have been cleared by HSQLDB. This is breaking the contract of thread interrupts making ordered shutdown impossible.Is there a particular reason for you to clear that flag? If it should not be set during the session execution, it would be important to self-interrupt the thread before returing to invoking code.
Exception with ON UPDATE CURRENT_TIMESTAMP.If I try to execute this statement:I get this exception:I don't think this is the expected behavior but of course I could be wrong.For what it's worth if I remove WITH TIME ZONE then the statement works.
data exception: invalid interval format.If I try to execute query likeI get exceptionIntervalType.getIntervalType() contains nothing about milliseconds. Seconds, minutes or another time field works good.
bad line numbers in recent jdk8debug Maven artifacts.I'm trying to see what's inside prepareStatement(), but with recent Maven artifacts for jdk8 the line numbers don't match. See the attached screenshot.
MEDIAN on TIMESTAMP Version 2.5.0.Congratulations to Fred and Blaine and HSQLDB team on the release of HSQLDB Version 2.5.0 .I have noted an item ( bug ) where the documentation does not match real world use.According to the documentation Chapter 7 Aggregate Functions:The SUM operations can be performed on numeric and interval expressions only. AVG and MEDIAN can be performed on numeric, interval or datetime expressions. AVG returns the average value, while SUM returns the sum of all values. MEDIAN returns the middle value in the sorted list of values.While AVG works as described with a datetime expression, MEDIAN returns an error incompatible data type in operation / Error Code: -5563 / State: 42563.The following code example can be used to re-create the issue, NOTE comment line to have it work:Sliderule
When trying to access a running HSQLDB process, a NPE ocurs.Hello,Using HSQLDB 2.3.3 (our current production version), there is no problem.Our server creates a separate java hsqldb process. When our process is abrupdly stopped, it may not have killed the hsqldb process using a SHUTDOWN sql. The java process then runs alone. To avoid problems when starting again our process, we then try to connect to a potentially running hsqldb process. During this attempt, we now always get a NPE while we never did get one before (using 2.3.3). The NPE is below.Thank you for having a look.
Error with UNDO and EXIT handlers in procedure creation.If I try to execute this:I get this error:If I change EXIT with UNDO there's a similar error.CONTINUE works, however.
Error when overloading procedures.This executs properly:However if after that I try to execute this......I get this error:This doesn't seem to be an issue with functions because after succesfully executing this......this executes successfully too:
rs.getObject(x, LocalDateTime.class) returne incorrect values prior to 1582-10-15.repro code:Interestingly, if the column is DATE then rs.getObject(1, LocalDate.class) returns the correct date.
Error with UNDO handler in trigger execution and deletion.I'm using r6016.To reproduce create a new in-memory database with DatabaseManagerSwing.Then execute these:I'm not sure if that's an error or expected behaviour.However with CONTINUE or EXIT instead of UNDO I get this:Which is what I thought (maybe erroneously) that I would get also with UNDO.Moreover if I try to delete the trigger:I get this:and the trigger isn't deleted.This I'm fairly sure is a a bug, please note that this only happens after executing the trigger, for example with the INSERT above.The trigger can be deleted just fine after creation, before it's used.
EXTRACT ( WEEK_OF_YEAR FROM ... ) does not adhere to ISO 8601 anymore.Starting with hsqldb 2.5 the statement:This problem happens, if the Locale.getDefault() is set to en_US. It disappears, if Locale.getDefault() is set to de_DE.This problem happens on hsqldb 2.5.0 only, it does not happen on 2.4.0 and 2.4.1.
Invalid exception "numeric value out of range" at converting Double in NumberType.I want to insert a double value '1.0E+38' to HSQLDB, but I get an error:When I insert value '1.4E-45', i don't get this error.I guess method toDouble(..) in NumberType does wrong comparing (see JPG attachment).I don't know why author of this code wrote such comparing.I get this error using UCanAccess driver loading access db with such values to HSQLDB.
Wrong result for quantified ALL predicate.The following query returns NULL as expected:But for the following query the expected result would be FALSE, but HSQLDB evaluates it to NULL again:
Minor Doc Error hsqldb.cache_size."Table 13.53. Size of Rows Cached in Memory " contains the following seemingly contradictory text:The value can range between 100 KB - 4 GB. The default is 10,000, representing 10,000 kilobytes. If the value is set via SET FILES then it becomes effective after the next database SHUTDOWN or CHECKPOINT.It's 100KB to 4GB but the default is 10KB?
Function creation before sequence creation in script file causes problems when function references sequence.If you create a sequence, and a user defined function that accesses that sequence, then the statement to create the function is put before the statement to create the sequence in the script file. This means that, although no errors are reported when creating the script, it will not reopen as the sequence is not recognised.results in:
Is hsqldb 2.3.7 available somewhere?My dears, it is not effectively a bug, but a doubt.We need HSQLdb to run with Java7, and, so, we need version 2.3.7, not 2.5.0. Is this version available somewhere? Thank you very much!
Incorrect domain constraint violation when using 'instead of' trigger.Please load the attached DB.If you then execute:Then it incorrectly reports a not-null violation on a domain 'money', for which there is a derived attribute 'unit_cost' in the view 'order_line_ext'.However if you insert directly into the base table:insert into order_line(customer_order, product, quantity) values ('ORD_0', 'PRD_4', 7);Then the violation is correctly not reported; querying from order_line shows that the value for attribute 'unit_cost' is not-null.On top of this, the 'instead of' trigger for inserting into 'order_line_ext' simply does the insert into order_line which succeeds if executed outside the trigger.
Insert INTO .. SELECT .. UNION ALL SELECT..  fills up varchar with whitspace.INSERT INTO with select union will fill up all varchars(x) with trailing whitespaces.Example:This will end up with a entry for 1 = "Ben "despite its declared as varchar2.
Is PreparedStatement.setFetchSize() works or not?I get an JVM OutOfMemory error on large dataset select.PreparedStatement.setFetchSize() seems does nothing. Is it a bug or just not implemented feature in driver?
Issues with set table source parameters.. (ignore_first, fs , all_quoted etc..)Hello there,It seems text file interaction still requires refinement .. please see below..Above file is not opened anywhere else. Just FYI.
Rejected update still commits data.Please see the attached DB - I'm running in shared mode withPlease try the following:This correctly gives the error:This is raised by a procedure called by a trigger fired after updates on ORDER_LINE, which is updated by the 'instead of' trigger for view ORDER_LINE_EXTBut now....Which is clearly not correct as the update has been committed instead of rejected.Seems like it's another problem with the 'instead of ' triggers like #1558. If I update the base table ORDER_LINE directly then the problem does not occur.
The value stored in the Timestamp column differs between INSERT and MERGE.The value stored in the Timestamp column differs between INSERT and MERGE.
JRT mapping for INTERVAL types is invalid.According to documentation, INTERVAL types correspond to Period and Duration Java types.Java mappings for INTERVAL SECOND and INTERVAL MONTH types are invalid in org.hsqldb.types.Types:624.Here is the opposite mapping in org.hsqldb.types.IntervalType:152.My guess is that HyperSQL Code Switcher directives are messed up somewhere and that's what causes the issue.Minimal example presenting the issue (HSQL 2.5.0, Java 8):package hsqltest;Also see this StackOverflow question.
Recursion never stops.Consider this recursive query:When running this on HSQLDB 2.5.0, the recursion never stops until we hit an OutOfMemoryException. It works perfectly fine on PostgreSQL. This query works fine on HSQLDB as well:
Inconsistent type inference in CTEs with bind variables.I've noticed a few interesting inconsistencies when using bind variables and depending on "type inference" of those bind variables when using JDBC. For example, the following logic yields 12, instead of the expected 3:At first, I was assuming this is because the bind variables are inferred to be of type VARCHAR rather than INT, so the + operation is really concatenation instead of addition. But the result is very different when I do this, instead:Now, I'm getting 11 as an output, which I cannot explain. No luck either when casting the bind variables to int explicitly. This yields 2, not 3:
'duplicate column name in derived table' when using wildcard.Please create a simple table such as
String truncation in derived view column.Please see the attached DB with a text table and a CSV with some large values for certain columns (>32K).When you do select * from v_view, you get 'data exception: string data, right truncation'. It seems there is an intermediate VARCHAR of length 32K being used in the view calculation which gets exceeded (the same happens if you just do the view definition query on its own).Is this perhaps related to, as you state in the guide, "a VARCHAR column declaration that has no size, is given a 32K size"? [but there isn't any way of hinting to the view that the derived column will be >32K]The table column definitions were LONGVARCHAR in the table definition, but I've tried various combinations, and also doing a e.g LEFT(xxx, 1024) for each column as part of the view definition, but nothing seems to work.
Sequence not found when allocation size is above 16383.I want to set a sequence allocation size of 20.000 ("twenty thousand") within a JPA entity. The parameter allocationSize will be managed by JPA (eclipselink in my case).For any reason my tests with hsqldb (v2.5) are failing when the allocation size is greater than 16383. The tests are failing during a sequence restart (see below). Following the documentation (http://www.hsqldb.org/doc/1.8/guide/ch09.html#alter_sequence-section) there nothing special here. Up to 16383 the tests run successfully.
Document capability of aliasing INSERT tables.This seems to work (just like in Oracle or PostgreSQL):But it isn't documented here:Aliasing DML target tables is documented for UPDATE, DELETE, and MERGE statements, so I'd say this is merely a documentation bug
Small typo in manual.The manual contains a small typo in the syntax example for "OVERRIDING SYSTEM VALUES"It says "ORERRIDING"
Parser error when using FOR SYSTEM_TIME BETWEEN syntax.I'm playing around with the temporal table syntax in HSQLDB. Given this table:I'd like to run a query like this, but it fails:SELECT *FROM public.t_sys_time_periodThe error is:The other syntaxes work, including:As a workaround, this syntax also works:
trunk rev 6100 breaks scripts with wrong CREATE TABLE ordering.I need to use the bugfix mentioned in this discussion: httpsTo this end, I checked out the SVN repo to rev 6100 and built a new JAR from trunk.However, opening a database, created by v2.5.0, with HSQLDB rev 6100 corrupts the DB script on shutdown.Somehow the table creation order is wrong. It has certainly changed since v2.5.0!I've attached a tiny demo database script.Open this using sqltool & hsqldb rev 6100 then type "SHUTDOWN" and quit sqltool.Attempting to re-open using sqltool & hsqldb rev 6100 gives me this error:As you can see from the newly mangled script, hsqldb is trying to create table GROUPADMINS, which has a foreign key constraint on GROUPS.group_id, before creating the GROUPS table.Sadly I can't seem to get Eclipse IDE to play nicely with gradle and so help debug exactly why this happens.Good luck!
Non deterministic INSERT statements generated by ScriptWriterText.I'm using the ScriptWriterText class to export databases between computers with differents JREs, and sometimes there is a mismatch between the order of the columns exported in the VALUES part of the INSERT statements, and the order of the column of the database where the script is imported.I suspect the iteration order of the columns is a not deterministic and may vary depending on the JRE used, maybe due to the use of non-ordered hashmaps?I've only tested with HSQLDB 1.8, but the 2.x code looks quite similar.To work around this issue I'd suggest adding the name of the columns in the INSERT statements generated:INSERT INTO foo (A, B, C) VALUES (value1, value2, value3);
Parser error when system_time refers to a variable.I'm trying out the temporal tables but have run into a problem trying to use them from within a stored procedure (or function too). In particualr, I want to have the time specification be a variable.For example, given the following table:I would like to do this, but it does not compile: "user lacks privilege or object not found: SINCE / Error Code: -5501 / State: 42501"(Obviously the given procedure doesn't do anything useful).It seems that the period specification doesn't know about variables. I'm not sure how this is possible since using variables/parameters in the WHERE part of a SELECT works just fine.Having traced through the code with the debugger a little bit, I think the problem is around ParserDML.java:978 in trunk (r6102). That is, the call to XreadSubqueryTableBody().This is because, later on, the references to variables are resolved, but the rangeVars (which the input variable belongs to) aren't saved anywhere (except for targets by XreadTargetSpecification() , but since the input variable is not a target, that doesn't get saved).I am not sure if my hypothesis is correct, or if so how to fix it. I will try to work on a fix and post it here if I come up with one.
DatabaseManagerSwing doesn't show returned result from PROCEDURE call.If you have any procedure with a DYNAMIC RESULT SET then this will not be shown in the GUI (even though the procedure will correctly evaluate).The following patch will show the first result in the table:I'm not sure if this is written correctly so that it works in all cases but I thought I would put it here in case someone else finds it helpful.
Issue with select for update statement.Hello,I am encountering an issue using hsqldb and "select for update" statementIn a nutshell, when the "select for update" is executed, it does not seem to lock the row (or the table) during the time of the transaction.I have made a small program that reproduces the issue on hsqldb which can be found in the attachment. The same program works with Oracle and other dbs.The program executes the following statements by 3 threads:Then each thread updates a global oid. If another thread founds the same oid as it own, the program stops. As it is, the program should not stop.I have the same behavior with the 2.5.0 version and the trunk version. All the configuration I am using can be found in the resources directory.Thank you.Best regards,Ludovic
using clob as a column type will result in a out of mem (or ever growing file)Sample code below.Problem is if you are using "clob" as a column then if you insert a clob then that will be at once 32kb of memory or disk usage (depending on mem: or file:)by itself not a big problem (thats why we do use clobs right? but it would be nice if they only took the amount of memory that they really are, with a few bytes of meta data like length)But the problem is if you delete the row with the clob, or even drop the whole table, then nothing is clean up, the clob manager (File or Mem based) just keeps growingIf you are using for example mem based and you use hsqldb really as a caching database (so you create temp tables, use that in your app, then drop the table complete) then the memory will grow and grow and you will get an out of mem in the end...This can be "worked" around by using then the file: so that at least the file will grow and grow.The test below is based on file because then it is easier to be seen. But mem works the same way (only file is even persistent after restart so you see the file grow and grow even over restarts when there is really no table at all in memory at first start)
General error when using DISTINCT predicate for row value expressions.Running the following query produces a "General error"Caused by: java.sql.SQLException: General error
General error with LATERAL and transitive join column.(Might be related to #1579)General case, using v2.5.0:Results in a "General Error" due to col1 inside the LATERAL().col1 shouldn't be ambiguous because it's the same colum in tableA and tableB, even though it's not qualified with a table name.Requires tableC.col2 to be primary key:
General error when table valued function returns values constructor.Run this script:This version of the function works as expected:
ALTER DOMAIN does not update DEFAULT on existing usages.Consider this script:I would expect the result to be 1, as it is also e.g. in PostgreSQL and Firebird, but it is null. The default value is not updated on existing columns as it should be.Likewise, when dropping a default from a domain:The result should be null, but it is 1. The existing column's default is not affected by the change of domain.This is not the case when adding / removing CHECK constraints, in case of which the behaviour is as expected. The following script fails with a constraint violation, as expected:
General Error when trying to use MICROSECOND with DATEDIFF()Try this query:It produces a "general error":I'm not sure if this is because MICROSECOND isn't supported, or if there's a bug? Trying an arbitrary date part yields a more specific message, though:Yields:
HSQLDB Deadlock using 2.4.1 and MVCC.We encounter a recurrent deadlock issue using the 2.4.1 version in one production environment. We have been using this version for a long time in various environments and have not seen deadlock issues until now.The issue appeared recently in this production environment, and is reappearing regularly after restarting the application and waiting for a few day of usage.The database is quite big, with million rows in some tables.The hsqldb server is configured in MVCC mode and sessions use READ_COMMITED transaction isolation.We did not change the defaults forhsqldb.tx_conflict_rollback or hsqldb.tx_interrupt_rollbackI wonder if these settings should be modified to prevent the deadlock from happening.After connecting to the database manually and inspecting the session, we observed that a checkpoint session is waiting for the following session, which never seems to terminate:The checkpoint statement, on the other hand is preventing many transactions to complete (which I believe is expected).We tried to manually end the blocking session 5969 using ALTER SESSION RELEASE (and then CLOSE), but the session does not seem to respond, we tried as well END STATEMENT without success.We tried as well to use ALTER SESSION RELEASE | CLOSE on the CHECKPOINT (6076), and here it disappeared, but all other sessions waiting for this checkpoint session 6076 were not unlocked and are still displaying THIS_WAITING_FOR 6076.It is quite difficult to understand the root cause of the issue as we cannot identify the origin of the 5969 session, which statement it ran, etc. If we could forcefully provoke an error on this transaction, we could hopefully see in our logs the error and thus could identify the origin. For now we are leaving the server in this deadlock state to hopefully investigate further.
Timestamp loses precision when stored and retrieved.This issue occurs when using JDBC with Java 9+ and HSQLDB 2.5.1.This does not occur on HSQLDB 2.5.0.In Java 9+, the Instant precision increased from milliseconds (2020-06-30T13:51:30.875Z) to microseconds (2020-06-30T13:51:30.875297Z).When storing and retrieving a timestamp with microsecond precision, it is returned with millisecond precision, making it less precise.The following example illustrates this, when run on Java 9 or greater.
Performance issues in queries with joins.I've noticed an unexpected performance issue on a few queries in my system, when they contain join clause.s For instance:-- tableA has around 3k lines, tableB around 50k linesThis takes around 20s to complete in my test environment (the original query takes over a minute). These tables are not really huge, so 20s seemed a little bit excessive to me.I think HSQL is using an inefficient join strategy in this case, but I wanted to see what you guys think about this.On a side note, if you create indexes for both tables, the response time is as expected (even though the amount of data processed in both cases should be roughly the same):
Regression when reading timestamp bind value around epoch.This seems to be a regression introduced in 2.5.1. I haven't seen this in 2.5.0:This works:But this doesn't:The exception is:
At '@/'  path dereferencing doesn't work in certain situations on Windows.When running on Windows, @ dereferencing doesn't work when using paths with backslashes in sqltool command-lines, nor with the SqlFile constructions that accept File arguments.For instance, for a script check-db-setup.sql that includes other scripts via \i @/other-script.sql, this constructor works,while this does not
Bug with selection of multiple boolean constants.Thank you for great database. We use it a lot for automatic testing of our DB layer. We have found strange issue related to selecting constants together with the actual data from the table. If we select two boolean constants with different names, the result set contains duplicated name. Query:While this might be bad design for most cases, we use this functionality in a very specific case.Attaching the image that shows that the result set contains two "WRITE_FLAG" columns. Please note that this is not the IDE bug, since the issue happends during automatic tests built with mvn.Also, the following query works fine:
Documentation: Database Limitations unclear.I can't find any reliable statements about the technical limitations of HSQL.The current size limit of an HSQLDB database is 8 TB for all CACHED tables and 256GB for each TEXT table. In addition, maximum totall lob size is 64TB.It's unclear, if the 8TB limit is per cached table or for all cached tables total. The Features page is equally ambiguous:Disk tables (CACHED TABLE) up to 8TB and text tables up to 256GB eachIt's clear that the 256GB limit applies to each text table. But it's ambiguous again, if the 8TB limit applies per cached table or for all cached tables total.In Data Types and Operations there's no mention of max. length, e.g. of the different character types like VARCHAR.Please clarify on these limitations and it would be great to have an overview like this one for MS Access
DB2 dialect issue with FETCH FIRST x ROWS ONLY FOR UPDATE.It is a specific DB2 dialect statement which fails only on HSQLDB.When try fetch limited rows for update it fails on delete such row with message attempt to assign to non-updatable column.But FOR UPDATE works like expected when is without FETCH FIRST 10 ROWS ONLYCode which fails:and exception:Notice that this statement works perfectly on real DB2 database but our unit tests which are based on hsqldb not.
Duplicative code.In the source file SchemaManager.java, the removeSchemaObjects method starting at line 2228 contains two identical back-to-back loops. This does not cause buggish behavior, but it is poor code.
Sensitive information may be leaked in condlPrint of org.hsqldb.cmdline.SqlFile.In org.hsqldb.cmdline.SqlFile,The sensitive information (String s) may be leaked.We may be able to add control on it.
Sensitive information may be leaked in displaySqlResults of org.hsqldb.cmdline.SqlFile.In org.hsqldb.cmdline.SqlFile,The sensitive information (for headerArray and dsvColDelim) may be leaked.We may be able to add control on them.
General error when using TRUNC in GROUP BY.Running the following script produces a "General error":It seems a regression in 2.5.1, because with 2.5.0 the script works.
Sensitive information may be leaked in write of org.hsqldb.result.Result from org.hsqldb.ParserDDL.In org.hsqldb.ParserDDL,In org.hsqldb.result.Result,The sensitive information (rowOut) may be leaked.We may be able to add control on them.
Sensitive information may be leaked in write of org.hsqldb.result.Result from org.hsqldb.dbinfo.DatabaseInformationFull.In org.hsqldb.dbinfo.DatabaseInformationFull{In org.hsqldb.result.Result,The sensitive information (rowOut) may be leaked.We may be able to add control on them.
Hsqldb should not ignore case of the user name.In org.hsqldb.Database,synchronized Session connect(String username, String password,Java is case sensitive language. Strings "SA", "Sa", "sA", and "sa" are different. Thus Hsqldb should only have one super user "SA" or "sa".
In displaySqlResults of org.hsqldb.cmdline.SqlFile, logger.warning(...) should be logger.error(...) to record exception.Two statements logger.warning("Failed to close SQL result set: " + se) and logger.warning("Failed to close SQL statement: " + se) should be logger.error("Failed to close SQL result set: " + se) and logger.error("Failed to close SQL statement: " + se), respectively.The reason is that they record exception messages.
Sensitive messages (URL and username) may leak in getConnection of org.hsqldb.lib.RCData when throwing MalformedURLException.Sensitive messages (URL and username) are outputted directly and may leak when throwing MalformedURLException.
HSQL files growing since update to 2.5.1.Hello,since I updated my Software to HSQL Version 2.5.1 from Verion 2.5.0, all Database files grow in an unexpected way. Most db sizes grow from 1Gb to over 14Gb, since the update to 2.5.1, without having significant more data stored.Most records in this databases get regulary updated by the System.I am using HSQL in embedded mode.Is this a Bug or do I have to change db setting that we used in 2.5.0 for 2.5.1 to get rid of this behaviour?Best regards
Queries aborted with timeout long before timeout is reached.I'm seeing occasional queries aborted with timeout long before timeout is reached.Symptoms sound very similar to https which was marked as fixed already.I'm using Hsqldb via Hibernate using c3p0 for connection pooling.I'm looking at a log file where the query could have started no more than 3 milliseconds prior to the "timeout reached" message, when the query should have a timeout on the order of 10s of seconds.
Session.java: unused variable sessionTxId.Looks like Session sessionTxId is totally not used?
Session sessionStartTimestamp is assigned but never accessed.Session.java sessionStartTimestamp has value assigned which seems to never be accessed
CREATE TABLE IF NOT EXISTS combined with WITH DATA not working.I tried to create a table with some data, if this table doesn't already exists.Tested with: v2.5.1
General error if GROUP BY using an alias for a function result.Hi,I'm using the HSQLDB version 2.5.1 as a standalone server instance (later I will switch to the file-based instance).Like the bug #1596 reported by Stefano Ravera, but more generally, I'm unable to group-by a result of a function call, e.g.
General error thrown while running SELECT query with group by time period.HiThe following query worked for us with hsqldb version 2.3.1 and even 2.5.0. But starting from 2.5.1 version it fails:In code it fails due to org.hsqldb.HsqlException: General errorIn HSQL Database Manager client I see :I simplified query and figured out that following query stopped to work starting from 2.5.1 version due to the same error:I'm attaching screenshot of error and table description.Thank you
CREATE PROCEDURE should not allow duplicate parameter names.I was trying to test something related to procedures and made a copy paste mistake, where I accidentally re-declared the same parameter names:What I meant to do is this:HSQLDB didn't complain about the non-sensical creation, but instead told me this:The reason being that the procedure was created as if I hadn't declared the OUT parameters:I think the parser should reject duplicate parameter names.
Variables declared in nested blocks in routines don't work.Consider this table:And call it as such:I would expect t to contain 10 records from 1-10, but it is empty:Trying it a bit differently, avoiding the DEFAULT clause:Now, this inserts 5 NULL values!This seems to work correctly, when I completely avoid declaring variables in nested scopes:
Functions returning a table are returned with DatabaseMetaData.functionNoTable instead of functionReturnsTable.For a function declared as RETURNS TABLE(...) DatabaseMetaData.getFunctions() returns the value "functionNoTable" in the column FUNCTION_TYPE of the ResultSet. As such a function does return a table I think the value "functionReturnsTable" would be correctTested with HyperSQL 2.5.1 and OpenJDK 11
TEXT TABLE connection gets lost.I use a csv.file for importing data. The text table is attached byThe data base is embedded in LibreOffice Base.When it happens that in a session the csv-file doesn't exist the connection is lost in following sessions, also if a new csv-file with the given name exists.The only way is to make a new connection.
General error when using FILTER (WHERE FALSE) on an aggregate function.The following query produces a "General error" in HSQLDB 2.5.1:This works:And so does this:
Regression in regexp_replace.I'm trying out HSQLDB 2.6.0, the Thu, 04 Mar 2021 22:14:17 GMT from here:This no longer works:It causes a general error:
HSQL 2.6.0 Release Candidate SCRIPT Error.Fred:While using my HSQLDB Version 2.5.1 and using the 2.6.0 Release Candidate ( RC ) JAR Version 3 ( as well as prior RC candidates ), when starting the database, the following error(s) result:I ultimately created a Version 2.6.0 database, starting from scratch, issuing commands to CREATE CACHED TABLES, CREATE FUNCTION, etc, and, INSERT data . . . I was able to create HSQL Version 2.6.0.I mention the able because the issue is NOT my connection to the JAR or JAVA Version, but rather something in the SCRIPT file. I would be happy to email the database ( a working HSQL 2.5.1 backup file ) to you if you want to investigate it, so, hopefully others will not have a similar issue.Sliderule
Wrong line number displayed with parser error messages.Consider this wrong statement:It produces this misleading error:here is no line 32) The token WITH is on line 1I've run into similar bad line counts in more complex queries, making the error message very confusing.
CTE cannot be used in some scalar subqueries.There are some scalar subqueries that cannot use WITH, others can. Here it doesn't work:Derived tables also work, as a generic workaround:Given that the distinction seems arbitrary (especially in the 1 IN (WITH ...) vs 1 = (WITH ...) case, this might just be a parser bug? If it's by design, then consider this to be a feature request.
UNION ALL or UNION With LIMIT Integer Error.Fred:Just as an FYI, the issue described here, has been present within HSQL for a long time ( prior versions ), but, perhaps never reported. It is present with HSQL 2.6.0 Beta ( RC6 ) as well.When using UNION ALL or UNION, when a Select ends with LIMIT INTEGER , for example LIMIT 5 , an error is returned ( Error Code: -5581 / State: 42581 ), however, the statement can be surrounded by parentheses and it will work, OR, use of TOP, for example ( TOP 5 ), parentheses are not required.For example:From INFORMATION_SCHEMA.SYSTEM_TABLESTATSWhere INFORMATION_SCHEMA.SYSTEM_TABLESTATS.TABLE_SCHEMA = CURRENT_SCHEMAI am providing the above example ( not realistic ) so you have an example to work with, after the first UNION ALL.Sliderule
General error when fetching two empty arrays.Try this in a SQL editor like DBeaver:It fails withAll of these work:The error seems to appear only when there are two empty arrays
Cannot fetch a constant NULL array without explicit cast.This works:Producing:But this doesn't workThrowing this error:The reason seems to be that HSQLDB assumes the type of NULL is VARCHAR, which cannot be converted to an array. But given that I haven't explicitly set the type to VARCHAR, I suspect that it might be possible to delay such a typing decision? I shouldn't have to cast this array, I think...
jdbcDriver 2.6.0  is unusable in JRE8.java.lang.UnsupportedClassVersionError: org/hsqldb/jdbcDriver has been compiled by a more recent version of the Java Runtime (class file version 55.0), this version of the Java Runtime only recognizes class file versions up to 52.0I see no artifact with classifier jdk8 or new artifactId with jdk8 suffix.
JDBC meta on READ_ONLY role returns empty.I am getting some failing tests since upgrading to 2.6.0The test is to test a READ_ONLY role in HSQLDB.as normal userIn 2.5.1 result is true, indicating that the "PUBLIC" schema exist.In 2.6.0 result is false, which in turn causes the code to try create the schema that then fails as the role is READ_ONLY. However the 'PUBLIC' schema does exist.Not really sure if the bug is in the JDBC driver or not. Using Intellij's database tool I can browse the 'PUBLIC' schema using the 'sqlgReadOnly' user. Trying to make any change fails as its READ_ONLY.ThanksPieter
Odd behavior for nvl2 in 2.5.2.Hello, I just tried upgrading from 2.4.0 to 2.5.2 and noticed a change in behavior for the nvl2 function that was quite unexpected:
Insert statement for BLOBs broken.Insert statement for BLOBs broken.I have upgraded from 2.5 to 2.6 and now insert statements are broken.The insert will now end up in this:Error 'incompatible data type in conversion' while executing statement 'INSERT INTO IWA_TaskData VALUES (1, '00' )'
Validating a Hibernate Schema causes a org.hsqldb.HsqlException: General error.A Spring Boot application that sets the property spring.jpa.hibernate.ddl-auto=validate will run the following SQL on startup (note - I have created tables within the schema "WEBSITE"):Versions 2.6.0 and 2.5.2 throw an exception on the last line of the above SQL.
2.6.0 often get Timeouts during selects.With HSQDB 2.6.0 we often getjava.sql.SQLTransactionRollbackException: statement execution aborted: timeout reachedExceptions for normal select statements. The Timeout seems to come after only 2 Seconds.Possible the 2.6.0 driver does not use the set timeout value?When we rollback to 2.5.1 this Timeouts do not happen.We are using the HSQLDb in Embedded Mode.
Constraint violation exception somtimes in mvcc mode.I have some transactional problem when set hsqldb.tx to mvcc. I can not reproduce it all the time but sometimes it occurs.ScenarioI have two tables A and B.B has a foreign key to A with column X.This all happens really fast ("under high pressure). Sometimes it works. Sometimes not.Does anyone has any clue about this?
numeric value out of range error on basic arithmetic.I get a data exception: numeric value out of range error (SQL Error: -3403, SQLState: 22003) with a very simple SQL queries:This fails:Version used: 2.6.0
like expression does not allow addition expression as its right expression.This query does not parse:addition expression should have a higher precedence than like, so Hsql should evaluate '%' + 'PUBLIC' + '%' first then apply it to like expression.
Release 2.6.0 is missing OSGi metadata.The release 2.6.0 is missing the OSGi metadata in the manifest. Both 2.5.1 and 2.5.2 are still properly including it (see META-INF/MANIFEST.MF).
null value causes NPE in JDBCResultSet.getObject.JDBCResultSet.getObject(int columnIndex, Class<t> type) causes a NPE if the value in DB is NULL.Worked on 2.4.1
Spurious unique index constraint violation on inserts.When inserting rows into the following table:using READ_COMMITTED / MVCC mode, and multiple threads to do inserting, spurious SQLIntegrityConstraintViolations are thrown (and also, mysteriously, all my stderr output seems to get consumed, don't know why but it's made debugging this very tricky)Having checked to ensure that there is in fact no violation of the constraint actually occurring, I wondered whether it might be that the unique index itself is failing because the resource_name field contents are "too big".Sure enough, using much shorter resource_names makes the problem go away.Spent all day tracking this one down :)
timeout reached HsqlException thrown when using setQueryTimeout.HiStarting from version 2.5.2 we are trying to use method setQueryTimeout for PreparedStatement, timeout value provided in seconds, I tried to pass 15, 40 or even 60. But anyway I get following exception:If query timeout not defined then any exception is not thrown. When I measure how much time such queries take I get maximum 100-110 msec, so always less than 1 second. I tried also to provide large number of seconds as a timeout, so in the case of 500 seconds exceptions were not thrown. Stack trace of exceptions and queries are attached.It seems me that seconds are considering as a msec.Thank you,Evgeny
org.hsqldb.HsqlException: statement is invalid thrown while deleting table rows using prepared statement.The following exception happens after upgrading from 2.3.2 to 2.5.2 ( full stack trace is attached ) while deleting data from tables, probably happens when there are thousands of rows that must be deleted:We are reusing PreparedStatement instances, but there is no access to the same instance at the same time, regression is after upgrading to 2.5.2.Thank you
NoSuchMethodException (invokeCleaner) on Android.We're using HSQL on embedded Android tablets running Android 4.2 (API level 17) and Android 8.0 (API level 26). After upgrading to 2.6.x I noticed the following error in our logs when we perform a CHECKPOINT DEFRAG command:This error occurs because the Java version detection in JavaSystem.java doesn't work correctly on Android platforms:returns "0.9" on our tablets and some random phones I tried it on. This causes the javaVersion variable to default to 11.To fix this, I slightly modified the existing code in the "unmap" method. When the javaVersion is > 8, then the "sun.misc.Unsafe" code branch is tried first, but it falls back to the existing code branch should a reflection error occur:I'm perfectly happy with maintaining my own branch if this is too obscure, but I figured you might be interested in this.Cheers!
DDL blocking on transaction in other connection with mvcc transaction model.When a transaction is running on one connection, and some data is selected in that transaction,then DDL in another connection will hang, but only with the MVCC transaction mode.From the docs it seems to me there should be no blocking in this case.See attached sample java program, run agains the latest 2.6.1 build
Unique Key constraint cannot be dropped.
getObject return value influenced by getting previous column.When getting a primitive type column that was NULL, the wasNullValue of the JDBCResultSet is set to true, which is correct. However, wasNullValue then takes effect for future calls to getObject(columnNumber, type) before actually checking the data in the column in question. This gives the surprise result that a NOT NULL column could return a null value. This effectively breaks the invariant on the column.This is confirmed in 2.6.0 and 2.5.2, and does not affect 2.5.1. I have not tested trunk as we use maven dependencies for hsqldb.This bug appears to be related to #1631 "null value causes NPE in JDBCResultSet.getObject", and I suspect that the fix for that issue will also resolve this bug. However in my view this is top priority; it's not possible to rely on returned data in any situation where getObject is used after any other nullable column, with an NPE being the more preferable outcome, but in many cases the symptoms may be far more insidious with nullable columns ignoring actual values. Not all users may realise they are experiencing this bug, as a result. Therfore 2.5.2+ has a very high priority bug and a fix should be pushed out to 2.5.x and 2.6.x to maven central to minimise the impact on users, IMHO.
Condition does not work for CTE WITH RECURSIVE .. WHERE ... IN (SELECT * FROM unnest(ARRAY[UUID('...')])...Hi guys!I have built the graph query with a loop prevent condition.The problem is 'in array' condition doesn't work during CTE WITH RECURSIVE.But works fine outside CTE or on stand-alone tests;Also query works fine on PostgreSQL with correct output.Arrays contains uuid type values.The problem is located on that line:I hope it will help to perpoduce and fix the problem
Changing table from CACHED to MEMORY does not work.If using a file based database it seems it is not possible to change a table from cached to memory.Creating the table as memory and then changing it to cached works fine.A "General error" exception is thrown with SQLState = S1000 and vendorCode = -458.The problem exists both in 2.6.0 and 2.6.1 but not in earlier versions.The problem does not occur is using memory database.The problem is reproduced in a simple Spring Boot project using a junit test here: https://github.com/nytro77/hsqldb-cached-to-memory-bug
Issues with timestamps in JPA named queries.Hi all,We're seeing strange issues when executing queries via JPA using HSQLDB 2.5.2.These queries perform null checks on incoming placeholder values. This causes data type conversion issues when the incoming placeholder is a SQL TIMESTAMP data type.These queries worked when using HSQLDB 2.5.1.Broken query example:Calling code:This query results in an HsqlException: "incompatible data type in conversion"This query worked as expected using HSQLDB 2.5.1, but this query fails under 2.5.2, 2.6.0, and 2.6.1.The query works when removing the :date IS NULL condition from the WHERE-clause.I've attached an example Spring Boot project which demonstrates this issue.This can be run using mvnw spring-boot:run using JDK 11.Full stack trace of the error when running the query:
java.sql.SQLSyntaxErrorException: user lacks privilege or object not found.
HSQLDB fails to compile query with complex conditions.The following schema:along with the following query:fails with this exception:Interestingly, if the last where condition is omitted, the query works. It also works if the "is not distinct from" predicate is replaced with a "=" predicate. I also tried to use "decode" or an emulation that involves an intersect exists subquery, but all approaches to execute such a query failed so far.The stack trace is from executing this with 2.3.6 as newer versions report just a "general error" without any context.
Push JDK8 compatible jar to Maven Central.It would be nice to have the Java 8 compatible jar pushed to Central. The current coordinate org.hsqldb:hsqldb will not run on Java 8. Specifically, the error follows:Error: A JNI error has occurred, please check your installation and try againException in thread "main" java.lang.UnsupportedClassVersionError: org/hsqldb/util/DatabaseManagerSwing has been compiled by a more recent version of the Java Runtime (class file version 55.0), this version of the Java Runtime only recognizes class file versions up to 52.0I'm currently leveraging a workaround using a file:// repo in my project. My coordinate for this solution is org.hsqldb:hsqldb-jdk8:2.6.1. Your free to borrow that. :)
CLOB value saved truncated when encryption is used.After upgrading to 2.16 we faced the issue that CLOB fields are saved corrupted (truncated) when flushed/persisted to the file.Environment:Steps to reproduce:Save value with large string (about 1 MiB) to the repositoryForce writing to disk (you better know how to do this, i waited 1 second, also stop application persists to disk)Read persisted value and compare saved String with the original oneActual Result:String is truncated to 512 KiBExpected Result:String is not changedNote:pls follow the PersistenceConfiguration, test the behavior in CorruptedDataSavedExample (Spring Boot Application) and provided test classes.Pls contact me in case of any question - happy to collaborate with you.
Can't use SHEMA other than PUBLIC in 2.61.With hsqldb 2.61:If I create a schema, a simple user can't see table and view.If I create user with ADMIN option: user can see table and view but can't use the set default schema Alternative: user see all table and view.If I use 2.51, all work fine....
NoSuchMethodError when using org.hsqldb.jdbc.JDBCClobClient.getAsciiStream() from alternative jar (Java 8)Due to incompatible changes in java.nio.ByteBuffer between Java 8 and 11 (methods clear() and flip() of class java.nio.ByteBuffer) calling org.hsqldb.jdbc.JDBCClobClient.getAsciiStream() from alternative jar using JDK8 throws a NoSuchMethodError. The issue as well as resolutions are described atIn order to reproduce the issue compile and run the following piece of code using JDK8:
org.hsqldb.jdbc.JDBCClobClient.getAsciiStream() returns an input stream with trailing ASCII control character 0.It looks like there is an issue in org.hsqldb.jdbc.JDBCClobClient.getAsciiStream() since it returns an input stream with lots of trailing ASCII control characters 0. I.e., an input stream created by calling java.sql.ResultSet.getAsciiStream(int) has different content than an input stream created by callingThe issue can be reproduced by running the following Unit test:I have tested versions 2.5.2 as well as 2.6.1.
Sporadic lock timeout.We see sporadic errors with HSQLDB (2.3.6+) that have to do with lock timeouts. The error is unfortunately not easily reproducible, but it happens a few times a week in the Hibernate testsuite. You can download the report here which contains more information about the error in documentation/target/reports/tests/test/index.html:The test failing here is org.hibernate.userguide.sql.SQLTest#test_sql_hibernate_scalar_named_query_example, but sometimes it's a different test that fails. Here is another failure in a different test:The relevant portion of the stacktrace is this:No idea why it runs into a timeout only from time to time. Other databases work fine.
Column altered with set default  nextval() causes org.hsqldb.HsqlException: General error.versions:description:create liquibase script kind of:When test is finishing, liquibase cannot execute remove script