

https://github.com/redisson/redisson
https://github.com/redisson/redisson/issues/1
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Implement with binary insertion algorithm
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Just an idea, would this be possible? Still new to Redis / Redisson.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
It would be great to see TIME supported.
See also #19 in lettuce.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/5
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi there!
As I understand, Future returned by RedisAsyncConnection moves API user back to the blocking world. Java futures are NOT non-blocking by nature, they have blocking get(). Thus API user needs to spawn new threads and say hello to threading overhead again. Then why Netty is used?
I propose to return promises (Java's 8 CompletableFuture, Guava's ListenableFuture or jdeferred's promises).
Thanks,
Denis
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/6
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I think this is a critical need as soon as you are using async API, could it be possible ti have this contribution reviewed ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/7
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/8
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi
I could not find a way to set expiry for the contents of the cache from within Java. Is this true, or did I miss something?
Thank you
Jozsef
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/9
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I just imported redisson 1.0.3 via maven, set up a redis-server on localhost on default port and wanted to try the redisson redis client. My test code looks as following:
Redisson redis = Redisson.create();
Map m = redis.getMap("someMap");

But I'm getting an Error:
java.lang.NoSuchFieldError: WRITE_BIGDECIMAL_AS_PLAIN
    at org.redisson.codec.JsonJacksonCodec.createObjectMapper(JsonJacksonCodec.java:90)
    at org.redisson.codec.JsonJacksonCodec.<init>(JsonJacksonCodec.java:43)
    at org.redisson.Config.<init>(Config.java:44)
    at org.redisson.Redisson.create(Redisson.java:85)
    at ...

Am I doing something wrong or is this a dependency problem?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/10
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@mp911de thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/11
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
in RedisClient.java
try {
        final ConnectionWatchdog watchdog = new ConnectionWatchdog(bootstrap, channels, timer);

        ChannelFuture connect = null;
        // TODO use better concurrent workaround
        synchronized (bootstrap) {
            connect = bootstrap.handler(new ChannelInitializer<Channel>() {
                @Override
                protected void initChannel(Channel ch) throws Exception {
                    ch.pipeline().addLast(watchdog, handler, connection);
                }
            }).connect();
        }
        connect.sync();

        watchdog.setReconnect(true);

        return connection;
    } catch (Throwable e) {
        throw new RedisException("Unable to connect", e);
    }

this "synchronized " protect what?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/12
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have test code for the load balance, but only the first instance got the load:
public static void main(String[] args) {
Config config = new Config();
//config.setConnectionPoolSize(100); // default 100
// Redisson will use load balance connections between listed servers
String[] redisInstances = new String[]{"192.168.9.101:6379", "192.168.9.102:6379"};
config.addAddress(redisInstances);
    Redisson redisson = Redisson.create(config);
    Queue<Integer> q = redisson.getQueue("QUEUE");

    for (int i = 0; i < 1_000_000; i++) {
        q.add(i);
        if (i % 10000 == 0) {
            System.out.println("put: " + i);
        }
    }

    System.out.println("DONE.");
    redisson.shutdown();
}

Do I miss any thing?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/13
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
It would be nice if the Redisson class exposed its connection manager.  The use case is to access low level redis commands using the same pool of connections as the high-level redisson abstractions.  Currently its protected and private which means I have to resort to ugly hacks to get to it.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/14
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The eval method does not seem to work for me.  I traced the cause to this line in theRedisAsyncConnection:eval() method:
args.addValue(script).add(keys.length).addKeys(keys).addValues(values)
It should instead be:
args.add(script).add(keys.length).addKeys(keys).addValues(values)
In its current form, the script is escaped with double quotes and cannot be interpreted by redis.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/15
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
See GIST: https://gist.github.com/mathieucarbou/21051be4a2abd7cc1006
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/16
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I do not have Jackson and do not want to use it. Sadly, the Config class has a hard pointer on it:
private RedissonCodec codec = new JsonJacksonCodec();
Thus when creating a new Config instance I have the exception:
Caused by: java.lang.NoSuchFieldError: WRITE_BIGDECIMAL_AS_PLAIN
    at org.redisson.codec.JsonJacksonCodec.createObjectMapper(JsonJacksonCodec.java:90)
    at org.redisson.codec.JsonJacksonCodec.<init>(JsonJacksonCodec.java:43)
    at org.redisson.Config.<init>(Config.java:44)
    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
    at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
    at java.lang.reflect.Constructor.newInstance(Constructor.java:408)
    at org.codehaus.groovy.reflection.CachedConstructor.invoke(CachedConstructor.java:77)

Codecs should be made optional or at least the default should be the Serializer codec which only depends on the JDK, or a simple String <=> String codec.
For now I cannot use Redisson properly :-(
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/17
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Pub a message doesn't require a pubsub connection, however get a RTopic does. There are many cases just want to publish a message, get a RTopic from Redisson will automatically subscribe on the channel, which is unnecessary and there is no safe way to close topic after publish message since there may be some listeners are actually interested in the topic.
BTW, RedisConnection has a method  publish(K channel, V message)
Unfortunelty the underlying connection manager is not exposed, see issue #13
Provide access to the underlying connection manager
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/18
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
It would be really nice if you can add support for PFADD | PFCOUNT | PFMERGE commands in Redisson.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/19
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I want to use this inside Android, is it supported?
Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/20
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
why do you have imported lettuce code into your project instead of referencing it via artifact?
The approach your library works is quite cool providing collections. It's just somehow annoying having no access to the underlying RedisClient. Redisson.create(RedisClient client) or even redisson.getList(RedisClient client, String name) etc. would be a way opener approach. The current way, it's Redisson who manages all the Redis stuff for you. I see Redisson as a sort of valueable add-on.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/21
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi Nikita, when I ran some load test, ConnectionWatchdog did not restore PubsubConnection correctly (my env is redis 2.8.3, java 1.7.0_45,Netty 4.0.19 final, OSX 10.9.2). After some digging, I found a couple of problems,

When ChannelInitilizor ChannelInitializer.initChannel is called,           pipeLine.get(CommandHandler.class) and pipeLine.get(RedisAsyncConnection.class) return null, I guess the old ChannelPipeline had been destroyed.
The connection retry and backoff doesn’t seem right, the connection attempt seems only fired when the channel is inactive, if re-connect did not work, no further attempt will be fired.
RedissonTopic.promise.get().setSuccess(true) will throw IllegalStateException: complete already when PubsubConnection is re established.
4)Though this is not a bug, it seems unnecessary to use a dedicated HashedTimeWheel to schedule reconnection task.

I will push a patch later.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/22
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Sorry Nikita, I didn't realise git pull will create an issue automatically, please close one of 21/22. Thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/23
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
When we create a Redisson object, I would also need to execute some Redis commands.
What is the best way ? Do I need to create another ConnectionManager completely separate from the one in the Redisson class, or it would be better to access the one created on the Redisson object, so that we can re-use it ?
Thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/24
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Does reddison support the ability to add both a master and slave addresses and only write to the master?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/25
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/26
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In RBucket we have:
    @Override
    public V get() {
        RedisConnection<String, V> conn = connectionManager.connectionReadOp();
        try {
            return conn.get(getName());
        } finally {
            connectionManager.release(conn);
        }
    }


get connection
do something
return back to pool

Before using this, I was simply getting a RedisConnection from the connection manager like this:
        Field field = Redisson.class.getDeclaredField("connectionManager");
        field.setAccessible(true);
        return (ConnectionManager) field.get(redisson);

The RedisConnection class javadoc states that the connection is thread-safe. So I was keeping a singleton reference over one connection to issue some simple commands like get, set, del, ... from several threads.
Questions:

Is a RedisConnection class is intended to be used this way (multiple threads doing get/set/del ops) ?
If yes, would it be possible to expose this behavior so that users could get from Redisson a connection (with auto-reconnect) ? This connection could be kept as a singleton ref during the entire lifetime of the server and not be returned back to the pool, because this connection will be used often (i.e. session management). This will avoid the burden of the get from pool / return to pool code.

Thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/27
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redisson clusters may return a 'MOVED' if a key is on another shard, does redisson handle that?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/28
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
After running for a week or two, the scores collapsed to zeros or nead zero (10^-300) and we encountered an infinite loop in redisson when adding (it couldnt settle on a score). So we will manage the score ourselves.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/29
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I just added requirepass and masterauth to my configuration for 3 slaves and a master.  Using 1.5 I am able to write just fine, but when I tried Map::get I get a RedisException: "NOAUTH Authentication required."
I've tried just using a single connection to the master, a 'useMasterSlaveConnection' with only 'setMasterAddress', and a 'useMasterSlaveConnection' with all hosts configured.
When I connect with a tool like Redis Desktop Manager I am able to view the updated values just fine.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/30
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/31
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/32
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Same client code worked with 1.4 but not 1.5
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/33
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
2014-06-09T22:04:34.459669+00:00 app[web.1]: WARN DefaultChannelPipeline [nioEventLoopGroup-2-1] An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
2014-06-09T22:04:34.459678+00:00 app[web.1]: java.lang.NullPointerException: null
2014-06-09T22:04:34.459681+00:00 app[web.1]:    at com.lambdaworks.redis.pubsub.RedisPubSubConnection.channelRead(RedisPubSubConnection.java:119)
2014-06-09T22:04:34.459684+00:00 app[web.1]:    at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:341)
2014-06-09T22:04:34.459686+00:00 app[web.1]:    at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:327)
2014-06-09T22:04:34.459688+00:00 app[web.1]:    at com.lambdaworks.redis.pubsub.PubSubCommandHandler.decode(PubSubCommandHandler.java:43)
2014-06-09T22:04:34.459691+00:00 app[web.1]:    at com.lambdaworks.redis.protocol.CommandHandler.channelRead(CommandHandler.java:51)
2014-06-09T22:04:34.459692+00:00 app[web.1]:    at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:341)
2014-06-09T22:04:34.459694+00:00 app[web.1]:    at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:327)
2014-06-09T22:04:34.459695+00:00 app[web.1]:    at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
2014-06-09T22:04:34.459697+00:00 app[web.1]:    at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:341)
2014-06-09T22:04:34.459699+00:00 app[web.1]:    at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:327)
2014-06-09T22:04:34.459700+00:00 app[web.1]:    at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:785)
2014-06-09T22:04:34.459702+00:00 app[web.1]:    at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:126)
2014-06-09T22:04:34.459703+00:00 app[web.1]:    at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:507)
2014-06-09T22:04:34.459734+00:00 app[web.1]:    at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:464)
2014-06-09T22:04:34.459736+00:00 app[web.1]:    at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:378)
2014-06-09T22:04:34.459737+00:00 app[web.1]:    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:350)
2014-06-09T22:04:34.459739+00:00 app[web.1]:    at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
2014-06-09T22:04:34.459740+00:00 app[web.1]:    at java.lang.Thread.run(Thread.java:724)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/34
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redis monitor shows the setex followed by the get
1402351706.438560 [0 107.21.134.1:43779] "SETEX" "\x03\x01api:sessions:dE9K23ZT4de6MHMn2V-mg\xf7" "2591977" "\xae\x02\x01o\x01\x00\xa4\x84\xe7\xaa\xd0Q\x01dE9K23ZT4de6MHMn2V-mg\xf7\xc6\x84\xe7\xaa\xd0Q\x01207.253.217.242,10.226.123.45, 54.87.64.23\xb0\x80\xb4\xbc\x02\x05\xaf\x02\x01\x01okoMskkfJxo9JcOzF7Bpi\xf7"
1402351707.163372 [0 107.21.134.1:43779] "GET" "\x03\x01api:sessions:dE9K23ZT4de6MHMn2V-mg\xf7"

the code:
        RBucket<StoredSession> bucket = redisson.<StoredSession>getBucket(PREFIX + id);
        try {
            return bucket.get();
        } catch (RuntimeException e) {
            LOGGER.log(Level.WARNING, "Removing malformed session " + id + ": " + e.getMessage(), e);
            bucket.delete();
            return null;
        }

code returns null.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/35
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Note: I don't really know if there is a better place to ask for these sorts of questions... ;-)
Besides all the cool features added to Redisson to use locks, queues, maps, etc... How does Redisson performs compared to Jedis in terms of:

memory usage
speed
number of concurrent connections supported
use in multi-threading app requiring in both case using a pool
thread-safety
etc...

For having used both, I strongly prefer the api of Redisson (using publish subscribe in a reliable way with Jedis is a pain, and also there is no codec). But I am wondering, since their implementation only rely on simple sockets and a pool, how it compares to Redisson, which is based on Netty.
Also concerning thread-safety, having already aked a question about it, and in both libraries a connection pool is used for each operation and it is better to do so. So does thread-safety on a connection level really used ?
Thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/36
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/37
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/38
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I think it's better to extend api if it possible, which commands do you need?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/39
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I'm trying to use Lock and Unlock on Jersey Resource.

User makes a POST request
System LOCK "A"
System does some stuff
System UNLOCK "A"
User makes another POST request
System LOCK "A"
System does some stuff
System UNLOCK "A"

The system crashes at point 6 (view attachment).
If i try to make some LOCK-UNLOCK in a while loop it works, but when i make these LOCK-UNLOCK from different Threads it does not works.
WARN  [2014-07-10 10:36:15,734] io.netty.channel.DefaultChannelPipeline: An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
! java.lang.IllegalStateException: complete already: DefaultPromise@3c519764(incomplete)
! at io.netty.util.concurrent.DefaultPromise.setSuccess(DefaultPromise.java:406) ~[netty-common-4.0.19.Final.jar:4.0.19.Final]
! at org.redisson.RedissonLock$1.subscribed(RedissonLock.java:177) ~[redisson-1.1.3.jar:na]
! at com.lambdaworks.redis.pubsub.RedisPubSubConnection.channelRead(RedisPubSubConnection.java:132) ~[redisson-1.1.3.jar:na]
! at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:341) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:327) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at com.lambdaworks.redis.pubsub.PubSubCommandHandler.decode(PubSubCommandHandler.java:46) [redisson-1.1.3.jar:na]
! at com.lambdaworks.redis.protocol.CommandHandler.channelRead(CommandHandler.java:52) [redisson-1.1.3.jar:na]
! at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:341) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:327) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:341) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:327) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:785) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:126) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:507) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:464) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:378) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:350) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116) [netty-common-4.0.19.Final.jar:4.0.19.Final]
! at java.lang.Thread.run(Thread.java:722) [na:1.7.0_10-ea]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/40
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Any plan to add TTL to a Lock operation? Don't confuse with tryLock with TIME.
I refer to a situation where a thread is dead and leave a resource locked (deadlock).
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/41
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
1.Sentinel not support auth password.（I have solve this problem）
2.When redis sentinel occur failover，redisson can not failover to new master automatic。
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/42
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Operates with async methods only. Code example:
RBatch batch = redisson.createBatch();

RMap<Integer, Integer> map = redisson.getMap("map");
map.fastPutAsync(1, 2);
map.putAsync(2, 3);
map.fastPutAsync(3, 4);

List<Future<?>> futures = batch.execute();
// or
Future<List<Future<?>>> futures = batch.executeAsync();
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/43
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/44
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/45
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/46
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/47
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
public interface IRedisson {
    <V> RBucket<V> getBucket(String name);
    <V> RHyperLogLog<V> getHyperLogLog(String name);
    <V> RList<V> getList(String name);
    <K, V> RMap<K, V> getMap(String name);
    .
    .
    .
}
public class Redisson implements IRedisson {

    private final ConnectionManager connectionManager;
    private final Config config;

    private final UUID id = UUID.randomUUID();
    .
    .
    .
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/48
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@mrniko What do you think about this suggestion?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/49
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Using Distributed Map, put obj is ok, when get some obj by key, an exception will occur:
Exception in thread "main" com.lambdaworks.redis.RedisException: Command timed out
at com.lambdaworks.redis.RedisAsyncConnection.await(RedisAsyncConnection.java:1179)
at com.lambdaworks.redis.RedisConnection.await(RedisConnection.java:843)
at com.lambdaworks.redis.RedisConnection.hget(RedisConnection.java:283)
at org.redisson.RedissonMap.get(RedissonMap.java:89)
at dispatcher.RedisRef.main(RedisRef.java:573)
the exception will not occur when get naive java obj (String, int, ...)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/50
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/51
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/52
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/53
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Does redisson support local cache?
For some usage scenario, local read is very heavy, local write is not much, and the delay of data synchronization can be tolerated in seconds. Some configurable cache mechanism could be helpful.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/54
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Use hmget
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/55
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/56
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/57
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/58
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
ability to register event listeners for sentinel server events
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/59
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I don't see any way to configure a timeout or select a database. Am I missing something?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/60
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RedissonList.subList() doesn't conform to the specifications of java.util.List, which states that subList() returns a view backed by the current list.
On a related note, it would be nice to also have access to some of the buffered collections in addition to the redisson wrapper collections. If you're expecting to read all or most of a list, it would be wasteful to have to call RedissonList.get() for each element, resulting in another redis query each time. (Currently you can get a buffered list by calling subList(), but that's a workaround unique to the list collection, and it shouldn't really work that way - as mentioned above.)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/61
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I ran into an issue in which I found if I remove a listener from an RTopic, it will unsubscribe the entire channel, which will kill the connection for all listeners and RTopic subscribed to the same channel. Following is the code in question.
RedissonTopic.class
@OverRide
public void removeListener(int listenerId) {
PubSubConnectionEntry entry = connectionManager.getEntry(getName());
if (entry == null) {
return;
}
synchronized (entry) {
if (entry.isActive()) {
entry.removeListener(getName(), listenerId);
connectionManager.unsubscribe(getName());
return;
}
}
    // entry is inactive trying add again
    removeListener(listenerId);
}

I am not quite sure whether I am using Redisson RTopic in the right way. Would you please help me to understand what’s the reason to unsubscribe the channel when removing one listener? And if I need to have multiple listeners subscribed on the same channel and the list of listeners will change dynamically (since it’s used on the application server to propagate changes to clients), what’s the right way to use RTopic?
Your help will be greatly appreciated.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/62
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hey folks, I'm seeing this error on redisson 1.1.5 and it seems completely sporadic
WARN  [2014-08-04 04:10:21,672] io.netty.channel.DefaultChannelPipeline: An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
! java.lang.NullPointerException: null
! at com.lambdaworks.redis.protocol.CommandOutput.decodeAscii(CommandOutput.java:110) ~[redisson-1.1.5.jar:na]
! at com.lambdaworks.redis.output.StatusOutput.set(StatusOutput.java:26) ~[redisson-1.1.5.jar:na]
! at com.lambdaworks.redis.protocol.RedisStateMachine.decode(RedisStateMachine.java:89) ~[redisson-1.1.5.jar:na]
! at com.lambdaworks.redis.protocol.CommandHandler.decode(CommandHandler.java:71) ~[redisson-1.1.5.jar:na]
! at com.lambdaworks.redis.protocol.CommandHandler.channelRead(CommandHandler.java:52) ~[redisson-1.1.5.jar:na]
! at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:341) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:327) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:341) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:327) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:785) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:126) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:507) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:464) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:378) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:350) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
! at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116) [netty-common-4.0.19.Final.jar:4.0.19.Final]
! at java.lang.Thread.run(Thread.java:744) [na:1.8.0]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/63
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/64
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I didn't catch your code example above. What is FastThreadLocal ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/65
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have created a cluster with 3 master and 3 slave.
port 7000 seems to be myself,master.
If 7000 goes down I get a connection refused exception with Redisson. Ideally it should shift to its slave.
I am copying the exception here
com.lambdaworks.redis.RedisConnectionException: Unable to connect /127.0.0.1:7000
at com.lambdaworks.redis.RedisClient.connect(RedisClient.java:183)
at com.lambdaworks.redis.RedisClient.connectAsync(RedisClient.java:143)
at com.lambdaworks.redis.RedisClient.connectAsync(RedisClient.java:104)
at org.redisson.connection.ClusterConnectionManager.(ClusterConnectionManager.java:54)
at org.redisson.Redisson.(Redisson.java:56)
at org.redisson.Redisson.create(Redisson.java:82)
Is it a known issue?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/66
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is there a way to distinguish between empty and non-existent collections? (Or some way to invoke the EXISTS command?)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/67
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
How is it ever safe to rely on RedissonList.size() when each invocation can technically return a different value? This would mean that calling subList(0, size()), or even two consecutive calls to hasNext() on the iterator (which is normally what happens) can potentially cause an exception.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/68
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
fixed! thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/69
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi guys!
When I get some error, eg: redis servers down, in getAsync and setAsync the connection is not released, once the release is done in a Promise listener, that never executes, can you check this please?
Regards,
Marcio
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/70
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I was working with redisson adding data to the data store.  I was having issues, so I went to the command line to check what was in the data store and couldn't find my structures (although the program seemed to find them OK).  So I listed the keys and got this:
127.0.0.1:6379> keys *

""resource""
""processedMap""
""agentCounter""
""processCounter""
""routedMap""

then from the cli, I entered "set foo bar" and listed the keys again and got this:
127.0.0.1:6379> keys *

""resource""
""processedMap""
"foo"
""agentCounter""
""processCounter""
""routedMap""

it seems that redisson is surrounding the key names with quotes before storing them.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/71
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Use Case:
1)Extending the Redisson data types as part of a data abstraction layer.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/72
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Invocation of init method failed; nested exception is java.lang.StackOverflowError
WARN  org.redisson.connection.RoundRobinLoadBalancer Can't connect to /192.168.1.203:6379, trying next connection!
2014-08-26 14:35:21,194 WARN  org.redisson.connection.RoundRobinLoadBalancer Slave subscribe-connection pool gets exhausted! Trying to acquire connection again...
2014-08-26 14:36:21,197 WARN  org.redisson.connection.RoundRobinLoadBalancer Can't connect to /192.168.1.203:6379, trying next connection!
2014-08-26 14:36:21,197 WARN  org.redisson.connection.RoundRobinLoadBalancer Slave subscribe-connection pool gets exhausted! Trying to acquire connection again...
2014-08-26 14:37:21,200 WARN  org.redisson.connection.RoundRobinLoadBalancer Can't connect to /192.168.1.203:6379, trying next connection!
2014-08-26 14:37:21,200 WARN  org.redisson.connection.RoundRobinLoadBalancer Slave subscribe-connection pool gets exhausted! Trying to acquire connection again...
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/73
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hey, I was wondering if there is any way to execute a LUA script in redisson. I can do it through the connection manager, using something like this:
ConnectionManager cm;

try{
    Field field = Redisson.class.getDeclaredField("connectionManager");
    field.setAccessible(true);
    cm = (ConnectionManager) field.get(redisson);
}
catch(Exception e){}

cm.connectionReadOp(0).eval(script, type, keys);
But obviously that's not the cleanest solution. Would it be possible to add a public evalScript() method, or something of the sort to the Redisson class? Thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/74
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/75
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/76
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The RedisPubSubConnection class already had a psubscribe and punsubscribe methods for dispatching commands to Redis, but they are not hooked up to anything
The RTopic interface should get a new addPListener and removePListener and all the underlying changes necessary to propagate down to RedisPubSubConnection
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/77
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/78
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
i.n.channel.DefaultChannelPipeline [151] - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
java.lang.NullPointerException: null
at com.lambdaworks.redis.protocol.CommandOutput.decodeAscii(CommandOutput.java:110) ~[redisson-1.1.5.jar:na]
at com.lambdaworks.redis.output.StatusOutput.set(StatusOutput.java:26) ~[redisson-1.1.5.jar:na]
at com.lambdaworks.redis.protocol.RedisStateMachine.decode(RedisStateMachine.java:89) ~[redisson-1.1.5.jar:na]
at com.lambdaworks.redis.protocol.CommandHandler.decode(CommandHandler.java:71) ~[redisson-1.1.5.jar:na]
at com.lambdaworks.redis.protocol.CommandHandler.channelRead(CommandHandler.java:52) ~[redisson-1.1.5.jar:na]
at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:341) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:327) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:341) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:327) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:785) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:126) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:507) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:464) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:378) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:350) [netty-transport-4.0.19.Final.jar:4.0.19.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116) [netty-common-4.0.19.Final.jar:4.0.19.Final]
at java.lang.Thread.run(Thread.java:744) [na:1.7.0_51]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/79
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Since RedissonCodec supports any type of serialized key, RedissonObject.name should be of type Object so that we can invoke Redisson.getList(someSerializableObject) etc.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/80
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I'm getting the following exception when deserializing some array types with JsonJacksonCodec:
com.fasterxml.jackson.databind.JsonMappingException: Unexpected token (VALUE_NUMBER_INT), expected VALUE_STRING: need JSON String that contains type id (for subtype of java.lang.Object)

To reproduce:
JsonJacksonCodec codec = new JsonJacksonCodec();
codec.decodeValue(ByteBuffer.wrap(codec.encodeValue(new int[] {1,2,3})));
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/81
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/82
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/83
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/84
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/85
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/86
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/87
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/88
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/89
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/90
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/91
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/92
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/93
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/94
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/95
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/96
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/97
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/98
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/99
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/100
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/101
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/102
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/103
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/104
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/105
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/106
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/107
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/108
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/109
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/110
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/111
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/112
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/113
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/114
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/115
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/116
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/117
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/118
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/119
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/120
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/121
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/122
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/123
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/124
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/125
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/126
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/127
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/128
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/129
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/130
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/131
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/132
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/133
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/134
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/135
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/136
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/137
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/138
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/139
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/140
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/141
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/142
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/143
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/144
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/145
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/146
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/147
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/148
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/149
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/150
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/151
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/152
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/153
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/154
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/155
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/156
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/157
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/158
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/159
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/160
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/161
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/162
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/163
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/164
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/165
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/166
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/167
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/168
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/169
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/170
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/171
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/172
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/173
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/174
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/175
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/176
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/177
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/178
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/179
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/180
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/181
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/182
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/183
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/184
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/185
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/186
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/187
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/188
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/189
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/190
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/191
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/192
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/193
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/194
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/195
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/196
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/197
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/198
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/199
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/200
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/201
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/202
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/203
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/204
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/205
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/206
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/207
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/208
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/209
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/210
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/211
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/212
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/213
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/214
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/215
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/216
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/217
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Was wondering if its possible to include RSortedSet as part of batch commands
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/218
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Oh, big Thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/219
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks in advance :)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/220
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redisson redisson = getClient();
    RTopic<String> topic = redisson.getTopic("__keyevent@0__:expired");
    topic.addListener(new MessageListener<String>() {
        @Override
        public void onMessage(String channel, String msg) {
            // no output,but redis-cli command line tool can work
            System.out.println(channel);
            System.out.println(msg);
        }
    });

    RBucket<String> bucket = redisson.getBucket("message");
    bucket.set("someValue", 1, TimeUnit.SECONDS);
    Thread.sleep(1000 * 10);
    redisson.shutdown();
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/221
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/222
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Cluster mode Redisson client running out of files (sockets) in communicating with Redis.
This occurs even when the Redisson client is not receiving any requests.  It must be a problem with cluster mode connectivity.
To reproduce, I simply made two calls to my server using Redisson to set a simple value on Redis and then retrieve a simple value.  Then we did nothing at all.
It appears the Redisson in cluster mode is continually opening new socket connections but not closing existing ones.
After about an hour, we started seeing the following exceptions in our server logs.
Note:  I am may have seen a similar behavior in sentinel mode.  We recently upgraded Redisson to 2.1.0 from 1.1.5.  Could this be a more general problem?  We will upgrade to 2.1.1 and test again.
Thank you very much.
--Michael

test machine
Aug 14, 2015 8:49:18 AM org.apache.tomcat.util.net.JIoEndpoint$Acceptor run
SEVERE: Socket accept failed
java.net.SocketException: Too many open files
at java.net.PlainSocketImpl.socketAccept(Native Method)
at java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:398)
at java.net.ServerSocket.implAccept(ServerSocket.java:530)
at java.net.ServerSocket.accept(ServerSocket.java:498)
at org.apache.tomcat.util.net.DefaultServerSocketFactory.acceptSocket(DefaultServerSocketFactory.java:60)
at org.apache.tomcat.util.net.JIoEndpoint$Acceptor.run(JIoEndpoint.java:220)
at java.lang.Thread.run(Thread.java:745)
Aug 14, 2015 8:49:18 AM org.apache.tomcat.util.net.JIoEndpoint$Acceptor run
SEVERE: Socket accept failed
java.net.SocketException: Too many open files
at java.net.PlainSocketImpl.socketAccept(Native Method)
at java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:398)
at java.net.ServerSocket.implAccept(ServerSocket.java:530)
at java.net.ServerSocket.accept(ServerSocket.java:498)
at org.apache.tomcat.util.net.DefaultServerSocketFactory.acceptSocket(DefaultServerSocketFactory.java:60)
at org.apache.tomcat.util.net.JIoEndpoint$Acceptor.run(JIoEndpoint.java:220)
at java.lang.Thread.run(Thread.java:745)
Aug 14, 2015 8:49:18 AM org.apache.tomcat.util.net.JIoEndpoint$Acceptor run

Connections on the Redis server continually increase:
[root@qa-mq01.artfact.local ~ $ date; netstat -an | grep 192.168.10.135 | wc -l
Tue Aug 18 09:55:51 EDT 2015
2523
[root@qa-mq01.artfact.local ~ $ date; netstat -an | grep 192.168.10.135 | wc -l
Tue Aug 18 09:56:04 EDT 2015
2536
[root@qa-mq01.artfact.local ~ $ date; netstat -an | grep 192.168.10.135 | wc -l
Tue Aug 18 10:12:13 EDT 2015
3490

Another instance just now from the test machine
Aug 18, 2015 10:29:36 AM org.apache.tomcat.util.net.JIoEndpoint$Acceptor run
SEVERE: Socket accept failed
java.net.SocketException: Too many open files
at java.net.PlainSocketImpl.socketAccept(Native Method)
at java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:398)
at java.net.ServerSocket.implAccept(ServerSocket.java:530)
at java.net.ServerSocket.accept(ServerSocket.java:498)
at org.apache.tomcat.util.net.DefaultServerSocketFactory.acceptSocket(DefaultServerSocketFactory.java:60)
at org.apache.tomcat.util.net.JIoEndpoint$Acceptor.run(JIoEndpoint.java:220)
at java.lang.Thread.run(Thread.java:745)
Aug 18, 2015 10:29:36 AM org.apache.tomcat.util.net.JIoEndpoint$Acceptor run
SEVERE: Socket accept failed
java.net.SocketException: Too many open files
at java.net.PlainSocketImpl.socketAccept(Native Method)
at java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:398)
at java.net.ServerSocket.implAccept(ServerSocket.java:530)
at java.net.ServerSocket.accept(ServerSocket.java:498)
at org.apache.tomcat.util.net.DefaultServerSocketFactory.acceptSocket(DefaultServerSocketFactory.java:60)
at org.apache.tomcat.util.net.JIoEndpoint$Acceptor.run(JIoEndpoint.java:220)
at java.lang.Thread.run(Thread.java:745)
Aug 18, 2015 10:29:36 AM org.apache.tomcat.util.net.JIoEndpoint$Acceptor run
SEVERE: Socket accept failed
java.net.SocketException: Too many open files
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/223
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Rmap.addAndGetAsync (and any *Async methonds) - as i understand it shouldn't lock the calling thread, and return value (Future) as soon as possible.
But if for any reason connection is not established yet the calling thread will be blocked.
And if redis server is not available at all it will be blocked for very long period of time.
Maybe i'm wrong but it doesn't look like async nor lock-free.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/224
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is there a reason that RCountDownLatch doesn't implement RExpirable? I'd like to be able to create a CountDownLatch that goes to 0 or is deleted if countDown isn't called the desired number of times before a timeout.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/225
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
It seems that in the following test, RObject#delete() will always return false, even though it appears the delete call should be synchronous.
public class TryRedisson {

  private Redisson redisson;

  @Before
  public void setupRedisson() {
    Config config = new Config();
    config.useSingleServer().setAddress("127.0.0.1:6379");
    this.redisson = Redisson.create(config);
  }

  @Test
  public void testRedissonLockTimeout() throws InterruptedException {
    String id = UUID.randomUUID().toString();
    RCountDownLatch latch = redisson.getCountDownLatch(id + "-latch");
    boolean deleted = latch.delete();
    assertTrue(deleted);
  }
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/226
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/227
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Duplicate to #226
:)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/228
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
sorry，you can delete this pull request. I operate error.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/229
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
org.redisson.client.RedisException: ERR Error running script (call to f_2d027cdc209d32fe7dade9ba284110f88d497180): @user_script:1: WRONGTYPE Operation against a key holding the wrong kind of value . channel: [id: 0x24baaaa8, /192.168.99.1:64875 => /192.168.99.100:6379]
ENV: redis 3.0.3/2.8.3
REDISSON: 2.1.1/1.3.1
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/230
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Since the fact that keys/Sets/Hashes in redis does not guarantee the order of the elements within, iterators should stick to the same node when iteration was first started, to avoid duplicate and/or missing items.
For example, when you have a Set "A" in master node contains:

"1"
"2"
"3"
"4"
"5"
"6"
"7"
"8"
"9"
"10"
"11"
"12"
...

a slave node could have it in a completely different ordering:

"8"
"2"
"7"
"3"
"9"
"1"
"4"
"6"
"5"
"10"
"11"
"12"
...

Obviously, the running the command SSCAN "A" 0 on master, the result is going to be different to the one from the slave. Further cursor call SSCAN "A" n, could also be different.
The problem is, under the default setting, SentinelConnectionManager uses the RoundRobinBalancer which is utilised to read from both master and slave nodes, and when you have a for loop like this:
for (String i : redisson.<String>getSet("A")) {
    System.out.println(i);
}
The output could contain duplicate/missing item(s), and the results could be different each time you run it.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/231
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/232
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
;)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/233
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello,
Nice work on the redis client.
I noticed that executeAsync did not complete while running a batch of rediscommands against a cluster.
I noticed that in the line:
for (java.util.Map.Entry<Integer, Entry> e : commands.entrySet()) {
            execute(e.getValue(), e.getKey(), voidPromise, new AtomicInteger(commands.size()), 0);
}

voidPromise may never complete successfully because it is being re-initialized for every slot entry and its successful completion depends on the number of slots being decremented to zero after all the entries run as shown in the line below from execute(...)
 attemptPromise.addListener(new FutureListener<Void>() {
            @Override
            public void operationComplete(Future<Void> future) throws Exception {
                if (future.isCancelled()) {
                    return;
                }

                if (future.cause() instanceof RedisMovedException) {
                    RedisMovedException ex = (RedisMovedException)future.cause();
                    execute(entry, ex.getSlot(), mainPromise, slots, attempt);
                    return;
                }

                if (future.isSuccess()) {
                    if (slots.decrementAndGet() == 0) {
                        mainPromise.setSuccess(future.getNow());
                    }
                } else {
                    mainPromise.setFailure(future.cause());
                }
            }
        });

Note that mainPromise is voidPromise from above.
Perhaps the previous line in executeAsync should have been like
AtomicInteger slots = new AtomicInteger(commands.size());

for (java.util.Map.Entry<Integer, Entry> e : commands.entrySet()) {
            execute(e.getValue(), e.getKey(), voidPromise, slots, 0);
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/234
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
i read redisson code that imply only the max connectionpoolsize is provide. but all other collection framework also support min size (and the not longest not used time).
when the system is not high load, as if cut down the connection that not used offen?
I found that if connection is create,it not close!(when one down the watch dog create a new one asap)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/235
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RedisConnection.updateChannel update the new channel obj。but the channel attr NOT on it, so the second time new channel is down, the watchdog channelInactive invoke method attr(RedisConnection.CONNECTION).get() can NPE.
i thinkd it is a bug.
version 2.1.1
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/236
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
already done
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/237
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We have a production system using Redisson to handle notification. However, recently we constantly run into subscription connection exhausted issue. After investigation, I found Redisson doesn't release the subscription connection after the last listener is removed.
Eventually, this issue is caused by the following line. It seems ConcurrentLinedQueue doesn't fully implement equals method to compare 2 linked list. Therefore, an empty linked list will never equals to another empty linked list, which eventually leaks all subscription connections.
public void removeListener(String channelName, RedisPubSubListener listener) {

  channelListeners.remove(channelName, new ConcurrentLinkedQueue<RedisPubSubListener>());

}

This is a very urgent issue to us. Any help or workaround will be greatly appreciated.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/238
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Sounds right
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/239
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When using redisson, I'm occasionally getting errors like this: "LEAK: you are creating too many HashedWheelTimer instances".What are possible causes of this issue?
I'm also seeing (probably related) errors like this: "LEAK: HashedWheelTimer.release() was not called before it's garbage-collected." I assume this is related to my problem, but I don't know where to look in my code for this leak. Could this be a bug?
Thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/240
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I have a setup with a master, 3 slaves and 3 sentinel nodes. I do not have too much data and cluster setup is not required. I should be able to support high throughput(400K Ops/sec). Most of them are read operations. Is there any way to split read requests among master and slaves?
If there is no way to do this, can this feature be added?
Thanks
Naresh
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/241
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We're using Redisson 2.1.1 on our production web cluster for session persistence: https://github.com/chexagon/redis-session-manager
Our redis implemention is AWS's ElastiCache where we have 2 nodes in a replication group. Elasticache provides 3 endpoints for this scenario:

foobar.elasticache.com - always points to the primary (read/write) node of the cluster
foobar-001.elasticache.com - direct connection to node1
foobar-002.elasticache.com - direct connection to node2

Normally node1 is the read/write master and node2 is a read slave with foobar.elasticache.com pointing to node1. In a failover scenario (http://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/AutoFailover.html for more info) Elasticache promotes node2 and repoints foobar.elasticache.com to now point at node2.
Our Redisson configuration is to use a SingleServerConfig with the endpoint of foobar.elasticache.com
Last night we experienced our first ever failover (exciting!). Unfortunately, this brought our application to a standstill with errors of
org.redisson.client.RedisException: READONLY You can't write against a read only slave.. channel: [id: 0x????????, / 10.0.x.x:yyyyy => foobar.elasticache.com]
The 10.0.x.x address listed is that of node1 which was demoted to read slave when node2 was promoted to master.
My belief is that using SingleServerConfig here is incorrect and led to this issue (i.e., redisson remained connected to node1 and never reconnected to foobar.elasticache.com to now be connected to node2. Am I correct in this analysis?  If so, I can't really seem to figure out which config is the proper one to use. MasterSlaveServersConfig seems logical at first glance, but looking through the code it appears only Sentinel and Cluster configurations invoke the paths that switch the master node.
Any help would be greatly appreciated.  Thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/242
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
If I enable security on redis, re-connection functionality no longer works - wihout security redisson works as expected and re-connects.
Steps to reproduce: enable redis security, run code below and restart redis somewhere in the middle.
        Config config = new Config();
        config.useSingleServer().setAddress( "127.0.0.1:6379" ).setPassword( "foobared" );
        Redisson redisson = Redisson.create( config );
        redisson.flushdb();

        for ( int i = 0; i < 100; i++ ) {
            RAtomicLong rAtomicLong = redisson.getAtomicLong( "x" );
            System.out.println( rAtomicLong.addAndGet( 1 ) );
            Thread.sleep( 1 * 1000 );
        }

        redisson.shutdown();
Exception
Exception in thread "main" org.redisson.client.RedisException: NOAUTH Authentication required.. channel: [id: 0x1e26a078, /127.0.0.1:57780 => /127.0.0.1:6379]
    at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:168)
    at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:104)
    at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:370)
    at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:230)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
    at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
    at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
    at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)
    at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
    at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
    at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
    at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
    at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:110)
    at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)
    at java.lang.Thread.run(Thread.java:745)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/243
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
FYI I'm working on a ElasticacheReplicationGroupServersConfig that is similar to the ClusterConfig, except it uses INFO replication to determine node role instead of CLUSTER commands.  So there's no auto-discovery of nodes, but it will handle role changes in a more efficient manner than monitoring DNS (as this PR does).
work in progress: scubasau@3c5346f
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/244
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I suggest you to rename ElasticacheReplicationGroupServers to ElasticacheServers
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/245
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/246
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Now, the ability to specify a different codec per object feature is added
d484c19, this has paved the way to implement a new type of object codec that serialise each field of POJO object into a redis hash.
Thinking it as a persistent layer for persisting an object to redis like the EntityManager does. Using reflection/javasisst to proxy the accessors of the POJO to read/write fields straight from/to redis.
It would allow different programs to be able to share sets of live data without needing to serialise and deserialise the entire object.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/247
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
By default any Number class descendants is serialized as ["java.lang.Long",1843] for example.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/248
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/249
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/250
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redisson does not seem to be detecting Redis master change in failover scenario.  (We are using Redisson 2.1.3).
I have 2 questions regarding this.

After the 60-second timeout (described below) everything started working again, although not in the original configuration.  Can this timeout be changed (lowered) and done so safely?
Should Redisson should be able to detect and react to this last master change back to our original configuration?  We were assuming that it should.

Details are below.
I can provide the redis commands we used to reconfigure Redis if they will help.
Thank you very much.
--Michael

In testing redis failover we have discovered that moving a master instance frmo one instance to another causes all our servers to hang.  We have reproduced the issue several times with the following process.
We are running 3 Redis servers (redis-01, redis-02, and redis-03).  Each server is running both a redis master and a redis slave.  Each master is associated with a slave on one of the other redis servers.
Start multiple work sessions on our application servers running light load

On redis-01, get a list of the redis instances running on this server (ps -ef | grep redis)
kill -9 
[At this point everything appears great - the test continues to run.  The slave instance has taken over the responsibilities for the failed redis node.  run "redis-cli cluster nodes" for a list of all the nodes, the reassigned master and a list of the failed shards.]
restart redis on the "failed" server - "service redis_master start" "service redis_slave start"
[After 60 seconds, we see our first indication of trouble - we get a redis connection timeout exception on each of the application servers.  If you look at the "cluster node" output you should see the two instances back in the list, however at this point they are both slave nodes.  Another server will have two master instances on it.]
rebalance the redis nodes - on the server that you just restarted the services, run "redis-cli cluster failover" this tells redis to failover the remote master to this instance.  After this step you should be back to the original configuration with one master and one slave instance on each server, with no master/slave combination on the same server.

This is where our application servers seem to hang.  From yourkit we see several of these:
++++++++++
http-bio-7001-exec-1 [WAITING] [DAEMON]
java.lang.Object.wait() Object.java:503
io.netty.util.concurrent.DefaultPromise.awaitUninterruptibly() DefaultPromise.java:286
io.netty.util.concurrent.DefaultPromise.awaitUninterruptibly() DefaultPromise.java:32
org.redisson.CommandExecutorService.get(Future) CommandExecutorService.java:181
org.redisson.RedissonObject.get(Future) RedissonObject.java:48
org.redisson.RedissonBucket.set(Object, long, TimeUnit) RedissonBucket.java:58
com.artfact.am2.service.MemoryManager.setValue(String, Object, long, TimeUnit) MemoryManager.java:154
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/251
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi, Developers of mrniko/redisson,
I am writing to report two race issues on use of ConcurrentHashMap. The issues are reported by our tool in an automatic way. Although manually confirmed, they would be false positives, given we do not know the specification of the program. We would very appreciate if you could check below for details and confirm with us whether they are real problems. For more information, please refer to our website: http://sav.sutd.edu.sg/?page_id=2845
File:
mrniko/redisson/src/main/java/org/redisson/RedissonCountDownLatch.java
Location: Line (66, 120)
Description:
Line 120 is in the synchronized block on "ENTRIES". If the intention is to guarantee exclusive access for the !containsKey checking on "ENTRIES" and to ensure the atomicity of the checking and unsubscription (line 120,121), then the write operations on "ENTRIES" in line 66, 115, 117, 136 may break this. Relying on the ConcurrentHashMap to ensure exclusive access is dangerous since ConcurrentHashMap has no guarantee of exclusive access.
File:
mrniko/redisson/src/main/java/org/redisson/RedissonLock.java
Location: Line (75, 113)
Description:
Same as above.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/252
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
ENV: redis 3.0.4
REDISSON: 2.1.3
io.netty.handler.codec.DecoderException: java.lang.NullPointerException
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:425)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:230)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:110)
at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.runtThreadFactory.java:137)
at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NullPointerException: null
at org.redisson.client.handler.CommandDecoder.decodeMulti(CommandDecoder.java:202)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:189)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:104)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:370)
... 18 common frames omitted
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/253
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi.
I'm relatively new to java, so sorry if i say something stupid.
When i'm storming my server with 50 concurrent requests using AB, i'm getting NPE during some channel negotiating (as i guess). The following line (CommandDecoder:267):
    private MultiDecoder<Object> messageDecoder(CommandData<Object, Object> data, List<Object> parts) {
        if (data == null) {
            if (Arrays.asList("subscribe", "psubscribe", "punsubscribe", "unsubscribe").contains(parts.get(0))) {
                String channelName = (String) parts.get(1);
                return channels.get(channelName).getCommand().getReplayMultiDecoder(); // <<<<
            } else if (parts.get(0).equals("message")) {
results in null pointer exception:
2015-30-09 18:28:11.271 [nioEventLoopGroup-2-2] WARN  i.n.channel.DefaultChannelPipeline - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
io.netty.handler.codec.DecoderException: java.lang.NullPointerException
    at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:425) ~[backend-phone-service-0.1.0-shaded-cp.jar:na]
    at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:230) ~[backend-phone-service-0.1.0-shaded-cp.jar:na]
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308) [backend-phone-service-0.1.0-shaded-cp.jar:na]
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294) [backend-phone-service-0.1.0-shaded-cp.jar:na]
    at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) [backend-phone-service-0.1.0-shaded-cp.jar:na]
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308) [backend-phone-service-0.1.0-shaded-cp.jar:na]
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294) [backend-phone-service-0.1.0-shaded-cp.jar:na]
    at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) [backend-phone-service-0.1.0-shaded-cp.jar:na]
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308) [backend-phone-service-0.1.0-shaded-cp.jar:na]
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294) [backend-phone-service-0.1.0-shaded-cp.jar:na]
    at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846) [backend-phone-service-0.1.0-shaded-cp.jar:na]
    at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131) [backend-phone-service-0.1.0-shaded-cp.jar:na]
    at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511) [backend-phone-service-0.1.0-shaded-cp.jar:na]
    at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468) [backend-phone-service-0.1.0-shaded-cp.jar:na]
    at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382) [backend-phone-service-0.1.0-shaded-cp.jar:na]
    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354) [backend-phone-service-0.1.0-shaded-cp.jar:na]
    at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:110) [backend-phone-service-0.1.0-shaded-cp.jar:na]
    at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137) [backend-phone-service-0.1.0-shaded-cp.jar:na]
    at java.lang.Thread.run(Thread.java:745) [na:1.8.0_60]
Caused by: java.lang.NullPointerException: null
    at org.redisson.client.handler.CommandDecoder.messageDecoder(CommandDecoder.java:267) ~[backend-phone-service-0.1.0-shaded-cp.jar:na]
    at org.redisson.client.handler.CommandDecoder.decodeMulti(CommandDecoder.java:202) ~[backend-phone-service-0.1.0-shaded-cp.jar:na]
    at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:189) ~[backend-phone-service-0.1.0-shaded-cp.jar:na]
    at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:97) ~[backend-phone-service-0.1.0-shaded-cp.jar:na]
    at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:370) ~[backend-phone-service-0.1.0-shaded-cp.jar:na]
    ... 18 common frames omitted

I'm not 100% sure where does this problem originate from, but i can tell that those requests use Redisson for inter-process locks and fetching/updating two string sets.
I'm using Redisson 2.1.3 against dockerized Redis 3.0.2 (the standard docker library image)
upd: debugger told me that client has received null for hannels.get() for redisson__lock__channel__{lock:pn:phone-number:79219767095}, which, i guess, means trouble with lock.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/254
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I configure Redisson to use SerializationCodec instead of default JsonJacksonCodec. Then I run my code in environment with concurrent threads and use Lock object to sync thread. After that I get exception and unlock only after expiration in 30 sec. Previous major version of Redisson does't contain this issues. Similar problem I have when I use CountDown.
[nioEventLoopGroup-4-7] WARN io.netty.channel.DefaultChannelPipeline - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
io.netty.handler.codec.DecoderException: java.io.EOFException
    at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:425)
    at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:230)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
    at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
    at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
    at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)
    at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
    at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
    at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
    at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
    at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:110)
    at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)
    at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.EOFException
    at java.io.ObjectInputStream$PeekInputStream.readFully(ObjectInputStream.java:2328)
    at java.io.ObjectInputStream$BlockDataInputStream.readShort(ObjectInputStream.java:2797)
    at java.io.ObjectInputStream.readStreamHeader(ObjectInputStream.java:802)
    at java.io.ObjectInputStream.<init>(ObjectInputStream.java:299)
    at org.redisson.codec.SerializationCodec$1.decode(SerializationCodec.java:42)
    at org.redisson.client.protocol.pubsub.PubSubMessageDecoder.decode(PubSubMessageDecoder.java:38)
    at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:179)
    at org.redisson.client.handler.CommandDecoder.decodeMulti(CommandDecoder.java:199)
    at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:189)
    at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:97)
    at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:370)
    ... 18 more
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/255
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/256
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am getting an exception when trying to add an ArrayList to a redisson RMap  on a Linux Server. I cam using Redis 3.0.4.  Below is an example of the code I am using
            Config config = new Config();
    config.useSingleServer().setAddress("127.0.0.1:6379");

    redisson = Redisson.create(config);
            RMap<String, ArrayList<Integer>> cache = redisson.getMap("data-cache");

            String key = "ed322dve343523fsaare3212d";
    ArrayList<Integer> td = new ArrayList<Integer>();
    td.add(15);
    td.add(id);
    cache.put(key, td);

This code works perfectly fine when running on an OSX machine but the folllowing exception is thrown when it is run on a Linux Server.
Exception in thread "main" org.redisson.client.RedisException: ERR unknown command 'EVAL'. channel: [id: 0x4c10588b, /127.0.0.1:53328 => /127.0.0.1:6379] command: CommandData [promise=DefaultPromise@ebf19db(incomplete), command=RedisCommand [name=EVAL, subName=null], params=[local v = redis.call('hget', KEYS[1], ARGV[1]); redis.call('hset', KEYS[1], ARGV[1], ARGV[2]); return v, 1, data-cache, 4806729cbca5f70c0ed0d2617de333eba7bd46a1, [0, 2]], codec=org.redisson.codec.JsonJacksonCodec@25679a96]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/257
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you! ✨
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/258
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When implementing my own custom code, I've found that it seems Codec key and value decoders are opposite.
public class CustomCodec implements Codec {
...
    @Override
    public Decoder<Object> getMapKeyDecoder() {
        return getValueDecoder();
    }
    @Override
    public Encoder getMapKeyEncoder() {
        return keyEncoder;
    }

    @Override
    public Decoder<Object> getMapValueDecoder() {
        return keyDecoder;
    }
    @Override
    public Encoder getMapValueEncoder() {
        return getValueEncoder();
    }
}
This works.
public class CustomCodec implements Codec {
...
    @Override
    public Decoder<Object> getMapKeyDecoder() {
        return keyDecoder;
    }
    @Override
    public Encoder getMapKeyEncoder() {
        return keyEncoder;
    }

    @Override
    public Decoder<Object> getMapValueDecoder() {
        return getValueDecoder();
    }
    @Override
    public Encoder getMapValueEncoder() {
        return getValueEncoder();
    }
}
This does not work.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/259
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[WARNING 14.10.2015 12:14:58.968] io.netty.channel.DefaultChannelPipeline-An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
io.netty.handler.codec.DecoderException: java.lang.NullPointerException
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:425)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:230)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:110)
at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)
at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NullPointerException
at org.redisson.client.handler.CommandDecoder.messageDecoder(CommandDecoder.java:267)
at org.redisson.client.handler.CommandDecoder.decodeMulti(CommandDecoder.java:202)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:189)
at org.redisson.client.handler.CommandDecoder.decodeMulti(CommandDecoder.java:208)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:189)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:97)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:370)
... 18 more
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/260
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is there any library for mocking Redisson? I have a scenario where I do not want to have Redis server running for unit tests.
There is a library for Jedis. https://github.com/50onRed/mock-jedis.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/261
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Didn't see it before. Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/262
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I have noticed something running some load tests recently.
I have a 3 sentinels, 1 slave and 1 master set up.
Initially I was running load tests on this exact set up and would occasionally run into org.redisson.client.RedisConnectionException: Slave connection pool gets exhausted! which is fine since when the load is reduced the app goes back to normal.
Then I had to switch off one of the sentinels and forgot to restart it, so now I was running with 2 sentinels, 1 slave and 1 master.
I would first again run into org.redisson.client.RedisConnectionException: Slave connection pool gets exhausted! but would also run into
org.redisson.client.WriteRedisConnectionException: Can't send command: RedisCommand [name=GET, subName=null], params: [Ljava.lang.Object;@44d02cc5, channel: [id: 0x08bfe466, 0.0.0.0/0.0.0.0:55173 :> /127.0.0.1:6379] (6379 is master)
org.redisson.client.WriteRedisConnectionException: Can't send command: RedisCommand [name=GET, subName=null], params: [Ljava.lang.Object;@1283c11d, channel: [id: 0x05e26dda, 0.0.0.0/0.0.0.0:54360 :> /127.0.0.1:6380] (6380 is slave)
and
org.redisson.client.WriteRedisConnectionException: Can't send command: RedisCommand [name=GET, subName=null], params: [Ljava.lang.Object;@2f0f4c9c, channel: [id: 0xf38de559, 0.0.0.0/0.0.0.0:55367]
here is one of them with full stack:
org.redisson.client.WriteRedisConnectionException: Can't send command: RedisCommand [name=GET, subName=null], params: [Ljava.lang.Object;@2f0f4c9c, channel: [id: 0xf38de559, 0.0.0.0/0.0.0.0:55367]
    at org.redisson.CommandExecutorService$6.operationComplete(CommandExecutorService.java:447)
    at org.redisson.CommandExecutorService$6.operationComplete(CommandExecutorService.java:442)
    at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:680)
    at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:567)
    at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:424)
    at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:801)
    at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:699)
    at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1122)
    at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:633)
    at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:32)
    at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:908)
    at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:960)
    at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:893)
    at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:356)
    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:357)
    at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:110)
    at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)
    at java.lang.Thread.run(Thread.java:745)
Caused by: java.nio.channels.ClosedChannelException: null

After reducing the load, org.redisson.client.RedisConnectionException: Slave connection pool gets exhausted! disappear, but org.redisson.client.WriteRedisConnectionException: Can't send command... persist and appear on every couple of calls even for 0.5QPS.
I tried this several times and it always was like this, 3 sentinels - all good, 2 sentinels - WriteRedisConnectionException exceptions.
Note that in both cases I passed all 3 sentinel's addresses to addSentinelAddress(...) for useSentinelConnection()
Maybe a check on the new Redis(...) call to ping all the sentinels would be nice
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/263
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I can not find “mget/mset” api in redisson, whether redisson support those multi-command? and for redis cluster mode?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/264
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
hi, @mrniko
when i execute the "cluster nodes" command, and displays like "7189722a77350361478f826e549e13270499261c 127.0.0.1:6309 master - 0 1445484940172 5 connected 0-299 5761-10922", then the redisson will go wrong:
org.redisson.client.RedisEmptySlotException: No node for slot: 9842
at org.redisson.connection.MasterSlaveConnectionManager.connectionWriteOp(MasterSlaveConnectionManager.java:481)
at org.redisson.CommandExecutorService.async(CommandExecutorService.java:434)
at org.redisson.CommandExecutorService$5.run(CommandExecutorService.java:421)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:581)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:655)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:367)
at java.lang.Thread.run(Thread.java:745)
i review the parse() function in ClusterConnectionManager.java, and it only parses one pair start_slot and end_slot.
Is it right, or my understanding is wrong?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/265
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have RMap<String, String> and static map with default values which I need to save but RMap.putAll keeps throwing exception:
me.mc2.internal.redisson.client.RedisException: ERR wrong number of arguments for 'hmset' command. channel: [id: 0x64225355, /109.120.149.72:45005 => /109.120.149.72:6379] command: CommandData [promise=DefaultPromise@1cfa79f9(incomplete), command=RedisCommand [name=HMSET, subName=null], params=[player:d2c75e6d-f726-4433-ab71-259e04cca4de:settings, {LANGUAGE=ENGLISH}], codec=me.mc2.internal.redisson.client.codec.StringCodec@3803fe0]
    at me.mc2.internal.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:168)
    at me.mc2.internal.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:104)
    at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:370)
    at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:230)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
    at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
    at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
    at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)
    at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
    at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
    at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
    at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
    at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:112)
    at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)
    at java.lang.Thread.run(Unknown Source)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/266
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi @mrniko,
I want to know what Redisson can do with Redis Cluster:
-check Redis Cluster memory
-handle exception when Redis Cluster exceed memory
Thanks & regard
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/267
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/268
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/269
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/270
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/271
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/272
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/273
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Command with MOVED response could be redirected to Master or Slave node.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/274
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/275
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/276
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Little modification to the testHeavyLoad reveals the problem I encountered when having a single listener processing many messages sent at the same time (in latest version):
volatile long counter;

@Test
public void testHeavyLoad() throws InterruptedException {
    final CountDownLatch messageRecieved = new CountDownLatch(1000);

    Redisson redisson1 = BaseTest.createInstance();
    RTopic<Message> topic1 = redisson1.getTopic("topic");
    topic1.addListener(new MessageListener<Message>() {
        @Override
        public void onMessage(String channel, Message msg) {
            Assert.assertEquals(new Message("123"), msg);
            messageRecieved.countDown();
            counter++;
        }
    });

    Redisson redisson2 = BaseTest.createInstance();
    RTopic<Message> topic2 = redisson2.getTopic("topic");
    topic2.addListener(new MessageListener<Message>() {
        @Override
        public void onMessage(String channel, Message msg) {
            Assert.assertEquals(new Message("123"), msg);
            messageRecieved.countDown();
        }
    });

    for (int i = 0; i < 500; i++) {
        topic2.publish(new Message("123"));
    }

    messageRecieved.await();

    Thread.sleep(1000);

    assertEquals(500, counter);

    redisson1.shutdown();
    redisson2.shutdown();
}

Running the test will fail for me many (but not every) time saying the listener got like 9000 messages instead of the 500 sent.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/277
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I have a Redis setup with 3 nodes (master, slave, slave) and 3 sentinels (one per node). When I try to iterate over a set within Redis, I'm getting some odd results that are breaking the Redis SCAN guarantees - that is, I'm losing some entries.
I'm pretty sure this is because the iterator isn't sticking to a single slave during its lifetime, and rather that it's using the default RoundRobinLoadBalancer switching between slaves for the same scan (which otherwise works well).
Example
Let's say I have a big set with 100K entries:
    for (int i=0; i<100; i++) {
        RBatch b = redis.createBatch();
        RSetAsync<Object> set = b.getSet("bigset");
        for (int j=0; j<1000; j++) {
            set.addAsync(UUID.randomUUID());
        }
        b.execute();
    }
with all nodes up (two slaves), and when iterating over the collection, adding all my results to a java.util.Set such as below, then I'm getting some random size result sets:
    Set<String> keep = new HashSet<>();
    RSet<String> set = redis.getSet("bigset");
    keep.addAll(set);
    log.info(String.valueOf(keep.size()));
[SetIterationTest] 81194

However, if I turn off a slave, I get the correct result 👍 :
[SetIterationTest] 100000

Example 2 (+Workaround)
I get similar results doing the same through the RScript (In READ_ONLY mode):
    String sha1 = redis.getScript().scriptLoad("return redis.call('SSCAN', KEYS[1], KEYS[2], 'COUNT', KEYS[3])");
    Set<Object> set = new HashSet<>();
    String cursor = "0";
    do {
        List res = redis.getScript().evalSha(RScript.Mode.READ_ONLY, sha1, RScript.ReturnType.MAPVALUELIST, Arrays.<Object>asList("bigset", cursor, "1000"));
        cursor = (String) res.get(0);
        for (Object o: (List)res.get(1)) {
            set.add(o);
        }
    } while(!cursor.equals("0"));
    log.info(String.valueOf(set.size()));
[SetIterationTest] 81233

but switching to READ_WRITE mode, it works fine again 👍
...
    List res = redis.getScript().evalSha(RScript.Mode.READ_WRITE, sha1, RScript.ReturnType.MAPVALUELIST, Arrays.<Object>asList("bigset", cursor, "1000"));
...

[SetIterationTest] 100000

and I agree with the behavior of the RScript (as Redisson would never implicitly know when to stick to a single server). Incidentally, the latter use of RScript provides me with a workaround, but it'd be nice to use the inbuilt iterators for simplicity.
Hope that make sense - cheers!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/278
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/279
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
HELP ME PLEASE..Thanks in advanced：）
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/280
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I have code running against redisson 2.1.3 that was adding a value at an index and after the add is called the list can no longer read, throwing this exception:
org.redisson.client.RedisException: Unexpected exception while processing command
    at org.redisson.CommandExecutorService.get(CommandExecutorService.java:185)
    at org.redisson.RedissonObject.get(RedissonObject.java:48)
    at org.redisson.RedissonList.getValue(RedissonList.java:291)
    at org.redisson.RedissonList.get(RedissonList.java:287)
    at com.senet.cache.redis.redisson.RedissonCache.main(RedissonCache.java:845)
Caused by: com.fasterxml.jackson.core.JsonParseException: Unexpected character ('b' (code 98)): expected a valid value (number, String, array, object, 'true', 'false' or 'null')
    at [Source: io.netty.buffer.ByteBufInputStream@7b205dbd; line: 1, column: 2]
    at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1369)
    at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:532)
    at com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:453)
    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2278)
    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:779)
    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:665)
    at com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:2926)
    at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:2873)
    at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2080)
    at org.redisson.codec.JsonJacksonCodec$2.decode(JsonJacksonCodec.java:59)
    at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:179)
    at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:104)
    at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:370)
    at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:230)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
    at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
    at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
    at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)
    at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
    at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
    at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
    at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
    at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:110)
    at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)
    at java.lang.Thread.run(Thread.java:745)

I wrote a simple test to see what was going on.  The code from test1 executes without issue.  The code for test2 throws the exception on the first pass through the for loop.
        RList<String> test1 = redisson.getList("test1");
        test1.add("foo");
        test1.add("bar");
        for (int i=0; i < test1.size(); i++) {
            logger.error("Got(" + (i+1)+ "): " + test1.get(i));
        }

        RList<String> test2 = redisson.getList("test2");
        test2.add("foo");
        test2.add(0, "bar");

        for (int i=0; i < test2.size(); i++) {
            logger.error("Got(" + (i+1)+ "): " + test2.get(i));
         }

I queried the redis server and here are the two lists.  In test 2 you can see that bar does not get the escaped quotes around it.
 127.0.0.1:6379> lrange test1 0 -1
 1) "\"foo\""
 2) "\"bar\""
 127.0.0.1:6379> lrange test2 0 -1
 1) "bar"
 2) "\"foo\""
 127.0.0.1:6379>
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/281
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/282
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/283
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/284
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/285
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I was crashed into a blocking issue when I was doing some configuration on my windows laptop. RLock.isLocked()  got hung forever with callstack as following:
Callstack:
Object.wait(long) line: not available [native method]   
DefaultPromise<V>(Object).wait() line: 503  
DefaultPromise<V>.awaitUninterruptibly() line: 286  
DefaultPromise<V>.awaitUninterruptibly() line: 32   
CommandExecutorService.get(Future<V>) line: 145 
CommandExecutorService.read(String, Codec, RedisCommand<T>, Object...) line: 160    
CommandExecutorService.read(String, RedisCommand<T>, Object...) line: 155   
RedissonLock.isLocked() line: 389   

The issue is repreduceable. Steps to reproduce the issue:
Code:
 RLock mRLock = //initialize the redisson lock
 if (mRLock.isLocked()) {
 }

My os is windows, and I haven't tested it on linux.
Steps: disable network.  Then enable network. The program will be blocked with the callstack I pasted
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/286
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Error like "LOADING Redis is loading the dataset in memory" should be handled correctly
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/287
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/288
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/289
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/290
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I can not find anything in RScoredSortedSet class...
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/291
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When slave-serve-stale-data is set to 'no' then this error occur:
MASTERDOWN Link with MASTER is down and slave-serve-stale-data is set to 'no'
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/292
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/293
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello. I have an RBatch variable that I've added some commands to. I noticed if I tax redis a bunch sometimes it has trouble writing a backup file (this might be the fault of my weak vm). At any rate, I'd like to detect this failure mode and tell the user about it if it ever happens.
I'm trying to figure out what RBatch.execute returns. There aren't any javadocs on this. I either get one of two responses:
[null, true, false, true, false ...]

or
[null, null, null, null, null ...]

The second one indicates failure.
The wiki suggests these are responses to the specific commands, which agrees with what I would assume from EXEC, but I'm not sure why I'm getting boolean results, because the commands I'm running should all be add commands (like HSET, ZADD, etc).
Do you mind updating the javadoc, and do you know why I'm getting booleans back (and what they mean) instead of ints?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/294
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi there, is there any hook somewhere for client to handle when connection to server gets dropped/lost ?
thany
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/295
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/296
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Return value of follow methods: RedissonScoredSortedSet.remove, RedissonScoredSortedSet.add, RedissonMap.fastPutAsync and so on could be changed from boolean to value returned by Redis.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/297
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/298
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/299
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/300
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/301
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/302
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/303
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/304
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/305
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/306
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/307
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/308
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/309
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/310
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/311
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/312
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/313
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/314
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/315
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/316
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/317
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/318
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/319
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/320
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/321
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/322
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/323
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/324
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/325
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/326
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/327
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/328
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/329
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/330
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/331
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/332
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/333
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/334
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/335
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/336
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/337
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/338
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/339
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/340
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/341
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/342
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/343
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/344
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/345
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/346
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/347
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/348
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/349
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/350
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/351
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/352
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/353
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/354
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/355
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/356
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/357
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/358
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/359
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/360
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/361
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/362
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/363
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/364
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/365
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/366
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/367
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/368
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/369
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/370
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/371
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/372
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/373
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/374
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/375
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/376
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/377
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/378
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/379
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/380
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/381
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/382
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/383
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/384
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/385
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/386
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/387
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/388
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/389
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/390
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/391
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/392
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/393
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/394
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/395
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/396
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/397
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/398
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/399
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/400
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/401
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/402
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/403
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/404
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/405
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/406
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/407
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/408
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/409
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/410
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/411
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/412
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/413
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/414
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/415
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/416
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/417
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/418
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/419
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/420
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/421
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/422
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/423
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/424
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/425
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/426
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/427
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/428
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/429
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/430
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/431
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/432
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/433
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
corresponding the ZREVRANK command
http://redis.io/commands/zrevrank
Thanks in advanced..
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/434
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
public interface MyServiceInterface {
  Long method1(SomeObject arg);
  Long method2(SomeObject arg1, Long arg2);
}

// server side - can be N servers (N Redisson instances)

MyServiceInterface bean = new MyObject(); // implements MyServiceInterface
redisson.getRemoteService().register(bean);

// client side - can be N clients (N Redisson instances)

// Invocation modes:
// 1. Concurrent (default) - 5 concurrent invocations leads to 5 parallel executions using 5 different Redisson instances on server side 
// 2. Queue - 5 concurrent invocations will be queued and executed one by one
MyServiceInterface remote = redisson.getRemoteService().get(MyServiceInterface.class);
Long res = remote.method1(new SomeObject());
Long res = remote.method2(new SomeObject(), 100L);

// Queued mode
MyServiceInterface remote = redisson.getRemoteService().get(MyServiceInterface.class, Mode.Queue);
Long res = remote.method1(new SomeObject());
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/435
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/436
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
in ReadLock and WriteLock,  the unlock method use thread id to determine whether it is owned by this thread. it works fine for a single machine.
However, when it is used in a distributed processing framework such as MapReduce, the Read and Write lock cannot be correctly unlocked.
I browse the source codes and find that the UUID is generated in the lock, I think it is better to use UUID as lock id  istead of thread id or provides a way to let users to set a unque id.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/437
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
version: redisson-2.2.9
test as following:
public static void main(String[] args) throws Exception { Config config = new Config(); config.useClusterServers().setReadMode(ReadMode.MASTER)// // .setSubscriptionsPerConnection(1024)// .setMasterConnectionMinimumIdleSize(2)// .setSlaveConnectionMinimumIdleSize(2)// .setMasterConnectionPoolSize(1024)// .setSlaveConnectionPoolSize(1024)// .setTimeout(2000)// .addNodeAddress("10.58.56.157:8300"); RedissonClient redisson = Redisson.create(config); for (int i = 0; i < 10240; i++) { System.out.println(i); RTopic<Object> topic = redisson.getTopic("test" + i); topic.addListener(new MessageListener<Object>() { @Override public void onMessage(String channel, Object msg) { System.out.println("channel=" + channel + ",msg=" + msg); } }); } }
exception:
0
1
2
3
4
......
124
125
Exception in thread "main" org.redisson.client.RedisConnectionException: Connection pool exhausted! All connections are busy. Try to increase connection pool size. Hosts with fully busy connections: [/10.58.56.157:8301]
at org.redisson.connection.pool.ConnectionPool.get(ConnectionPool.java:164)
at org.redisson.connection.pool.PubSubConnectionPool.get(PubSubConnectionPool.java:26)
at org.redisson.connection.SingleEntry.nextPubSubConnection(SingleEntry.java:75)
at org.redisson.connection.MasterSlaveConnectionManager.nextPubSubConnection(MasterSlaveConnectionManager.java:653)
at org.redisson.connection.MasterSlaveConnectionManager.connect(MasterSlaveConnectionManager.java:416)
at org.redisson.connection.MasterSlaveConnectionManager.subscribe(MasterSlaveConnectionManager.java:410)
at org.redisson.connection.MasterSlaveConnectionManager.subscribe(MasterSlaveConnectionManager.java:363)
at org.redisson.RedissonTopic.addListener(RedissonTopic.java:81)
at org.redisson.RedissonTopic.addListener(RedissonTopic.java:77)
at org.redisson.RedisssonBugOfConnectionLimitTest.main(RedisssonBugOfConnectionLimitTest.java:23)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/438
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
version: redisson-2.2.9
test as following:
public static void main(String[] args) throws Exception {
        Config config = new Config();
        config.useClusterServers().setReadMode(ReadMode.MASTER)//
                // .setSubscriptionsPerConnection(1024)//
                .setMasterConnectionMinimumIdleSize(2)//
                .setSlaveConnectionMinimumIdleSize(2)//
                .setMasterConnectionPoolSize(1024)//
                .setSlaveConnectionPoolSize(1024)//
                .setTimeout(2000)//
                .addNodeAddress("10.58.56.157:8300");
        RedissonClient redisson = Redisson.create(config);
        for (int i = 0; i < 10240; i++) {
            System.out.println(i);
            RTopic<Object> topic = redisson.getTopic("test" + i);
            topic.addListener(new MessageListener<Object>() {
                @Override
                public void onMessage(String channel, Object msg) {
                    System.out.println("channel=" + channel + ",msg=" + msg);
                }
            });
        }
    }


exception:
0
1
2
3
4
......
124
125
Exception in thread "main" org.redisson.client.RedisConnectionException: Connection pool exhausted! All connections are busy. Try to increase connection pool size. Hosts with fully busy connections: [/10.58.56.157:8301]
at org.redisson.connection.pool.ConnectionPool.get(ConnectionPool.java:164)
at org.redisson.connection.pool.PubSubConnectionPool.get(PubSubConnectionPool.java:26)
at org.redisson.connection.SingleEntry.nextPubSubConnection(SingleEntry.java:75)
at org.redisson.connection.MasterSlaveConnectionManager.nextPubSubConnection(MasterSlaveConnectionManager.java:653)
at org.redisson.connection.MasterSlaveConnectionManager.connect(MasterSlaveConnectionManager.java:416)
at org.redisson.connection.MasterSlaveConnectionManager.subscribe(MasterSlaveConnectionManager.java:410)
at org.redisson.connection.MasterSlaveConnectionManager.subscribe(MasterSlaveConnectionManager.java:363)
at org.redisson.RedissonTopic.addListener(RedissonTopic.java:81)
at org.redisson.RedissonTopic.addListener(RedissonTopic.java:77)
at org.redisson.RedisssonBugOfConnectionLimitTest.main(RedisssonBugOfConnectionLimitTest.java:23)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/439
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/440
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Use case:
Redis clustering is implemented using twemproxy, and its location should be discovered and monitored using Consul, etcd or whatever else. Currently I have to either use DNS monitoring (which is not an option in some cases) or wrap Redisson instances into a proxy to implement this. It would be better to have an option to implement such behavior in custom ConnectionManager.
I can make pull request with implementation, if anyone else needs this.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/441
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/442
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Great work! Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/443
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/444
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have seen the source codes and found that many codes use java string join parameter.
I think it is not inefficient.
May be use StringBuffer of use static string values, so that the interactions between Redis and Redission can be more efficient.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/445
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
oneShotListener must remove itself automatically after execution
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/446
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Implement correct cancellation handling for Future object returned by pollAsync, pollFromAnyAsync, takeAsync, pollLastAsync, pollLastFromAnyAsync, takeAsync and pollLastAndOfferFirstToAsync methods
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/447
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/448
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/449
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
BlockingQueue\Deque Commands like take, poll and pollLastAndOfferFirstTo must be reconnected to a new channel after RedisConnection has been reconnected.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/450
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/451
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I know my question is not an issue but I couldn't find a better way to get an answer, sorry!
Would you recommend Redisson as a session manager (as in HttpSession)?
Spring Session comes with a clustered version using Redis but it does not support locks (AFAIK) and personally I find that useless. Then I found this project and it sounds suitable but there's so much to consider and trying to get advise from the community I thought this is the best place to ask.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/452
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/453
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
i use Reddison framework with scala and noticed very strange behavior. If I use sync. and pub \ subscribe features all system get unstable and issue an exception listed below. Also below is the simple test which produce this behavior. Any comments ?
`
import org.redisson.RedissonClient
import org.redisson._
import org.redisson.core.{ RTopic, MessageListener }
import org.scalatest._
import org.slf4j.LoggerFactory
object RedissonTest {
val config = new Config().setUseLinuxNativeEpoll( true )
config.useSingleServer().setAddress("127.0.0.1:6379")
val redis = Redisson.create( config  )
val set_test = java.util.UUID.randomUUID
val system_topic = "system_bus"
class RedissonTestSet extends FlatSpec with Matchers {
val logger = LoggerFactory.getLogger( this.getClass.getSimpleName )

val topic:RTopic[String] = redis.getTopic( system_topic )
val redisSet:java.util.Set[String] =  redis.getSet( set_test.toString )

it should "produce exception " in {

  val listener = new MessageListener[ String ] () {
    override def onMessage( chanel: String, message: String ) {
      logger.info( s"received $chanel, $message.toString")
      checkSet
    }
  }
  topic.addListener( listener )
  for ( i <- 1 to 1000 ) {
    redisSet.add( i.toString  )
  }
  topic.publish( new String( "hey this is the bug" ) )
}

def checkSet {
  for ( i <-1 to 1000 ) {
    if ( redisSet.contains( i.toString ) ) {
    }
  }
}

}
}
 
2016-03-27 17:36:30.385  WARN  [epollEventLoopGroup-2-12] i.n.channel.DefaultChannelPipeline.warn(151) - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
io.netty.handler.codec.DecoderException: io.netty.util.concurrent.BlockingOperationException: DefaultPromise@19827b5e(incomplete)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:431) ~[netty-codec-4.0.34.Final.jar:4.0.34.Final]
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:244) ~[netty-codec-4.0.34.Final.jar:4.0.34.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:307) [netty-transport-4.0.34.Final.jar:4.0.34.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:293) [netty-transport-4.0.34.Final.jar:4.0.34.Final]
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) [netty-transport-4.0.34.Final.jar:4.0.34.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:307) [netty-transport-4.0.34.Final.jar:4.0.34.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:293) [netty-transport-4.0.34.Final.jar:4.0.34.Final]
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) [netty-transport-4.0.34.Final.jar:4.0.34.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:307) [netty-transport-4.0.34.Final.jar:4.0.34.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:293) [netty-transport-4.0.34.Final.jar:4.0.34.Final]
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:840) [netty-transport-4.0.34.Final.jar:4.0.34.Final]
at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:830) [netty-transport-native-epoll-4.0.34.Final-linux-x86_64.jar:na]
at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:348) [netty-transport-native-epoll-4.0.34.Final-linux-x86_64.jar:na]
at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:264) [netty-transport-native-epoll-4.0.34.Final-linux-x86_64.jar:na]
at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:112) [netty-common-4.0.34.Final.jar:4.0.34.Final]
at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137) [netty-common-4.0.34.Final.jar:4.0.34.Final]
at java.lang.Thread.run(Thread.java:745) [na:1.8.0_77]
Caused by: io.netty.util.concurrent.BlockingOperationException: DefaultPromise@19827b5e(incomplete)
at io.netty.util.concurrent.DefaultPromise.checkDeadLock(DefaultPromise.java:391) ~[netty-common-4.0.34.Final.jar:4.0.34.Final]
at io.netty.util.concurrent.DefaultPromise.awaitUninterruptibly(DefaultPromise.java:284) ~[netty-common-4.0.34.Final.jar:4.0.34.Final]
at io.netty.util.concurrent.DefaultPromise.awaitUninterruptibly(DefaultPromise.java:33) ~[netty-common-4.0.34.Final.jar:4.0.34.Final]
at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:84) ~[redisson-2.2.9.jar:na]
at org.redisson.RedissonObject.get(RedissonObject.java:49) ~[redisson-2.2.9.jar:na]
at org.redisson.RedissonSet.contains(RedissonSet.java:70) ~[redisson-2.2.9.jar:na]
at com.web3.RedissonTest$RedissonTestSet$$anonfun$checkSet$1.apply$mcVI$sp(ReddisonSetPubSubTest.scala:45) ~[test-classes/:na]
at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141) ~[scala-library-2.10.4.jar:na]
at com.web3.RedissonTest$RedissonTestSet.checkSet(ReddisonSetPubSubTest.scala:44) ~[test-classes/:na]
at com.web3.RedissonTest$RedissonTestSet$$anonfun$1$$anon$1.onMessage(ReddisonSetPubSubTest.scala:30) ~[test-classes/:na]
at com.web3.RedissonTest$RedissonTestSet$$anonfun$1$$anon$1.onMessage(ReddisonSetPubSubTest.scala:27) ~[test-classes/:na]
at org.redisson.PubSubMessageListener.onMessage(PubSubMessageListener.java:73) ~[redisson-2.2.9.jar:na]
at org.redisson.client.RedisPubSubConnection.onMessage(RedisPubSubConnection.java:68) ~[redisson-2.2.9.jar:na]
at org.redisson.client.handler.CommandDecoder.handleMultiResult(CommandDecoder.java:277) ~[redisson-2.2.9.jar:na]
at org.redisson.client.handler.CommandDecoder.decodeMulti(CommandDecoder.java:242) ~[redisson-2.2.9.jar:na]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:217) ~[redisson-2.2.9.jar:na]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:97) ~[redisson-2.2.9.jar:na]
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:376) ~[netty-codec-4.0.34.Final.jar:4.0.34.Final]
... 16 common frames omitted
`
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/454
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
From gitter:
I just want to confirm but redisson.getSetCache would be appropriate for locking? That is using .add() to see if it was able to add a guid to the set (unlocked) or not (locked)
@mrniko  As you can see lua-script from this method doesn't check element expiration as others do. Could you create an issue about this?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/455
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I use Redisson 2.2.10 to implement distributed lock in my project. And then I run load test for this distributed lock using SINGLE redis mode. But I found there are many long latency APIs and it's wired that almost all the long latency APIs are a little greater than 1000ms. The average latency and 99 percent latecy is about 15ms and 30ms respectively. And then I used jstack to get the call stack and found most of the threads are WAITING at the same place just as the following
"Processor-35" prio=10 tid=0x00007f61900e3800 nid=0x2614 in Object.wait() [0x00007f61027e5000]
 java.lang.Thread.State: WAITING (on object monitor)
       at java.lang.Object.wait(Native Method)
       at java.lang.Object.wait(Object.java:503)
       at io.netty.util.concurrent.DefaultPromise.awaitUninterruptibly(DefaultPromise.java:286)
       - locked <0x0000000600aa3e50> (a io.netty.util.concurrent.DefaultPromise)
       at io.netty.util.concurrent.DefaultPromise.awaitUninterruptibly(DefaultPromise.java:32)
       at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:84)
       at org.redisson.RedissonObject.get(RedissonObject.java:49)
       at org.redisson.RedissonLock.tryAcquire(RedissonLock.java:139)
       at org.redisson.RedissonLock.tryLock(RedissonLock.java:225)
       at com.mytest.lock.impl.redis.BaseRedisLockClientImpl.tryLock(BaseRedisLockClientImpl.java:72)

Meanwhile, during the test, I dumped the network packages using tcpdump and found that it took about 1000ms before the first package was sent to Redis. And in Redis server, I didn't find any slow query whose latency is more than 10ms. So I think, for the long latency API, most of the time might be cost in the project not the network. So can you help me to have a check or give me some suggestion about this issue?  Many thanks.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/456
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks a lot for your work!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/457
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/458
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/459
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/460
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/461
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/462
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I have setup Redis in sentinel mode with 4 slaves and 1 master. As I increase the number of read requests, Redission is throwing RedisTimeoutException. The TimeOut is set to 5 sec and retry count is set to 5. Will increasing the number of slaves help?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/463
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/464
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/465
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I am using a single server connection and set the connection pool size to 10. I have created multiple threads to test a code snippet where I am saving an object to RBucket<> object and deleting it afterwards in a same transaction block. I get following error sometime in the process,
Exception in thread "51" org.redisson.client.RedisConnectionException: Can't init enough connections amount! Only 0 from 5 were initialized. Server: /127.0.0.1:6379
at org.redisson.connection.pool.ConnectionPool$2.operationComplete(ConnectionPool.java:112)
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:683)
at io.netty.util.concurrent.DefaultPromise$2.run(DefaultPromise.java:593)
at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:358)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:357)
at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:112)
at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)
at java.lang.Thread.run(Thread.java:745)
Any suggestion?
Thanks.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/466
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have a simple setup with a SingleServer connected to a ElasticCache-Redis instance. I upload various sizes of bytes to measure the performance between those. Small objects up to 3 MB perform fine but above that I receive this error:
Exception in thread "main" org.redisson.client.RedisTimeoutException: Command execution timeout for command: (SETEX) with params: [da515c20-cba8-42ca-bd18-66249f4e06d9, 60, StorageObject@255d177b]
    at org.redisson.command.CommandAsyncService$5.run(CommandAsyncService.java:403)
    at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:581)
    at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:655)
    at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:367)
    at java.lang.Thread.run(Thread.java:745)

In "Batch" mode is also see this:
Exception in thread "main" org.redisson.client.RedisTimeoutException: Batch command execution timeout
    at org.redisson.command.CommandBatchService$3.run(CommandBatchService.java:243)
    at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:581)
    at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:655)
    at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:367)
    at java.lang.Thread.run(Thread.java:745)

My setup for connecting looks as following (I have a similar setup with redisson-reactive showing the same problem):
        final Config config = new Config();

        config.useSingleServer().setSubscriptionConnectionMinimumIdleSize(1);
        config.useSingleServer().setSubscriptionConnectionPoolSize(5);
        config.useSingleServer().setSubscriptionsPerConnection(5);
        config.setCodec(new SerializationCodec());
        config.useSingleServer().setAddress(configuration.getString("redis.endpoint"));
        config.useSingleServer().setDatabase(configuration.getInt("redis.database"));
        config.useSingleServer().setConnectionPoolSize(configuration.getInt("redis.pool.max"));
        config.useSingleServer().setConnectionMinimumIdleSize(configuration.getInt("redis.pool.min"));
        config.useSingleServer().setTimeout(60000);

        redissonClient = Redisson.create(config);

        // single
        redissonClient.getBucket(storageObject.getId()).set(storageObject, 60, SECONDS);

        // batch
        final RBatch batch = redissonClient.createBatch();
        for (final StorageObject storageObject : storageObjects)
        {
            batch.getBucket(storageObject.getId()).setAsync(storageObject, 60, SECONDS);
        }
        batch.execute();

I have tried using the latest versions (release + HEAD). I have debugged the issue but haven't found any obvious problem. The only thing I found is the timeout in "new HashedWheelTimer(minTimeout, TimeUnit.MILLISECONDS);" which is set to a 100ms (from MasterSlaveConfig) and seems to be the reason for cancelling the commands? Though I tried changing this without success.
Somebody has an idea about what might be causing the timeouts? Can I configure those to be suitable for bigger objects?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/467
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am using simple app to run on 2 clients to test locks.
While using RedissonMultiLock with 3 locks both clients blocks.
public class App 
{
    public static void main( String[] args )
    {
        Config config = new Config();
        config.useSingleServer().setAddress("127.0.0.1:6379");
        RedissonClient client = Redisson.create(config);

        for(int i = 0; i < 100000; i++)
        {
            RLock lock1 = client.getLock("lock1");
            RLock lock2 = client.getLock("lock2");
            RLock lock3 = client.getLock("lock3");

            RedissonMultiLock lock = new RedissonMultiLock(lock1, lock2, lock3);
            lock.lock();

             RBucket<Object> bucket = client.getBucket("myLong");
             Object value = bucket.get();
             long newValue = 1;
             if(value != null){
                 newValue = (Long)value;
                 newValue++;
             }
             bucket.set(newValue);

            lock.unlock();
        }
        System.exit(0);
    }
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/468
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
While iterating over an RMapCache object with an iterator, an "IllegalStateException" occurs  on the second removal of an entry from the map.
The map structure is RMapCache<String, List>.
The iterator is received via cacheMap.entrySet().iterator().
The iterator removes successfully the first entry, but upon the second entry removal it fails with the exception mentioned above.
Please note this code used to work fine with a regular Java Map.
Here is the code:
`
private long clearExpiredItems(RMapCache<String, List<ItemInfo>> mapCache) {
    long maximalExpirationTime = 0;
    Iterator<Entry<String, List<ItemInfo>>> mapCacheIterator = mapCache.entrySet().iterator();
    while (mapCacheIterator.hasNext()) {
        Entry<String, List<ItemInfo>> userMapCacheEntry = mapCacheIterator.next();
        List<ItemInfo> userMapCache = userMapCacheEntry.getValue();
        for (Iterator<ItemInfo> iterator = userMapCache.iterator(); iterator.hasNext();) {
            ItemInfo itemInfo = iterator.next();
            long tempMaximalExpirationTime = itemInfo.getExpirationTime();
            if (itemInfo.getExpirationTime() < System.currentTimeMillis() / 1000) {
                tempMaximalExpirationTime = 0;
                iterator.remove();
            }
            maximalExpirationTime = tempMaximalExpirationTime > maximalExpirationTime ? tempMaximalExpirationTime : maximalExpirationTime;
        }
        if (userMapCache.isEmpty()) {
            mapCacheIterator.remove();
        }
    }
    return maximalExpirationTime;
}`

And here is the relevant stack trace:

java.lang.IllegalStateException
at java.util.HashMap$HashIterator.remove(HashMap.java:1441) ~[?:1.8.0_40]
at org.redisson.RedissonBaseMapIterator.remove(RedissonBaseMapIterator.java:117) ~[redisson-2.2.10.jar:?]
at org.redisson.RedissonMapIterator.remove(RedissonMapIterator.java:23) ~[redisson-2.2.10.jar:?]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/469
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/470
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks a lot!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/471
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I recently change some code to use maxIdle timeouts on a map.  I.e changed from RMap to RMapCache.   Put and gets are working as expected but the .values() call doesnt work.
ERR Error running script (call to f_7e9dc69eeb0d7798de8f6a1bb0f5a10381585c62): @user_script:1: @user_script: 1: Write commands not allowed after non deterministic commands . channel: [id: 0x52db1332, L:/127.0.0.1:37320 - R:localhost/127.0.0.1:6379] command: CommandData [promise=ImmediateEventExecutor$ImmediatePromise@5ba21282(incomplete), command=(EVAL), params=[local result = {}; local res = redis.call('hscan', KEYS[1], ARGV[2]); for i, value in ipairs(res[2]) do if i % 2 == 0 then local key = res[2][i-1]; local expireDate = 92233720368547758; local expireDateScore = redis.call('zscore', KEYS[2], key); if expireDateScore ~= false then expireDate = tonumber(expireDateScore) end; local t, val = struct.unpack('dLc0', value); if t ~= 0 then local expireIdle = redis.call('zscore', KEYS[3], key); if expireIdle ~= false then if tonumber(expireIdle) > tonumber(ARGV[1]) then local value = struct.pack('dLc0', t, string.len(val), val); redis.call('hset', KEYS[1], key, value); redis.call('zadd', KEYS[3], t + tonumber(ARGV[1]), key); end; expireDate = math.min(expireDate, tonumber(expireIdle)) end; end; if expireDate > tonumber(ARGV[1]) then table.insert(result, key); table.insert(result, val); end; end; end;return {res[1], result};, 3, testRMapCacheValues, redisson__timeout__set__{testRMapCacheValues}, redisson__idle__set__{testRMapCacheValues}, 1460720927535, 0], codec=org.redisson.client.codec.ScanCodec@6d6d43cd]
I have attached a test class to show this.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/472
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/473
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/474
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I configured Redisson, see below, and it works, but when I shutdown one redis master and his slave on other machine becomes a master (in 5 sec) Redisson cannot recognize the new master and the request seems like still go to the old master which is not exist.
Please assist ASAP.
Thanks!
Redisson.json:
{
"clusterServersConfig":{
"idleConnectionTimeout":10000,
"pingTimeout":1000,
"connectTimeout":1000,
"timeout":1000,
"retryAttempts":3,
"retryInterval":1000,
"reconnectionTimeout":3000,
"failedAttempts":3,
"password":null,
"subscriptionsPerConnection":5,
"clientName":null,
"loadBalancer":{
"class":"org.redisson.connection.balancer.RoundRobinLoadBalancer"
},
"slaveSubscriptionConnectionMinimumIdleSize":1,
"slaveSubscriptionConnectionPoolSize":25,
"slaveConnectionMinimumIdleSize":5,
"slaveConnectionPoolSize":100,
"masterConnectionMinimumIdleSize":5,
"masterConnectionPoolSize":100,
"readMode":"SLAVE",
"nodeAddresses":[
"//172.31.160.110:7000",
"//172.31.160.110:7001",
"//172.31.160.112:7000",
"//172.31.160.112:7001",
"//172.31.160.111:7000",
"//172.31.160.111:7001"
],
"scanInterval":1000
},
"threads":0,
"codec":null,
"useLinuxNativeEpoll":false,
"eventLoopGroup":null
}
Redis.conf:
port 7000
bind 172.31.160.110
cluster-enabled yes
cluster-config-file nodes.conf
cluster-node-timeout 5000
cluster-slave-validity-factor 1
maxmemory 2048mb
maxmemory-policy volatile-ttl
slave-read-only yes
save 900 1
save 300 10
save 60 10000
stop-writes-on-bgsave-error yes
rdbchecksum yes
dbfilename dump.rdb
appendonly yes
logfile redis.log
loglevel notice
slowlog-log-slower-than 10000
slowlog-max-len 64
latency-monitor-threshold 100
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/475
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/476
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi Niko, seems like problem really exists with redisson driver for cluster.
Here is our configuration:
aa19c3c2a927384b6a4673539cd7dcdb2efa33e8 10.20.21.113:7001 slave d20242223349a4d51b30da40dad09f0dbc9a2cc8 0 1461081575219 1 connected d20242223349a4d51b30da40dad09f0dbc9a2cc8 10.20.21.44:7000 myself,master - 0 0 1 connected 0-5461 ba12c571516b130a9973fdc95ba8cebbfaf5ac7e 10.20.21.113:7000 master - 0 1461081576222 3 connected 5462-10922 4a21be5ffb25369bf4243918c34467103fa9c8a4 10.20.21.59:7001 slave ba12c571516b130a9973fdc95ba8cebbfaf5ac7e 0 1461081577222 3 connected f6b4e5a94409ca397731165acad90f2193154c62 10.20.21.59:7000 master - 0 1461081576422 0 connected 10923-16383 6a7c1e8510d29aed17dc1e0ca7f0e6a7278b4de5 10.20.21.44:7001 slave f6b4e5a94409ca397731165acad90f2193154c62 0 1461081576721 5 connected
I'm shutting down Redis instances on 10.20.21.113:  ba12c571516b130a9973fdc95ba8cebbfaf5ac7e and aa19c3c2a927384b6a4673539cd7dcdb2efa33e8
When I did this Redis cluster reorganized to following:
aa19c3c2a927384b6a4673539cd7dcdb2efa33e8 10.20.21.113:7001 slave,fail d20242223349a4d51b30da40dad09f0dbc9a2cc8 1461081896304 1461081894700 1 disconnected d20242223349a4d51b30da40dad09f0dbc9a2cc8 10.20.21.44:7000 myself,master - 0 0 1 connected 0-5461 ba12c571516b130a9973fdc95ba8cebbfaf5ac7e 10.20.21.113:7000 master,fail - 1461081896204 1461081895202 3 disconnected 4a21be5ffb25369bf4243918c34467103fa9c8a4 10.20.21.59:7001 master - 0 1461081995791 6 connected 5462-10922 f6b4e5a94409ca397731165acad90f2193154c62 10.20.21.59:7000 master - 0 1461081994787 0 connected 10923-16383 6a7c1e8510d29aed17dc1e0ca7f0e6a7278b4de5 10.20.21.44:7001 slave f6b4e5a94409ca397731165acad90f2193154c62 0 1461081996293 5 connected 
As you can see cluster is ok, but requests are failing for some reason.
If I restart tomcat without touching anything on Redis requests are not failing.
Very strange.
This is the link to the redisson log: https://www.dropbox.com/s/pluyzxtxpd0u23z/redisson.log?dl=0
Please assist,
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/477
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have a Master Master redis cluster of 3 (node1,node2,node3). Locking mechanism works fine if we block the network for node2 or node 3. But if we block node1's network then it fails with the below error
Exception in thread "main" org.redisson.client.RedisNodeNotFoundException: No node for slot: 15087 and command (EVAL)
at org.redisson.connection.MasterSlaveConnectionManager.getEntry(MasterSlaveConnectionManager.java:578)
at org.redisson.connection.MasterSlaveConnectionManager.connectionWriteOp(MasterSlaveConnectionManager.java:563)
at org.redisson.command.CommandAsyncService.async(CommandAsyncService.java:368)
at org.redisson.command.CommandAsyncService.evalAsync(CommandAsyncService.java:334)
at org.redisson.command.CommandAsyncService.evalWriteAsync(CommandAsyncService.java:282)
at org.redisson.RedissonLock.tryLockInnerAsync(RedissonLock.java:207)
at org.redisson.RedissonLock.tryAcquire(RedissonLock.java:139)
at org.redisson.RedissonLock.tryLock(RedissonLock.java:225)
at com.seamless.common.cache.distributed.LockManager.getLock(LockManager.java:37)
at com.testlock.app.App.main(App.java:34)

Below is how I'm creating the Redission client
`
import java.util.List;
import java.util.concurrent.TimeUnit;
import org.apache.log4j.Logger;
import org.redisson.ClusterServersConfig;
import org.redisson.Config;
import org.redisson.ReadMode;
import org.redisson.Redisson;
import org.redisson.RedissonClient;
import org.redisson.core.RLock;
public class LockManager {
private static final Logger LOG = Logger.getLogger(LockManager.class);


private RedissonClient redissonClient;

LockManager(List<String> nodes){
    Config config = new Config();
    ClusterServersConfig serverConfig=config.useClusterServers();
    serverConfig.setReadMode(ReadMode.MASTER);

    for(String node :nodes){
        serverConfig.addNodeAddress(node);
    }
    redissonClient = Redisson.create(config);

}

public boolean getLock(final String lockKey,int timeout){
    RLock lock=redissonClient.getLock(lockKey);
    try {
        return lock.tryLock(0, timeout, TimeUnit.MILLISECONDS);
    } catch (InterruptedException e) {
        LOG.error("Error getting lock "+e.getMessage());
    }
    return false;
}   

public void releaseLock(final String lockKey){
    RLock lock=redissonClient.getLock(lockKey);
    if(lock.isHeldByCurrentThread())
        lock.unlock();
}

}
`
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/478
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
public static void main(String[] args) {
    Config config = new Config();

    config.setCodec(new JsonJacksonCodec());
            config.useSingleServer().setAddress("127.0.0.1:6379");

            RedissonClient redisson = Redisson.create(config);
            RScoredSortedSet<Integer> set = redisson.getScoredSortedSet("test");
            set.add(1.0, 4);

            Integer rank = set.revRank(4); // no problem 
            System.out.println(rank);
            Integer rank1 = set.revRank(1); // throw java.lang.NullPointerException, I think rank1 should be null and not throw Exception 
            System.out.println(rank1 == null);

            redisson.shutdown();
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/479
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi Niko!
We constantly have "connection pool exhausted" errors on our env.
The configuration is : 3 machines with 1 master and 1 slave on each machine.
May be we should tune some configurations in our redisson config?
Can you please explain briefly the meaning of these:
"slaveSubscriptionConnectionMinimumIdleSize":1, "slaveSubscriptionConnectionPoolSize":25, "slaveConnectionMinimumIdleSize":5, "slaveConnectionPoolSize":100, "masterConnectionMinimumIdleSize":5, "masterConnectionPoolSize":100, "readMode":"SLAVE",
This is our redisson config file:
{
"clusterServersConfig":{
"idleConnectionTimeout":10000,
"pingTimeout":1000,
"connectTimeout":1000,
"timeout":1000,
"retryAttempts":3,
"retryInterval":1000,
"reconnectionTimeout":3000,
"failedAttempts":3,
"password":null,
"subscriptionsPerConnection":5,
"clientName":null,
"loadBalancer":{
"class":"org.redisson.connection.balancer.RoundRobinLoadBalancer"
},
"slaveSubscriptionConnectionMinimumIdleSize":1,
"slaveSubscriptionConnectionPoolSize":25,
"slaveConnectionMinimumIdleSize":5,
"slaveConnectionPoolSize":100,
"masterConnectionMinimumIdleSize":5,
"masterConnectionPoolSize":100,
"readMode":"SLAVE",
"nodeAddresses":[
"//10.20.21.44:7000",
"//10.20.21.44:7001",
"//10.20.21.113:7000",
"//10.20.21.113:7001",
"//10.20.21.59:7000",
"//10.20.21.59:7001"
],
"scanInterval":1000
},
"threads":0,
"codec":null,
"useLinuxNativeEpoll":false,
"eventLoopGroup":null
}
These are errors that we get:
21 Apr 2016 12:16:43  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[0-5461]] Disconnected hosts: [/10.20.21.44:7000]
21 Apr 2016 12:16:44  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[0-5461]] Disconnected hosts: [/10.20.21.44:7000]
21 Apr 2016 12:19:31  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[0-5461]] Hosts with fully busy connections: [ip-10-20-21-113.ec2.internal/10.20.21.113:7001]
21 Apr 2016 12:19:31  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[10923-16383]] Hosts with fully busy connections: [ip-10-20-21-59.ec2.internal/10.20.21.59:7000]
21 Apr 2016 12:19:31  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[5462-10922]] Hosts with fully busy connections: [/10.20.21.113:7000]
21 Apr 2016 12:19:31  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[10923-16383]] Hosts with fully busy connections: [ip-10-20-21-59.ec2.internal/10.20.21.59:7000]
21 Apr 2016 12:19:31  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[10923-16383]] Hosts with fully busy connections: [ip-10-20-21-59.ec2.internal/10.20.21.59:7000]
21 Apr 2016 12:19:31  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[10923-16383]] Hosts with fully busy connections: [ip-10-20-21-59.ec2.internal/10.20.21.59:7000]
21 Apr 2016 12:19:31  ERROR - An error occurred when closing a session. Error: Connection pool exhausted! for slots: [[10923-16383]] Hosts with fully busy connections: [ip-10-20-21-59.ec2.internal/10.20.21.59:7000]
21 Apr 2016 12:19:31  ERROR - An error occurred when closing a session. Error: Connection pool exhausted! for slots: [[5462-10922]] Hosts with fully busy connections: [/10.20.21.113:7000]
21 Apr 2016 12:19:31  ERROR - An error occurred when closing a session. Error: Connection pool exhausted! for slots: [[10923-16383]] Hosts with fully busy connections: [ip-10-20-21-59.ec2.internal/10.20.21.59:7000]
21 Apr 2016 12:19:31  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[10923-16383]] Hosts with fully busy connections: [ip-10-20-21-59.ec2.internal/10.20.21.59:7000]
21 Apr 2016 12:19:31  ERROR - An error occurred when closing a session. Error: Connection pool exhausted! for slots: [[5462-10922]] Hosts with fully busy connections: [/10.20.21.113:7000]
21 Apr 2016 12:19:31  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[10923-16383]] Hosts with fully busy connections: [ip-10-20-21-59.ec2.internal/10.20.21.59:7000]
21 Apr 2016 12:19:31  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[5462-10922]] Hosts with fully busy connections: [/10.20.21.113:7000]
21 Apr 2016 12:19:31  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[10923-16383]] Hosts with fully busy connections: [ip-10-20-21-59.ec2.internal/10.20.21.59:7000]
21 Apr 2016 12:19:31  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[10923-16383]] Hosts with fully busy connections: [ip-10-20-21-59.ec2.internal/10.20.21.59:7000]
21 Apr 2016 12:19:31  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[0-5461]] Hosts with fully busy connections: [ip-10-20-21-113.ec2.internal/10.20.21.113:7001]
21 Apr 2016 12:19:31  ERROR - An error occurred when closing a session. Error: Connection pool exhausted! for slots: [[10923-16383]] Hosts with fully busy connections: [ip-10-20-21-59.ec2.internal/10.20.21.59:7000]
21 Apr 2016 12:19:31  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[5462-10922]] Hosts with fully busy connections: [/10.20.21.113:7000]
21 Apr 2016 12:19:31  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[5462-10922]] Hosts with fully busy connections: [/10.20.21.113:7000]
21 Apr 2016 12:19:31  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[10923-16383]] Hosts with fully busy connections: [ip-10-20-21-59.ec2.internal/10.20.21.59:7000]
21 Apr 2016 12:19:31  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[0-5461]] Hosts with fully busy connections: [ip-10-20-21-113.ec2.internal/10.20.21.113:7001]
21 Apr 2016 12:19:31  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[10923-16383]] Hosts with fully busy connections: [ip-10-20-21-59.ec2.internal/10.20.21.59:7000]
21 Apr 2016 12:19:31  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[10923-16383]] Hosts with fully busy connections: [ip-10-20-21-59.ec2.internal/10.20.21.59:7000]
21 Apr 2016 12:19:31  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[10923-16383]] Hosts with fully busy connections: [ip-10-20-21-59.ec2.internal/10.20.21.59:7000]
21 Apr 2016 12:19:31  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[10923-16383]] Hosts with fully busy connections: [ip-10-20-21-59.ec2.internal/10.20.21.59:7000]
21 Apr 2016 12:19:31  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[0-5461]] Hosts with fully busy connections: [ip-10-20-21-113.ec2.internal/10.20.21.113:7001]
21 Apr 2016 12:19:31  ERROR - An error occurred when opening a session. Error: Connection pool exhausted! for slots: [[0-5461]] Hosts with fully busy connections: [ip-10-20-21-113.ec2.internal/10.20.21.113:7001]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/480
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi
I am using redis 3.0.6 (4 node cluster  ) and redisson version 2.2.5.
Sometimes when I try lock a key I get the following exceptions:
my code :
String key = String.valueOf("425011000000151"); RLock lc = client.getLock(key); lc.lock(lockTime,TimeUnit.MILLISECONDS); System.out.println("Got key: " + key); lc.unlock(); 
org.redisson.client.RedisException: ERR Error running script (call to f_93cfc048f82624d1670a310aa0ad58918c0824a5): @user_script:1: WRONGTYPE Operation against a key holding the wrong kind of value . channel: [id: 0x6280a1db, /10.135.50.64:59377 => /10.10.25.183:7002] command: CommandData [promise=DefaultPromise@79d4be49(incomplete), command=(EVAL), params=[if (redis.call('exists', KEYS[1]) == 0) then redis.call('publish', KEYS[2], ARGV[1]); return 1; end;if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then return nil;end; local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); if (counter > 0) then redis.call('pexpire', KEYS[1], ARGV[2]); return 0; else redis.call('del', KEYS[1]); redis.call('publish', KEYS[2], ARGV[1]); return 1; end; return nil;, 2, 425011000000151, redisson_lock__channel__{425011000000151}, 0, 30000, 15f636a8-4b5b-4351-9f55-14ade7a2cbd4:359], codec=org.redisson.client.codec.LongCodec@13a20a95]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:190)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:105)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:370)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:244)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:112)
at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)
at java.lang.Thread.run(Thread.java:744)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/481
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have a problem with a RSetCache with TTL.   The problem seems to be that the value is not returned from the iterator and calling readAll throws an exception.
Redisson : 2.2.12
Redis : 3.0.7 (00000000/0) 64 bit
I have attached a test which reproduces the issue.
RSetCacheTest.java.txt
When I run this, it keeps adding a string into the set and it should expire but be replaced quickly, this doesn't happen and the set is empty after the 30 seconds.
Calling readAll() on the set it fails with the following error.
ERR Error running script (call to f_288eac369e58accf826304d109d8a5d7ac3e8343): @user_script:1: @user_script: 1: Wrong number of args calling Redis command From Lua script . channel: [id: 0x9894758e, L:/127.0.0.1:54251 - R:localhost/127.0.0.1:6379] command: CommandData [promise=ImmediateEventExecutor$ImmediatePromise@1e313298(incomplete), command=(EVAL), params=[local expireHead = redis.call('zrange', KEYS[2], 0, 0, 'withscores');local keys = redis.call('hkeys', KEYS[1]); if #keys == 0 then return {}; end; local maxDate = ARGV[1]; local minExpireDate = 92233720368547758;if #expireHead == 2 and tonumber(expireHead[2]) <= tonumber(maxDate) then for i = #keys, 1, -1 do local key = keys[i]; local expireDate = redis.call('zscore', KEYS[2], key); if expireDate ~= false and tonumber(expireDate) <= tonumber(maxDate) then minExpireDate = math.min(tonumber(expireDate), minExpireDate); table.remove(keys, i); end;end;end; return redis.call('hmget', KEYS[1], unpack(keys));, 2, testRSetCacheTTL, redisson__timeout__set__{testRSetCacheTTL}, 1461683799524], codec=org.redisson.codec.JsonJacksonCodec@2ff0a8a4]
Using :

hscan testRSetCacheTTL 0

shows the value in the set while its running and after (when I disable the delete() call).
Also note that removing the delete() call seems to stop the exception from readAll().  So using readAll() with no delete() works or using delete() without the readAll().   But I have a feeling that it could be timing related.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/482
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/483
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/484
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/485
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Almost forgot about it! Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/486
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi
I am using reddison Rlock with a cluster setup , and sometimes I see latency( up to 1000ms)  when trying to acquire the lock or unlock.
I saw this issue opened by zhxjouc  (#455) with a similar problem  and I am working with 2.2.13 but I am still getting latency when a thread is trying  lock a key.
My code is running with Java thread pool for accessing redis, I notice that if I work with pool of size 1-2
almost no latency when getting the lock, but working with 30-50 threads cause the lock delay.
It could be thread overhead issue but I think that 1000ms is too long for that.
Any help on how can I get better performance when locking an unlocking?.
Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/487
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi:
when I was using getBlockingQueue method.
following exception happened to me:
[nioEventLoopGroup-2-4] WARN io.netty.channel.DefaultChannelPipeline - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
io.netty.handler.codec.DecoderException: java.lang.IndexOutOfBoundsException: readerIndex(0) + length(2) exceeds writerIndex(1): SlicedAbstractByteBuf(ridx: 0, widx: 1, cap: 1/1, unwrapped: UnpooledUnsafeDirectByteBuf(ridx: 11, widx: 464, cap: 496))
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:431)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:245)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:292)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:278)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:292)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:278)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:292)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:278)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:962)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:112)
at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)
at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IndexOutOfBoundsException: readerIndex(0) + length(2) exceeds writerIndex(1): SlicedAbstractByteBuf(ridx: 0, widx: 1, cap: 1/1, unwrapped: UnpooledUnsafeDirectByteBuf(ridx: 11, widx: 464, cap: 496))
at io.netty.buffer.AbstractByteBuf.checkReadableBytes0(AbstractByteBuf.java:1178)
at io.netty.buffer.AbstractByteBuf.checkReadableBytes(AbstractByteBuf.java:1172)
at io.netty.buffer.AbstractByteBuf.skipBytes(AbstractByteBuf.java:758)
at org.redisson.client.protocol.decoder.KeyValueObjectDecoder.decode(KeyValueObjectDecoder.java:30)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:217)
at org.redisson.client.handler.CommandDecoder.decodeMulti(CommandDecoder.java:239)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:229)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:108)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:376)
... 18 more
and this exception will double the connection numbers with redis server.
my env:
Redis 3.0.2
Redisson 2.2.11
java version "1.8.0_25"
Java(TM) SE Runtime Environment (build 1.8.0_25-b17)
Java HotSpot(TM) 64-Bit Server VM (build 25.25-b02, mixed mode)
Java code looks like this:
package com.James.redis_failover_client;
import junit.framework.Test;
import junit.framework.TestCase;
import junit.framework.TestSuite;
import org.redisson.Config;
import org.redisson.Redisson;
import org.redisson.RedissonClient;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import java.util.Random;
import java.util.concurrent.TimeUnit;
/**


Unit test for simple App.
*/
public class blpopTest extends TestCase {
private static final Logger logger = LoggerFactory.getLogger(blpopTest.class.getName());
public static RedissonClient rclient;
private static final String value = "keyorg_token_tracker_385b678b153d44beba0eb72746e72f02," +
" value:{"token":"385b678b153d44beba0eb72746e72f02","job_paths":{},"emptyRpt":0,"RptRequird":"true",   " +
""org_account":"qufenqi","RawdataRequird":"false","Category":"","RptVer":"4.0"," +
""RptType":"token","AwsNum":0,"Aws":[],"CompleteTask":[],"interfaceSucTask":[],"RptNum":0," +
""TkStatus":"未开始","accounts":[],"ver":0,"InterfaceDBStatus":{}}" ;
public blpopTest(){
rclient = getPool();
}
/**

Create the test case
*
@param testName name of the test case
*/
public blpopTest(String testName)
{
super( testName );
}

/**

@return the suite of tests being tested
*/
public static Test suite()
{
return new TestSuite( blpopTest.class );
}

/**

Rigourous Test :-)
*/
public void testApp()
{
assertTrue( true );
}

public static void main(String[] args) throws Exception {
try {


//            RedisClient.INSTATNCE.initRandomMode("127.0.0.1@6380@foobared,127.0.0.1@6379",9093);
//            RedisClient.INSTATNCE.initRandomMode("127.0.0.1@6380@foobared",9093);
new blpopTest();
while(true){
int ran = new Random().nextInt(1000);
rclient.getBlockingQueue(String.valueOf(ran)).add(value);
rclient.getBlockingQueue(String.valueOf(ran)).expire(1, TimeUnit.SECONDS);
rclient.getBlockingQueue(String.valueOf(ran)).poll(1, TimeUnit.SECONDS);
}
    }catch(Exception e){
        e.printStackTrace();

    }

}


private RedissonClient getPool(){
    String password = "foobared";
    String redis_ip ="127.0.0.1";
    String redis_port="6380";
    Config config = new Config();

    if(password!=null&&!password.isEmpty()){
        config.useSingleServer().setAddress(redis_ip.concat(":").concat(String.valueOf(redis_port)))
                .setPassword(password)
                .setIdleConnectionTimeout(5000)
                .setConnectionMinimumIdleSize(20)
                .setTimeout(3000).setFailedAttempts(5)
                .setRetryAttempts(5).setClientName("name");

    }else{
        config.useSingleServer().setAddress(redis_ip.concat(":").concat(String.valueOf(redis_port)))
                .setIdleConnectionTimeout(5000)
                .setConnectionMinimumIdleSize(20)
                .setTimeout(3000).setFailedAttempts(5)
                .setClientName("name");
    }

    rclient = Redisson.create(config);
    return rclient;
}

}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/488
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Nice fix!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/489
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/490
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
/**
     * Set an expire date for object. When expire date comes
     * the key will automatically be deleted.
     *
     * @param timestamp - expire date in milliseconds (Unix timestamp)
     * @return <code>true</code> if the timeout was set and <code>false</code> if not
     */
    boolean expireAt(long timestamp);


 /**
     * Returns the number of milliseconds since January 1, 1970, 00:00:00 GMT
     * represented by this <tt>Date</tt> object.
     *
     * @return  the number of milliseconds since January 1, 1970, 00:00:00 GMT
     *          represented by this date.
     */
    public long getTime() {
        return getTimeImpl();
    }


SO
public boolean expireAt(Date timestamp) {         return expireAt(timestamp.getTime() / 1000);     }

Should be
public boolean expireAt(Date timestamp) {         return expireAt(timestamp.getTime());     }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/491
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
when heavy concurrency happens in my application, a few lock requests will "sink" without any responses, even after the lock lease time has passed. All of these requests wait at RedissonLock.lockInterruptibly().The exact position is RedissonLock.get() after RedissonLock.subscribe().
In my opinion, this may be due to a thread removes the netty listener which is used by another thread. It can happen in this way:

Thread A is in the loop of getting the lock after subscription.
Thread B has also applied subscription and waits for result.
Thread A gets the lock very soon and enters  RedissonLock.unsubscribe(). In this step, it possibly removes all the listeners on the same channel, which includes the listener used by Thread B. It causes Thread B can never get subscription response and hang on forever.

The similar issue is at [https://github.com//pull/93]. But I think it is not solved completely.
Also I suggest  to apply the ttl algorithm to RedissonLock.get() because this step can cost some time. And if it has a timeout, dead lock can be prevented in a work-around way.
This is the thread dump when dead lock happens:
"http-nio-8001-exec-567" #5935 daemon prio=5 os_prio=0 tid=0x00007f15f81ca000 nid=0x6b3e waiting on condition [0x00007f154468a000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for  <0x00000000bf468fc8> (a java.util.concurrent.CountDownLatch$Sync) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836) at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997) at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304) at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231) at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:95) at org.redisson.RedissonObject.get(RedissonObject.java:55) at org.redisson.RedissonLock.lockInterruptibly(RedissonLock.java:113) at org.redisson.RedissonLock.lock(RedissonLock.java:92) ...
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/492
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/493
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
This is more a question than an issue, and please excuse me if this is a dumb question, I may be wrong, I am just beginning to dig into the code.
Here I suppose that the clients are able to issue calls more quickly that the servers can respond to.
In RedissonRemoteService, is it possible that the server ends up invoking simultaneously more than the expected executorsAmount given that it re-subscribe before the invokeMethod, and even before the ack ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/494
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Here, two things that would be great additions (I think) to the RedissonRemoteService.
1) Be able to choose the remote service interface prefix
Right now its hardcoded to redisson_remote_service:.
The use case is simple: for example I want to be able to deploy the same worker application (that expose the same service) on two types of instances (say some AWS m3-* for standard use, and some c4-* for hardcore use).
So on the server side I would call:
String servicePrefix = System.getProperty("SERVICE_PREFIX"); // whatever where this come from
RRemoteService remoteService = client.getRemoteSerivce(servicePrefix);
remoteService.register(...) // as usual
And on the client side:
String servicePrefix = /* whatever code that decide if its a standard call or an hardcore one */;
RRemoteService remoteService = client.getRemoteSerivce(servicePrefix);
remoteService.get(...) // as usual
2) Be able to issue one-way call (ie: wait for the ack, but not the actual response)
This could be a client side only change, for example, by having a new set of RRemoteService.get(...) methods, that takes a boolean waitForResponse...
Or, maybe, re-use the RRemoteService.get(...)'s long executionTimeout, where a value of executionTimeout < 0 would indicate to the client to wait for the ack, but not the actual response.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/495
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/496
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Will check that
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/497
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you for a great work!
I think it's inconvenient to use timeouts to determine invocation mode (fire-and-forget or unacknowledged).
I suggest to introduce an enum for this:
enum InvocationMode {
// fire-and-forget call
DONT_WAIT, 
// unacknowledged call
WAIT_ACK, 
// default behaviour of get method
WAIT_RESULT
};

RemoteService service = remoteService.get(RemoteService.class, InvocationMode.WAIT_ACK);
InvocationMode.DONT_WAIT and InvocationMode.WAIT_ACK modes are available for methods with void result only. It will be validated during invocation. So default values are not needed.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/498
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/499
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/500
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/501
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Serialization based codecs should work well too. You can add a fix for this issue to this PR.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/502
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/503
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I'm trying to create an infrastructure where different machines acquire shared locks through Redisson. Once the lock is acquired, some async tasks gets done, finally, when I finish the job, I'm releasing the Redisson lock through the thread currently running - but i receive the following error
java.lang.IllegalMonitorStateException: attempt to unlock lock, not locked by current thread by node id: xxxxx thread-id: 57
So, I understand the meaning of that, but since I want to perform asynchronous work, I cannot use the acquiring thread to perform the release.
Is there a solution for asynchronous programming? Should I not use Redisson Lock?
I also references the issue on SO
Thanks.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/504
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/505
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Juste a little something.
In the FstCodec, when an object in encoded, an FSTObjectOutput is first borrowed from the FSTConfiguration, then used to write the object and then closed.
In the FST Serialization Recommended threadsafe Use, they recommend, when using the factory method, not closing this stream in order for it to be reused.
I think that only an oos.flush() instead of a oos.close() will do the job here.
Not a big deal, but still....
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/506
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/507
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/508
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/509
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/510
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/511
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/512
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/513
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/514
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/515
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/516
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/517
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/518
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/519
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/520
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/521
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/522
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/523
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/524
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/525
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/526
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/527
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/528
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/529
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/530
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/531
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/532
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/533
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/534
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/535
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/536
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/537
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/538
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/539
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/540
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/541
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/542
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/543
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/544
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/545
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/546
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/547
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/548
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/549
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/550
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/551
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/552
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/553
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/554
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/555
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/556
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/557
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/558
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/559
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/560
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/561
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/562
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/563
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/564
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/565
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/566
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/567
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/568
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/569
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/570
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/571
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/572
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/573
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/574
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/575
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/576
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/577
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/578
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/579
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/580
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/581
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/582
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/583
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/584
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/585
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/586
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/587
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/588
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/589
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/590
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/591
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/592
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/593
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/594
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/595
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/596
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/597
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/598
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/599
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/600
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/601
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/602
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/603
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/604
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/605
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/606
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/607
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/608
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/609
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/610
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/611
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/612
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/613
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/614
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/615
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/616
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/617
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/618
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/619
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/620
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/621
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/622
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/623
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/624
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/625
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/626
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/627
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/628
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/629
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/630
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/631
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/632
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Test code as below:
public class RedissonTest {
public static void main(String[] args) {
    Config config = new Config();
    config.useSentinelServers()
    .setMasterName("atomic_counter_dev")
    .addSentinelAddress("127.0.0.1:26379");

    Redisson.create(config);
}

}
Redisson 2.3.0
JDK 1.8.0_92
INFO  2016-09-26 14:45:46 [main] org.redisson.Version.logVersion:41 - Redisson 2.3.0
INFO  2016-09-26 14:45:47 [main] o.r.c.SentinelConnectionManager.:80 - master: 127.0.0.1:6379 added
Exception in thread "main" java.lang.ClassCastException: java.util.HashMap cannot be cast to java.util.List
at org.redisson.connection.SentinelConnectionManager.(SentinelConnectionManager.java:83)
at org.redisson.config.ConfigSupport.createConnectionManager(ConfigSupport.java:169)
at org.redisson.Redisson.(Redisson.java:103)
at org.redisson.Redisson.create(Redisson.java:133)
at com.coupang.reconciliation.configuration.RedissonTest.main(RedissonTest.java:14)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/633
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
This issue related to #575
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/634
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Remain time calculation should take in account command time execution when waitTime param defined during "sync" method invocation of RLock, RSemaphore, RCountDownLatch object.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/635
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/636
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/637
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Let's consider such object:
    @REntity
    public static class TestREntityWithMap implements Comparable<TestREntityWithMap>, Serializable {

        @RId
        private String name;
        private Map value;

   }
Follow test doesn't work:
        TestREntityWithMap so = redisson.getLiveObjectService().create(TestREntityWithMap.class);
        so.getValue().put("1", "2");

        so = redisson.getLiveObjectService().detach(so);
        assertThat(so.getName()).isNotNull();
        assertThat(so.getValue()).containsKey("1");
        assertThat(so.getValue()).containsValue("2");

        so = redisson.getLiveObjectService().get(TestREntityWithMap.class, so.getName());
        assertThat(so.getName()).isNotNull();
        assertThat(so.getValue()).containsKey("1");
        assertThat(so.getValue()).containsValue("2");
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/638
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/639
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
persist method should be used instead of create and getOrCreate methods
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/640
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
If I try to call addAll I get a RedisException:
redisson.getLexSortedSet("mash:active-accounts").addAll(Arrays.asList("foo"))

I am using 2.4.0.
RedisException: ERR wrong number of arguments for 'zadd' command. channel: [id: 0xf5b079ba, L:/127.0.0.1:54944 - R:/127.0.0.1:6379] command: CommandData [promise=org.redisson.misc.RedissonPromise@6cca2408, command=(ZADD), params=[mash:active-accounts, [Ljava.lang.Object;@36cc628b], codec=org.redisson.client.codec.StringCodec@4b03c104]
->>  265 | decode    in org.redisson.client.handler.CommandDecoder
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
|    125 | decode    in     ''
|    367 | callDecode in io.netty.handler.codec.ReplayingDecoder
|    248 | channelRead in io.netty.handler.codec.ByteToMessageDecoder
|    366 | invokeChannelRead in io.netty.channel.AbstractChannelHandlerContext
|    352 | invokeChannelRead in     ''
|    345 | fireChannelRead in     ''
|     86 | channelRead in io.netty.channel.ChannelInboundHandlerAdapter
|    366 | invokeChannelRead in io.netty.channel.AbstractChannelHandlerContext
|    352 | invokeChannelRead in     ''
|    345 | fireChannelRead in     ''
|   1294 | channelRead in io.netty.channel.DefaultChannelPipeline$HeadContext
|    366 | invokeChannelRead in io.netty.channel.AbstractChannelHandlerContext
|    352 | invokeChannelRead in     ''
|    911 | fireChannelRead in io.netty.channel.DefaultChannelPipeline
|    131 | read      in io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe
|    611 | processSelectedKey in io.netty.channel.nio.NioEventLoop
|    552 | processSelectedKeysOptimized in     ''
|    466 | processSelectedKeys in     ''
|    438 | run       in     ''
|    140 | run . . . in io.netty.util.concurrent.SingleThreadEventExecutor$2
|    144 | run       in io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator
^    744 | run . . . in java.lang.Thread
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/641
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/642
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/643
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/644
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
It's not possible to encapsulate logic to work with fields in LiveObject proxied object.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/645
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/646
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When using RedissonSetCache.add(value, ttl, unit) method, TTL is not updated if the element is already in the set. I think the problem is in the addAsync(value, ttl, unit) method, in the script passed to redis:
"local expireDateScore = redis.call('zscore', KEYS[1], ARGV[3]); "
+ "if expireDateScore ~= false and tonumber(expireDateScore) > tonumber(ARGV[1]) then "
+ "return 0;"
+ "end; " +
"redis.call('zadd', KEYS[1], ARGV[2], ARGV[3]); " +
"return 1; "
If I'm getting it right, when the element is not expired the script returns 0 without calling ZADD and updating the TTL. I would expect 'false' return code (according to Set interface), but also TTL to be updated.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/647
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/648
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/649
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/650
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/651
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/652
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/653
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/654
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/655
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/656
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
it's reproducible, my code is below.
RLock singlelock = redissonClient.getLock("lock2");
        RLock multilock1 = redissonClient.getLock("lock1");
        RLock multilock2 = redissonClient.getLock("lock2");
        RLock multilock3 = redissonClient.getLock("lock3");

        singlelock.forceUnlock();
        multilock1.forceUnlock();
        multilock2.forceUnlock();
        multilock3.forceUnlock();

        Thread t = new Thread(() -> {
            try {
                boolean singlelock_result = singlelock.tryLock(10,300, TimeUnit.SECONDS);
                System.out.println(Thread.currentThread().getId() + " single lock result : " + singlelock_result);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        });
        t.start();
        Thread.sleep(5000);

        RedissonRedLock redlock = new RedissonRedLock(multilock1,multilock2,multilock3);
        boolean redlock_result = redlock.tryLock(5,300, TimeUnit.SECONDS);
        System.out.println(Thread.currentThread().getId() + " multi lock result : " + redlock_result);

redlock lock result will be success, but when I check redis, I found the multi locks belong to different thread.
like:
lock1 : 8d3c3d43-03b0-4cd8-8966-8bbd088f8c58:1
lock2 : 8d3c3d43-03b0-4cd8-8966-8bbd088f8c58:29
lock3 : 8d3c3d43-03b0-4cd8-8966-8bbd088f8c58:1
I did more test and found:

if the single lock is the first of redlock, it's ok.
when I move multilock2 to first position ,it will return false correctly.
the code below

RedissonRedLock redlock = new RedissonRedLock(multilock2,multilock1,multilock3);
boolean redlock_result = redlock.tryLock(5,300, TimeUnit.SECONDS);


if there are just 2 multi locks, it's ok.
the code below will return false.

RedissonRedLock redlock = new RedissonRedLock(multilock1,multilock2);
boolean redlock_result = redlock.tryLock(5,300, TimeUnit.SECONDS);

I am wondering if it is a bug or not?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/657
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
127.0.0.1:6379> lpush name li lee zhang si
(integer) 4
127.0.0.1:6379> lrange name 0 -1

"si"
"zhang"
"lee"
"li"
127.0.0.1:6379>

RedissonClient redisson = Redisson.create(config);
RList list = redisson.getList("name");
ListIterator iterator = list.listIterator();
while(iterator.hasNext()){
System.out.println(iterator.next());
}
Exception in thread "main" org.redisson.client.RedisException: Unexpected exception while processing command
at org.redisson.command.CommandAsyncService.convertException(CommandAsyncService.java:305)
at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:150)
at org.redisson.RedissonObject.get(RedissonObject.java:55)
at org.redisson.RedissonList.getValue(RedissonList.java:301)
at org.redisson.RedissonList$1.hasNext(RedissonList.java:470)
at com.omniprimeinc.redis.RedisList.main(RedisList.java:18)
Caused by: com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'si': was expecting ('true', 'false' or 'null')
at [Source: io.netty.buffer.ByteBufInputStream@3c130745; line: 1, column: 5]
at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1586)
at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:521)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/658
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/659
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/660
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Looks funny! Thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/661
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello!
Will it be a big effort to support java.util.LinkedHashSet-like behavior in one of redisson data structures?
Basically what I need is a collection with element uniqueness and preserved insertion order.
Would be happy to contribute as well, but I would need some guidance or example where to start from.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/662
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/663
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redis use  Sentinel when switch master slave  where cause it
2016-10-11 19:10:26.625 WARN  o.r.c.SentinelConnectionManager.onNodeDown:272 master: 10.116.192.13:7091 has down
2016-10-11 19:10:27.666 WARN  o.r.c.SentinelConnectionManager.slaveDown:286 slave: 10.116.192.13:7091 has down
2016-10-11 19:10:42.937 WARN  o.r.c.SentinelConnectionManager.slaveDown:286 slave: 10.116.192.13:7091 has down
2016-10-11 19:12:18.385 WARN  i.n.c.DefaultChannelPipeline.warn:151 An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
org.redisson.client.RedisConnectionException: MasterConnectionPool exhausted!  Disconnected hosts: [10.25.63.47/10.25.63.47:7091]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/664
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi!
First off, thank you for this awesome library! :)
I've noticed a potential bug with Live Objects IDs. It is caused by the calls to isGetter and isSetter in the intercept() method of the AccessorInterceptor class (lines 102-108):
if (isGetter(method, getREntityIdFieldName(me))) {
    return ((RLiveObject) me).getLiveObjectId();
}

if (isSetter(method, getREntityIdFieldName(me))) {
    ((RLiveObject) me).setLiveObjectId(args[0]);
    return null;
}

These helper methods only compare prefix and suffix of method name. For example, this means that an @RId field named Id is overwritten by a call to  setSomeOtherId.
As a workaround, I avoid naming things get...Id and set...Id for now :)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/665
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/666
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/667
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
under heavy load we experience a NPE in the CommandDecoder sometimes [1]. Do you have a guess about what could be going wrong here?
Thanks.
Cheers,
Philipp
[1]
An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
io.netty.handler.codec.DecoderException: java.lang.NullPointerException
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:422) [74:io.netty.codec:4.1.1.Final]
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:248) [74:io.netty.codec:4.1.1.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [79:io.netty.transport:4.1.1.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:334) [79:io.netty.transport:4.1.1.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:326) [79:io.netty.transport:4.1.1.Final]
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) [79:io.netty.transport:4.1.1.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [79:io.netty.transport:4.1.1.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:334) [79:io.netty.transport:4.1.1.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:326) [79:io.netty.transport:4.1.1.Final]
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1320) [79:io.netty.transport:4.1.1.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [79:io.netty.transport:4.1.1.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:334) [79:io.netty.transport:4.1.1.Final]
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:905) [79:io.netty.transport:4.1.1.Final]
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:123) [79:io.netty.transport:4.1.1.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:563) [79:io.netty.transport:4.1.1.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:504) [79:io.netty.transport:4.1.1.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:418) [79:io.netty.transport:4.1.1.Final]
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:390) [79:io.netty.transport:4.1.1.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:742) [76:io.netty.common:4.1.1.Final]
at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:145) [76:io.netty.common:4.1.1.Final]
at java.lang.Thread.run(Thread.java:745) [?:?]
Caused by: java.lang.NullPointerException
at org.redisson.client.handler.CommandDecoder.selectDecoder(CommandDecoder.java:397) ~[275:redisson:2.2.24]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:269) ~[275:redisson:2.2.24]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:110) ~[275:redisson:2.2.24]
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:367) ~[74:io.netty.codec:4.1.1.Final]
... 20 more
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/668
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is it safe to exclude the byte-buddy dependency, or is it required at runtime?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/669
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
From Gitter user @cdeszaq:

Wanting to keep memory usage within my app as low as possible. We're getting large collection-like responses from a backend system, processing them "item" at a time, and we want to be able to cache that response in a streamy way
Needs to keep memory low are many concurrent requests, large collections of things processed a streamy way, and we're hitting issues with OOM due to having large strings flying around
It's a CSV response from a back-end webservice, so we process it in a streamy way, but it'll easily get to sizes of 100MB for each response, and we often have to have 30+ of these responses being processed at once. We process it 1 row at a time within our code to keep memory low, but hit OOM when we go to/from our current caching layer because it converts to/from massive strings
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/670
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
when redis unlock publish the message,where is deal with the message and release semaphore?I can't find
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/671
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When restarting the Redis server all connection threads logged the following exception.
2016-10-18 12:45:59,686 ERROR [redisson-netty-1-1] (org.redisson.client.handler.CommandsQueue) Exception occured. Channel: [id: 0xa23d4302, L:0.0.0.0/0.0.0.0:42732 ! R:xxxxxxxxxxxxxx]
java.lang.NullPointerException: null
    at org.redisson.client.handler.ConnectionWatchdog.reconnect(ConnectionWatchdog.java:88) ~[redisson-2.5.0.jar:?]
    at org.redisson.client.handler.ConnectionWatchdog.channelInactive(ConnectionWatchdog.java:75) ~[redisson-2.5.0.jar:?]
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:251) [netty-transport-4.0.42.Final.jar:4.0.42.Final]
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:237) [netty-transport-4.0.42.Final.jar:4.0.42.Final]
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:230) [netty-transport-4.0.42.Final.jar:4.0.42.Final]
    at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1289) [netty-transport-4.0.42.Final.jar:4.0.42.Final]

After the connection "interruption" the application starts logging the following..
2016-10-18 13:10:34,676 ERROR [globalEventExecutor-2-1] (org.redisson.connection.ElasticacheConnectionManager) Command execution timeout for xxxxxxxxxxxx
org.redisson.client.RedisTimeoutException: Command execution timeout for xxxxxxxxxxx
    at org.redisson.client.RedisConnection.await(RedisConnection.java:126) ~[redisson-2.5.0.jar:?]
    at org.redisson.client.RedisConnection.sync(RedisConnection.java:158) ~[redisson-2.5.0.jar:?]
    at org.redisson.client.RedisConnection.sync(RedisConnection.java:144) ~[redisson-2.5.0.jar:?]
    at org.redisson.connection.ElasticacheConnectionManager$1.run(ElasticacheConnectionManager.java:134) [redisson-2.5.0.jar:?]
    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_102]
    at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:126) [netty-common-4.0.42.Final.jar:4.0.42.Final]
    at io.netty.util.concurrent.GlobalEventExecutor$TaskRunner.run(GlobalEventExecutor.java:237) [netty-common-4.0.42.Final.jar:4.0.42.Final]
    at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144) [netty-common-4.0.42.Final.jar:4.0.42.Final]
    at java.lang.Thread.run(Thread.java:745) [?:1.8.0_102]

The host resolves to the same IP so that isn't a problem and I am able to telnet and issue the replication command without problems (immediate response)..
Escape character is '^]'.
INFO replication
$178
# Replication
role:master
connected_slaves:0
master_repl_offset:0
repl_backlog_active:0
repl_backlog_size:1048576
repl_backlog_first_byte_offset:0
repl_backlog_histlen:0
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/672
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for an attempt, but such fix would be wrong. setMasterAddress, addSlaveAddress method should be called before init(this.config); line.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/673
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/674
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I use 1000 mutliple thread to test the list operation. the costTime is average 1000~2000ms. But when single thread it costs 1ms.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/675
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
<dependency>
    <groupId>org.redisson</groupId>
    <artifactId>redisson</artifactId>
    <version>2.4.0</version>
</dependency>

java:
Config config = new Config();
        config.useSentinelServers()
               .setMasterName("mymaster")
               .addSentinelAddress("192.168.109.5:26379");
        RedissonClient redisson = Redisson.create(config);

Exception in thread "main" org.redisson.client.RedisConnectionException: Can't init enough connections amount! Only 0 from 5 were initialized. Server: /127.0.0.1:6380
at org.redisson.connection.pool.ConnectionPool$2.operationComplete(ConnectionPool.java:120)
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:514)
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:488)
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:427)
at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:129)
at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:75)
at org.redisson.connection.pool.ConnectionPool.promiseFailure(ConnectionPool.java:257)
at org.redisson.connection.pool.ConnectionPool.access$200(ConnectionPool.java:51)
at org.redisson.connection.pool.ConnectionPool$3.operationComplete(ConnectionPool.java:221)
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:514)
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:488)
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:427)
at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:129)
at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:75)
at org.redisson.connection.ClientConnectionsEntry$1.operationComplete(ClientConnectionsEntry.java:149)
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:514)
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:488)
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:427)
at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:129)
at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:75)
at org.redisson.client.RedisClient$2$2.run(RedisClient.java:159)
at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:408)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:441)
at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
at java.lang.Thread.run(Thread.java:745)
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: no further information: /127.0.0.1:6380
at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:628)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:552)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:466)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:438)
... 3 more
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/676
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
see http://redis.io/commands/client-reply. probably most AWS users are still on 2.8 as 3.2 has just made available, so it might make sense to document this on the API.
ImmediateEventExecutor$ImmediatePromise@241ecb4(failure: org.redisson.client.RedisException: ERR Syntax error, try CLIENT (LIST | KILL ip:port | GETNAME | SETNAME connection-name). channel: [id: 0xb4ff98ef, L:/127.0.0.1:54955 - R:localhost/127.0.0.1:6379] command: CommandData [promise=org.redisson.misc.RedissonPromise@6e2742ee, command=(CLIENT REPLY), params=[ON], codec=null])
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/677
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello,
I am using Redisson library version 2.2.4. I have the following settings configured for when I want to create a Redisson Client object for connecting to the datastore.
"elasticacheServersConfig": {
    "nodeAddresses": [
          "//XXX.001.cache.amazonaws.com:6379",
          "//XXX.002.cache.amazonaws.com:6379"
     ],
    "timeout": 3000
}

As you can see from the above settings I am setting the timeout explicitly to be 3 seconds. But I am seeing exceptions in the log which says mentions 1 second timeout. Here is the exception,
error: org.redisson.client.RedisTimeoutException: Redis server response timeout (1000 ms) occured for command: (GET) with params: [XXXXX] channel: [id: 0x002202e0, L:/172.17.0.160:43221 - R://XXX.002.cache.amazonaws.com/10.169.226.201:6379]
        at org.redisson.command.CommandAsyncService$10.run(CommandAsyncService.java:528)
        at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:588)
        at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:662)
        at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:385)
        at java.lang.Thread.run(Thread.java:745)

I am wondering how is this is possible? Also I think there is also auto-retry feature in Redisson, which defaults to 3 attempts. Then why would this happen?
Can I provide some more info to debug this issue?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/678
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/679
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hey, I experienced two more NPE if I am using Redisson under load. Do you have an idea what might be the problem? Thx Philipp
2016-10-25T08:24:20,935 | WARN | LABS | i-5a270ba2 | 2016.0.0.426 | valid_b5099182-52b6-b069-65c6-65fd8b26d7a9 | XXX-Redis-Autobahn-1-2 | io.netty.channel.DefaultChannelPipeline | 2016-10-25T08:23:13,631_twoUserCollaborate_80c54f49-768d-2eee-bcd5-45d1337684b1 | An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception. io.netty.handler.codec.DecoderException: java.lang.NullPointerException at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:422) [78:io.netty.codec:4.1.6.Final] at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:248) [78:io.netty.codec:4.1.6.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:373) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:351) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:373) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:351) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1334) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:373) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:926) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:129) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:651) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:574) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:488) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:450) [83:io.netty.transport:4.1.6.Final] at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:873) [80:io.netty.common:4.1.6.Final] at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144) [80:io.netty.common:4.1.6.Final] at java.lang.Thread.run(Thread.java:745) [?:?] Caused by: java.lang.NullPointerException at org.redisson.client.handler.CommandDecoder.selectDecoder(CommandDecoder.java:414) ~[285:redisson:2.4.0] at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:280) ~[285:redisson:2.4.0] at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:118) ~[285:redisson:2.4.0] at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:367) ~[78:io.netty.codec:4.1.6.Final] ... 20 more
and
2016-10-25T08:24:28,370 | WARN | LABS | i-af1e993c | 2016.0.0.426 | valid_0418a877-2e5f-ea68-18d6-76def289edbe | XXX-Redis-Autobahn-1-2 | io.netty.channel.DefaultChannelPipeline | 2016-10-25T08:23:13,631_twoUserCollaborate_1f6eab22-4072-5c98-9e8e-12accb75d2cf | An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception. io.netty.handler.codec.DecoderException: java.lang.NullPointerException at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:422) [78:io.netty.codec:4.1.6.Final] at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:248) [78:io.netty.codec:4.1.6.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:373) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:351) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:373) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:351) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1334) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:373) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:926) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:129) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:651) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:574) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:488) [83:io.netty.transport:4.1.6.Final] at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:450) [83:io.netty.transport:4.1.6.Final] at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:873) [80:io.netty.common:4.1.6.Final] at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144) [80:io.netty.common:4.1.6.Final] at java.lang.Thread.run(Thread.java:745) [?:?] Caused by: java.lang.NullPointerException at org.redisson.client.handler.CommandDecoder.selectDecoder(CommandDecoder.java:414) ~[285:redisson:2.4.0] at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:280) ~[285:redisson:2.4.0] at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:118) ~[285:redisson:2.4.0] at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:367) ~[78:io.netty.codec:4.1.6.Final] ... 20 more
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/680
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Connection pool should wait for free connection instead of throwing pool exhausted error. This improves command handling performance.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/681
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Amazon has announced new version of ElastiCache with Redis Cluster support. Redisson should be checked for proper work with it.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/682
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
we sometimes run into OutOfMemoryException while Redisson is trying to log a warning, since it includes the content in the log message [1]. Would it be possible to check for the instance type and in case of byte[] just log something else? I.e.
log.warn("response has been skipped due to timeout! channel: {}, command: {}, result: {}", channel, data, result instanceof byte[] ? result.hashCode() : result);
Or omit the content in the WARN-log and do a second INFO-log containing the data. So you can toggle this via the log level?
log.warn("response has been skipped due to timeout! channel: {}, command: {}", channel, data); log.info("skipped response data for timeout {}", result); 
From what I can see that's the only place where large content might be locked, though I am not sure about the log.error in CommandDecoder#decode, as it is using the CommandData.toString() content.
Thanks,
Philipp
[1]
An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception. io.netty.handler.codec.DecoderException: java.lang.OutOfMemoryError: Java heap space at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:422) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:248) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:373) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:351) at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:373) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:351) at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1334) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:373) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:926) at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:1018) at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:402) at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:307) at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:873) at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144) at java.lang.Thread.run(Thread.java:745) Caused by: java.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:3332) at java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:124) at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:448) at java.lang.StringBuilder.append(StringBuilder.java:136) at org.slf4j.helpers.MessageFormatter.byteArrayAppend(MessageFormatter.java:342) at org.slf4j.helpers.MessageFormatter.deeplyAppendParameter(MessageFormatter.java:276) at org.slf4j.helpers.MessageFormatter.arrayFormat(MessageFormatter.java:227) at org.ops4j.pax.logging.slf4j.Slf4jLogger.warn(Slf4jLogger.java:715) at org.redisson.client.handler.CommandDecoder.handleResult(CommandDecoder.java:384) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:283) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:125) at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:367) ... 18 more
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/683
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I have a thread stuck in the CommandAsyncService#get() indefinitely waiting for the CountdownLatch. I don't have a particular repro case but this happens every once in a while on our servers (under load). Redis itself is still delivering events and the instance receives objects on other threads as well.
Would it make sense instead of waiting indefinitely on the latch to only wait as long as the timeout is configured (as a safe belt) and abort the action if there hasn't been any success/failure by then?
Cheers,
Philipp
Redisson-Version: 3.0.0
Redis-Server: ElasticCache w/ engine 3.2.4
Redis-Config: SingleServerConfig w/ mostly the default values
java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for  <0x000000031c2237d0> (a java.util.concurrent.CountDownLatch$Sync) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836) at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997) at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304) at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231) at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:133) at org.redisson.RedissonObject.get(RedissonObject.java:55) at org.redisson.RedissonBucket.get(RedissonBucket.java:91)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/684
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In our micro services system, we use RTopic process messages between services. In the onMessage method, I need to get data from redis, or set data. But in the test env, when it got or set data from/to redis, there ware always timeout errors (maybe one error for 2 tests). When I commented the code, no more errors.
So, is there any handling time limitation in onMessage method for RTopic? Or any limitation to interact with redis in onMessage method?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/685
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I add schedule job and cron quartz expression,but it' not exectue.
<dependency>
	<groupId>org.redisson</groupId>
	<artifactId>redisson</artifactId>
	<version>2.4.0</version>
</dependency>

public class ParentTask implements Runnable {
    
    @RInject
    private RedissonClient redissonClient;

    @Override
    public void run() {
        System.out.println("execute parent task");
    }
    
    public static void main(String[] args) {
        Config config = new Config();
        config.useSingleServer().setPassword("redhat").setAddress("192.168.109.5:6379");
        RedissonClient redisson = Redisson.create(config);
        RScheduledExecutorService executorService = redisson.getExecutorService("parentTask");
        executorService.schedule(new ParentTask(), CronSchedule.of("0/5 * * * * ?"));
    }
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/686
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Fix message at https://github.com/redisson/redisson/blob/master/redisson/src/main/java/org/redisson/connection/MasterSlaveConnectionManager.java#L677
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/687
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
This is a proposal for the issue. Tbh I don't know if this is overengineered and it might just be ok to check for byte[] and Strings and limit these in their size :)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/688
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello,
I haven't found an explanation about how to upload pure array of bytes. Redisson has a RBitSet but it manages an array of bits not bytes. How to store a byte array by using Redisson?
Here is my configuration:
Config config = new Config();

LoadBalancer loadBalancer = new RoundRobinLoadBalancer();

config.useClusterServers()
        .setScanInterval(5000) // cluster state scan interval in milliseconds
        .addNodeAddress("192.168.0.14:6379", "192.168.0.15:6379")
        .setReadMode(ReadMode.MASTER_SLAVE)
        .setLoadBalancer(loadBalancer)
        .setPassword("bTFBx1NYYWRMTUEyNHhsCg")
        .setSlaveConnectionPoolSize(10)
        .setMasterConnectionPoolSize(10);

RedissonClient redisson = Redisson.create(config);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/689
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Sorry, I don't see any changes
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/690
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have two schedule job parent and children,the children depend on parent job.when parent job done,then  the children job execute.but the children can not execute
public class ParentTask implements Runnable {
    
    @RInject
    private RedissonClient redissonClient;

    @Override
    public void run() {
        System.out.println("execute parent task");
        RTopic<String> topic = redissonClient.getTopic("topic");
        topic.publish("complete");
    }
    
}


public class SubTask implements Runnable {
    
    @RInject
    private RedissonClient redissonClient;
    
    @Override
    public void run() {
        RTopic<String> topic = redissonClient.getTopic("topic");
        topic.addListener(new MessageListener<String>() {
            @Override
            public void onMessage(String channel, String message) {
                System.out.println("receive message : " + message);
                System.out.println("execute sub task");
            }
        });
    }
}

 public static void main(String[] args) {
        // Redisson程序化配置代码
        Config config = new Config();
        config.useSingleServer().setPassword("redhat").setAddress("192.168.109.5:6379");
        RedissonClient redisson = Redisson.create(config);
        
       
        // Redisson Node 程序化配置方法
        RedissonNodeConfig nodeConfig = new RedissonNodeConfig(config);
        Map<String, Integer> workers = new HashMap<String, Integer>();
        workers.put("parentjob", 1);
        workers.put("subjob", 1);
        nodeConfig.setExecutorServiceWorkers(workers);
        
        // 创建一个Redisson Node实例
        RedissonNode node = RedissonNode.create(nodeConfig);
//        
        node.start();
        RScheduledExecutorService executorParent = redisson.getExecutorService("parentjob");
        executorParent.schedule(new ParentTask(), CronSchedule.of("0/10 * * * * ?"));
   
        RScheduledExecutorService executorSub = redisson.getExecutorService("subjob");
        executorSub.schedule(new SubTask(), CronSchedule.of("0/2 * * * * ?"));
        
       // node.shutdown();
    }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/691
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/692
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have experienced some NullPointerExceptions in the CommandDecoder (besides the ones reported in #667.  In the handleResult method is a check if data is null so I guess there are situations where this can be null. In the bottom of the method where the NPE occurs the check is missing though. Should this be checked as well? I am using Redisson 3.0.0.
2016-11-04T00:01:09,935 | WARN | LABS | i-5dc2f5a5 | 1.0.0.0 | valid_0835907a-bf24-79f0-26e5-779d69317af6 | XXXX | io.netty.channel.DefaultChannelPipeline | 2016-11-03T09:59:13,694_twoUserCollaborate_b3a2aa58-bd2a-41de-c3d7-e41512e75e7a | An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
io.netty.handler.codec.DecoderException: java.lang.NullPointerException
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:422)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:248)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:373)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:351)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:373)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:351)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1334)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:373)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:926)
at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:1018)
at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:402)
at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:307)
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:873)
at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NullPointerException
at org.redisson.client.handler.CommandDecoder.handleResult(CommandDecoder.java:384)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:232)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:119)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:367)
... 18 more
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/693
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
If you run the JUnit tests for Redisson a lot of client and their associated connections/threads are leaking because they are not properly shutdown. This will prevent the build to be successful on system with limited number of user-processes/open-files (i.e. MacOS El Capitain).
To verify this, build the project with an attached debugger and watch the constantly growing amount of threads.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/694
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Please don't merge yet. The first upload is just a preview for now and I would like to add some annotations first since this is a lot of changed files =)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/695
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In case when queue consumers in different parts of network: some of them closer to redis and some farther.
"Farther" consumers will get lower amount of messages from queue due to network delays. In turn "closer" consumers will get higher amount and this could lead to client overloading.
Blocking queue with fair polling and guarantees access order for poll and take methods and allows to get uniformly distributed consumption by clients.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/696
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/697
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for pointed out!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/698
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/699
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/700
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Address like 192.168.234.129:7001@17001 should be converted to 192.168.234.129:7001
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/701
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/702
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In the below code snippet , can the cache name use wildcard . for example '*'
Map<String, CacheConfig> _config = Maps.newHashMap();
 _config.put("cache*", new CacheConfig(1000 * 60 * 10, 0));
 return new RedissonSpringCacheManager(redissonClient, _config);
when i write '*' in the code, but donot effective
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/703
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/704
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/705
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/706
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Could be attached to destination queue only. All elements are inserted with transfer delay to destination queue.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/707
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/708
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
十一月 15, 2016 1:47:28 下午 io.netty.util.concurrent.DefaultPromise notifyListener0
警告: An exception was thrown by org.redisson.cluster.ClusterConnectionManager$4.operationComplete()
java.util.concurrent.RejectedExecutionException: event executor terminated
at io.netty.util.concurrent.SingleThreadEventExecutor.reject(SingleThreadEventExecutor.java:805)
at io.netty.util.concurrent.SingleThreadEventExecutor.offerTask(SingleThreadEventExecutor.java:345)
at io.netty.util.concurrent.SingleThreadEventExecutor.addTask(SingleThreadEventExecutor.java:338)
at io.netty.util.concurrent.SingleThreadEventExecutor.execute(SingleThreadEventExecutor.java:748)
at io.netty.util.concurrent.AbstractScheduledEventExecutor.schedule(AbstractScheduledEventExecutor.java:190)
at io.netty.util.concurrent.AbstractScheduledEventExecutor.schedule(AbstractScheduledEventExecutor.java:134)
at org.redisson.client.RedisConnection.async(RedisConnection.java:179)
at org.redisson.client.RedisConnection.async(RedisConnection.java:170)
at org.redisson.client.RedisConnection.async(RedisConnection.java:162)
at org.redisson.cluster.ClusterConnectionManager.updateClusterState(ClusterConnectionManager.java:361)
at org.redisson.cluster.ClusterConnectionManager.access$900(ClusterConnectionManager.java:60)
at org.redisson.cluster.ClusterConnectionManager$4.operationComplete(ClusterConnectionManager.java:355)
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:514)
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:488)
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:427)
at io.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:170)
at org.redisson.misc.RedissonPromise.addListener(RedissonPromise.java:85)
at org.redisson.misc.RedissonPromise.addListener(RedissonPromise.java:34)
at org.redisson.cluster.ClusterConnectionManager.checkClusterState(ClusterConnectionManager.java:345)
at org.redisson.cluster.ClusterConnectionManager.access$800(ClusterConnectionManager.java:60)
at org.redisson.cluster.ClusterConnectionManager$3.run(ClusterConnectionManager.java:331)
at io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38)
at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:120)
at io.netty.util.concurrent.GlobalEventExecutor$TaskRunner.run(GlobalEventExecutor.java:237)
at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
at java.lang.Thread.run(Unknown Source)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/709
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
is there still any interest in the PR?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/710
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We started using redis hash for our logged in user session data, and I am having trouble getting a simple map of string key/vals.  I made a little test, where I create the same hash map in java/redisson and in PHP, and I am getting errors when I try to read the map that was created in our PHP application.
This is what they look like via rediscli:
127.0.0.1:6379> type test_string_map
hash
127.0.0.1:6379> type web:test_string_map
hash

127.0.0.1:6379> hgetall test_string_map
1) "\"key1\""
2) "\"stringval1\""
3) "\"key2\""
4) "\"50\""

127.0.0.1:6379> hgetall web:test_string_map
1) "key1"
2) "stringval1"
3) "key2"
4) "50"

Example that triggeres the warning:
# test RMap created in redisson (reads/writes fine)
RMap<String, String> testStringMap = redissonClient.getMap("test_string_map");
testStringMap.put("key1", "stringval1");
testStringMap.put("key2", "50");

# error trying to read hash map created in PHP
RMap<String, String> webStringMap = redissonClient.getMap("web:test_string_map");

# ExceptionCaught() event warning in log triggered when I call redissonClient.getMap()

10:19:12,542 11-18-2016 [WARN ] io.netty.channel.DefaultChannelPipeline::warn:151()
An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.

io.netty.handler.codec.DecoderException: java.lang.NullPointerException
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:422) ~[rt.runnable.ej.build.30.jar:?]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:248) ~[rt.runnable.ej.build.30.jar:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367) [rt.runnable.ej.build.30.jar:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353) [rt.runnable.ej.build.30.jar:?]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346) [rt.runnable.ej.build.30.jar:?]
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) [rt.runnable.ej.build.30.jar:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367) [rt.runnable.ej.build.30.jar:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353) [rt.runnable.ej.build.30.jar:?]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346) [rt.runnable.ej.build.30.jar:?]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294) [rt.runnable.ej.build.30.jar:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367) [rt.runnable.ej.build.30.jar:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353) [rt.runnable.ej.build.30.jar:?]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911) [rt.runnable.ej.build.30.jar:?]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131) [rt.runnable.ej.build.30.jar:?]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:652) [rt.runnable.ej.build.30.jar:?]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575) [rt.runnable.ej.build.30.jar:?]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489) [rt.runnable.ej.build.30.jar:?]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451) [rt.runnable.ej.build.30.jar:?]
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140) [rt.runnable.ej.build.30.jar:?]
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144) [rt.runnable.ej.build.30.jar:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_101]
Caused by: java.lang.NullPointerException
	at org.redisson.client.handler.CommandDecoder.handleResult(CommandDecoder.java:384) ~[rt.runnable.ej.build.30.jar:?]
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:284) ~[rt.runnable.ej.build.30.jar:?]
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:119) ~[rt.runnable.ej.build.30.jar:?]
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:367) ~[rt.runnable.ej.build.30.jar:?]
	... 20 more

When I try to retrieve a redis hash with redisson that originated in our PHP application (via Predis), I get that exception and I am unable to read that hash map from PHP key: "web:test_string_map"
Is there a way to handle cases like these?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/711
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/712
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/713
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/714
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Introduce task objects instead of methods
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/715
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Not really an issue per say, more of a clarification really.  I'm about to launch a new feature that will be making use of the expires for individual entries in RMapCache and RSetCache, and I was wondering how that works regarding restarting the Java process that created/set it.  Will they be expired on shutdown, not touched at all and the expire is lost?
Just want to be sure of what is expected when I restart my Java service.
Thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/716
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Poll method blocks infinitely if timeout specified during invocation less than 1 second
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/717
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/718
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/719
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/720
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/721
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/722
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/723
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/724
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/725
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/726
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/727
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/728
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/729
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/730
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/731
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/732
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/733
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/734
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/735
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/736
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/737
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/738
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/739
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/740
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/741
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/742
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/743
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/744
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/745
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/746
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/747
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/748
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/749
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/750
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/751
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/752
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/753
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/754
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/755
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/756
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/757
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/758
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/759
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/760
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/761
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/762
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/763
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/764
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/765
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/766
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/767
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/768
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/769
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/770
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/771
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/772
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/773
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/774
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/775
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/776
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/777
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/778
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/779
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/780
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/781
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/782
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/783
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/784
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/785
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/786
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/787
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/788
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/789
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/790
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/791
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/792
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/793
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/794
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/795
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/796
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/797
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/798
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/799
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/800
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/801
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/802
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/803
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/804
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/805
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/806
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/807
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/808
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/809
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/810
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/811
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/812
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/813
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/814
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/815
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/816
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/817
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/818
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/819
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/820
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/821
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/822
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/823
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/824
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/825
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/826
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/827
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/828
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/829
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/830
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/831
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/832
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/833
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/834
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/835
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/836
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/837
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/838
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/839
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/840
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/841
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/842
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/843
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/844
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/845
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/846
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/847
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/848
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
org/redisson/spring/support/redisson-1.0.xsd
line 780:    <xsd:attribute name="database" type="xsd:int">
It will  be wrong like this:
<redisson:single-server address="${redisson.address}" database="${redisson.dbid}"></redisson:single-server>
Is it?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/849
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I think there is some bug in [RedissonCacheMap.putIfAbsentAsync].
    @Override
    public RFuture<V> putIfAbsentAsync(K key, V value, long ttl, TimeUnit ttlUnit, long maxIdleTime, TimeUnit maxIdleUnit) {
        .......
        .......
        .......
        return commandExecutor.evalWriteAsync(getName(key), codec, EVAL_PUT_TTL,
                      "if redis.call('hexists', KEYS[1], ARGV[4]) == 0 then "
                        + "if tonumber(ARGV[1]) > 0 then "
                            + "redis.call('zadd', KEYS[2], ARGV[1], ARGV[4]); "
                        + "end; "
                        + "if tonumber(ARGV[2]) > 0 then "
                            + "redis.call('zadd', KEYS[3], ARGV[2], ARGV[4]); "
                        + "end; "
                        + "local value = struct.pack('dLc0', ARGV[3], string.len(ARGV[5]), ARGV[5]); "
                        + "redis.call('hset', KEYS[1], ARGV[4], value); "
                        + "return nil; "
                    + "else "
                        + "local value = redis.call('hget', KEYS[1], ARGV[4]); "
                        + "if value == false then "
                            + "return nil; "
                        + "end;"
                        + "local t, val = struct.unpack('dLc0', value); "
                        + "return val; "
                    + "end",
                Arrays.<Object>asList(getName(key), getTimeoutSetNameByKey(key), getIdleSetNameByKey(key)), ttlTimeout, maxIdleTimeout, maxIdleDelta, key, value);
    }

And I made this test code.
    @Test
    public void testPutIfAbsent() throws Exception {
        RMapCache<SimpleKey, SimpleValue> map = redisson.getMapCache("simple");
        SimpleKey key = new SimpleKey("1");
        SimpleValue value = new SimpleValue("2");
        map.put(key, value);
        Assert.assertEquals(value, map.putIfAbsent(key, new SimpleValue("3"), 1, TimeUnit.SECONDS));
        Assert.assertEquals(value, map.get(key));

        map.putIfAbsent(new SimpleKey("4"), new SimpleValue("4"), 1, TimeUnit.SECONDS);
        Assert.assertEquals(new SimpleValue("4"), map.get(new SimpleKey("4")));

        Thread.sleep(1000);

        Assert.assertNull(map.get(new SimpleKey("4")));
        
        //
        // this should be passed, but fail
        map.putIfAbsent(new SimpleKey("4"), new SimpleValue("4"), 1, TimeUnit.SECONDS);
        Assert.assertEquals(new SimpleValue("4"), map.get(new SimpleKey("4")));
        //
        // 

        SimpleKey key1 = new SimpleKey("2");
        SimpleValue value1 = new SimpleValue("4");
        Assert.assertNull(map.putIfAbsent(key1, value1, 2, TimeUnit.SECONDS));
        Assert.assertEquals(value1, map.get(key1));
    }

This test should be passed, but failed.
As you can see, there is no code for checking ttl or idle time in [putIfAbsentAsync] method,
not like [getAsync] or [fastPutIfAbsent] I have added.
If it's alright, I'm ready to PR to fix it.
Please verify whethrer my found is right.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/850
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The redisson JSR107 org.redisson.jcache.JCache implementation throws exception like org.redisson.client.RedisException. According to the JSR107 specification this exception should be wrapped into javax.cache.CacheException . This way when interchanging cache implementation one can expect same error handling.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/851
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I did not see previously that master branch also has the same issue and same fix needs to be applied there
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/852
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Actuator is an optional feature in Spring Boot, there are a lot of projects that do not use actuator due to additional dependencies and complexity.
Redisson 3.3.1 worked fine without actuator but 3.3.2 fails to start with ClassNotFoundException for org.springframework.boot.actuate.cache.CacheStatisticsProvider.
Suggested change registers Redisson AutoConfiguration only if actuator is in the classpath
Pull request #851
That pull request is only for 3.0.0 but change changes apply for the master branch
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/853
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/854
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/855
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
With GEORADIUS | GEORADIUSBYMEMBER ... STORE key, Redis stores the result to the specified key, and returns the result size.
https://redis.io/commands/georadius
I see two ways to implement this into the Redisson API:

Add new radiusStore...() methods to RGeo and RGeoAsync, with a fromKey parameter. Search the Geo specified by fromKey, and store the result in this RGeo. This mirrors the API for intersecting and unioning sorted sets.

GEORADIUS fromKey ... STORE getName()


Add new radiusStore...() methods to RGeo and RGeoAsync, with a storeKey parameter. Search this Geo, and store the results in the Geo specified by storeKey. This is more straightforward to implement.

GEORADIUS getName() ... STORE storeKey

Which is preferred? Are there alternate suggestions? I vote for # 1.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/856
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Forgot to mention:

the commit aaf3166 also fixed a bug where slots were incorrectly allocated to slave nodes instead of only for masters.
SpringNamespaceTest.java is modified to demonstrate the capability of running a redis cluster with multiple masters with multiple slaves and as well as having multiple slave nodes connected to a slave.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/857
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/858
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Do Redisson  version 2.8.2 compatibly to jdk 1.6  ???
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/859
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
2017/04/21 23:28:43 12283  INFO redisson.Version:41 - Redisson 2.8.1
2017/04/21 23:28:43 12530  INFO pool.ConnectionPool$2$1:137 - 5 connections initialized for /192.168.0.121:7001
2017/04/21 23:28:43 12532 ERROR logging.Slf4JLogger:181 - Failed to submit a listener notification task. Event loop shut down?
2017/04/21 23:28:43 12535 ERROR logging.Slf4JLogger:181 - Failed to submit a listener notification task. Event loop shut down?
2017/04/21 23:28:43 12531  INFO pool.ConnectionPool$2$1:137 - 5 connections initialized for /192.168.0.121:7003
2017/04/21 23:28:43 12539 ERROR logging.Slf4JLogger:181 - Failed to submit a listener notification task. Event loop shut down?
2017/04/21 23:28:43 12545 ERROR logging.Slf4JLogger:181 - Failed to submit a listener notification task. Event loop shut down?
2017/04/21 23:28:43 12551 ERROR logging.Slf4JLogger:181 - Failed to submit a listener notification task. Event loop shut down?
2017/04/21 23:28:43 12555 ERROR logging.Slf4JLogger:181 - Failed to submit a listener notification task. Event loop shut down?
2017/04/21 23:28:43 12558 ERROR logging.Slf4JLogger:181 - Failed to submit a listener notification task. Event loop shut down?
2017/04/21 23:28:43 12561 ERROR logging.Slf4JLogger:181 - Failed to submit a listener notification task. Event loop shut down?
2017/04/21 23:28:43 12565 ERROR logging.Slf4JLogger:181 - Failed to submit a listener notification task. Event loop shut down?
2017/04/21 23:28:43 12568 ERROR logging.Slf4JLogger:181 - Failed to submit a listener notification task. Event loop shut down?
2017/04/21 23:28:43 12569  INFO cluster.ClusterConnectionManager$2$1$1:294 - master: redis://192.168.0.121:7001 added for slot ranges: [[5461-10922]]
2017/04/21 23:28:43 12572 ERROR logging.Slf4JLogger:181 - Failed to submit a listener notification task. Event loop shut down?
2017/04/21 23:28:43 12575 ERROR logging.Slf4JLogger:181 - Failed to submit a listener notification task. Event loop shut down?
2017/04/21 23:28:43 12577  INFO cluster.ClusterConnectionManager$2$1$1:294 - master: redis://192.168.0.121:7003 added for slot ranges: [[0-5460]]
2017/04/21 23:28:43 12579 ERROR logging.Slf4JLogger:181 - Failed to submit a listener notification task. Event loop shut down?
2017/04/21 23:28:43 12583 ERROR logging.Slf4JLogger:181 - Failed to submit a listener notification task. Event loop shut down?
2017/04/21 23:28:43 12586 ERROR logging.Slf4JLogger:181 - Failed to submit a listener notification task. Event loop shut down?
2017/04/21 23:28:43 12589 ERROR logging.Slf4JLogger:181 - Failed to submit a listener notification task. Event loop shut down?
2017/04/21 23:28:43 12593 ERROR logging.Slf4JLogger:181 - Failed to submit a listener notification task. Event loop shut down?
2017/04/21 23:28:43 12597 ERROR logging.Slf4JLogger:181 - Failed to submit a listener notification task. Event loop shut down?
2017/04/21 23:28:43 12600 ERROR logging.Slf4JLogger:181 - Failed to submit a listener notification task. Event loop shut down?
java.lang.StackOverflowError
at java.lang.ClassLoader.defineClass1(Native Method)
at java.lang.ClassLoader.defineClassCond(ClassLoader.java:631)
at java.lang.ClassLoader.defineClass(ClassLoader.java:615)
at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:141)
at org.apache.catalina.loader.WebappClassLoader.findClassInternal(WebappClassLoader.java:2944)
at org.apache.catalina.loader.WebappClassLoader.findClass(WebappClassLoader.java:1208)
at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1688)
at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1569)
at java.lang.ClassLoader.defineClass1(Native Method)
at java.lang.ClassLoader.defineClassCond(ClassLoader.java:631)
at java.lang.ClassLoader.defineClass(ClassLoader.java:615)
at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:141)
at org.apache.catalina.loader.WebappClassLoader.findClassInternal(WebappClassLoader.java:2944)
at org.apache.catalina.loader.WebappClassLoader.findClass(WebappClassLoader.java:1208)
at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1688)
at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1569)
at org.apache.log4j.spi.ThrowableInformation.getThrowableStrRep(ThrowableInformation.java:87)
at org.apache.log4j.spi.LoggingEvent.getThrowableStrRep(LoggingEvent.java:413)
at org.apache.log4j.WriterAppender.subAppend(WriterAppender.java:313)
at org.apache.log4j.WriterAppender.append(WriterAppender.java:162)
at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
at org.apache.log4j.Category.callAppenders(Category.java:206)
at org.apache.log4j.Category.forcedLog(Category.java:391)
at org.apache.log4j.Category.log(Category.java:856)
at org.slf4j.impl.Log4jLoggerAdapter.error(Log4jLoggerAdapter.java:571)
at io.netty.util.internal.logging.Slf4JLogger.error(Slf4JLogger.java:181)
at io.netty.util.concurrent.DefaultPromise.execute(DefaultPromise.java:673)
at io.netty.util.concurrent.DefaultPromise.access$400(DefaultPromise.java:32)
at io.netty.util.concurrent.DefaultPromise$LateListeners.run(DefaultPromise.java:850)
at io.netty.util.concurrent.ImmediateEventExecutor.execute(ImmediateEventExecutor.java:87)
at io.netty.util.concurrent.DefaultPromise.execute(DefaultPromise.java:671)
at io.netty.util.concurrent.DefaultPromise.access$400(DefaultPromise.java:32)
at io.netty.util.concurrent.DefaultPromise$LateListeners.run(DefaultPromise.java:850)
at io.netty.util.concurrent.ImmediateEventExecutor.execute(ImmediateEventExecutor.java:87)
at io.netty.util.concurrent.DefaultPromise.execute(DefaultPromise.java:671)
at io.netty.util.concurrent.DefaultPromise.access$400(DefaultPromise.java:32)
at io.netty.util.concurrent.DefaultPromise$LateListeners.run(DefaultPromise.java:850)
at io.netty.util.concurrent.ImmediateEventExecutor.execute(ImmediateEventExecutor.java:87)
at io.netty.util.concurrent.DefaultPromise.execute(DefaultPromise.java:671)
at io.netty.util.concurrent.DefaultPromise.access$400(DefaultPromise.java:32)
at io.netty.util.concurrent.DefaultPromise$LateListeners.run(DefaultPromise.java:850)
at io.netty.util.concurrent.ImmediateEventExecutor.execute(ImmediateEventExecutor.java:87)
at io.netty.util.concurrent.DefaultPromise.execute(DefaultPromise.java:671)
at io.netty.util.concurrent.DefaultPromise.access$400(DefaultPromise.java:32)
at io.netty.util.concurrent.DefaultPromise$LateListeners.run(DefaultPromise.java:850)
at io.netty.util.concurrent.ImmediateEventExecutor.execute(ImmediateEventExecutor.java:87)
at io.netty.util.concurrent.DefaultPromise.execute(DefaultPromise.java:671)
at io.netty.util.concurrent.DefaultPromise.access$400(DefaultPromise.java:32)
at io.netty.util.concurrent.DefaultPromise$LateListeners.run(DefaultPromise.java:850)
at io.netty.util.concurrent.ImmediateEventExecutor.execute(ImmediateEventExecutor.java:87)
at io.netty.util.concurrent.DefaultPromise.execute(DefaultPromise.java:671)
at io.netty.util.concurrent.DefaultPromise.access$400(DefaultPromise.java:32)
at io.netty.util.concurrent.DefaultPromise$LateListeners.run(DefaultPromise.java:850)
at io.netty.util.concurrent.ImmediateEventExecutor.execute(ImmediateEventExecutor.java:87)
at io.netty.util.concurrent.DefaultPromise.execute(DefaultPromise.java:671)
at io.netty.util.concurrent.DefaultPromise.access$400(DefaultPromise.java:32)
at io.netty.util.concurrent.DefaultPromise$LateListeners.run(DefaultPromise.java:850)
at io.netty.util.concurrent.ImmediateEventExecutor.execute(ImmediateEventExecutor.java:87)
at io.netty.util.concurrent.DefaultPromise.execute(DefaultPromise.java:671)
at io.netty.util.concurrent.DefaultPromise.access$400(DefaultPromise.java:32)
at io.netty.util.concurrent.DefaultPromise$LateListeners.run(DefaultPromise.java:850)
at io.netty.util.concurrent.ImmediateEventExecutor.execute(ImmediateEventExecutor.java:87)
at io.netty.util.concurrent.DefaultPromise.execute(DefaultPromise.java:671)
at io.netty.util.concurrent.DefaultPromise.access$400(DefaultPromise.java:32)
at io.netty.util.concurrent.DefaultPromise$LateListeners.run(DefaultPromise.java:850)
at io.netty.util.concurrent.ImmediateEventExecutor.execute(ImmediateEventExecutor.java:87)
at io.netty.util.concurrent.DefaultPromise.execute(DefaultPromise.java:671)
at io.netty.util.concurrent.DefaultPromise.access$400(DefaultPromise.java:32)
at io.netty.util.concurrent.DefaultPromise$LateListeners.run(DefaultPromise.java:850)
at io.netty.util.concurrent.ImmediateEventExecutor.execute(ImmediateEventExecutor.java:87)
at io.netty.util.concurrent.DefaultPromise.execute(DefaultPromise.java:671)
at io.netty.util.concurrent.DefaultPromise.access$400(DefaultPromise.java:32)
at io.netty.util.concurrent.DefaultPromise$LateListeners.run(DefaultPromise.java:850)
at io.netty.util.concurrent.ImmediateEventExecutor.execute(ImmediateEventExecutor.java:87)
......
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/860
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/861
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi, I used redisson to keep my tomcat session, and deserializing session error when the tomcat was restart.
The error info is 'the class missing default constructor or creator, or perhaps need to add/enable type information'.
So I add jackson annotation JsonDeserialize to my class, but it does not worked.
Can you help me solve this problem?
I have try deserializing the class with Jackson, and it can working
The code:
@JsonDeserialize(using = UsernamePasswordAuthenticationTokenSerializer.class)
public class UsernamePasswordAuthenticationTokenExt extends UsernamePasswordAuthenticationToken {
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/862
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I'm using redisson JSR107 implementation and after upgrading from version 3.3.1 to 3.3.2 I start to get following exception immediately:
Caused by: java.lang.NoClassDefFoundError: net/openhft/hashing/LongHashFunction 
	at org.redisson.misc.Hash.hashToBase64(Hash.java:43) 
	at org.redisson.jcache.JCache.getLockName(JCache.java:560) 
	at org.redisson.jcache.JCache.getLockedLock(JCache.java:744) 
	at org.redisson.jcache.JCache.put(JCache.java:809)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/863
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have this message quite often in my logs. There is a StackOverflowException happening right before that (though I am not sure whether these two correlate). Do you have an idea what is happening? Is the message too long to be processed? (Just for the context we have a pub/sub on expired keys.)
2017-04-26T15:51:45,881 | WARN | io.netty.channel.DefaultChannelPipeline | 2017-04-26T11:55:49,825_load_twoUserCollaborate_d4bd6e09-1bab-d0ff-b03f-823eb4c9442d | An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
io.netty.handler.codec.DecoderException: java.lang.IllegalStateException: Can't decode replay: *4
$8
pmessage
$16
__keyevent@*__:*
$21
__keyevent@0__:expire
$45
pack_501134d3-f81b-4ad8-dfb9-bc63bbe830a8.idx
*4
$8
pmessage
$16
__keyevent@*__:*
$21
__keyevent@0__:expire
$45
pack_350da5f7-3827-b630-7744-e9c7ecbf62db.idx
*4
$8
pmessage
$16
__keyevent@*__:*
$21
__keyevent@0__:expire
$46
pack_350da5f7-3827-b630-7744-e9c7ecbf62db.pack
*4
$8
pmessage
$16
__keyevent@*__:*
$21
__keyevent@0__:expire
$85
fc_gzip_b028edc1-2a3a-8d08-5c13-fe25bd1de7de_b2106b913601c201e1687aa7da9f2938b6fc2d03
*4
$8
pmessage
$16
__keyevent@*__:*
$21
__keyevent@0__:expire
$45
pack_91fd49c4-4bd0-5f78-d0e1-f3f278ba6880.idx
*4
$8
pmessage
$16
__keyevent@*__:*
$21
__keyevent@0__:expire
$46
pack_30c173d4-9f54-5532-24f4-6cca218ca8f2.pack
*4
$8
pmessage
$16
__keyevent@*__:*
$22
__keyevent@0__:expired
$46
pack_f1476d2d-d46f-506a-8f76-4e6e1a34aedd.pack
*4
$8
pmessage
$16
__keyevent@*__:*
$22
__keyevent@0__:expired
$85
fc_gzip_dcd6dbfa-e6b5-3798-64ff-08331278ab61_b68a1cdb9552248089bb739e119929d56e1033d4
*4
$8
pmessage
$16
__keyevent@*__:*
$22
__keyevent@0__:expired
$46
pack_01fb66ff-6c32-07ef-5f15-ae7e009a1e9b.pack
*4
$8
pmessage
$16
__keyevent@*__:*
$21
__keyevent@0__:expire
$45
pack_660999bc-d87b-73a1-3700-ee494e4e629a.idx
*4
$8
pmessage
$16
__keyevent@*__:*
$21
__keyevent@0__:expire
$46
pack_8cb9d5f8-bf22-e20a-fc22-6c43c6c2209f.pack
*4
$8
pmessage
$16
__keyevent@*__:*
$21
__keyevent@0__:expire
$45
pack_7f32f80d-ef10-d9fa-0cbc-bc6907b41403.idx
*4
$8
pmessage
$16
__keyevent@*__:*
$21
__keyevent@0__:expire
$46
pack_d3c04450-7a2c-76d6-4694-d1a809373736.pack
*4
$8
pmessage
$16
__keyevent@*__:*
$21
__keyevent@0__:expire
$45
pack_edfcb536-287a-7f63-7b42-909b5f6b815c.idx
*4
$8
pmessage
$16
__keyevent@*__:*
$21
__keyevent@0__:expire
$46
pack_60cc8f0a-98de-d61c-f6bd-8a90114d41bb.pack
*4
$8
pmessage
$16
__keyevent@*__:*
$22
__keyevent@0__:expired
$45
pack_d1e992c7-ee8a-6b7a-360f-eb340e69d696.idx
*4
$8
pmessage
$16
__keyevent@*__:*
$21
__keyevent@0__:expire
$45
pack_d1e992c7-ee8a-6b7a-360f-eb340e69d696.idx
*4
$8
pmessage
$16
__keyevent@*__:*
$21
__keyevent@0__:expire
$45
pack_7e134dc6-9748-521c-5340-e97a1c790ed3.idx
*4
$8
pmessage
$16
__keyevent@*__:*
$21
__keyevent@0__:expire
$45
pack_ce902045-ea2c-055d-87e2-ded21f156227.idx
*4
$8
pmessage
$16
__keyevent@*__:*
$21
__keyevent@0__:expire
$45
pack_deba09f5-e7e0-879a-305b-fa0aaef2b12f.idx
*4
$8
pmessage
$16
__keyevent@*__:*
$21
__keyevent@0__:expire
$48
pack_775d43a6-c38e-51ff-72b8-a045871140d6.bitmap
*4
$8
pmessage
$16
__keyevent@*__:*
$22
__keyevent@0__:expired
$45
pack_436b03f5-2a47-c03a-36b5-c65df9fb830d.idx
*4
$8
pmessage
$16
__keyevent@*__:*
$22
__keyevent@0__:expired
$48
pack_0ceea1c5-d2b3-3a28-0246-8116a1588dd8.bitmap
*4
$8
pmessage
$16
__keyevent@*__:*
$21
__keyevent@0__:expire
$45
pack_e931dc2d-de9a-696e-2c89-35ea0bd926f4.idx
*4
$8
pmessage
$16
__keyevent@*__:*
$21
__keyevent@0__:expire
$48
pack_96ebc9ff-32d9-f910-925d-911a6ac8b53a.bitmap
*4
$8
pmessage
$16
__keyevent@*__:*
$22
__keyevent@0__:expired
$46
pack_c52dee39-468b-4c5f-c9e1-337f2a8ca1be.pack
*4
$8
pmessage
$16
__keyevent@*__:*
$21
__keyevent@0__:expire
$45
pack_461227e4-88fd-9689-4c9c-f6453c3a4eca.idx
*4
$8
pmessage
$16
__keyevent@*__:*
$21
__keyevent@0__:expire
$45
pack_1a4904bc-3db3-c88b-9560-ea62d0a839c5.idx
*4
$8
pmessage
$16
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/864
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
One of our use case requires that if there is a failover, we reconnect automatically to another node. This is available in single server config as DnsMonitoring but not in Master Slave mode. Is there a specific reason for this? Can there be a support added? @mrniko
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/865
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
04-27 09:56:07.361 3495-3495/com.medzone.redisson E/AndroidRuntime: FATAL EXCEPTION: main
                                                                    Process: com.medzone.redisson, PID: 3495
                                                                    java.lang.NoClassDefFoundError: Failed resolution of: Lcom/fasterxml/jackson/dataformat/avro/PackageVersion;
                                                                        at org.redisson.codec.DefenceModule.<init>(DefenceModule.java:72)
                                                                        at org.redisson.codec.JsonJacksonCodec.init(JsonJacksonCodec.java:146)
                                                                        at org.redisson.codec.JsonJacksonCodec.<init>(JsonJacksonCodec.java:102)
                                                                        at org.redisson.codec.JsonJacksonCodec.<init>(JsonJacksonCodec.java:87)
                                                                        at org.redisson.codec.JsonJacksonCodec.<clinit>(JsonJacksonCodec.java:62)
                                                                        at org.redisson.config.Config.<init>(Config.java:101)
                                                                        at org.redisson.Redisson.<init>(Redisson.java:113)
                                                                        at org.redisson.Redisson.create(Redisson.java:154)
                                                                        at com.medzone.redisson.redis.RedisActivity$2.call(RedisActivity.java:84)
                                                                        at com.medzone.redisson.redis.RedisActivity$2.call(RedisActivity.java:65)
                                                                        at rx.internal.util.ActionSubscriber.onNext(ActionSubscriber.java:39)
                                                                        at rx.observers.SafeSubscriber.onNext(SafeSubscriber.java:134)
                                                                        at com.jakewharton.rxbinding.view.ViewClickOnSubscribe$1.onClick(ViewClickOnSubscribe.java:23)
                                                                        at android.view.View.performClick(View.java:5697)
                                                                        at android.widget.TextView.performClick(TextView.java:10815)
                                                                        at android.view.View$PerformClick.run(View.java:22526)
                                                                        at android.os.Handler.handleCallback(Handler.java:739)
                                                                        at android.os.Handler.dispatchMessage(Handler.java:95)
                                                                        at android.os.Looper.loop(Looper.java:158)
                                                                        at android.app.ActivityThread.main(ActivityThread.java:7237)
                                                                        at java.lang.reflect.Method.invoke(Native Method)
                                                                        at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1230)
                                                                        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1120)
                                                                     Caused by: java.lang.ClassNotFoundException: Didn't find class "com.fasterxml.jackson.dataformat.avro.PackageVersion" on path: DexPathList[[zip file "/data/app/com.medzone.redisson-2/base.apk", zip file "/data/app/com.medzone.redisson-2/split_lib_dependencies_apk.apk", zip file "/data/app/com.medzone.redisson-2/split_lib_slice_0_apk.apk", zip file "/data/app/com.medzone.redisson-2/split_lib_slice_1_apk.apk", zip file "/data/app/com.medzone.redisson-2/split_lib_slice_2_apk.apk", zip file "/data/app/com.medzone.redisson-2/split_lib_slice_3_apk.apk", zip file "/data/app/com.medzone.redisson-2/split_lib_slice_4_apk.apk", zip file "/data/app/com.medzone.redisson-2/split_lib_slice_5_apk.apk", zip file "/data/app/com.medzone.redisson-2/split_lib_slice_6_apk.apk", zip file "/data/app/com.medzone.redisson-2/split_lib_slice_7_apk.apk", zip file "/data/app/com.medzone.redisson-2/split_lib_slice_8_apk.apk", zip file "/data/app/com.medzone.redisson-2/split_lib_slice_9_apk.apk"],nativeLibraryDirectories=[/data/app/com.medzone.redisson-2/lib/arm64, /vendor/lib64, /system/lib64]]
                                                                        at dalvik.system.BaseDexClassLoader.findClass(BaseDexClassLoader.java:56)
                                                                        at java.lang.ClassLoader.loadClass(ClassLoader.java:511)
                                                                        at java.lang.ClassLoader.loadClass(ClassLoader.java:469)
                                                                        at org.redisson.codec.DefenceModule.<init>(DefenceModule.java:72) 
                                                                        at org.redisson.codec.JsonJacksonCodec.init(JsonJacksonCodec.java:146) 
                                                                        at org.redisson.codec.JsonJacksonCodec.<init>(JsonJacksonCodec.java:102) 
                                                                        at org.redisson.codec.JsonJacksonCodec.<init>(JsonJacksonCodec.java:87) 
                                                                        at org.redisson.codec.JsonJacksonCodec.<clinit>(JsonJacksonCodec.java:62) 
                                                                        at org.redisson.config.Config.<init>(Config.java:101) 
                                                                        at org.redisson.Redisson.<init>(Redisson.java:113) 
                                                                        at org.redisson.Redisson.create(Redisson.java:154) 
                                                                        at com.medzone.redisson.redis.RedisActivity$2.call(RedisActivity.java:84) 
                                                                        at com.medzone.redisson.redis.RedisActivity$2.call(RedisActivity.java:65) 
                                                                        at rx.internal.util.ActionSubscriber.onNext(ActionSubscriber.java:39) 
                                                                        at rx.observers.SafeSubscriber.onNext(SafeSubscriber.java:134) 
                                                                        at com.jakewharton.rxbinding.view.ViewClickOnSubscribe$1.onClick(ViewClickOnSubscribe.java:23) 
                                                                        at android.view.View.performClick(View.java:5697) 
                                                                        at android.widget.TextView.performClick(TextView.java:10815) 
                                                                        at android.view.View$PerformClick.run(View.java:22526) 
                                                                        at android.os.Handler.handleCallback(Handler.java:739) 
                                                                        at android.os.Handler.dispatchMessage(Handler.java:95) 
                                                                        at android.os.Looper.loop(Looper.java:158) 
                                                                        at android.app.ActivityThread.main(ActivityThread.java:7237) 
                                                                        at java.lang.reflect.Method.invoke(Native Method) 
                                                                        at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1230) 
                                                                        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1120) 
                                                                    	Suppressed: java.lang.ClassNotFoundException: com.fasterxml.jackson.dataformat.avro.PackageVersion
                                                                        at java.lang.Class.classForName(Native Method)
                                                                        at java.lang.BootClassLoader.findClass(ClassLoader.java:781)
                                                                        at java.lang.BootClassLoader.loadClass(ClassLoader.java:841)
                                                                        at java.lang.ClassLoader.loadClass(ClassLoader.java:504)
                                                                        		... 24 more
                                                                     Caused by: java.lang.NoClassDefFoundError: Class not found using the boot class loader; no stack trace available
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/866
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
hello friend
For blow code with stress test redisson client, but test_redisson_set method add loop items, have Exception message
`public class RedisClientTestUnit extends BaseTest{
public static final int invocations = 1000;

public static final int threads = 1;

public static final int duration = 6000;

@Rule
public ContiPerfRule rule = new ContiPerfRule();

@Autowired
private RedissonTemplete<String, Object> redissonTemplete;

@Before
public void check_bean_is_not_null(){
	Assert.assertNotNull(redissonTemplete);
}

@Test
@PerfTest(invocations = invocations, threads = threads, duration = duration)
public void test_redisson_set(){
	for(long i=1; i<=100000; i++){
		System.out.println(redissonTemplete.hashCode());
		long start = System.currentTimeMillis();
		Order order = new Order(); 
		order.setOrderId(i);
		order.setOrderSn(UUIDUtil.randomString(10));
		redissonTemplete.set(String.valueOf(i), order);
		System.out.println("i:" + (System.currentTimeMillis()-start));
	}
}

@Test
@PerfTest(invocations = invocations, threads = threads, duration = duration)
public void test_redisson_get(){
	for(int i=1; i<=1000; i++){
		long start = System.currentTimeMillis();
		List<Order> orders = (List<Order>) redissonTemplete.get(String.valueOf(i));
		System.out.println(orders.get(0).getOrderSn());
		System.out.println("i:" + (System.currentTimeMillis()-start));
	}
}

}`
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/867
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello,
I'm trying to use redisson for my project that will run on AWS lambda and will use AWS Elasticache Redis Cluster. I have the following snippet:
URL redissonConfig = RedisCacheClient.class.getResource("/redisson.yaml");
logger.debug("URL is " + redissonConfig);
File configFile = new File(redissonConfig.toURI());
Config config;
config = Config.fromYAML(configFile);
logger.debug("Configuration Input is" + config.toJSON());
client = Redisson.create(config);
logger.debug("Client Created");
The configuration is
clusterServersConfig:
idleConnectionTimeout: 10000
pingTimeout: 1000
connectTimeout: 10000
timeout: 3000
retryAttempts: 3
retryInterval: 1500
reconnectionTimeout: 3000
failedAttempts: 3
password: null
subscriptionsPerConnection: 5
clientName: null
loadBalancer: !<org.redisson.connection.balancer.RoundRobinLoadBalancer> {}
slaveSubscriptionConnectionMinimumIdleSize: 1
slaveSubscriptionConnectionPoolSize: 50
slaveConnectionMinimumIdleSize: 10
slaveConnectionPoolSize: 64
masterConnectionMinimumIdleSize: 10
masterConnectionPoolSize: 64
readMode: "SLAVE"
nodeAddresses:

"redis://usercache-0001-001.awtwec.0001.use1.cache.amazonaws.com:6379"
"redis://usercache-0001-002.awtwec.0001.use1.cache.amazonaws.com:6379"
"redis://usercache-0001-003.awtwec.0001.use1.cache.amazonaws.com:6379"
scanInterval: 1000
threads: 4
nettyThreads: 4
codec: !<org.redisson.codec.JsonJacksonCodec> {}
useLinuxNativeEpoll: false

I had the threads and nettyThreads as 0 and that was even worse. I now set it up to 4... and the startup is about 1440 ms.
Can someone please advise the right cluster configuration for Redisson in AWS Lambda?
Rgds.
Dheepak
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/868
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/869
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Great work! But there is some remarks. If you have a look at org.redisson.api.RSortable interface you may notice that it uses storeTo names. With key destination name and not from destination. Please rework your patch according this naming convention.
For example:
radiusStoreAsync(String fromKey, V member, double radius, GeoUnit geoUnit);
could be renamed to
radiusStoreToAsync(String destinationKey, V member, double radius, GeoUnit geoUnit);
the method itself applied against geo source and the destination
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/870
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
My RedissonClient codec is Config config = new Config().setCodec(new KryoCodec());
use this codec. Get RMap via RedissonClient, and then call RMAP's addAndGet method. Can be successful, but I then throw out the RMap when the exception thrown: Throws an exception: Unable to evaluate the expression Method threw 'org.redisson.client.RedisException' exception.
p.s:If the codec from KryoCodec into StringCodec or default codec(Jackson JSON) will not be an error.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/871
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Add metric for each command execution.
Add metrics for succeed and failed commands.
Add metrics for connections utilization
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/872
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/873
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/874
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Running redisson 2.9.1, jasckon dataformat 2.7.2.
I'm attempting to use AvroJacksonCodec with redisson client. This stack trace occurs when attempting to serialize and deserialize avro data from redis.
Failed to mark a promise as failure because it has failed already: DefaultChannelPromise@60a37695(failure: io.netty.handler.codec.EncoderException: com.fasterxml.jackson.databind.JsonMappingException: Incompatible types: declared root type ([simple type, class com.sumologic.app.api.ProtocolContinuousQueryRecordList]) vs java.lang.String), unnotified cause: io.netty.handler.codec.EncoderException: com.fasterxml.jackson.databind.JsonMappingException: Incompatible types: declared root type ([simple type, class com.sumologic.app.api.ProtocolContinuousQueryRecordList]) vs java.lang.String at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125) at org.redisson.client.handler.CommandEncoder.write(CommandEncoder.java:63) at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:739) at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:731) at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:817) at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:724) at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:120) at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:739) at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:731) at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:817) at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:724) at io.netty.channel.ChannelOutboundHandlerAdapter.write(ChannelOutboundHandlerAdapter.java:104) at org.redisson.client.handler.CommandsQueue.write(CommandsQueue.java:76) at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:739) at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:802) at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:815) at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:795) at io.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:1027) at io.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:301) at org.redisson.client.handler.CommandsQueue.sendData(CommandsQueue.java:102) at org.redisson.client.handler.CommandsQueue.write(CommandsQueue.java:79) at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:739) at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:731) at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38) at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1090) at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1137) at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1079) at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163) at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:445) at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144) at java.lang.Thread.run(Thread.java:745) Caused by: com.fasterxml.jackson.databind.JsonMappingException: Incompatible types: declared root type ([simple type, class com.sumologic.app.api.ProtocolContinuousQueryRecordList]) vs java.lang.String at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:262) at com.fasterxml.jackson.databind.SerializerProvider._reportIncompatibleRootType(SerializerProvider.java:1115) at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:225) at com.fasterxml.jackson.databind.ObjectWriter$Prefetch.serialize(ObjectWriter.java:1425) at com.fasterxml.jackson.databind.ObjectWriter._configAndWriteValue(ObjectWriter.java:1129) at com.fasterxml.jackson.databind.ObjectWriter.writeValueAsBytes(ObjectWriter.java:1025) at org.redisson.codec.AvroJacksonCodec$AvroExtendedMapper.writeValueAsBytes(AvroJacksonCodec.java:52) at org.redisson.codec.JsonJacksonCodec$1.encode(JsonJacksonCodec.java:75) at org.redisson.client.handler.CommandEncoder.encode(CommandEncoder.java:103) at org.redisson.client.handler.CommandEncoder.encode(CommandEncoder.java:45) at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107) ... 32 more 
This is how the codec is being created (note, the environment is scala).
  private val codec = new AvroJacksonCodec( classOf[ProtocolContinuousQueryRecordList], new AvroSchema(ProtocolContinuousQueryRecordList.SCHEMA$))
It works when I use JsonJacksonCodec, but not with AvroJacksonCodec. Am I doing something incorrectly which would be causing this issue?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/875
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
hello mrniko:
Config = ...
RedissonClient redisson = Redisson.create(config);
RAtomicLong  atomicLong = redisson.getAtomicLong(key);
Long result = atomicLong.addAndGet(10L);
//execute successful
RBucket bucket = redisson.getBucket(key)
But (bucket.get()) return Integer result? why?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/876
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
With present radisson is it possible to search more than one item by id or  other properties ?
for example :
 RLiveObjectService liveObjectService = redisson.getLiveObjectService();
List ids = new ArrayList<>();
ids.add(12);
ids.add(13);
ids.add(14);
 List customers = liveObjectService.get(Customer.class, ids );


if not this way. are there any other ways to do this ?
Question 2:
Is it possible to search objects by property name?
for eg: searching customer by product id.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/877
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
This  bug could be a duplicate of #349 but this is not the same method.
The following code:
RBlockingQueue<Message> messageQueue = redissonClient.getBlockingQueue(Constants.MESSAGE_QUEUE);
Message message = messages.pollLastAndOfferFirstTo(Constants.PROCESSING_QUEUE);

Does not block until a message is available
In the documentation https://github.com/redisson/redisson/wiki/11.-Redis-commands-mapping, it is said that BRPOPLPUSH can be replaced by a call to RBlockingQueue.pollLastAndOfferFirstTo().
So this call should bock until a message is available.
As a workaround, I can use RBlockingQueue.pollLastAndOfferFirstToAsync() or pollLastAndOfferFirstTo(String queueName, long timeout, TimeUnit unit) throws InterruptedException.
By the way,  Reddis is a fantastic framework and I love it 👍
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/878
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
what about delay to  connect to redis  , by the first function call ?
rather than connect to redis immediately  when  application startup .
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/879
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I'm investigating moving from Hazelcast to Redisson and one question popped up that I can't seem to work out the answer for. Perhaps I'm trying to incorrectly compare functionality between the two?
Anyway, in our code that uses Hazelcast, we create a distributed IMap and add listeners so that each process (Hazelcast client) can listen for changes to that map. I can't seem to work out how to get the same functionality using the RMap. Is this possible or is this functionality only available using the LiveObject? Or do I have to mimic this functionality using a topic perhaps?
Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/880
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I configure Redisson by spring xml, and I use gson as codec, I want to remove jackson dependencies from maven, but report "No class com/fastxml/...... found" error.
#######Splitter of Disgusting Libs############
jackson-dataformat-yaml
jackson-core
jackson-databind
######################################
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/881
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/882
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/883
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
我用redission 集成tomcat中session共享的，项目用的是spring security。
对象序列化使用默认方式。
登录的时候 redis里能存入格式如下
"SPRING_SECURITY_CONTEXT" { "@class": "org.springframework.security.core.context.SecurityContextImpl", "authentication": { "@class": "org.springframework.security.authentication.UsernamePasswordAuthenticationToken", "authenticated": true, "authorities": [ "java.util.ArrayList", [ { "@class": "org.springframework.security.core.authority.GrantedAuthorityImpl", "role": "ROLE_ADMIN" }, { "@class": "org.springframework.security.core.authority.GrantedAuthorityImpl", "role": "ROLE_BASE" }, { "@class": "org.springframework.security.core.authority.GrantedAuthorityImpl", "role": "ROLE_BASE_CHANNEL" }, { "@class": "org.springframework.security.core.authority.GrantedAuthorityImpl", "role": "ROLE_BASE_LOG" }, { "@class": "org.springframework.security.core.authority.GrantedAuthorityImpl", "role": "basic_admin_role" }, { "@class": "org.springframework.security.core.authority.GrantedAuthorityImpl", "role": "login_role" }, { "@class": "org.springframework.security.core.authority.GrantedAuthorityImpl", "role": "um_admin_role" } ] ], "details": { "@class": "org.springframework.security.web.authentication.WebAuthenticationDetails", "remoteAddress": "10.100.40.192", "sessionId": "A39B28F397825AC625A6BEE61EC5CC43" }, "principal": { "@class": "org.springframework.security.core.userdetails.User", "accountNonExpired": true, "accountNonLocked": true, "authorities": [ "java.util.Collections$UnmodifiableSet", [ { "@class": "org.springframework.security.core.authority.GrantedAuthorityImpl", "role": "ROLE_ADMIN" }, { "@class": "org.springframework.security.core.authority.GrantedAuthorityImpl", "role": "ROLE_BASE" }, { "@class": "org.springframework.security.core.authority.GrantedAuthorityImpl", "role": "ROLE_BASE_CHANNEL" }, { "@class": "org.springframework.security.core.authority.GrantedAuthorityImpl", "role": "ROLE_BASE_LOG" }, { "@class": "org.springframework.security.core.authority.GrantedAuthorityImpl", "role": "basic_admin_role" }, { "@class": "org.springframework.security.core.authority.GrantedAuthorityImpl", "role": "login_role" }, { "@class": "org.springframework.security.core.authority.GrantedAuthorityImpl", "role": "um_admin_role" } ] ], "credentialsNonExpired": true, "enabled": true, "username": "admin" } } }
RMap<String,Object> map = localRedisson.getMap("redisson_tomcat_session:70F928E6F059B511C2F732DB6B56001E"); System.out.println(map.get("SPRING_SECURITY_CONTEXT"));
但是在取的时候报错，如下：
org.redisson.client.RedisException: Unexpected exception while processing command at org.redisson.command.CommandAsyncService.convertException(CommandAsyncService.java:322) at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:165) at org.redisson.RedissonObject.get(RedissonObject.java:69) at org.redisson.RedissonMap.get(RedissonMap.java:197) at org.test.Test.main(Test.java:54) Caused by: com.fasterxml.jackson.databind.JsonMappingException: No suitable constructor found for type [simple type, class org.springframework.security.authentication.UsernamePasswordAuthenticationToken]: can not instantiate from JSON object (missing default constructor or creator, or perhaps need to add/enable type information?) at [Source: io.netty.buffer.ByteBufInputStream@1dbb35; line: 1, column: 183] (through reference chain: org.springframework.security.core.context.SecurityContextImpl["authentication"]) at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:148) 
请问如果解决。
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/884
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for contribution. Could you please remain header and comment unchanged?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/885
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am using version 2.2.24 of redisson and using getKeysByPattern command. It works fine if no keys are found in the redis. But, if at least one key is found then the code returns successfully. But the scan command keeps on running on the redis server.
Sample code:
Iterator keysIterator = redissonClient.getKeys().getKeysByPattern(pattern).iterator();
while (keysIterator.hasNext()) {
String key = keysIterator.next();
keysToDelete.add(key);
}
Redis
1495458904.136225 [0 127.0.0.1:65465] "SCAN" "14" "MATCH" "TeSt" "COUNT" "10"
1495458904.136298 [0 127.0.0.1:65466] "SCAN" "7" "MATCH" "TeSt" "COUNT" "10"
1495458904.136359 [0 127.0.0.1:65467] "SCAN" "0" "MATCH" "TeSt""COUNT" "10"
1495458904.136432 [0 127.0.0.1:65468] "SCAN" "14" "MATCH" "TeSt" "COUNT" "10"
1495458904.136507 [0 127.0.0.1:65469] "SCAN" "7" "MATCH" "TeSt" "COUNT" "10"
1495458904.136579 [0 127.0.0.1:65470] "SCAN" "0" "MATCH" "TeSt" "COUNT" "10"
1495458904.136650 [0 127.0.0.1:65472] "SCAN" "14" "MATCH" "TeSt" "COUNT" "10"
1495458904.136726 [0 127.0.0.1:65471] "SCAN" "7" "MATCH" "TeSt" "COUNT" "10"
1495458904.136842 [0 127.0.0.1:65473] "SCAN" "0" "MATCH" "TeSt" "COUNT" "10"
1495458904.136958 [0 127.0.0.1:65474] "SCAN" "14" "MATCH" "TeSt""COUNT" "10"
1495458904.137054 [0 127.0.0.1:65465] "SCAN" "7" "MATCH" "TeSt""COUNT" "10"
1495458904.137149 [0 127.0.0.1:65466]
Please share the sample code of getKeysByPattern command.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/886
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When I use CompositeCacheManager with many different CacheManagers, for example:
        List<CacheManager> cacheManagers = new ArrayList<>();
        cacheManagers.add(commonCacheManager());
        cacheManagers.add(redissonCacheManager());
        compositeCacheManager.setCacheManagers(cacheManagers);

where commonCacheManager - is a  CaffeineCacheManager and redissonCacheManager is a RedissonSpringCacheManager, and when I try to use @Cacheable(value = "cacheName"), there is a bug in discovering a needed cache.
The deal is - spring trying to find cache by its name from @Cacheable and it's iterating through all registered caches in composite manager, calling  getCache(String name) in every cacheManager.
The problem is - in another cache managers there is an additional variable for dynamic getting cache and usual discovering. When you make a simple cacheManager.getCache("cache"), method getCache() creates a new cache if it's null and it's normal, but in dynamic resolving as in the @Cacheable annotation getCache() should return null.
Here is an example, how it's done in CaffeineCacheManager:
public Cache getCache(String name) {
    Cache cache = this.cacheMap.get(name);
    if (cache == null && this.dynamic) {
      synchronized (this.cacheMap) {
        cache = this.cacheMap.get(name);
	if (cache == null) {
	    cache = createCaffeineCache(name);
	    this.cacheMap.put(name, cache);
	}
      }
    }
    return cache;
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/887
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is Redisson support querying metrics from Redis?
For example :
redis-cli -h host ping
redis-cli -h host info [replication]
redis-benchmark -h host -c 10 -n 10000 -t set,get,inc -q
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/888
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
i got in trouble when i use it to share session  ,  i Configure it as the document and  create two pods with docker ,then i visit the webapp in docker , After I login successfully, I refresh the page, it  indicating that I am not logged in,Is there anyone like me? can someone tell me something ,please
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/889
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
all application threads are blocked with stack trace
``
"thrift-worker-5" #68 prio=5 os_prio=0 tid=0x00007f575c85f000 nid=0x6e69 waiting on condition [0x00007f5754a9c000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <0x00000000e356d560> (a java.util.concurrent.CountDownLatch$Sync)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
	at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231)
	at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:148)
	at org.redisson.command.CommandBatchService.execute(CommandBatchService.java:134)
	at org.redisson.RedissonBatch.execute(RedissonBatch.java:253)

redisson version 3.4.2
cluster configuration
d61dd782a6545ad61e1443b081cc940b8b2bf4bb XXX:6382 slave 1b5e1e32fc5fcbb741dc8f17528e178cc43f72af 0 1495639973317 18 connected
df0f58cba6088e5f90dc7606603535ebd7b35d7d XXX:6381 slave be530716595b868ec75bba96377c2876822432fa 0 1495639973820 19 connected
be530716595b868ec75bba96377c2876822432fa XXX:6381 master - 0 1495639973819 19 connected 6070-10069
5765a883861af184e6807dc11cb9fd1c4c9a9748 XXX:6379 myself,master - 0 0 16 connected 12070-16383
17c6e10f6c25c97e390c36849514c0b268ca97e7 XXX:6380 slave 3c649506252fd43ef1c59ebbf2413d7cef9f36a7 0 1495639972817 20 connected
bad3c26e74a9dbfee472cfcef177bee87fd56d4c XXX:6379 slave 5765a883861af184e6807dc11cb9fd1c4c9a9748 0 1495639973017 16 connected
3c649506252fd43ef1c59ebbf2413d7cef9f36a7 XXX:6380 master - 0 1495639974422 20 connected 0-2069 10070-12069
1b5e1e32fc5fcbb741dc8f17528e178cc43f72af XXX:6382 master - 0 1495639974321 18 connected 2070-6069
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/890
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Details : Redisson (3.3.1) using cluster mode:
Exception:
com.revcontent.spark.streaming.exception.RedisClientAdaptorException: ERR Error running script (call to f_04ca52da6f32fea58a7378efe5e857fbdc376470): @user_script:1: user_script:1: bad argument #2 to 'unpack' (data string too short) . channel: [id: 0xafc7451e, /10.99.1.42:59157 => /10.120.42.238:6379] command: CommandData [promise=org.redisson.misc.RedissonPromise@32a8871[Not completed], command=(EVAL), params=[if redis.call('hexists', KEYS[1], ARGV[4]) == 0 then if tonumber(ARGV[1]) > 0 then redis.call('zadd'..., 3, campaign_widget_stats, redisson__timeout__set:{campaign_widget_stats}, redisson__idle__set:{campaign_widget_stats}, 1498161005083, 0, 0, impressions, 0], codec=org.redisson.client.codec.StringCodec@414979d2]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/891
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
While using RReadWriteLock, a bug (or not?) confuse me for a long time.
I described a wrong ops yesterday, and fix it now. Sorry about this.
There is a sure logic problem if ops like this:

write lock A (succeed)
read lock A (succeed)
read unlock A (succeed)
write unlock A (not hold by current thread!!!)

Assuming every unlock op is after a holding check.
So if there is no holding check and running in a concurrent environment, op4 may throw IllegalMonitorException.
But it's ok as follows:

write lock A (succeed)
write lock A again (succeed)
write unlock A (succeed)
write unlock A (succeed)

I found that "read unlock" will delete the whole lock without checking if there is any other write lock.
Is it a bug, or it just shouldn't do and need to do in another way?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/892
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The default is Jaxson, can we use a combination of Jaxson with Snappy for compression?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/893
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We are storing objects that is an abstract class.
@JsonTypeInfo(
        use = JsonTypeInfo.Id.NAME,
        include = JsonTypeInfo.As.PROPERTY,
        property = "type")
@JsonSubTypes({
        @JsonSubTypes.Type(value = Queue.class, name = "Queue"),
})
public abstract class BaseQueue {

The Jaxson codec fails while de-serializing the object, how to i set subType can you help me out with an example?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/894
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/895
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I'm testing Redisson JCache with following configuration:
---
replicatedServersConfig:
  clientName: "bsfapp.localdomain"
  idleConnectionTimeout: 10000
  pingTimeout: 1000
  connectTimeout: 10000
  timeout: 3000
  retryAttempts: 3
  retryInterval: 1500
  reconnectionTimeout: 3000
  failedAttempts: 3
  subscriptionsPerConnection: 5
  loadBalancer: !<org.redisson.connection.balancer.RoundRobinLoadBalancer> {}
  slaveConnectionMinimumIdleSize: 10
  slaveConnectionPoolSize: 64
  masterConnectionMinimumIdleSize: 10
  masterConnectionPoolSize: 64
  password: "123456"
  readMode: "MASTER_SLAVE"
  subscriptionMode: "SLAVE"
  subscriptionConnectionMinimumIdleSize: 1
  subscriptionConnectionPoolSize: 50
  nodeAddresses: ["redis://bsfapp.localdomain:6379", "redis://bsfapp2.localdomain:6379"]
  scanInterval: 2000
  database: 0
  slaveSubscriptionConnectionPoolSize: 50
  slaveSubscriptionConnectionMinimumIdleSize: 1
threads: 0
nettyThreads: 0
codec: !<org.redisson.codec.FstCodec> {}
codecProvider: !<org.redisson.codec.DefaultCodecProvider> {}
resolverProvider: !<org.redisson.liveobject.provider.DefaultResolverProvider> {}
redissonReferenceEnabled: true
useLinuxNativeEpoll: false


After crashing the slave (DEBUG SEGFAULT) the client reconnects but doesn't authenticate. I see endless errors like this:
ERROR  [11:36:28.961] [redisson-netty-1-2] o.r.c.ReplicatedConnectionManager -  NOAUTH Authentication required.. channel: [id: 0xdc3558ca, L:/192.168.56.132:36320 - R:bsfapp2.localdomain/192.168.56.134:6379] command: CommandData [promise=org.redisson.misc.RedissonPromise@7325eb72[Not completed], command=(INFO REPLICATION), params=[], codec=null] 
org.redisson.client.RedisException: NOAUTH Authentication required.. channel: [id: 0xdc3558ca, L:/192.168.56.132:36320 - R:bsfapp2.localdomain/192.168.56.134:6379] command: CommandData [promise=org.redisson.misc.RedissonPromise@7325eb72[Not completed], command=(INFO REPLICATION), params=[], codec=null]
        at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:267)
        at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:127)
        at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:367)
        at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:248)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
        at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1334)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
        at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:926)
        at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:134)
        at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:644)
        at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
        at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
        at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
        at java.lang.Thread.run(Thread.java:745)

Is this a bug or wrong configuration?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/896
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In RedissonBoundedBlockingQueue.pollAsync, if timeout is less than 1 second, it will be round to 0. 0 is interpreted as indefinite timeout. Thus, pollAsync never returns.
    @Override
    public RFuture<V> pollAsync(long timeout, TimeUnit unit) {
        RFuture<V> takeFuture = commandExecutor.writeAsync(getName(), codec, RedisCommands.BLPOP_VALUE, getName(), unit.toSeconds(timeout));
        return wrapTakeFuture(takeFuture);
    }

I understand timeout < 1 second is not supported in  BLPOP command, but at least, this behavior is a surprise for me who didn't know poll is map to BLPOP command.
I am not sure what is the best way to improve this, here are some ideas:

default behavior should round up to 1 second if not 0
do not allow time out less than 1 second
just mention this behavior in the documentation
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/897
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redission can  use oracle jdk? there is a old project in my company, I use the redisson as a redis client in my project ,but the console like this:java.lang.ClassNotFoundException: jdk.internal.misc.Unsafe, so I see the oracle jdk , it only sun.misc.Unsafe, thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/898
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have a LiveObject A, with a List of B as a field. Definitions are as below:
@REntity
public class A {
    @RId
    private Long id;

    private List<B> listB;
    
    ...
}

@REntity
public class B {
    @RId(generator = LongGenerator.class)
    private Long id;

    private int index;

    ...
}


When I iterate through listB of A, it sometimes fails with error message: "java.lang.ClassCastException: org.redisson.RedissonReference cannot be cast to com.xxx.B."
When I run in debug mode, I found out the reference has content as below:
B reference = {
   type = "com.xxx.B",
   keyName = "redisson_live_object:{XXXXX}:com.xxx.B:id:java.lang.Long",
   codec = null,
}

Is this a bug or wrong usage of live object?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/899
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Currently i'm using Redisson 2.7.4  as JCache Provider, and some cache operations are taking a long time to execute, as can be seen in the log below:
2017-06-05 11:44:18.103 WARN  [com.contaazul.cache.cdi.interceptor.CacheResultInterceptor] (http-executor-threads - 89) Cache result for CompanyDemoFindService.find took 1669045 milliseconds

in some cases it takes ~30 minutes
Taking a thread dump I noticed that all EJB async threads (and some http-executor threads too) were in the same state, generating a huge queue in the async thread pool:

Thread dump for some threads (Complete thread dump can be downloaded here):
2017-06-05 11:03:55

"EJB async - 2" - Thread t@1214
   java.lang.Thread.State: TIMED_WAITING
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for <b485fd6> (a java.util.concurrent.Semaphore$NonfairSync)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1033)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1326)
	at java.util.concurrent.Semaphore.tryAcquire(Semaphore.java:414)
	at org.redisson.RedissonLock.lockInterruptibly(RedissonLock.java:133)
	at org.redisson.RedissonLock.lock(RedissonLock.java:99)
	at org.redisson.jcache.JCache.getLockedLock(JCache.java:746)
	at org.redisson.jcache.JCache.get(JCache.java:194)
	at com.contaazul.cache.FailSafeCache.get(FailSafeCache.java:21)
	at org.jsr107.ri.annotations.AbstractCacheResultInterceptor.cacheResult(AbstractCacheResultInterceptor.java:71)
	at com.contaazul.cache.cdi.interceptor.CacheResultInterceptor.cacheResult(CacheResultInterceptor.java:28)
	at sun.reflect.GeneratedMethodAccessor141.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.jboss.weld.interceptor.proxy.SimpleMethodInvocation.invoke(SimpleMethodInvocation.java:30)
	at org.jboss.weld.interceptor.proxy.SimpleInterceptionChain.invokeNextInterceptor(SimpleInterceptionChain.java:69)
	at org.jboss.weld.bean.InterceptorImpl.intercept(InterceptorImpl.java:92)
	at org.jboss.as.weld.ejb.DelegatingInterceptorInvocationContext.proceed(DelegatingInterceptorInvocationContext.java:71)
	at org.jboss.as.weld.ejb.Jsr299BindingsInterceptor.delegateInterception(Jsr299BindingsInterceptor.java:72)
	at org.jboss.as.weld.ejb.Jsr299BindingsInterceptor.doMethodInterception(Jsr299BindingsInterceptor.java:84)
	at org.jboss.as.weld.ejb.Jsr299BindingsInterceptor.processInvocation(Jsr299BindingsInterceptor.java:97)
	at org.jboss.as.ee.component.interceptors.UserInterceptorFactory$1.processInvocation(UserInterceptorFactory.java:63)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.invocation.WeavedInterceptor.processInvocation(WeavedInterceptor.java:53)
	at org.jboss.as.ee.component.interceptors.UserInterceptorFactory$1.processInvocation(UserInterceptorFactory.java:63)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.as.ejb3.component.invocationmetrics.ExecutionTimeInterceptor.processInvocation(ExecutionTimeInterceptor.java:43)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.as.jpa.interceptor.SBInvocationInterceptor.processInvocation(SBInvocationInterceptor.java:47)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.as.weld.ejb.EjbRequestScopeActivationInterceptor.processInvocation(EjbRequestScopeActivationInterceptor.java:73)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.invocation.InitialInterceptor.processInvocation(InitialInterceptor.java:21)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.invocation.ChainedInterceptor.processInvocation(ChainedInterceptor.java:61)
	at org.jboss.as.ee.component.interceptors.ComponentDispatcherInterceptor.processInvocation(ComponentDispatcherInterceptor.java:53)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.as.ejb3.component.pool.PooledInstanceInterceptor.processInvocation(PooledInstanceInterceptor.java:51)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.as.ejb3.tx.CMTTxInterceptor.invokeInNoTx(CMTTxInterceptor.java:259)
	at org.jboss.as.ejb3.tx.CMTTxInterceptor.notSupported(CMTTxInterceptor.java:323)
	at org.jboss.as.ejb3.tx.CMTTxInterceptor.processInvocation(CMTTxInterceptor.java:236)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.as.ejb3.component.interceptors.CurrentInvocationContextInterceptor.processInvocation(CurrentInvocationContextInterceptor.java:41)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.as.ejb3.component.interceptors.ShutDownInterceptorFactory$1.processInvocation(ShutDownInterceptorFactory.java:64)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.as.ejb3.component.interceptors.LoggingInterceptor.processInvocation(LoggingInterceptor.java:59)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.as.ee.component.NamespaceContextInterceptor.processInvocation(NamespaceContextInterceptor.java:50)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.as.ejb3.component.interceptors.AdditionalSetupInterceptor.processInvocation(AdditionalSetupInterceptor.java:55)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.as.ee.component.TCCLInterceptor.processInvocation(TCCLInterceptor.java:45)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.invocation.ChainedInterceptor.processInvocation(ChainedInterceptor.java:61)
	at org.jboss.as.ee.component.ViewService$View.invoke(ViewService.java:185)
	at org.jboss.as.ee.component.ViewDescription$1.processInvocation(ViewDescription.java:182)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.invocation.ChainedInterceptor.processInvocation(ChainedInterceptor.java:61)
	at org.jboss.as.ee.component.ProxyInvocationHandler.invoke(ProxyInvocationHandler.java:73)
	at com.contaazul.company.CompanyDemoFindService$$$view659.find(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor146.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.jboss.weld.util.reflection.SecureReflections$13.work(SecureReflections.java:267)
	at org.jboss.weld.util.reflection.SecureReflectionAccess.run(SecureReflectionAccess.java:52)
	at org.jboss.weld.util.reflection.SecureReflectionAccess.runAsInvocation(SecureReflectionAccess.java:137)
	at org.jboss.weld.util.reflection.SecureReflections.invoke(SecureReflections.java:263)
	at org.jboss.weld.bean.proxy.EnterpriseBeanProxyMethodHandler.invoke(EnterpriseBeanProxyMethodHandler.java:115)
	at org.jboss.weld.bean.proxy.EnterpriseTargetBeanInstance.invoke(EnterpriseTargetBeanInstance.java:56)
	at org.jboss.weld.bean.proxy.ProxyMethodHandler.invoke(ProxyMethodHandler.java:105)
	at com.contaazul.company.CompanyDemoFindService$Proxy$_$$_Weld$Proxy$.find(CompanyDemoFindService$Proxy$_$$_Weld$Proxy$.java)
	at com.contaazul.fanout.ApplicationTrackService.resolveOrigin(ApplicationTrackService.java:161)
	at com.contaazul.fanout.ApplicationTrackService.getContentDTO(ApplicationTrackService.java:131)
	at com.contaazul.fanout.ApplicationTrackService.sendTrack(ApplicationTrackService.java:104)
	at com.contaazul.fanout.ApplicationTrackService.sendTrackOperation(ApplicationTrackService.java:72)
	at com.contaazul.fanout.ApplicationTrackService.track(ApplicationTrackService.java:48)
	at sun.reflect.GeneratedMethodAccessor565.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.jboss.as.ee.component.ManagedReferenceMethodInterceptor.processInvocation(ManagedReferenceMethodInterceptor.java:52)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.invocation.WeavedInterceptor.processInvocation(WeavedInterceptor.java:53)
	at org.jboss.as.ee.component.interceptors.UserInterceptorFactory$1.processInvocation(UserInterceptorFactory.java:63)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.invocation.InterceptorContext$Invocation.proceed(InterceptorContext.java:374)
	at org.jboss.as.weld.ejb.Jsr299BindingsInterceptor.doMethodInterception(Jsr299BindingsInterceptor.java:86)
	at org.jboss.as.weld.ejb.Jsr299BindingsInterceptor.processInvocation(Jsr299BindingsInterceptor.java:97)
	at org.jboss.as.ee.component.interceptors.UserInterceptorFactory$1.processInvocation(UserInterceptorFactory.java:63)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.invocation.WeavedInterceptor.processInvocation(WeavedInterceptor.java:53)
	at org.jboss.as.ee.component.interceptors.UserInterceptorFactory$1.processInvocation(UserInterceptorFactory.java:63)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.as.ejb3.component.invocationmetrics.ExecutionTimeInterceptor.processInvocation(ExecutionTimeInterceptor.java:43)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.as.jpa.interceptor.SBInvocationInterceptor.processInvocation(SBInvocationInterceptor.java:47)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.as.weld.ejb.EjbRequestScopeActivationInterceptor.processInvocation(EjbRequestScopeActivationInterceptor.java:93)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.invocation.InitialInterceptor.processInvocation(InitialInterceptor.java:21)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.invocation.ChainedInterceptor.processInvocation(ChainedInterceptor.java:61)
	at org.jboss.as.ee.component.interceptors.ComponentDispatcherInterceptor.processInvocation(ComponentDispatcherInterceptor.java:53)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.as.ejb3.component.pool.PooledInstanceInterceptor.processInvocation(PooledInstanceInterceptor.java:51)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.as.ejb3.tx.CMTTxInterceptor.invokeInNoTx(CMTTxInterceptor.java:259)
	at org.jboss.as.ejb3.tx.CMTTxInterceptor.notSupported(CMTTxInterceptor.java:323)
	at org.jboss.as.ejb3.tx.CMTTxInterceptor.processInvocation(CMTTxInterceptor.java:236)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.as.ejb3.component.interceptors.CurrentInvocationContextInterceptor.processInvocation(CurrentInvocationContextInterceptor.java:41)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.as.ejb3.component.interceptors.ShutDownInterceptorFactory$1.processInvocation(ShutDownInterceptorFactory.java:64)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.as.ejb3.component.interceptors.LoggingInterceptor.processInvocation(LoggingInterceptor.java:59)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.as.ee.component.NamespaceContextInterceptor.processInvocation(NamespaceContextInterceptor.java:50)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.as.ejb3.component.interceptors.AdditionalSetupInterceptor.processInvocation(AdditionalSetupInterceptor.java:55)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.as.ee.component.TCCLInterceptor.processInvocation(TCCLInterceptor.java:45)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.invocation.ChainedInterceptor.processInvocation(ChainedInterceptor.java:61)
	at org.jboss.as.ee.component.ViewService$View.invoke(ViewService.java:185)
	at org.jboss.as.ee.component.ViewDescription$1.processInvocation(ViewDescription.java:182)
	at org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)
	at org.jboss.as.ejb3.component.interceptors.AsyncFutureInterceptorFactory$1$1.runInvocation(AsyncFutureInterceptorFactory.java:89)
	at org.jboss.as.ejb3.component.interceptors.AsyncInvocationTask.run(AsyncInvocationTask.java:73)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
	at org.jboss.threads.JBossThread.run(JBossThread.java:122)

   Locked ownable synchronizers:
	- locked <f75019a> (a java.util.concurrent.ThreadPoolExecutor$Worker)


"redisson-3-9" - Thread t@1416
   java.lang.Thread.State: WAITING
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for <2d3b7977> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:745)

   Locked ownable synchronizers:
	- None


"redisson-netty-1-9" - Thread t@1297
   java.lang.Thread.State: RUNNABLE
	at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
	at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
	at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)
	- locked <7ed0d3e3> (a io.netty.channel.nio.SelectedSelectionKeySet)
	- locked <130940b7> (a java.util.Collections$UnmodifiableSet)
	- locked <4eab503d> (a sun.nio.ch.EPollSelectorImpl)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)
	at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:746)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:391)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:745)

   Locked ownable synchronizers:
	- None

it looks like that is a lock issue, but i don't know how to solve it.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/900
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Caused by: java.lang.StackOverflowError
at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/901
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I upgraded Redisson to 2.9.2 and several JsonMappingException occurred:
Caused by: com.fasterxml.jackson.databind.JsonMappingException: 
        No suitable constructor found for type

Looking for why it happened i discovered that it happens because support for @ConstructorProperties was added only in Jackson 2.7 version (FasterXML/jackson-databind#905) and in this commit c14e97c jackson was downgraded to 2.6.7 to maintain JDK 1.6 compatibility.
According to Jackson release notes, still be possible to use Jackson 2.7 on Java 6: https://github.com/FasterXML/jackson/wiki/Jackson-Release-2.7#changes-compatibility
@mrniko can i open a pull request to upgrade jackson to 2.7.6 again?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/902
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I made the following test:
Config config = new Config();
config.useSingleServer().setAddress("redis://127.0.0.1:6379");

I had an error message like this:
java.lang.IllegalArgumentException: port out of range:-1

Using like this:
Config config = new Config();
config.useSingleServer().setAddress("127.0.0.1:6379");

It works perfectly.
Shouldn't be better to accept all the configuration formats without problems? Like using config.useClusterServers().addNodeAddress("redis://127.0.0.1:7181"); (from Wiki).
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/903
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/904
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/905
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
spring boot support?
希望能有官方的spring boot starter
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/906
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I may have missed this, but is there a way to get a list of all the map caches in Redisson? I have this functionality in my hazelcast based code that I am trying to update and it's useful to use for logging.
Thinking about it, this feature would be useful for other collections and objects etc.
Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/907
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I'm using a lock in Hazelcast to implement "single master" functionality for service applications. Hazelcast's lock is release when the owner dies.
So basically, say I have two applications that provide the same service, called A and B. A and B both start, but B grabs the lock for that service. B becomes ACTIVE and starts its processing. A becomes STANDBY and waits for that lock.
B dies, the lock is released. A grabs the lock and it becomes ACTIVE and starts its processing.
B restarts, tries to grab the lock but fails, so it becomes STANDBY and it waits for the lock.
Now I read in a ticket that a lock is still held when the owning process dies, which is counter to what I need.
Can you make any suggestions how to implement this functionality in Redisson?
Thanks again
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/908
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redis version / mode
AWS Elasticache Redis 3.2.4 (cluster mode enabled)
Redisson version
3.4.2
Questions
I recently switched from Hazelcast to Redisson and I have a question about the cluster mode and sharding.

When I create my configuration, should I use useClusterServers method or another?
Which nodes address should I add? All? One node per shard? Other?
The great feature of the cluster mode is the ability to partition data accross shards. But I'm asking myself if it is automatically done by AWS? Actually, I saw in the documentation that the RClusteredLocalCachedMap is a pro feature, but by using RLocalCachedMap and AWS redis, does the sharding works as if I was using RClusteredLocalCachedMap? Or you "simply" put the data in all the nodes I provide at start?
Is there an auto-discovery features of all nodes so I don't have to hardcode endpoint addresses in the application?

Thanks,
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/909
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I'm sure I'm missing something obvious here but I'm getting an exception when I remove an entry from the map cache, using the KryoNet encoder. I can put an entry into the map cache but I can't remove from it.
[redisson-netty-6-14] WARN io.netty.channel.DefaultChannelPipeline - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
io.netty.handler.codec.DecoderException: java.lang.IndexOutOfBoundsException: index: 45, length: -516868041 (expected: range(0, 193))
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:422)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1334)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:926)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:134)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:644)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.IndexOutOfBoundsException: index: 45, length: -516868041 (expected: range(0, 193))
	at io.netty.buffer.AbstractByteBuf.checkIndex0(AbstractByteBuf.java:1353)
	at io.netty.buffer.AbstractUnpooledSlicedByteBuf.slice(AbstractUnpooledSlicedByteBuf.java:230)
	at io.netty.buffer.AbstractByteBuf.readSlice(AbstractByteBuf.java:836)
	at org.redisson.codec.MapCacheEventCodec.decode(MapCacheEventCodec.java:101)
	at org.redisson.codec.MapCacheEventCodec.access$100(MapCacheEventCodec.java:35)
	at org.redisson.codec.MapCacheEventCodec$1.decode(MapCacheEventCodec.java:47)
	at org.redisson.client.protocol.pubsub.PubSubMessageDecoder.decode(PubSubMessageDecoder.java:38)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:283)
	at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:313)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:302)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:120)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:367)
	... 24 more

Any suggestions would be appreciated, thanks.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/910
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Would it be possible in the future to have a feature which can get entries matching a Predicate?
For example, if I have an RMap<String, MyObject>
class MyObject {
   public String a;
   ...
}
With an EntryProcessor i could have the ability to get all MyObject in the map that match a == "hello" for instance.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/911
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I didn't find any simple examples about how to retrieve an object using RBucketReactive. Here's my example:
RedissonReactiveClient reactiveClient = Redisson.createReactive();
List<RBucketReactive<MyDTO>> buckets = reactiveClient.findBuckets("dtos::*");
for (RBucketReactive<MyDTO> bucket: buckets)
{
    // First I tried to obtain an object just with the `.get()` method, but the return is a Publisher<MyDTO>. 
    MyDTO test = bucket.get(); // conversion error

    // I found this: https://github.com/redisson/redisson/blob/master/redisson/src/test/java/org/redisson/BaseReactiveTest.java
    // Tried to do something similar:
    MyDTO test = ((Promise<MyDTO>)bucket.get()).poll(); // this gives java.lang.ClassCastException: org.redisson.reactive.NettyFuturePublisher cannot be cast to reactor.rx.Promise
}

Can someone help?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/912
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
There is a deserialization security vulnerability in the jackson-databind version you are using.
See Jackson Deserializer security vulnerability issue 1599
Fixed in 2.7.9.1
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/913
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
This is the error which i was receiving while with Oracle JDK this was working fine
Caused by: java.lang.NoSuchMethodError: io/netty/util/internal/PlatformDependent.newAtomicIntegerFieldUpdater(Ljava/lang/Class;Ljava/lang/String;)Ljava/util/concurrent/atomic/AtomicIntegerFieldUpdater; (loaded from file:/app/jws-3.1/tomcat8/webapps/livpvnasci01.r1-core.r1.aig.netisoAbhishekOHTechStackJun6ReferenceDataService/WEB-INF/lib/netty-common-4.1.8.Final.jar by WebappClassLoader
    at io.netty.channel.ChannelOutboundBuffer.<clinit>(ChannelOutboundBuffer.java:92) ~[netty-all-4.1.5.Final.jar:4.1.5.Final]
    at io.netty.channel.AbstractChannel$AbstractUnsafe.<init>(AbstractChannel.java:421) ~[netty-all-4.1.5.Final.jar:4.1.5.Final]
    at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.<init>(AbstractNioChannel.java:218) ~[netty-all-4.1.5.Final.jar:4.1.5.Final]
    at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.<init>(AbstractNioByteChannel.java:72) ~[netty-all-4.1.5.Final.jar:4.1.5.Final]
    at io.netty.channel.socket.nio.NioSocketChannel$NioSocketChannelUnsafe.<init>(NioSocketChannel.java:458) ~[netty-all-4.1.5.Final.jar:4.1.5.Final]
    at io.netty.channel.socket.nio.NioSocketChannel$NioSocketChannelUnsafe.<init>(NioSocketChannel.java:458) ~[netty-all-4.1.5.Final.jar:4.1.5.Final]
    at io.netty.channel.socket.nio.NioSocketChannel.newUnsafe(NioSocketChannel.java:455) ~[netty-all-4.1.5.Final.jar:4.1.5.Final]
    at io.netty.channel.socket.nio.NioSocketChannel.newUnsafe(NioSocketChannel.java:50) ~[netty-all-4.1.5.Final.jar:4.1.5.Final]
    at io.netty.channel.AbstractChannel.<init>(AbstractChannel.java:80) ~[netty-all-4.1.5.Final.jar:4.1.5.Final]
    at io.netty.channel.nio.AbstractNioChannel.<init>(AbstractNioChannel.java:84) ~[netty-all-4.1.5.Final.jar:4.1.5.Final]
    at io.netty.channel.nio.AbstractNioByteChannel.<init>(AbstractNioByteChannel.java:54) ~[netty-all-4.1.5.Final.jar:4.1.5.Final]
    at io.netty.channel.socket.nio.NioSocketChannel.<init>(NioSocketChannel.java:98) ~[netty-all-4.1.5.Final.jar:4.1.5.Final]
    at io.netty.channel.socket.nio.NioSocketChannel.<init>(NioSocketChannel.java:88) ~[netty-all-4.1.5.Final.jar:4.1.5.Final]
    at io.netty.channel.socket.nio.NioSocketChannel.<init>(NioSocketChannel.java:81) ~[netty-all-4.1.5.Final.jar:4.1.5.Final]
    at io.netty.channel.socket.nio.NioSocketChannel.<init>(NioSocketChannel.java:74) ~[netty-all-4.1.5.Final.jar:4.1.5.Final]
    at java.lang.J9VMInternals.newInstanceImpl(Native Method) ~[na:na]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/914
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When the network is unavailable I get the following error
org.redisson.client.RedisTimeoutException: Command execution timeout for xxxxxx/xx.xx.xx.xx:6379
at org.redisson.client.RedisConnection$2.run(RedisConnection.java:193) [redisson-3.4.2.jar:?]
at io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38) [netty-common-4.1.10.Final.jar:4.1.10.Final]
at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:120) [netty-common-4.1.10.Final.jar:4.1.10.Final]
at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163) [netty-common-4.1.10.Final.jar:4.1.10.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403) [netty-common-4.1.10.Final.jar:4.1.10.Final]
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:462) [netty-transport-4.1.10.Final.jar:4.1.10.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) [netty-common-4.1.10.Final.jar:4.1.10.Final]
at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144) [netty-common-4.1.10.Final.jar:4.1.10.Final]
at java.lang.Thread.run(Thread.java:745) [?:1.8.0_73]
Which is expected but once the network connection is restored redisson never reconnects. I am using ElasticCache and Redisson version 3.4.2. Most of my settings are default, I tried some settings but nothing works. I presume that this should happen by default which is the case when I use Jedis
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/915
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
look at the code below:
RBucket rBucket = redissonClient.getBucket(key); //key="redisson_lx"
rBucket.set(value); //value = "ok";
then i use redis-cli ：
ip:7001)>get redisson_lx
"\xA2ok"
why the value include :\xA2 ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/916
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Version:2.9.2
                final SetFutureByteArrayListener listener = new SetFutureByteArrayListener();
                final String measureUID = StringUtil.createMeasureUID();
                final RMap<Long, byte[]> rMap = redisson.getMap(measureUID);

                Observable.interval(1L, TimeUnit.SECONDS).map(new Func1<Long, Pair<Long, byte[]>>() {
                    @Override
                    public Pair<Long, byte[]> call(Long aLong) {
                        byte[] bytes = new byte[200];
                        ByteUtil.random(bytes);
                        return Pair.create(aLong, bytes);
                    }
                }).map(new Func1<Pair<Long,byte[]>, RFuture<byte[]>>() {
                    @Override
                    public RFuture<byte[]> call(Pair<Long, byte[]> longPair) {
                        return rMap.putAsync(longPair.first, longPair.second);
                    }
                }).compose(RxUtils.<RFuture<byte[]>>applyNewThreadSchedulers()).subscribe(new Subscriber<RFuture<byte[]>>() {
                    @Override
                    public void onCompleted() {
                        Log.v(RedisActivity.class.getSimpleName(), RedisActivity.class.getSimpleName().concat(":upload byte array completed"));
                    }

                    @Override
                    public void onError(Throwable e) {
                        Toast.makeText(RedisActivity.this, e.getMessage(), Toast.LENGTH_LONG).show();
                    }

                    @Override
                    public void onNext(RFuture<byte[]> rFuture) {
                        rFuture.addListener(listener);
                    }
                });
public class SetFutureByteArrayListener implements FutureListener<byte[]> {
    @Override
    public void operationComplete(Future<byte[]> future) throws Exception {
        byte[] res = future.getNow();
        Log.e(SetFutureByteArrayListener.class.getSimpleName(), String.valueOf(res.length));
    }
}
I try to get the value of future.getNow() when debugging, but I get io.netty.util.concurrent.DefaultPromise#SUCCESS and the value is null.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/917
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Version:2.9.3
                        Observable.just(1)
                        .map(new Func1<Integer, RedissonClient>() {
                            @Override
                            public RedissonClient call(Integer integer) {
                                Config config = new Config();
                                SingleServerConfig singleServerConfig = config.useSingleServer();
//                ReplicatedServersConfig singleServerConfig = config.useReplicatedServers();
                                String address = redisResult.getHost().concat(":").concat(redisResult.getPort());
                                singleServerConfig.setAddress(address);
                                singleServerConfig.setSubscriptionConnectionMinimumIdleSize(Constant.SUBSCRIPTION_CONNECTION_MINIMUM_IDLE_SIZE);
                                singleServerConfig.setSubscriptionConnectionPoolSize(Constant.SUBSCRIPTION_CONNECTION_POOL_SIZE);
                                singleServerConfig.setConnectionMinimumIdleSize(Constant.CONNECTION_MINIMUM_IDLE_SIZE);
                                singleServerConfig.setTimeout(Constant.TIME_OUT);
                                singleServerConfig.setRetryAttempts(Constant.RETRY_ATTEMPTS);
                                singleServerConfig.setRetryInterval(Constant.RETRY_INTERVAL);
//                singleServerConfig.setScanInterval(Constant.SCAN_INTERVAL);
                                singleServerConfig.setReconnectionTimeout(Constant.RECONNECTION_TIME_OUT);
                                singleServerConfig.setFailedAttempts(Constant.FAILED_ATTEMPT);
                                singleServerConfig.setPassword(redisResult.getPassword());
                                singleServerConfig.setSubscriptionsPerConnection(Constant.SUBSCRIPTIONS_PER_CONNECTION);
                                redisson = Redisson.create(config);
                                return redisson;
                            }
                        })
                        .compose(RxUtils.<RedissonClient>applyNewThreadSchedulers()).subscribe(
                        new Action1<RedissonClient>() {
                            @Override
                            public void call(RedissonClient redissonClient) {
                                Toast.makeText(RedisActivity.this, redissonClient.toString(), Toast.LENGTH_LONG).show();
                            }
                        },
                        new Action1<Throwable>() {
                            @Override
                            public void call(Throwable throwable) {
                                Log.e("RedisActivity", "configuration", throwable);
                            }
                        }
                );
I got the error message as followed when the code to the singleServerConfig.setAddress(address);.
E/RedisActivity: configuration
                                                                 java.lang.IllegalArgumentException: Illegal character in scheme at index 0: [s4.*********.com]:????
                                                                     at java.net.URI.create(URI.java:733)
                                                                     at org.redisson.misc.URIBuilder.create(URIBuilder.java:37)
                                                                     at org.redisson.config.SingleServerConfig.setAddress(SingleServerConfig.java:129)
                                                                     at com.++++++.redisson.redis.RedisActivity$2$3.call(RedisActivity.java:102)
                                                                     at com.++++++.redisson.redis.RedisActivity$2$3.call(RedisActivity.java:95)
                                                                     at rx.internal.operators.OnSubscribeMap$MapSubscriber.onNext(OnSubscribeMap.java:69)
                                                                     at rx.internal.util.ScalarSynchronousObservable$WeakSingleProducer.request(ScalarSynchronousObservable.java:276)
                                                                     at rx.internal.operators.OperatorSubscribeOn$1$1$1.request(OperatorSubscribeOn.java:80)
                                                                     at rx.Subscriber.setProducer(Subscriber.java:209)
                                                                     at rx.internal.operators.OperatorSubscribeOn$1$1.setProducer(OperatorSubscribeOn.java:76)
                                                                     at rx.internal.operators.OnSubscribeMap$MapSubscriber.setProducer(OnSubscribeMap.java:102)
                                                                     at rx.internal.util.ScalarSynchronousObservable$JustOnSubscribe.call(ScalarSynchronousObservable.java:138)
                                                                     at rx.internal.util.ScalarSynchronousObservable$JustOnSubscribe.call(ScalarSynchronousObservable.java:129)
                                                                     at rx.Observable.unsafeSubscribe(Observable.java:10142)
                                                                     at rx.internal.operators.OnSubscribeMap.call(OnSubscribeMap.java:48)
                                                                     at rx.internal.operators.OnSubscribeMap.call(OnSubscribeMap.java:33)
                                                                     at rx.Observable.unsafeSubscribe(Observable.java:10142)
                                                                     at rx.internal.operators.OperatorSubscribeOn$1.call(OperatorSubscribeOn.java:94)
                                                                     at rx.internal.schedulers.ScheduledAction.run(ScheduledAction.java:55)
                                                                     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:423)
                                                                     at java.util.concurrent.FutureTask.run(FutureTask.java:237)
                                                                     at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:154)
                                                                     at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:269)
                                                                     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1113)
                                                                     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:588)
                                                                     at java.lang.Thread.run(Thread.java:818)
                                                                  Caused by: rx.exceptions.OnErrorThrowable$OnNextValue: OnError while emitting onNext value: 1
                                                                     at rx.internal.operators.OnSubscribeMap$MapSubscriber.onNext(OnSubscribeMap.java:73)
                                                                     at rx.internal.util.ScalarSynchronousObservable$WeakSingleProducer.request(ScalarSynchronousObservable.java:276) 
                                                                     at rx.internal.operators.OperatorSubscribeOn$1$1$1.request(OperatorSubscribeOn.java:80) 
                                                                     at rx.Subscriber.setProducer(Subscriber.java:209) 
                                                                     at rx.internal.operators.OperatorSubscribeOn$1$1.setProducer(OperatorSubscribeOn.java:76) 
                                                                     at rx.internal.operators.OnSubscribeMap$MapSubscriber.setProducer(OnSubscribeMap.java:102) 
                                                                     at rx.internal.util.ScalarSynchronousObservable$JustOnSubscribe.call(ScalarSynchronousObservable.java:138) 
                                                                     at rx.internal.util.ScalarSynchronousObservable$JustOnSubscribe.call(ScalarSynchronousObservable.java:129) 
                                                                     at rx.Observable.unsafeSubscribe(Observable.java:10142) 
                                                                     at rx.internal.operators.OnSubscribeMap.call(OnSubscribeMap.java:48) 
                                                                     at rx.internal.operators.OnSubscribeMap.call(OnSubscribeMap.java:33) 
                                                                     at rx.Observable.unsafeSubscribe(Observable.java:10142) 
                                                                     at rx.internal.operators.OperatorSubscribeOn$1.call(OperatorSubscribeOn.java:94) 
                                                                     at rx.internal.schedulers.ScheduledAction.run(ScheduledAction.java:55) 
                                                                     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:423) 
                                                                     at java.util.concurrent.FutureTask.run(FutureTask.java:237) 
                                                                     at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:154) 
                                                                     at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:269) 
                                                                     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1113) 
                                                                     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:588) 
                                                                     at java.lang.Thread.run(Thread.java:818) 

But I promiss that address== s4.*********.com:???? in String address = redisResult.getHost().concat(":").concat(redisResult.getPort());
Fortunately, there is no error with 2.9.2.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/918
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Caused by: com.esotericsoftware.kryo.KryoException: Class cannot be created (missing no-arg constructor): java.util.Arrays$ArrayList
Serialization trace:
keyHashes (org.redisson.RedissonLocalCachedMap$LocalCachedMapInvalidate)
	at com.esotericsoftware.kryo.Kryo$DefaultInstantiatorStrategy.newInstantiatorOf(Kryo.java:1310) ~[kryo-4.0.0.jar:na]
	at com.esotericsoftware.kryo.Kryo.newInstantiator(Kryo.java:1127) ~[kryo-4.0.0.jar:na]
	at com.esotericsoftware.kryo.Kryo.newInstance(Kryo.java:1136) ~[kryo-4.0.0.jar:na]
	at com.esotericsoftware.kryo.serializers.CollectionSerializer.create(CollectionSerializer.java:107) ~[kryo-4.0.0.jar:na]
	at com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:111) ~[kryo-4.0.0.jar:na]
	at com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:40) ~[kryo-4.0.0.jar:na]
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:734) ~[kryo-4.0.0.jar:na]
	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125) ~[kryo-4.0.0.jar:na]
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:540) ~[kryo-4.0.0.jar:na]
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:816) ~[kryo-4.0.0.jar:na]
	at org.redisson.codec.KryoCodec$1.decode(KryoCodec.java:112) ~[redisson-3.4.2.jar:na]
	at org.redisson.client.protocol.pubsub.PubSubMessageDecoder.decode(PubSubMessageDecoder.java:38) ~[redisson-3.4.2.jar:na]
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:283) ~[redisson-3.4.2.jar:na]
	at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:313) ~[redisson-3.4.2.jar:na]
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:302) ~[redisson-3.4.2.jar:na]
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:120) ~[redisson-3.4.2.jar:na]
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:367) ~[netty-codec-4.1.10.Final.jar:4.1.10.Final]
	... 20 common frames omitted

Source code about org.redisson.RedissonLocalCachedMap$LocalCachedMapInvalidate:
public static class LocalCachedMapInvalidate implements Serializable {
     
     private byte[] excludedId;
     private List<byte[]> keyHashes;

     public LocalCachedMapInvalidate() {
     }
     
     public LocalCachedMapInvalidate(byte[] excludedId, byte[]... keyHash) {
         super();
         this.keyHashes = Arrays.asList(keyHash);
         this.excludedId = excludedId;
     }
     
     public byte[] getExcludedId() {
         return excludedId;
     }
     
     public Collection<byte[]> getKeyHashes() {
         return keyHashes;
     }
     
 }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/919
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/920
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
TaskId parameter should be exposed by api during task submission through RExecutorService. To achieve a new interface RExecutorFuture is required.
Usage example:
RExecutorFuture<Integer> future = service.submit(task);

service.cancelTask(future.getTaskId());
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/921
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/922
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Just looking for some clarification on how the RLocalCachedMap works.
The documentation says it's better suited for read heavy operations (and less network round trips), which sounds perfect for something I'm implementing currently, which is a small map of runtime configurations (for simple settings like max for this and limit on that etc... Then the map in redis can be altered externally, and in turn my application without having to restart, since it's a service)
My question is does the RLocalCachedMap periodically update it's values from Redis every so often?  If so, how frequent?  If not, is there a mechanism to force it to update?  Would RLocalCachedMap be a good use case for having update on the fly, runtime config vals?
Thanks and keep up the awesome work!
P.S.
Using Redisson 3.4.3 (sentinel master/slave setup), and Java 8 on Centos linux 64bit
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/923
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/924
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
here is  my config code:

<redisson:client id="redissonClient">
<redisson:sentinel-servers master-name="${redis.master.name}" database="3">
<redisson:sentinel-address value="${redis.sentinel.address}" />
</redisson:sentinel-servers>
</redisson:client>

when i start my application,some exception happen:

Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.redisson.api.RedissonClient]: Factory method 'create' threw exception; nested exception is org.redisson.client.RedisConnectionException: Can't connect to servers!
at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:189)
at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
... 37 more
Caused by: org.redisson.client.RedisConnectionException: Can't connect to servers!
at org.redisson.connection.SentinelConnectionManager.(SentinelConnectionManager.java:122)
at org.redisson.config.ConfigSupport.createConnectionManager(ConfigSupport.java:234)
at org.redisson.Redisson.(Redisson.java:115)
at org.redisson.Redisson.create(Redisson.java:154)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)

and i track the sourecode,

for (URI addr : cfg.getSentinelAddresses()) {
RedisClient client = createClient(NodeType.SENTINEL, addr, this.config.getConnectTimeout(), this.config.getRetryInterval() * this.config.getRetryAttempts());
try {
RedisConnection connection = client.connect();
if (!connection.isActive()) {
continue;
}
....

the code RedisConnection connection = client.connect() throws Exception:

Caused by: org.redisson.client.RedisException: ERR unknown command 'SELECT'. channel: [id: 0x030d3a7f, L:/10.21.51.59:63744 - R:/114.55.11.93:7010] command: CommandData [promise=org.redisson.misc.RedissonPromise@9db3b5a, command=(SELECT), params=[3], codec=null]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:267)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:127)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:367)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1334)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:926)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:134)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:644)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
at java.lang.Thread.run(Thread.java:745)

it's seem like execute 'select 3' in sentinel, then cause the exception
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/925
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RScoredSortedSet always put the double quotes to the string value which stored in Redis. The following is how to reproduce the issue:

Add string value to RScoredSortedSet in Java

RScoredSortedSet<String> set = redisson.getScoredSortedSet("test_score_set_1");
set.add(1d, "1:100");


List all the values in the ZSet via redis-cli

127.0.0.1:6379> zrange test_score_set_1 0 -1
1) "\"1:100\""

The listed value should be "1:100" instead of "\"1:100\""
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/926
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I have 3 nodes of redis configured as sentinel.
This is my config:
                    SentinelServersConfig sentinelServersConfig = config.useSentinelServers();                    
                    sentinelServersConfig.setMasterName("redis-cluster");
                    for (String server : servers) {
                        sentinelServersConfig.addSentinelAddress("redis://" + server + ":" + port);
                    }
                    Redisson.create(config)

When terminating the master node, redis cluster allocated a new master but Redisson fails to recognize that and starts to fail with this error:
MasterConnectionPool no available Redis entries.  Disconnected hosts: [/100.127.5.18:6379]
Seems that it fails to recover and locate the new master.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/927
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/928
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Using Spring + RedissonSpringCacheManager, I can't cache methods returning Optional<T>. Sample:
@Service
public class MyService {
    @Cacheable("myCache")
    public Optional<String> testCache(int foo) {
        return Optional.empty();
    }
}
Spring automatically "unwraps" the result from Optional before sending it to cache manager, see org.springframework.cache.interceptor.CacheAspectSupport#unwrapReturnValue:
private Object unwrapReturnValue(Object returnValue) {
	if (returnValue != null && returnValue.getClass() == javaUtilOptionalClass) {
		return OptionalUnwrapper.unwrap(returnValue);
	}
	return returnValue;
}
Which returns null when the optional is empty:
public static Object unwrap(Object optionalObject) {
	Optional<?> optional = (Optional<?>) optionalObject;
	if (!optional.isPresent()) {
		return null;
	}
	Object result = optional.get();
	Assert.isTrue(!(result instanceof Optional), "Multi-level Optional usage not supported");
	return result;
}
Then org.redisson.RedissonMap#fastPutAsync doesn't support map's value being null, so I receive a NullPointerException.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/929
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am trying to use a Live Object with a Map<DateTime, T> field. I use the rLiveObjectService.merge() to persist to Redis.
I can retrieve the Live Object OK using get(), but the Map field is always empty. I have stepped through the code and the Map field is populated OK - something appears to be going wrong when persisting the Map to Redis.
If I use a List field, this returns correctly i.e. is populated.
From the Live Object example code, the Map should work.
I'm using Redisson 3.4.3.
Are there any known issues with using a Map<> field on Live Object?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/930
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/931
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/932
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/933
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/934
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/935
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/936
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/937
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/938
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/939
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/940
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/941
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/942
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/943
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/944
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/945
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/946
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/947
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/948
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/949
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/950
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/951
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/952
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/953
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/954
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/955
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/956
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/957
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/958
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/959
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/960
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/961
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/962
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/963
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/964
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/965
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/966
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/967
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/968
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/969
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/970
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/971
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/972
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/973
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/974
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/975
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/976
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/977
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/978
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/979
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/980
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/981
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/982
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/983
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/984
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/985
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/986
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/987
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/988
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/989
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/990
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/991
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/992
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/993
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/994
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/995
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/996
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/997
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/998
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/999
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1000
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1001
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1002
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1003
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1004
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1005
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1006
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1007
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1008
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1009
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1010
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1011
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1012
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1013
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1014
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1015
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1016
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1017
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1018
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1019
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1020
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1021
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1022
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1023
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1024
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1025
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1026
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1027
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1028
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1029
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1030
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1031
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1032
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1033
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1034
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1035
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1036
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1037
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1038
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1039
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1040
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1041
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1042
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1043
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1044
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1045
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1046
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1047
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1048
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1049
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1050
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1051
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1052
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We just upgraded our redisson library from 3.3.2 to 3.5.1. Our application has no problems when run in a single Redis server mode or with 3.3.2, but when we run it in a sentinel mode with 3.5.1 it does not work at all, constantly generating error messages. Our sentinel cluster consists of 3 servers (master and 2 slaves) and 5 sentinel clients. Redis version :3.2.8. Here is example of error log
49022 13 Sep 2017 22:09:53 +0000 [qtp786041152-21] INFO  org.redisson.Version - Redisson 3.5.1
49241 13 Sep 2017 22:09:54 +0000 [qtp786041152-21] INFO  o.r.c.SentinelConnectionManager - master: redis://172.30.1.87:6379 added
49251 13 Sep 2017 22:09:54 +0000 [qtp786041152-21] INFO  o.r.c.SentinelConnectionManager - slave: redis://172.30.0.8:6379 added
49251 13 Sep 2017 22:09:54 +0000 [qtp786041152-21] INFO  o.r.c.SentinelConnectionManager - slave: redis://172.30.1.206:6379 added
49292 13 Sep 2017 22:09:54 +0000 [redisson-netty-1-4] INFO  o.r.c.pool.SlaveConnectionPool - 10 connections initialized for /172.30.0.8:6379
49292 13 Sep 2017 22:09:54 +0000 [redisson-netty-1-3] INFO  o.r.c.pool.PubSubConnectionPool - 1 connections initialized for /172.30.1.206:6379
49292 13 Sep 2017 22:09:54 +0000 [redisson-netty-1-3] INFO  o.r.c.pool.SlaveConnectionPool - 10 connections initialized for /172.30.1.206:6379
49292 13 Sep 2017 22:09:54 +0000 [redisson-netty-1-3] INFO  o.r.c.pool.PubSubConnectionPool - 1 connections initialized for /172.30.0.8:6379
49300 13 Sep 2017 22:09:54 +0000 [redisson-netty-1-3] INFO  o.r.c.pool.MasterConnectionPool - 10 connections initialized for /172.30.1.87:6379
49313 13 Sep 2017 22:09:54 +0000 [redisson-netty-1-1] INFO  o.r.c.SentinelConnectionManager - sentinel: 172.30.0.8:26379 added
49316 13 Sep 2017 22:09:54 +0000 [redisson-netty-1-3] INFO  o.r.c.SentinelConnectionManager - sentinel: 172.30.1.206:26379 added
49840 13 Sep 2017 22:09:54 +0000 [redisson-netty-1-3] WARN  i.n.util.concurrent.DefaultPromise - An exception was thrown by org.redisson.command.CommandAsyncService$14.operationComplete()
java.lang.NullPointerException: null
        at org.redisson.connection.pool.ConnectionPool.returnConnection(ConnectionPool.java:441)
        at org.redisson.connection.pool.SlaveConnectionPool.returnConnection(SlaveConnectionPool.java:30)
        at org.redisson.connection.balancer.LoadBalancerManager.returnConnection(LoadBalancerManager.java:210)
        at org.redisson.connection.MasterSlaveEntry.releaseRead(MasterSlaveEntry.java:459)
        at org.redisson.connection.MasterSlaveConnectionManager.releaseRead(MasterSlaveConnectionManager.java:770)
        at org.redisson.command.CommandAsyncService$14.operationComplete(CommandAsyncService.java:732)
        at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
        at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:500)
        at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:479)
        at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
        at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)
        at org.redisson.misc.RedissonPromise.trySuccess(RedissonPromise.java:78)
        at org.redisson.client.handler.CommandDecoder.handleResult(CommandDecoder.java:322)
        at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:253)
        at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:103)
        at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
        at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:367)
        at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
        at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
        at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1334)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
        at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:926)
        at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:134)
        at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:644)
        at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
        at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
        at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:745)


Here is our Sentinel info
# Server
redis_version:3.2.8
redis_git_sha1:00000000
redis_git_dirty:0
redis_build_id:79ea7151812d6ea4
redis_mode:sentinel
os:Linux 4.4.51-40.58.amzn1.x86_64 x86_64
arch_bits:64
multiplexing_api:epoll
gcc_version:4.8.3
process_id:27343
run_id:c42dedde7048b62d9163b65b330834e01cda4231
tcp_port:26379
uptime_in_seconds:14205790
uptime_in_days:164
hz:18
lru_clock:12177654
executable:/usr/local/bin/redis-server
config_file:/etc/redis/sentinel.conf

# Clients
connected_clients:5
client_longest_output_list:0
client_biggest_input_buf:0
blocked_clients:0

# CPU
used_cpu_sys:15195.70
used_cpu_user:11351.15
used_cpu_sys_children:0.00
used_cpu_user_children:0.00

# Stats
total_connections_received:21
total_commands_processed:66455494
instantaneous_ops_per_sec:4
total_net_input_bytes:3763710843
total_net_output_bytes:398315069
instantaneous_input_kbps:0.30
instantaneous_output_kbps:0.03
rejected_connections:0
sync_full:0
sync_partial_ok:0
sync_partial_err:0
expired_keys:0
evicted_keys:0
keyspace_hits:0
keyspace_misses:0
pubsub_channels:0
pubsub_patterns:0
latest_fork_usec:0
migrate_cached_sockets:0

# Sentinel
sentinel_masters:1
sentinel_tilt:0
sentinel_running_scripts:0
sentinel_scripts_queue_length:0
sentinel_simulate_failure_flags:0
master0:name=xxxxxx,status=ok,address=172.30.1.87:6379,slaves=2,sentinels=6
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1053
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Classes:
1、Main:
RedissonClient redisson = Redisson.create(config);
RMap<String, String> map = redisson.getMap("wordsMap");
map.put("line1", "Alice was beginning to get very tired");
map.put("line2", "of sitting by her sister on the bank and");
map.put("line3", "of having nothing to do once or twice she");
map.put("line4", "had peeped into the book her sister was reading");
map.put("line5", "but it had no pictures or conversations in it");
map.put("line6", "and what is the use of a book");
map.put("line7", "thought Alice without pictures or conversation");
RMapReduce<String, String, String, Integer> mapReduce = map.<String, Integer>mapReduce().mapper(new WordMapper()).reducer(new WordReducer()).timeout(60, TimeUnit.MINUTES);
// count occurrences of words
Map<String, Integer> mapToNumber = mapReduce.execute();
System.out.println("mapToNumber=" + mapToNumber);
// count total words amount
Integer totalWordsAmount = mapReduce.execute(new WordCollator());
System.out.println("totalWordsAmount=" + totalWordsAmount);
2、public class WordCollator implements RCollator<String, Integer, Integer> {
public Integer collate(Map<String, Integer> resultMap) {
int result = 0;
for (Integer count : resultMap.values()) {
result += count;
}
return result;
}
}
3、WordMapper：
public void map(String key, String value, RCollector<String, Integer> collector) {
String[] words = value.split("[^a-zA-Z]");
for (String word : words) {
collector.emit(word, 1);
}
}
4、WordReducer：
public Integer reduce(String reducedKey, Iterator values) {
int sum = 0;
while (values.hasNext()) {
Integer i = (Integer) values.next();
sum += i;
}
return sum;
}
Result as following: mapReduce.execute(new WordCollator()) is error.
[main] INFO org.redisson.Version - Redisson 3.5.3
[redisson-netty-1-5] INFO org.redisson.connection.pool.MasterPubSubConnectionPool - 1 connections initialized for /11.1.1.1:7379
[redisson-netty-1-6] INFO org.redisson.connection.pool.MasterConnectionPool - 10 connections initialized for /11.1.1.1:7379
mapToNumber={sitting=1, Alice=2, beginning=1, by=1, to=2, was=2, her=2, and=2, tired=1, the=3, had=2, sister=2, once=1, peeped=1, bank=1, reading=1, into=1, she=1, but=1, no=1, pictures=2, it=2, thought=1, conversations=1, what=1, without=1, in=1, conversation=1, use=1, a=1, get=1, very=1, of=3, on=1, having=1, nothing=1, do=1, or=3, twice=1, book=2, is=1}
Exception in thread "main" org.redisson.client.RedisException: Unexpected exception while processing command
at org.redisson.command.CommandAsyncService.convertException(CommandAsyncService.java:322)
at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:165)
at org.redisson.mapreduce.MapReduceExecutor.execute(MapReduceExecutor.java:156)
at org.redisson.mapreduce.RedissonMapReduce.execute(RedissonMapReduce.java:38)
at org.redisson.example.mr.Test.main(Test.java:34)
Caused by: java.lang.IllegalArgumentException: java.lang.NullPointerException
at .executeCallable(TasksRunnerService.java:183)
at .executeCallable(TasksRunnerService.java:163)
at .invoke0(Native Method)
at .invoke(NativeMethodAccessorImpl.java:62)
at .invoke(DelegatingMethodAccessorImpl.java:43)
at .invoke(Method.java:498)
at .invokeMethod(RedissonRemoteService.java:276)
at .access$400(RedissonRemoteService.java:59)
at .run(RedissonRemoteService.java:239)
at .call(Executors.java:511)
at .run(FutureTask.java:266)
at .runWorker(ThreadPoolExecutor.java:1142)
at .run(ThreadPoolExecutor.java:617)
at .run(DefaultThreadFactory.java:138)
at .run(Thread.java:745)
Caused by: java.lang.NullPointerException
at .executeCollator(CoordinatorTask.java:147)
at .call(CoordinatorTask.java:129)
at .executeCallable(TasksRunnerService.java:176)
... 14 more
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1054
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
use spring-session+redisson+spring security(spring boot 1.5.7, redisson3.5.3, spring-security4.2.3)，when i access controller throw exception like this:
org.redisson.client.RedisException: Unexpected exception while processing command
at org.redisson.command.CommandAsyncService.convertException(CommandAsyncService.java:322)
at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:165)
at org.redisson.RedissonObject.get(RedissonObject.java:72)
at org.redisson.RedissonMap.readAllEntrySet(RedissonMap.java:371)
at org.redisson.spring.session.RedissonSessionRepository$RedissonSession.load(RedissonSessionRepository.java:95)
at org.redisson.spring.session.RedissonSessionRepository.getSession(RedissonSessionRepository.java:300)
at org.redisson.spring.session.RedissonSessionRepository.getSession(RedissonSessionRepository.java:51)
at org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper.getSession(SessionRepositoryFilter.java:327)
at org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper.getSession(SessionRepositoryFilter.java:344)
at org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper.getSession(SessionRepositoryFilter.java:217)
at javax.servlet.http.HttpServletRequestWrapper.getSession(HttpServletRequestWrapper.java:231)
at org.springframework.security.web.context.HttpSessionSecurityContextRepository.loadContext(HttpSessionSecurityContextRepository.java:110)
at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:100)
at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)
at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56)
at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)
at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214)
at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177)
at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:346)
at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:262)
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108)
at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81)
at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
at org.springframework.session.web.http.SessionRepositoryFilter.doFilterInternal(SessionRepositoryFilter.java:167)
at org.springframework.session.web.http.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:80)
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106)
at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:478)
at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:80)
at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:799)
at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1457)
at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
at java.lang.Thread.run(Thread.java:745)
Caused by: com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of org.springframework.security.web.savedrequest.DefaultSavedRequest (no Creators, like default construct, exist): cannot deserialize from Object value (no delegate- or property-based Creator)
at [Source: (io.netty.buffer.ByteBufInputStream); line: 1, column: 79]
at com.fasterxml.jackson.databind.exc.InvalidDefinitionException.from(InvalidDefinitionException.java:67)
at com.fasterxml.jackson.databind.DeserializationContext.reportBadDefinition(DeserializationContext.java:1438)
at com.fasterxml.jackson.databind.DeserializationContext.handleMissingInstantiator(DeserializationContext.java:1027)
at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromObjectUsingNonDefault(BeanDeserializerBase.java:1275)
at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeFromObject(BeanDeserializer.java:325)
at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:194)
at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:161)
at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedForId(AsPropertyTypeDeserializer.java:130)
at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:97)
at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromAny(AsPropertyTypeDeserializer.java:193)
at com.fasterxml.jackson.databind.deser.std.UntypedObjectDeserializer$Vanilla.deserializeWithType(UntypedObjectDeserializer.java:712)
at com.fasterxml.jackson.databind.deser.impl.TypeWrappedDeserializer.deserialize(TypeWrappedDeserializer.java:68)
at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4001)
at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3058)
at org.redisson.codec.JsonJacksonCodec$2.decode(JsonJacksonCodec.java:87)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:259)
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:289)
at org.redisson.client.handler.CommandDecoder.decodeFromCheckpoint(CommandDecoder.java:154)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:101)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:367)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:134)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
... 1 common frames omitted
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1055
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@mrniko
Hi, Master.
Is Redisson suitable for developing the realtime anti-fraud system which needs high performance, such as 10 millisecond to finish the computing?
Thank you very much!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1056
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1057
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I'm confused when I read RedissonBoundedBlockingQueue.takeAsync() as follow
@Override
    public RFuture<V> takeAsync() {
        RFuture<V> takeFuture = commandExecutor.writeAsync(getName(), codec, RedisCommands.BLPOP_VALUE, getName(), 0);
        return wrapTakeFuture(takeFuture);
    }

the takeAsync method first use BLPOP to take object from redis,then if success will call releaseAsync() to increment capacity, I think that two request is not atomic operation, and will cause concurrent issues?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1058
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
fieldTransformation - 字段转换模式。如上所述，为了尽可能的保证RLO的用法和普通Java对象一直，Redisson会自动将常用的普通Java对象转换成与其匹配的Redisson分布式对象。这是由于字段转换模式的默认值是ANNOTATION_BASED，修改为ANNOTATION_BASED就可以不转换。
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1059
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
How properly remove stale tasks if my supervisor(who submits tasks) not gracefully exited - crashed.
Workers(redisson nodes) see submited task, executes them and put result back to redis. So after several crashes of supervisor I'v got alot of staled tasks: around 3k.
So how gracefully handle this? What you would recommend to handle this situation?
I have used Distributed scheduled executor service.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1060
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Because map use the jaskson codec,it seem can't resove empty value.But redis server support it.
How can i do this?
也就是说，缓存map的时候，不能有相应的空值，所以我之前使用jedis客户端存进去的值，部分为Null的会取不出来，
Caused by: com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'language': was expecting ('true', 'false' or 'null')
at [Source: io.netty.buffer.ByteBufInputStream@535b8c24; line: 1, column: 17]
at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1586)
at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:521)
at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._reportInvalidToken(UTF8StreamJsonParser.java:3464)
at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2628)
at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:854)
at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:748)
at com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:3847)
at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3792)
at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2867)
at org.redisson.codec.JsonJacksonCodec$2.decode(JsonJacksonCodec.java:87)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1061
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1062
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We are receiving an issue where we start getting the "too many open files" error in production.  This happens roughly 60 minutes after the application is running.

Ubuntu 16.04.2
java:

OpenJDK 64-bit Server VM (build 15.131-b11, mixed mode)
1.8.0_131


Redisson Pro v 3.5.3 (also experience this issue in 3.5.1).

We create a singleton (using Guice) that is injected into relevant classes in our application:
`
@singleton
public class CacheHelper implements ICacheHelper {
private Boolean useCache;

public Boolean getUseCache() {
    return useCache;
}

public void setUseCache(Boolean useCache) {
    this.useCache = useCache;
}

private final String redissonKey;
private final String cacheNodeAddressList;
private RedissonClient client;

@Inject
public  CacheHelper(@Named("cache.enabled") Boolean useCache, @Named("cache.authKey") String redissonKey, @Named("cache.nodeAddressList") String cacheNodeAddressList) {
    this.useCache = useCache;
    this.redissonKey = redissonKey;
    this.cacheNodeAddressList = cacheNodeAddressList;

    //we will not support redis caching on PAM instances, but are designing the cache layer to seamlessly support it in the future.
    if (useCache) {
        client = createClient();
    }
}

private RedissonClient createClient() {
    Config config = new Config();

    config.setCodec(new JsonJacksonCodec(getObjectMapper()));
    config.setRegistrationKey(this.redissonKey);
    config.setNettyThreads(16);
    config.setThreads(16);

    //split the injected urls into an array
    String[] nodeAddressArray = cacheNodeAddressList.split(";");

    //configure cluster addresses.
    for (String address : nodeAddressArray) {
        config.useClusterServers()
                .addNodeAddress(address);
    }

    //create config
    return Redisson.create(config);
}

private ObjectMapper getObjectMapper() {
    ObjectMapper mapper = new ObjectMapper();

    mapper.configure(MapperFeature.DEFAULT_VIEW_INCLUSION, true);
    mapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);
    mapper.disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS);
    mapper.disable(DeserializationFeature.ADJUST_DATES_TO_CONTEXT_TIME_ZONE);

    mapper.setSerializationInclusion(JsonInclude.Include.NON_NULL);
    mapper.setVisibility(mapper.getSerializationConfig().getDefaultVisibilityChecker().withFieldVisibility(JsonAutoDetect.Visibility.ANY).withGetterVisibility(JsonAutoDetect.Visibility.NONE).withSetterVisibility(JsonAutoDetect.Visibility.NONE).withCreatorVisibility(JsonAutoDetect.Visibility.NONE));

    mapper.configure(MapperFeature.SORT_PROPERTIES_ALPHABETICALLY, true);
    mapper.addMixIn(Throwable.class, JsonJacksonCodec.ThrowableMixIn.class);

    mapper.findAndRegisterModules();
    mapper.registerModule(new JavaTimeModule());

    return mapper;
}

public <T extends BaseTimeEntity> RMap<String, T> getMapCache(String mapName) {
    RMap<String, T> map = client.getMapCache(mapName);
    if (map == null) return null;

    return map;
}

    public <T extends BaseTimeEntity> T getValueFromMap(String mapName, String key) {
    RMap<String, T> map = client.getMapCache(mapName);
    if (map == null) return null;

    return map.get(key);
}

public <T> void setMapCache(String mapName, String key, T entity) {
    RMap<String, T> map = client.getMapCache(mapName);
    if (map == null) return;

    map.put(key, entity);
}

public <T> void setMapCache(String mapName, String key, T entity, int lifetime, TimeUnit timeUnit) {
    RMapCache<String, T> map = client.getMapCache(mapName);
    if (map == null) return;

    map.fastPut(key, entity, lifetime, timeUnit);
}

public <T> void removeKeyFromMapCache(String mapName, String key) {
    RMap<String, T> map = client.getMapCache(mapName);
    if (map == null) return;

    map.fastRemove(key);
}

public <T> void replaceMapCacheKeyValue(String mapName, String key, T entity) {
    RMap<String, T> map = client.getMapCache(mapName);
    if (map == null) return;

    map.fastRemove(key);

    map.fastPut(key, entity);
}

public <T> T getObject(CacheKeys key) {
    return getObject(key.getValue());
}

public <T> T getObject(String key) {
    RBucket<T> bucket = client.getBucket(key);
    if (bucket == null || bucket.size() < 1) {
        return null;
    }

    T value = bucket.get();

    return value;
}

public <T> void setObject(CacheKeys key, T object) {
    setObject(key.getValue(), object);
}

public <T> void setObject(String key, T object) {
    RBucket<T> bucket = client.getBucket(key);

    if (bucket != null) {
        bucket.set(object);
    }
}

public <T> void setObject(CacheKeys key, T object, Long lifetime, TimeUnit timeUnit) {
    setObject(key.getValue(), object, lifetime, timeUnit);
}

public <T> void setObject(String key, T object, Long lifetime, TimeUnit timeUnit) {
    RBucket<T> bucket = client.getBucket(key);
    if (bucket != null) {
        bucket.set(object, lifetime, timeUnit);
    }
}

public <T> void deleteObject(String key) {
    RBucket<T> bucket = client.getBucket(key);

    if (bucket == null) return;

    bucket.delete();
}

@WebApplicationHook(phase = AppPhase.SHUTDOWN)
public void shutdown() {
    client.shutdown();
}

}
`
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1063
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I want to make my multi-locks locate on different redis instances.
I find out that redission can specify an instance to execute command on, but if the command is key-related, the instance specified will transmit the command to another instance.
Can you give me some advice?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1064
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We are using redisson with spring cache and setting ttl on our keys. The problem is that we are not seeing any ttl being set on any key. Instead, I can see that some unnecessary keys are present in the redis database.
Here is the result of "keys *" command:
redisson__timeout__set:{acl_user_by_userid}"
3) "redisson__idle__set:{experiment_FG_mapping_by_release_id}"
4) "redisson__idle__set:{release}"
5) "acl_user_by_userid"
6) "redisson__idle__set:{acl_user_by_userid}"
7) "release"
8) "redisson__timeout__set:{experiment_FG_mapping_by_release_id}"
9) "association_by_releaseid"
10) "acl_org_by_id"
11) "redisson__timeout__set:{business_rules}"
12) "redisson__timeout__set:{acl_org_by_id}"
13) "redisson__timeout__set:{association_by_releaseid}"
14) "business_rules"
15) "redisson__idle__set:{association_by_releaseid}"
16) "redisson__timeout__set:{acl_org_roles_for_user}"
17) "redisson__idle__set:{acl_org_roles_for_user}"
18) "redisson__idle__set:{acl_org_by_id}"
19) "redisson__timeout__set:{release}"
You can see that for a key "release", the redisson creates two more keys "redisson__timeout__set:{release}" and "redisson__idle__set:{release}". Also, there is no ttl present on key "release".
My code is :
private Map<String, CacheConfig> getCacheConfigs() {
Map<String, CacheConfig> cacheConfigs = new HashMap<>();
//Set the ttl in miliseconds
    cacheConfigs.put(CACHE_NAME_RELEASE, new CacheConfig(ONE_DAY, ONE_DAY));
    ...

.       ....
.....
return cacheConfigs;
}
@Bean
public CacheManager cacheManager() {
    CacheManager cacheManager = new RedissonSpringCacheManager(redissonClient(), getCacheConfigs());
    return cacheManager;
}

We are using caching here:
@OverRide
@Cacheable(cacheNames = CACHE_NAME_RELEASE, key = "#releaseId", unless = "#result == null")
public ReleaseQO getReleaseById(Integer releaseId) {
// Some Code
}
I can see that redisson is internally using lua scripts for managing the ttl from client side:
(EVAL) with params: [local value = redis.call('hget', KEYS[1], ARGV[2]); if value == false then return nil; end; local t,..., 3, client_pv, redisson__timeout__set:{client_pv}, redisson__idle__set:{client_pv}, 1505747133337, pc_KCCC_pv_4.2]
Info commandstats gives me the following result:
info commandstats
Commandstats
cmdstat_get:calls=16257,usec=43644,usec_per_call=2.68
cmdstat_set:calls=367,usec=2267,usec_per_call=6.18
cmdstat_del:calls=163442,usec=1926658,usec_per_call=11.79
cmdstat_zadd:calls=112389614,usec=489906259,usec_per_call=4.36
cmdstat_zrem:calls=584488,usec=1861150,usec_per_call=3.18
cmdstat_zrange:calls=3,usec=12,usec_per_call=4.00
cmdstat_zrangebyscore:calls=1086546,usec=4011007,usec_per_call=3.69
cmdstat_zscore:calls=220466356,usec=945053083,usec_per_call=4.29
cmdstat_hset:calls=111150865,usec=167392674,usec_per_call=1.51
cmdstat_hget:calls=113042156,usec=231292617,usec_per_call=2.05
cmdstat_hdel:calls=295601,usec=668863,usec_per_call=2.26
cmdstat_hlen:calls=5,usec=6,usec_per_call=1.20
cmdstat_hgetall:calls=559,usec=4265,usec_per_call=7.63
cmdstat_hexists:calls=5,usec=9,usec_per_call=1.80
cmdstat_hscan:calls=1,usec=17,usec_per_call=17.00
cmdstat_select:calls=2,usec=2,usec_per_call=1.00
cmdstat_expire:calls=300847,usec=552356,usec_per_call=1.84
cmdstat_keys:calls=313,usec=191647,usec_per_call=612.29
cmdstat_ping:calls=3936569,usec=4360878,usec_per_call=1.11
cmdstat_psync:calls=12,usec=1602,usec_per_call=133.50
cmdstat_replconf:calls=15624259,usec=19486629,usec_per_call=1.25
cmdstat_flushall:calls=69,usec=98473,usec_per_call=1427.14
cmdstat_info:calls=6551875,usec=459090708,usec_per_call=70.07
cmdstat_ttl:calls=4,usec=18,usec_per_call=4.50
cmdstat_pttl:calls=1,usec=2,usec_per_call=2.00
cmdstat_slaveof:calls=1,usec=142,usec_per_call=142.00
cmdstat_config:calls=1571031,usec=30747726,usec_per_call=19.57
cmdstat_publish:calls=1833889,usec=595647,usec_per_call=0.32
cmdstat_client:calls=130970,usec=38079168,usec_per_call=290.75
cmdstat_eval:calls=113372429,usec=5402870353,usec_per_call=47.66
cmdstat_command:calls=37,usec=16061,usec_per_call=434.08
We are not using zset and eval commands. But, still the use of these calls are too high from redisson.
Also, I have see that there are almost ~4M sortedSetTypeCommands on the redis cluster from redisson under our peak load which is degrading our performance.
I want to know why redisson is not setting ttl on the key and managing it using sorted sets on the client side. It is not advisable to do it on the client side if the server automatically gives that feature.
Is there any way to disable this ttl management from redisson so that it will just set that on the redis server and these calls are not fired.
PS: We are using AWS elasticache redis server.
Redisson version: 3.4.2
Redis Version: 3.2.4 with 1 master and 3 slaves.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1065
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@Component
public class RedissonConnector {

    @Autowired
    private RedisProperties redisProperties;

    @Bean
    public RedissonClient redissonClient() {
        Config config = new Config();
        //sentinel
        if (redisProperties.getSentinel() != null) {
            SentinelServersConfig sentinelServersConfig = config.useSentinelServers();
            sentinelServersConfig.setMasterName(redisProperties.getSentinel().getMaster());
            redisProperties.getSentinel().getNodes();
            sentinelServersConfig.addSentinelAddress(redisProperties.getSentinel().getNodes().split(","));
            sentinelServersConfig.setDatabase(redisProperties.getDatabase());
            if (redisProperties.getPassword() != null) {
                sentinelServersConfig.setPassword(redisProperties.getPassword());
            }
        } else { //single server
            SingleServerConfig singleServerConfig = config.useSingleServer();
            // format as redis://127.0.0.1:7181 or rediss://127.0.0.1:7181 for SSL
            String schema = redisProperties.isSsl() ? "rediss://" : "redis://";
            singleServerConfig.setAddress(schema + redisProperties.getHost() + ":" + redisProperties.getPort());
            singleServerConfig.setDatabase(redisProperties.getDatabase());
            if (redisProperties.getPassword() != null) {
                singleServerConfig.setPassword(redisProperties.getPassword());
            }
            RedisProperties.Pool pool = redisProperties.getPool();
            if (pool != null) {
                singleServerConfig.setConnectionPoolSize(pool.getMaxActive());
                singleServerConfig.setConnectionMinimumIdleSize(pool.getMinIdle());
                singleServerConfig.setIdleConnectionTimeout(pool.getMaxWait());
            }
            singleServerConfig.setConnectTimeout(redisProperties.getTimeout());
        }
        return Redisson.create(config);
    }

}
use redisson in spring-boot with spring-data-redis-stater.
startup exception stack:
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'com.mpr.nosql.redis.RedisLockerImpl': Unsatisfied dependency expressed through field 'redissonClient'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'redissonClient' defined in class path resource [com/mpr/nosql/redis/RedissonConnector.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.redisson.api.RedissonClient]: Factory method 'redissonClient' threw exception; nested exception is java.lang.IllegalArgumentException: initialDelay: -1 (expected: >= 0)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:588)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	... 24 common frames omitted
Caused by: java.lang.IllegalArgumentException: initialDelay: -1 (expected: >= 0)
	at io.netty.util.concurrent.AbstractScheduledEventExecutor.scheduleWithFixedDelay(AbstractScheduledEventExecutor.java:180)
	at io.netty.util.concurrent.AbstractEventExecutorGroup.scheduleWithFixedDelay(AbstractEventExecutorGroup.java:65)
	at org.redisson.connection.IdleConnectionWatcher.<init>(IdleConnectionWatcher.java:57)
	at org.redisson.connection.MasterSlaveConnectionManager.init(MasterSlaveConnectionManager.java:243)
	at org.redisson.connection.MasterSlaveConnectionManager.<init>(MasterSlaveConnectionManager.java:167)
	at org.redisson.connection.SingleConnectionManager.<init>(SingleConnectionManager.java:49)
	at org.redisson.config.ConfigSupport.createConnectionManager(ConfigSupport.java:255)
	at org.redisson.Redisson.<init>(Redisson.java:115)
	at org.redisson.Redisson.create(Redisson.java:154)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1066
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
My host alias is redis_db, test found that contain ‘_’  will throw this Exception.
Caused by: org.springframework.beans.PropertyBatchUpdateException; nested PropertyAccessExceptions (1) are:
PropertyAccessException 1: org.springframework.beans.MethodInvocationException: Property 'address' threw exception; nested exception is java.lang.IllegalArgumentException: Malformed IPv6 address at index 9: redis://[redis_db]:6379
at org.springframework.beans.AbstractPropertyAccessor.setPropertyValues(AbstractPropertyAccessor.java:108)
at org.springframework.beans.AbstractPropertyAccessor.setPropertyValues(AbstractPropertyAccessor.java:62)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1490)
... 38 more
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1067
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1068
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1069
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redisson running on tomcat.The program is working.redisson throw exception few minutes,
Exception in thread "redisson-3-10" java.lang.ArrayIndexOutOfBoundsException: 1 at org.redisson.spring.session.RedissonSessionRepository.onMessage(RedissonSessionRepository.java:259) at org.redisson.spring.session.RedissonSessionRepository.onMessage(RedissonSessionRepository.java:50) at org.redisson.PubSubPatternMessageListener.onPatternMessage(PubSubPatternMessageListener.java:80) at org.redisson.client.RedisPubSubConnection.onMessage(RedisPubSubConnection.java:86) at org.redisson.client.handler.CommandDecoder$1.run(CommandDecoder.java:368) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137) at java.lang.Thread.run(Thread.java:745)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1070
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Marking javax.cache api and reactor-stream dependencies as optional in pom makes it easier to deploy redisson in an OSGi environment when not using these modules. This change is in continuation to #793
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1071
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
byte-buddy too?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1072
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Using version 3.5.0, we've noticed a very strange behavior in RMapCache map-iteration APIs (keySet,  entrySet, etc). It seems that the map sometimes contains "inverted" entries in which the key looks like a (bogus) instance produced by a value encoder, and the value looks like an (again) bogus instance produced by the key encoder*. When they do, these entries show alongside the normal entries. It's only because of Type Erasure that the code doesn't break until one actually calls an iterartion API: Because the original entries are still in place, get, put, etc. works as expected even when the map is in this broken state. We've managed to workaround this issue by using readAllKeys rather than keySet.


We have a custom extremely type-aware jackson-based codec, which makes this bug very easy to spot.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1073
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello, seems there is some tricky code which creates the wrong type of cache map.
RedissonSpringCacheManager has the protected method:
protected CacheConfig createDefaultConfig() { return new CacheConfig(); }
This is a protected method, so it can be overriden, but in the method:
`public Cache getCache(String name) {
Cache cache = instanceMap.get(name);
if (cache != null) {
return cache;
}
if (!dynamic) {
return cache;
}
    CacheConfig config = configMap.get(name);
    if (config == null) {
        config = createDefaultConfig();
        configMap.put(name, config);
        // Here it is not analysed the ttl nor max idle time params of the default config.
        // seems this return must be omitted to let the further code check the values in
        // default config is case if the createDefaultConfig() was overriden
        return createMap(name, config);
    }
    
    if (config.getMaxIdleTime() == 0 && config.getTTL() == 0) {
        return createMap(name, config);
    }
    
    return createMapCache(name, config);
}`

Also it would be really great to have an ability to set ttl and max idle time by default for all caches.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1074
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Wrong window
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1075
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Code:
// redisson 3.5.3
//  <logger name="org.redisson" level="TRACE"/>
// config.useSingleServer().setClientName("local-u0")
RPatternTopic<String> patternTopic = c.getPatternTopic("*", new StringCodec());

patternTopic.addListener((pattern, channel, msg) -> {
     System.err.println(pattern + ", " + channel + ", " +msg);
});

Test
redis-cli PUBLISH aaa 111 # works

Restart redis, log https://gist.github.com/valodzka/5fe65c7cb8cf66747b2850a6601d50c3
Test again:
 redis-cli PUBLISH aaa 111 # never works
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1076
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
final RedisClient client = RedisClient.create(clientConfig);
final RedisConnection con = client.connect();
con.closeAsync().addListener(l -> {
client.shutdownAsync().addListener(cl -> {
showThreas();
});
});
threads info
name - id - state - daemon
Reference Handler - 2 - WAITING - true
Finalizer - 3 - WAITING - true
Signal Dispatcher - 4 - RUNNABLE - true
Attach Listener - 5 - RUNNABLE - true
nioEventLoopGroup-2-1 - 12 - RUNNABLE - false
DestroyJavaVM - 13 - RUNNABLE - false
nioEventLoopGroup-2-2 - 14 - RUNNABLE - false
threadDeathWatcher-3-1 - 15 - TIMED_WAITING - true
nioEventLoopGroup-2-3 - 16 - RUNNABLE - false
ForkJoinPool.commonPool-worker-1 - 17 - TIMED_WAITING - true
globalEventExecutor-1-1 - 18 - RUNNABLE - false
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1077
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I'm testing the useSentinelServers connexion. I have 1 master and 1 slave.
If I kill the slave, wait and then restart it, I have the folowing trace in the Tomcat console when
calling redisson.getNodesGroup().getNodes().
GRAVE: org.redisson.client.RedisConnectionException: Can't aquire connection to [freeSubscribeConnectionsAmount=0, freeSubscribeConnectionsCounter=org.redisson.pubsub.AsyncSemaphore@5f8198cc, freeConnectionsAmount=0, freeConnectionsCounter=org.redisson.pubsub.AsyncSemaphore@37aac6d8, freezed=true, freezeReason=SYSTEM, client=[addr=/172.16.50.12:6380], nodeType=SLAVE, failedAttempts=0]
        at org.redisson.connection.pool.ConnectionPool.get(ConnectionPool.java:206)
        at org.redisson.connection.pool.SlaveConnectionPool.get(SlaveConnectionPool.java:30)
        at org.redisson.connection.balancer.LoadBalancerManager.getConnection(LoadBalancerManager.java:197)
        at org.redisson.connection.MasterSlaveEntry.connectionReadOp(MasterSlaveEntry.java:431)


If I look at the Redisson ConnectionPool.java, I see that the method will never retry a connexion on a freezed slave :
 public  RFuture<T> get(RedisCommand<?> command, ClientConnectionsEntry entry) {
        if (((entry.getNodeType() == NodeType.MASTER && entry.getFreezeReason() == FreezeReason.SYSTEM) || !entry.isFreezed())
                && tryAcquireConnection(entry)) {
            return acquireConnection(command, entry);
        }

        RedisConnectionException exception = new RedisConnectionException(
                "Can't aquire connection to " + entry.getClient().getAddr());
        return connectionManager.newFailedFuture(exception);
    }


Question : How can I get Redisson to reconnect the resurected slave ?
My conf:
				Config config = new Config();
				config.useSentinelServers()
					.setTimeout(timeout)
					.setConnectTimeout(timeout)
					.setReadMode(ReadMode.SLAVE)
					.setMasterName("MCACHEREDISIMPL")
					.setMasterConnectionPoolSize(20)
					.setMasterConnectionMinimumIdleSize(1)				    
					.setSlaveConnectionPoolSize(20)
					.setSlaveConnectionMinimumIdleSize(1)				    
					.setIdleConnectionTimeout(5000)
					.setReconnectionTimeout(3000)
					.addSentinelAddress(Iterables.toArray(sentinels, String.class));


thx,
Xavier
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1078
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Good point! Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1079
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We have been using Redisson successfully for the past few months, since our version was pretty old we just tried and upgrade to the latest version today.
With version 3.4.2 we used  SnappyCodec as follows
SnappyCodec snappyCodec = new SnappyCodec(new StringCodec());
  Config config = new Config();
 config.useSingleServer().setAddress(DynamicApplicationConfig.getStringProperty("REDIS_SERVER","localhost")+":6379");
  config.setCodec(snappyCodec);
  redissonClient = Redisson.create(config);

This setup fails with the new 3.5.3 version
`org.redisson.command.CommandAsyncService.convertException(CommandAsyncService.java:322)
 at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:165) at org.redisson.RedissonObject.get(RedissonObject.java:72) 
at org.redisson.RedissonMap.get(RedissonMap.java:251)`

Example client usage
String key = namespace + ":" + id;
                RMap<String, Object> cachedMap = redissonClient.getMap(cacheGroup);
                ObjectWriter writer = mapper.writer();
                cachedMap.fastPutAsync(key, writer.writeValueAsString(data));

With so many release since 3.4.2, many other codecs have been added. We store JSON string so which is the best codec to use for this case?.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1080
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is the wait command not yet supported in Redisson?
https://redis.io/commands/wait
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1081
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello,
We have performance issue in org.redisson.connection.MasterSlaveConnectionManager#getEntry(java.net.InetSocketAddress)
We did profile the JVM to see what's happening and we have a lot's of invocations in this method.

While looking at the code, we found a "TODO OPTIMIZE" at the place we have performance issue :)

  
    
      redisson/redisson/src/main/java/org/redisson/connection/MasterSlaveConnectionManager.java
    
    
         Line 675
      in
      99827db
    
  
  
    

        
          
           // TODO optimize 
        
    
  


Is there an optimization planned on this part of the lib soon ? Do you have any workaround to fix this ?
Thanks !
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1082
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1083
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
It's important to do execute data encoding on client thread rather than netty's event loop.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1084
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1085
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1086
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi, when I try to run tests on master (063dcab) as CONTRIBUTING.md states, I get the following error:
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:testCompile (default-testCompile) on project redisson: Compilation failure
[ERROR] /Users/rafael.acevedo/code/redisson/redisson/src/test/java/org/redisson/spring/cache/RedissonSpringCacheShortTTLTest.java:[79,64] error: cannot find symbol
[ERROR]   symbol:   method sync()
[ERROR]   location: @interface Cacheable
[ERROR]
[ERROR] -> [Help 1]

It's likely due to the spring version being used, [3.1,4.3).
Maven version:
Apache Maven 3.5.0 (ff8f5e7444045639af65f6095c62210b5713f426; 2017-04-03T16:39:06-03:00)
Maven home: /usr/local/Cellar/maven/3.5.0/libexec
Java version: 1.8.0_112, vendor: Oracle Corporation
Java home: /Library/Java/JavaVirtualMachines/jdk1.8.0_112.jdk/Contents/Home/jre
Default locale: en_US, platform encoding: UTF-8
OS name: "mac os x", version: "10.12.6", arch: "x86_64", family: "mac"

Am I doing something wrong or is it actually failing?
Thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1087
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
We are using AWS Elastic Cache (3.2.4-cache.m3.xLarge).
We are trying to solve for scheduling events using Redisson Executor Service (https://github.com/redisson/redisson/wiki/9.-distributed-services). We have a setup of 1master and 4 slave nodes.
When we are trying to send scheduling request at rate of around 1000 request per sec for more than 1hour duration, we are seeing that current connections shoots up to max and they are never reclaimed and the app starts throwing errors.
These are our Redisson Client setting: (Replicated servers configuration)
Elasticache node scan interval in milliseconds=5000
masterConnectionPoolSize=5000
slaveConnectionPoolSize=5000
masterConnectionMinimumIdleSize=50
slaveConnectionMinimumIdleSize=50
idleConnectionTimeout=30000
connectTimeout=30000
timeout=30000
Executor service workers=10
We are creating a executor service on startup and use it throughout the app. We are using the scheduleAsync function and Runnable implementation.
We have a 6node (EC2 instanceC3.xLarge) app Cluster taking to Redis. (Each node has the above configuration)
Can you please help provide guidance as to what might be the issue here and how we can resolve it.
Thanks.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1088
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1089
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I get "too many results to unpack" exception when calling RMapCache::getAll on a large (~10000+) keyset. Tested on both v.3.5.0 and v3.5.4.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1090
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
To reproduce the problem:
1 Create a Runnable job which will last ~ 1 minutes (greater than "internalLockLeaseTime" used by RedissonLock.java), get a lock and lock it by lock.tryLock(), release the lock after the job is done.
2 Schedule and run this job using Redission framework.
3 After start RedissonNode, just call node.shutdown(), following exception will be raised.
org.redisson.RedissonShutdownException: Redisson is shutdown
at org.redisson.command.CommandAsyncService.async(CommandAsyncService.java:481)
at org.redisson.command.CommandAsyncService.evalAsync(CommandAsyncService.java:455)
at org.redisson.command.CommandAsyncService.evalWriteAsync(CommandAsyncService.java:398)
at org.redisson.RedissonLock$3.run(RedissonLock.java:206)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:663)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:738)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:466)
at java.lang.Thread.run(Thread.java:745)
This is because RedissonLock.scheduleExpirationRenewal still running after we shutdown the node.
Can Redisson stop the scheduleExpirationRenewal when user call node.shutdown()?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1091
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I have very large objects that are hard to serialize, so opted for RLocalCachedMap with eviction policy as LRU and Invalidation policy on change. I notice that when I add key, value to the map, both key and value are serialized sent to redis server in serialized format often resulting in errors. Is there any way to preserve the eviction and invalidation and not send the value to redis server with serialization.
initializeNetworkCache(); long sTime = System.currentTimeMillis(); LocalCachedMapOptions options = LocalCachedMapOptions.defaults() // LFU, LRU, SOFT, WEAK and NONE policies are available .evictionPolicy(EvictionPolicy.LRU) // If cache size is 0 then local cache is unbounded. .cacheSize(1000) // if value is ON_CHANGE, ON_CHANGE_WITH_CLEAR_ON_RECONNECTorON_CHANGE_WITH_LOAD_ON_RECONNECT`
// corresponding map entry is removed from cache across all RLocalCachedMap instances
// during every invalidation message sent on each map entry update/remove operation
.invalidationPolicy(InvalidationPolicy.ON_CHANGE)
// max idle time for each map entry in local cache
.maxIdle(10, TimeUnit.MINUTES)
// time to live for each map entry in local cache
//			     .timeToLive(10000)
// or
.timeToLive(2, TimeUnit.HOURS);
// max idle time for each map entry in local cache
RLocalCachedMap<String, List> m = cacheClient.getLocalCachedMap("localMap", options);
	List<String> l = new ArrayList<String>();
	l.add("one");
	l.add("two");
	m.put("k1", l);
	
	m.remove("k1");
	cacheClient.shutdown();`

From redis monitor
1507592155.240247 [0 172.17.0.1:56610] "SUBSCRIBE" "{localMap}:topic"
1507592155.281269 [0 172.17.0.1:56604] "EVAL" "local v = redis.call('hget', KEYS[1], ARGV[1]); if redis.call('hset', KEYS[1], ARGV[1], ARGV[2]) == 0 then if ARGV[4] == '1' then redis.call('publish', KEYS[2], ARGV[3]); end;if ARGV[4] == '2' then redis.call('zadd', KEYS[3], ARGV[5], ARGV[6]);redis.call('publish', KEYS[2], ARGV[3]); end;end; return v; " "3" "localMap" "{localMap}:topic" "redisson__cache_updates_log:{localMap}" ""k1"" "["java.util.ArrayList",["one","two"]]" "{"@Class":"org.redisson.cache.LocalCachedMapInvalidate","excludedId":"WafQgVF3KraC2OpfcpRcDg==","keyHashes":["0BYDzEh2fI8Kf2PGRxfrdQ=="]}" "1" "1507592155273" "\xd0\x16\x03\xccHv|\x8f\n\x7fc\xc6G\x17\xebu:\xbb\xd7\x9dY\xd4R\xc4f"
1507592155.281378 [0 lua] "hget" "localMap" ""k1""
1507592155.281387 [0 lua] "hset" "localMap" ""k1"" "["java.util.ArrayList",["one","two"]]"
1507592155.284735 [0 172.17.0.1:56606] "EVAL" "local v = redis.call('hget', KEYS[1], ARGV[1]); if redis.call('hdel', KEYS[1], ARGV[1]) == 1 then if ARGV[3] == '1' then redis.call('publish', KEYS[2], ARGV[2]); end; if ARGV[3] == '2' then redis.call('zadd', KEYS[3], ARGV[4], ARGV[5]);redis.call('publish', KEYS[2], ARGV[2]); end;end; return v" "3" "localMap" "{localMap}:topic" "redisson__cache_updates_log:{localMap}" ""k1"" "{"@Class":"org.redisson.cache.LocalCachedMapInvalidate","excludedId":"WafQgVF3KraC2OpfcpRcDg==","keyHashes":["0BYDzEh2fI8Kf2PGRxfrdQ=="]}" "1" "1507592155283" "\xd0\x16\x03\xccHv|\x8f\n\x7fc\xc6G\x17\xebu:\x10_\x15\xfde\xce\xc2\xb0"
1507592155.284837 [0 lua] "hget" "localMap" ""k1""
1507592155.284857 [0 lua] "hdel" "localMap" ""k1""
1507592155.284863 [0 lua] "publish" "{localMap}:topic" "{"@Class":"org.redisson.cache.LocalCachedMapInvalidate","excludedId":"WafQgVF3KraC2OpfcpRcDg==","keyHashes":["0BYDzEh2fI8Kf2PGRxfrdQ=="]}"
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1092
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
org.redisson.client.RedisConnectionException: MasterConnectionPool no available Redis entries.  Hosts disconnected due to failedAttempts limit reac
hed: [/192.168.10.109:6459]
at org.redisson.connection.pool.ConnectionPool.get(ConnectionPool.java:196) ~[redisson-2.9.3.jar:?]
at org.redisson.connection.pool.MasterConnectionPool.get(MasterConnectionPool.java:31) ~[redisson-2.9.3.jar:?]
at org.redisson.connection.MasterSlaveEntry.connectionWriteOp(MasterSlaveEntry.java:409) ~[redisson-2.9.3.jar:?]
at org.redisson.connection.SingleEntry.connectionReadOp(SingleEntry.java:45) ~[redisson-2.9.3.jar:?]
at org.redisson.connection.MasterSlaveConnectionManager.connectionReadOp(MasterSlaveConnectionManager.java:745) ~[redisson-2.9.3.jar:?]
at org.redisson.command.CommandAsyncService.async(CommandAsyncService.java:500) ~[redisson-2.9.3.jar:?]
at org.redisson.command.CommandAsyncService$7.run(CommandAsyncService.java:551) ~[redisson-2.9.3.jar:?]
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:663) ~[netty-common-4.1.11.Final.jar:4.1.11.Final]
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:738) ~[netty-common-4.1.11.Final.jar:4.1.11.Final]
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:466) ~[netty-common-4.1.11.Final.jar:4.1.11.Final]
at java.lang.Thread.run(Thread.java:745) [?:1.7.0_60]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1093
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redis cluster, when the master-slave relationship changes, the Redisson Client links to the original master node and cannot link the changed master node, resulting in no data write.
WARN io.netty.util.concurrent.DefaultPromise: An exception was thrown by org.redisson.command.CommandAsyncService$9.operationComplete()
org.redisson.client.RedisNodeNotFoundException: Node: /192.168.16.118:10377
for slot: 5997 hasn't been discovered yet
at org.redisson.connection.MasterSlaveConnectionManager.getEntry(MasterSlaveConnectionManager.java:684) ~[redisson-2.9.1.jar:?]
at org.redisson.connection.MasterSlaveConnectionManager.connectionWriteOp(MasterSlaveConnectionManager.java:674) ~[redisson-2.9.1.jar:?]
at org.redisson.command.CommandAsyncService.async(CommandAsyncService.java:503) ~[redisson-2.9.1.jar:?]
at org.redisson.command.CommandAsyncService.checkAttemptFuture(CommandAsyncService.java:751) ~[redisson-2.9.1.jar:?]
at org.redisson.command.CommandAsyncService.access$300(CommandAsyncService.java:80) ~[redisson-2.9.1.jar:?]
at org.redisson.command.CommandAsyncService$9.operationComplete(CommandAsyncService.java:610) ~[redisson-2.9.1.jar:?]
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507) [netty-common-4.1.8.Final.jar:4.1.8.Final]
at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:500) [netty-common-4.1.8.Final.jar:4.1.8.Final]
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:479) [netty-common-4.1.8.Final.jar:4.1.8.Final]
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420) [netty-common-4.1.8.Final.jar:4.1.8.Final]
at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122) [netty-common-4.1.8.Final.jar:4.1.8.Final]
at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:75) [redisson-2.9.1.jar:?]
at org.redisson.client.protocol.CommandData.tryFailure(CommandData.java:78) [redisson-2.9.1.jar:?]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:247) [redisson-2.9.1.jar:?]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:127) [redisson-2.9.1.jar:?]
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:367) [netty-codec-4.1.8.Final.jar:4.1.8.Final]
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:248) [netty-codec-4.1.8.Final.jar:4.1.8.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363) [netty-transport-4.1.8.Final.jar:4.1.8.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:349) [netty-transport-4.1.8.Final.jar:4.1.8.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:341) [netty-transport-4.1.8.Final.jar:4.1.8.Final]
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) [netty-transport-4.1.8.Final.jar:4.1.8.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363) [netty-transport-4.1.8.Final.jar:4.1.8.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:349) [netty-transport-4.1.8.Final.jar:4.1.8.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:341) [netty-transport-4.1.8.Final.jar:4.1.8.Final]
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1334) [netty-transport-4.1.8.Final.jar:4.1.8.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363) [netty-transport-4.1.8.Final.jar:4.1.8.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:349) [netty-transport-4.1.8.Final.jar:4.1.8.Final]
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:926) [netty-transport-4.1.8.Final.jar:4.1.8.Final]
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:129) [netty-transport-4.1.8.Final.jar:4.1.8.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:642) [netty-transport-4.1.8.Final.jar:4.1.8.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:565) [netty-transport-4.1.8.Final.jar:4.1.8.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:479) [netty-transport-4.1.8.Final.jar:4.1.8.Final]
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:441) [netty-transport-4.1.8.Final.jar:4.1.8.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) [netty-common-4.1.8.Final.jar:4.1.8.Final]
at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144) [netty-common-4.1.8.Final.jar:4.1.8.Final]
at java.lang.Thread.run(Thread.java:745) [?:1.7.0_80]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1094
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
i'm trying to learn Redis through Redisson. Here is my code to insert into redis using multiple threads.
package redisson

import java.io.File;
import java.util.concurrent.atomic.AtomicInteger;
import org.redisson.Redisson;
import org.redisson.api.RBatch;
import org.redisson.api.RMap;
import org.redisson.api.RedissonClient;
import org.redisson.config.Config;


public class RedisTest extends Thread {

    static RMap<String, String> dMap = null;
    static RMap<String, String> wMap = null;
    static RMap<String, String> mMap = null;
    static RedissonClient redisson = null;

    public static void main(String[] args) throws Exception {

        Config config = Config.fromJSON(new File("C:\\Users\\neon-workspace\\RedisProject\\src\\main\\resources\\SingleNodeConfig.json"));
            RedissonClient redisson = Redisson.create(config);
            dMap = redisson.getMap("Daily");
            wMap = redisson.getMap("Weekly");
            mMap = redisson.getMap("Monthly");

            connectHbse(dMap,wMap,mMap,redisson);
            redisson.shutdown();

    }

    public static void connectHbse(RMap<String, String> dMap,RMap<String, String> wMap,RMap<String, String> mMap,RedissonClient redisson) {
        int totalSize=500000;
        int totalThread=2;
        int chunkSize = totalSize/totalThread;
        AtomicInteger total = new AtomicInteger(chunkSize);
        RedisTest test1[] = new RedisTest[totalThread];
        for (int i = 0; i < test1.length; i++) {
            test1[i] = new RedisTest(total,dMap,wMap,mMap,redisson);
            total.set(total.intValue()+chunkSize);
        }
        long t1 = System.currentTimeMillis();
        for (int i = 0; i < test1.length; i++) {
            test1[i].start();
        }
        try {
            for (int i = 0; i < test1.length; i++) {
                test1[i].join();
            }
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        System.out.println("Final Total Time Taken ::>>>>>>>>>>>>>>>>> " + ((System.currentTimeMillis() - t1))+"ms");
    }

    private AtomicInteger total = null;
    public RedisTest(AtomicInteger total,RMap<String, String> dMap,RMap<String, String> wMap,RMap<String, String> mMap,RedissonClient redisson) {
        this.total = new AtomicInteger(total.intValue());
        this.dMap = dMap;
        this.wMap = wMap;
        this.mMap = mMap;
        this.redisson = redisson;
    }

    public static int getRandomInteger(int maximum, int minimum) {
        return ((int) (Math.random() * (maximum - minimum))) + minimum;
    }

    public void run() {

        try {

            long t1 = System.currentTimeMillis();
            dMap.clear();
            wMap.clear();
            mMap.clear();
            RBatch batch = redisson.createBatch();

            for (;total.decrementAndGet()>=0;) {    
                String dvalue = ""+getRandomInteger(100,200);
                String wvalue = "" +getRandomInteger(200, 300);
                String mvalue = "" +getRandomInteger(300, 400);

                batch.getMap("Daily").fastPutAsync(""+total.get(), dvalue);
                batch.getMap("Weekly").fastPutAsync(""+total.get(), wvalue);
                batch.getMap("Monthly").fastPutAsync(""+total.get(), mvalue);

                    synchronized (total) {
                        if(total.get()%100==0)
                            System.out.println(total.get()+" Records in Seconds:::::" + ((System.currentTimeMillis() - t1))/1000);
                    }
            }
            batch.execute();

            System.out.println("Time Taken for completion::::: " + ((System.currentTimeMillis() - t1))+" by thread:::::"+Thread.currentThread().getName());
            System.out.println("Done !!!");
        } catch (Exception e) {
            System.out.println("Done !!!" + e.getMessage());
            e.printStackTrace();
        } finally {

        }
    }
}

This code works fine until totalSize=400000. When i put the totalSize=500000, its throwing the following exception:
io.netty.handler.codec.EncoderException: io.netty.util.internal.OutOfDirectMemoryError: failed to allocate 16777216 byte(s) of direct memory (used: 939524096, max: 954466304)
    at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
    at org.redisson.client.handler.CommandBatchEncoder.write(CommandBatchEncoder.java:45)
    at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
    ... 25 more
Caused by: io.netty.util.internal.OutOfDirectMemoryError: failed to allocate 16777216 byte(s) of direct memory (used: 939524096, max: 954466304)
    at io.netty.util.internal.PlatformDependent.incrementMemoryCounter(PlatformDependent.java:627)
    at io.netty.util.internal.PlatformDependent.allocateDirectNoCleaner(PlatformDependent.java:581)
    at io.netty.buffer.PoolArena$DirectArena.allocateDirect(PoolArena.java:764)
    at io.netty.buffer.PoolArena$DirectArena.newChunk(PoolArena.java:740)
    at io.netty.buffer.PoolArena.allocateNormal(PoolArena.java:244)
    at io.netty.buffer.PoolArena.allocate(PoolArena.java:226)
    at io.netty.buffer.PoolArena.reallocate(PoolArena.java:397)
    at io.netty.buffer.PooledByteBuf.capacity(PooledByteBuf.java:118)
    at io.netty.buffer.AbstractByteBuf.ensureWritable0(AbstractByteBuf.java:285)
    at io.netty.buffer.AbstractByteBuf.ensureWritable(AbstractByteBuf.java:265)
    at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1046)
    at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1054)
    at org.redisson.client.handler.CommandEncoder.writeArgument(CommandEncoder.java:169)
    at org.redisson.client.handler.CommandEncoder.encode(CommandEncoder.java:110)
    at org.redisson.client.handler.CommandBatchEncoder.encode(CommandBatchEncoder.java:52)
    at org.redisson.client.handler.CommandBatchEncoder.encode(CommandBatchEncoder.java:32)
    at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
    ... 27 more

Can someone explain to me the reason why this is happening?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1095
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello, i'm new to redisson and using version 2.10.4. Assume that i have a master node M1 and a slave node R1. 3 sentinels are connected to M1 namely, S1,S2,S3. I have connected Redisson to the 3 sentinels and started inserting data. Following is my code:
static RMap<Object, String> map = null;
		static String resp = null;
		Config config = new Config();
		config.useSentinelServers().setMasterName("mymaster")
									.addSentinelAddress("redis://0.0.0.82:5001")
									.addSentinelAddress("redis://0.0.0.82:5002")
									.addSentinelAddress("redis://0.0.0.35:5003")
									.setIdleConnectionTimeout(10000)
									.setPingTimeout(1000)
									.setConnectTimeout(10000)
									.setTimeout(20000)
									.setRetryAttempts(3)
									.setRetryInterval(1500)
									.setReconnectionTimeout(3000)
									.setFailedAttempts(3)
									.setSlaveConnectionMinimumIdleSize(20)
									.setSlaveConnectionPoolSize(64)
									.setMasterConnectionMinimumIdleSize(20)
									.setMasterConnectionPoolSize(64)
									.setDatabase(0);
		RedissonClient redisson = Redisson.create(config);
		map = redisson.getMap("My-Map");
		map.clear();
		for(int i=0;i<1000000;i++) {
			resp = map.put("key"+i,"value"+i);
			System.out.println(resp+" for key "+"key"+i);
		}
		redisson.shutdown();

In the middle of insertion, i kill M1, so insertion interrupted. So the sentinels make R1 as the new master. Redisson identifies that R1 has been made the new master, but it doesn't continue inserting the data to the new master rather it throws a server response timeout exception.
Following is the stacktrace:
[main] INFO org.redisson.Version - Redisson 2.10.4
[main] INFO org.redisson.connection.SentinelConnectionManager - master: redis://0.0.0.35:6385 added
[main] INFO org.redisson.connection.SentinelConnectionManager - slave: redis://0.0.0.82:6382 added
[redisson-netty-1-4] INFO org.redisson.connection.pool.SlaveConnectionPool - 20 connections initialized for /0.0.0.82:6382
[redisson-netty-1-5] INFO org.redisson.connection.pool.PubSubConnectionPool - 1 connections initialized for /0.0.0.82:6382
[redisson-netty-1-4] INFO org.redisson.connection.pool.MasterConnectionPool - 20 connections initialized for /0.0.0.35:6385
[redisson-netty-1-7] INFO org.redisson.connection.SentinelConnectionManager - sentinel: 0.0.0.82:5001 added
[redisson-netty-1-2] INFO org.redisson.connection.SentinelConnectionManager - sentinel: 0.0.0.82:5002 added
[redisson-netty-1-3] INFO org.redisson.connection.SentinelConnectionManager - sentinel: 0.0.0.35:5003 added
null
null
null
null
null
null
null
[redisson-3-3] INFO org.redisson.connection.MasterSlaveEntry - master /0.0.0.82:6382 excluded from slaves
[redisson-3-3] INFO org.redisson.connection.SentinelConnectionManager - slave: 0.0.0.35:6385 has up
[redisson-3-5] INFO org.redisson.connection.MasterSlaveEntry - master /0.0.0.82:6382 excluded from slaves
[redisson-3-5] INFO org.redisson.connection.SentinelConnectionManager - slave: 0.0.0.35:6385 has up
[redisson-3-4] INFO org.redisson.connection.MasterSlaveEntry - master /0.0.0.82:6382 excluded from slaves
[redisson-3-4] INFO org.redisson.connection.SentinelConnectionManager - slave: 0.0.0.35:6385 has up
[redisson-netty-1-7] INFO org.redisson.connection.pool.MasterConnectionPool - 20 connections initialized for /0.0.0.82:6382
[redisson-netty-1-7] INFO org.redisson.connection.MasterSlaveEntry - master /0.0.0.35:6385 has changed to redis://0.0.0.82:6382
Exception in thread "main" org.redisson.client.RedisTimeoutException: Redis server response timeout (20000 ms) occured for command: (EVAL) with params: [local v = redis.call('hget', KEYS[1], ARGV[1]); redis.call('hset', KEYS[1], ARGV[1], ARGV[2]); retur..., 1, My-Map, PooledUnsafeDirectByteBuf(ridx: 0, widx: 10, cap: 256), PooledUnsafeDirectByteBuf(ridx: 0, widx: 12, cap: 256)] channel: [id: 0x6ffe7551, L:0.0.0.0/0.0.0.0:59826 ! R:/0.0.0.35:6385]
	at org.redisson.command.CommandAsyncService$11.run(CommandAsyncService.java:696)
	at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:663)
	at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:738)
	at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:466)
	at java.lang.Thread.run(Unknown Source)

My question is whether this is some configuration issue from my side or does redisson not support failover?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1096
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The take() method in RedissonBlockingQueue uses Future.getNow(), which returns null if an exception occurs. In our case, we have tons of NPEs when the application is stopped.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1097
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am using redisson 2.8.2 with Java 1.7 and redis in Cluster mode. Recently we had an incident related to connection count of redis servers. After further investigation we have found that after each redis failover, connection count from each client to redis servers get increased and not going back to the earlier values. This happens after each failover in the redis servers whose role got change.
Then eventually connection count reaches maximum connection count and application goes to a freeze state.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1098
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
#Hi,
I'm encountering the CROSSSLOT keys error when I get a lock a ReadWriteLock of a map in a clustered environment. The normal Lock of a map works fine tho.
or do I need the RClusteredMap instead of the normal map when clustered even if I don't need the data partitioning?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1099
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
在集群模式下。偶尔会报Not all slots are covered! Only 10923 slots are avaliable。
通过redis查看。  redis是没有问题的。经过不断的排查。后面发现原来跟serverConfig.addNodeAddress("redis://192.168.0.208:7000","redis://192.168.0.208:7004","redis://192.168.0.208:7003","redis://192.168.0.208:7005","redis://192.168.0.208:7001","redis://192.168.0.208:7002");添加节点地址的顺序有关。我个是三主三从。如果你前面三个全部是主或者全部是从。就会把我上面说的哪种错。
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1100
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1101
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
不好意思，英文不太好，刚过3级
......
RBucket bucket = redisson.getBucket("mykey");
bucket.get();
.....
上面的get读取的主从只能使用readmodel做全局设置，
但是我有场景，在设置完后需要立即读取，主从同步会有延迟，可能导致读不到，
后续是否会考虑针对某次get做主从切换
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1102
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Using the latest 3.5.4 version and Java 8. getting the error when deserialize the json to Java objects.
Oct 16, 2017 11:53:09 AM org.apache.catalina.core.StandardWrapperValve invoke SEVERE: Servlet.service() for servlet [jersey-serlvet] in context with path [/] threw exception [org.redisson.client.RedisException: Unexpected exception while processing command] with root cause com.fasterxml.jackson.databind.JsonMappingException: No suitable constructor found for type [simple type, class com.google.maps.model.LatLng]: can not instantiate from JSON object (missing default constructor or creator, or perhaps need to add/enable type information?) at [Source: (io.netty.buffer.ByteBufInputStream); line: 1, column: 1397] (through reference chain: com.google.maps.model.GeocodingResult["geometry"]->com.google.maps.model.Geometry["bounds"]->com.google.maps.model.Bounds["northeast"]) at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:256) at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromObjectUsingNonDefault(BeanDeserializerBase.java:1134) at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeFromObject(BeanDeserializer.java:298) at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:168) at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:135) at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedForId(AsPropertyTypeDeserializer.java:120) at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:91) at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeWithType(BeanDeserializerBase.java:1021) at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:493) at com.fasterxml.jackson.databind.deser.impl.FieldProperty.deserializeAndSet(FieldProperty.java:101) at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:260)
For my own classes, I could implement a default constructor to workaround the issue, but not on other classes that I dont have access to
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1103
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi, i have a usecase that i'm trying to implement using redisson. I have 2 redisson instances running on the same server performing the same operation.
Code snippet of redisson instance 1:
Config config = Config.fromJSON(new File("//home//user//SingleNodeConfig.json"));
		RedissonClient redisson = Redisson.create(config);
		
		RMap<String,String> map = redisson.getMap("map");
		map.put("key1", "value1");

Code snippet of redisson instance 2:
Config config = Config.fromJSON(new File("//home//user//SingleNodeConfig.json"));
		RedissonClient redisson = Redisson.create(config);
		
		RMap<String,String> map = redisson.getMap("map");
		map.put("key1", "value2");

My use case is this: At an instant of time both the instances could access the same key and update its value twice. I want to restrict this i.e., if both instances are accessing the same key at the same time, only one update should occur and not both.
My question is this, which would be the best locking mechanism to deal with this or should i handle this on my own???
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1104
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I would like to report a locking issue we are seeing using redisson versions 3.3.2 to 3.5.4, using RFairLock.
We have 3 instances of an application competing for a fair lock. After some time, the timeout of the fair lock queue gets set to a time many hours in the future, and no thread ever gets the lock.
Here is what redis is reporting during one of the occurences - both commands ran at about 9:30AM PST on 10/17/2017 (1508257800000):
redis > zrange "redisson_lock_timeout:{mylock}" 0 99 WITHSCORES
1) "3b9c4448-dfaa-4b4e-a691-cfee25458333:88"
2) "1508278998141"
3) "a8baa8c5-d42d-4912-9a1b-e72d0728ae88:90"
4) "1508278998141"
5) "17cd3d41-8ea1-44c7-b458-a530aff209f0:88"
6) "1508279003141"

redis > lrange "redisson_lock_queue:{mylock}" 0 99
1) "17cd3d41-8ea1-44c7-b458-a530aff209f0:88"
2) "3b9c4448-dfaa-4b4e-a691-cfee25458333:88"
3) "a8baa8c5-d42d-4912-9a1b-e72d0728ae88:90"

You can see that the timeout (zscore of the timeout keys) is set about 6 hours in the future.
Current time = Tuesday, October 17, 2017 9:30:00.000 AM GMT-07:00 DST
1508278998141 = Tuesday, October 17, 2017 3:23:18.141 PM GMT-07:00 DST
1508279003141 = Tuesday, October 17, 2017 3:23:23.141 PM GMT-07:00 DST
So far, we haven't been able to reproduce the issue locally, but it is happening daily in our production environment. We are suspecting the problem is happening randomly when one of the application gets killed by the operating system (kill -9), something that can happen quite often due to the way we manage the apps.
We were using redisson version 3.2.3 before, and never experienced the issue.
Earlier this year, we tried updating to version 3.3.2 and started seeing the problem within a day or so. We reverted to 3.2.3, and waited for an updated version.
Two days ago, we decided to upgrade to 3.5.4 assuming the problem was fixed, but it happened again within a few hours.
I will keep on trying to reproduce the issue, but any help is appreciated.
Thanks,
Michael
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1105
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
You're right ability to extension is an important thing. Could you please apply your changes also to tomcat 6 & 7?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1106
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
测试环境：3主3从，key值为b的数据存在A主节点及D从节点，客户端单线程循环读取key值为b的数据（读取做了异常捕获）
很短时间关闭D从节点再启动，客户端会短时间等待后，继续从D从节点取数据；
稍微长时间关闭D从节点再启动（超过重试时间），客户端在等待超时异常后，继续从A主节点读取数据，后续时间重启D从节点对读操作无影响，证明一直使用的是主节点读取；
关闭A主节点后，在主从切换之前启动A主节点，客户端读取会等待后继续从A主节点读取数据（也没有切换到D从节点）；
长时间关闭A主节点（主从已切换，过程中有报org.redisson.client.RedisConnectionException: SlaveConnectionPool no available Redis entries，但是从节点都是可用的），客户端读取操作转到D节点，此时D节点已为主节点；
通过上面的测试发现只要从节点下线超过一定时间，后续的读操作就不会从从节点读取了
期望结果应该是从节点恢复后，读操作可以走从节点，不确定是bug还是配置问题
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1107
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi there,
I was looking around and I cannot find if there is socks proxy support.
I am creating the socks Authenticator like this.
 System.setProperty("socksProxyHost", this.host); System.setProperty("socksProxyPort", this.port); if (StringUtils.isNotEmpty(this.user)) { System.setProperty("java.net.socks.username", this.user); System.setProperty("java.net.socks.password", this.password); this.auth = new SocksProxy.ProxyAuthenticator(this.user, this.password); Authenticator.setDefault(this.auth); }
And the RedissonClient is created like so:
Config config = new Config(); config.useSingleServer().setAddress(String.format("redis://%s:%s", redisHost, redisPort)); config.setLockWatchdogTimeout( redissonLockWatchdogTimeoutInSecs * 1000L); Redisson.create(config);
But when it tries to initialize the connection it always tries to access the redisHost directly.
Is there support for socks proxy and if so how can I properly enable it?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1108
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Guys,
I have a redis 3.2 setup with sentinel (3 nodes). I'm using redisson 2x.
I'm performing some HA tests, dropping some slaves or making them fail to test the resilience of the system.
My simple config:
# redisson configuration for redis servers
# see : https://github.com/mrniko/redisson/wiki/2.-Configuration

sentinelServersConfig:
  idleConnectionTimeout: 10000
  pingTimeout: 1000
  connectTimeout: 10000
  timeout: 3000
  retryAttempts: 3
  retryInterval: 1500
  reconnectionTimeout: 3000
  failedAttempts: 3
  subscriptionsPerConnection: 5
  clientName: "bar"
  loadBalancer: !<org.redisson.connection.balancer.RoundRobinLoadBalancer> {}
  slaveConnectionMinimumIdleSize: 10
  slaveConnectionPoolSize: 64
  masterConnectionMinimumIdleSize: 10
  masterConnectionPoolSize: 64
  readMode: "SLAVE"
  sentinelAddresses: ["redis://sentinel.dev.foo.net:30039"]
  masterName: "mymaster"
codec: !<org.redisson.codec.SnappyCodec> {}
So I got this scenario where one of slaves is disconnected and with error on master link (check lines 10 and 33):
sentinel slaves mymaster
 1) "name"
  2)   "192.168.112.20:30079"
  3)   "ip"
  4)   "192.168.112.20"
  5)   "port"
  6)   "30079"
  7)   "runid"
  8)   "5533a09464369994a52b4d4a80e490a8613920ce"
  9)   "flags"
  10)   "s_down,slave,disconnected"**
  11)   "link-pending-commands"
  12)   "57515"
  13)   "link-refcount"
  14)   "1"
  15)   "last-ping-sent"
  16)   "60798317"
  17)   "last-ok-ping-reply"
  18)   "60799373"
  19)   "last-ping-reply"
  20)   "60799373"
  21)   "s-down-time"
  22)   "60788261"
  23)   "down-after-milliseconds"
  24)   "10000"
  25)   "info-refresh"
  26)   "60805267"
  27)   "role-reported"
  28)   "slave"
  29)   "role-reported-time"
  30)   "146523425"
  31)   "master-link-down-time"
  32)   "1508340989000"
  33)   "master-link-status"
  34)   "err"
  35)   "master-host"
  36)   "192.168.112.21"
  37)   "master-port"
  38)   "30079"
  39)   "slave-priority"
  40)   "100"
  41)   "slave-repl-offset"
  42)   "1"

The problem is that redisson tries to connect to this slave for reading regardless of its status instead of picking another slave.  Shouldn't redisson consider sentinel flags in this case? Maybe it is just a configuration I'm missing.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1109
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I got this problem when I trying to locking an object. Here is the problem:

org.redisson.client.RedisException: Unexpected exception while processing command
at org.redisson.command.CommandAsyncService.convertException(CommandAsyncService.java:325)
at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:168)
at org.redisson.RedissonObject.get(RedissonObject.java:72)
at org.redisson.RedissonLock.tryAcquire(RedissonLock.java:145)
at org.redisson.RedissonLock.lockInterruptibly(RedissonLock.java:114)
at org.redisson.RedissonLock.lockInterruptibly(RedissonLock.java:108)
at org.redisson.RedissonLock.lock(RedissonLock.java:90)
at com.hoaiduy.hello.service.WalletService.transferMoney(WalletService.java:72)
at com.hoaiduy.hello.service.WalletService$$FastClassBySpringCGLIB$$93c88aa5.invoke()
at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99)
at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:282)
at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
at com.hoaiduy.hello.service.WalletService$$EnhancerBySpringCGLIB$$6cba96ac.transferMoney()
at com.hoaiduy.hello.controller.WalletController.createTransaction(WalletController.java:37)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133)
at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97)
at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)
at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)
at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)
at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967)
at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901)
at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872)
at javax.servlet.http.HttpServlet.service(HttpServlet.java:661)
at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108)
at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81)
at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:478)
at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:80)
at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:799)
at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1457)
at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalStateException: Can't decode replay: HTTP/1.1 400
Transfer-Encoding: chunked
Date: Thu, 19 Oct 2017 10:15:31 GMT
Connection: close

And my code
redisson = (Redisson) Redisson.create();
Wallet wallet = walletRepository.findOne(senderId);
RLock lockSender = redisson.getLock(String.valueOf(wallet));
lockSender.lock();
try {
Amount amountIn = new Amount();
amountIn.setTransaction(transaction);
amountIn.setWallet(wallet);
amountIn.setAmount(amount);
amountIn.setState("RESERVED");
amountRepository.save(amountIn);
}finally {
lockSender.unlock();
}
what I'm missing?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1110
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
This issue is related to #891.

write lock for 10 seconds
write lock for 1 second

Now after 1 second the whole lock is released. I'm not sure if this is a bug, but logically the system should not unlock the because the first lock request is done for 10 seconds.
`
ExecutorService executor = Executors.newCachedThreadPool(new ThreadFactoryBuilder().setNameFormat("redis-%d").build());
RedissonClient client = Redisson.create(config);
	RReadWriteLock rw1 = client.getReadWriteLock("test2s3");
	
	RLock l1 = rw1.writeLock();
	System.out.println(l1.tryLock(10000, 10000, TimeUnit.MILLISECONDS));
	RLock l2 = rw1.writeLock();
	System.out.println(l2.tryLock(1000, 1000, TimeUnit.MILLISECONDS));
	executor.execute(()->{
		RReadWriteLock rw2 = client.getReadWriteLock("test2s3");
		try {
			if (rw2.writeLock().tryLock(3000, 1000, TimeUnit.MILLISECONDS)) {
				System.out.println("This is not expected!");
			}
		} catch (InterruptedException e) {
			e.printStackTrace();
		}
	});
	executor.shutdown();
	executor.awaitTermination(10, TimeUnit.MINUTES);
	client.shutdown();

`
Manually calling l2.unlock() manually works as expected, that is fixed in #891
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1111
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
因为我想定义一套接口，里面有多个实现，像redisson只能先查找出来，然后再进行该方面的操作，而查询又分为int类型的查询，map类型的查询等等，给统一接口带来一些不便，不知道有没有相应的解决办法，或者是我并不了解相应的api呢？
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1112
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I'm using cron schedules on an executor service but the schedules stop after a certain amount of time.
I've reproduced the issue in a small standalone project.
Here the scenario ;

Use latest redisson (3.5.4) with single node redis and using linux native epoll in configuration
Create a single worker for an executor service
Create the corresponding executor service
Schedule a cron task every seconds
Schedule a cron task every days at midnight

After a certain amount of time, the cron task every seconds will stop working.
When midnight comes, the midnight cron task works, and the every seconds task resume, but then stop again after a certain time.
I did not wait midnight on the standalone project, but I have had this behaviour in my project.
I looked into redis and saw that the every seconds task is still here, and the zset contains valid value for the next run in the score.
Note that I also reproduced the bug with every 5 seconds or every 5 minutes task and the task every days at midnight, but I had to wait longer.
I reproduced also without using the native linux epoll.
Redis version : 3.2.9 from docker official image redis:3.2.9 after 1 to 2 minutes
Redis version : 4.0.2 from docker official image redis:4.0.2 after around 8 minutes
redisson-issue.log
redisson-issue.tar.gz
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1113
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1114
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
What's the correct way of setting redisson up to work against a standard tier Azure Redis Cache? I'm asking because the standard tier Redis Cache is replicated, but Azure doesn't provide the connection details for the slave instance.
According to the documentation, Redisson's "replicated mode" requires that

All nodes (master and slaves) should be provided.

So do I use "replicated mode" and only specify a single instance, or do I use "single instance mode"?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1115
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1116
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1117
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1118
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Using singleServer mode without slave.
        Config config = new Config();
        config.useSingleServer().setAddress(redisServer1);
        client = Redisson.create(config);
        ....
        RBucket<Object> bucket = client.getBucket("TestKey");
        bucket.get();

now, when the Redis server is down, an exception will be throw:
org.redisson.client.RedisConnectionException: MasterConnectionPool no available Redis entries
	at org.redisson.connection.pool.ConnectionPool.get(ConnectionPool.java:196)
	at org.redisson.connection.pool.MasterConnectionPool.get(MasterConnectionPool.java:31)
	at org.redisson.connection.MasterSlaveEntry.connectionWriteOp(MasterSlaveEntry.java:419)
	at org.redisson.connection.SingleEntry.connectionReadOp(SingleEntry.java:45)
	at org.redisson.connection.MasterSlaveConnectionManager.connectionReadOp(MasterSlaveConnectionManager.java:752)
	at org.redisson.command.CommandAsyncService.async(CommandAsyncService.java:504)
	at org.redisson.command.CommandAsyncService$8.run(CommandAsyncService.java:585)
	at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:663)
	at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:738)
	at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:466)
	at java.lang.Thread.run(Thread.java:745)

I'd like to handle this in our app, but it looks like the getBucket() or get() is an async call, so the function doesnt throw the exception, I look through the docs, and found nothing to configure Redission to work in synchronized mode. Is  synchronous mode supported by Redission or is there a different way to handle this?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1119
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
`org.redisson.client.RedisTimeoutException: Redis server response timeout (10000 ms) occured for command: (EVAL) with params: [if (redis.call('exists', KEYS[1]) == 0) then redis.call('hset', KEYS[1], ARGV[2], 1); redis.call('pe..., 1, 123, 30000, cb52c4c0-bcf8-49e2-9b27-a68401b43123:147] channel: [id: 0x500b5be9, L:/192.168.1.165:36618

R:/192.168.1.46:6379
]
at org.redisson.command.CommandAsyncService$11.run(CommandAsyncService.java:696)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:663)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:738)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:466)
at java.lang.Thread.run(Thread.java:745)`

redis server 信息
1，redis 版本 3.0.6，
2，单节点
3，server配置

redisson信息
1，版本2.10.4
2，配置如下
SingleServerConfig singleSerververConfig = config.useSingleServer(); singleSerververConfig.setConnectionPoolSize(300);		singleSerververConfig.setConnectionMinimumIdleSize(10); singleSerververConfig.setConnectTimeout(10000); singleSerververConfig.setTimeout(10000); singleSerververConfig.setRetryAttempts(3); singleSerververConfig.setRetryInterval(1000);	singleSerververConfig.setSubscriptionConnectionMinimumIdleSize(1); singleSerververConfig.setSubscriptionConnectionPoolSize(25);
出现RedisTimeoutException是并发量很少的时候，高峰期并没有这样的错误，请帮忙看看是哪里有问题
谢谢
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1120
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
How can I make sure that if a certain nodes takes a scheduled task but crashes, someone else would try and recover it?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1121
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
这个问题之前提过：#1106
redisson版本：3.5.4
看了下源码，从节点恢复时，会走MasterSlaveEntry.slaveUp方法，但是在判断当前恢复节点不是主节点后，会从slaveBalancer中下线主节点，但是代码却下线了从节点（刚恢复的节点），代码行数：349
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1122
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi. I am using redisson 3.5.4.
I am using redisson for task service management. However, I am seeing a bunch of redis errors - not for every call, but for enough calls to where I am concerned. Here is a sample:
 RedisTimeoutException occurred when processing request: [GET] /tasks/74618b07-dbce-4c06-93e9-8720b59d56f9
Redis server response timeout (3000 ms) occured for command: (EVAL) with params: [local value = redis.call('hget', KEYS[1], ARGV[2]); if value == false then return nil; end; local t,..., 3, ns:redisson-task:results, redisson__timeout__set:{ns:redisson-task:results}, redisson__idle__set:{ns:redisson-task:results}, 1509457132711, 74618b07-dbce-4c06-93e9-8720b59d56f9] channel: [id: 0xa8085706, L:/10.10.41.230:57794 - R:non-prod-cache-dev.dkmn9o.0001.use1.cache.amazonaws.com/10.10.41.103:6379]. Stacktrace follows:
org.redisson.client.RedisTimeoutException: Redis server response timeout (3000 ms) occured for command: (EVAL) with params: [local value = redis.call('hget', KEYS[1], ARGV[2]); if value == false then return nil; end; local t,..., 3, ns:redisson-task:results, redisson__timeout__set:{ns:redisson-task:results}, redisson__idle__set:{ns:redisson-task:results}, 1509457132711, 74618b07-dbce-4c06-93e9-8720b59d56f9] channel: [id: 0xa8085706, L:/10.10.41.230:57794 - R:non-prod-cache-dev.dkmn9o.0001.use1.cache.amazonaws.com/10.10.41.103:6379]
        at org.redisson.command.CommandAsyncService$10.run(CommandAsyncService.java:647)
        at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:661)
        at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:736)
        at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:464)
        at java.lang.Thread.run(Thread.java:748)

and a different error:
RedisConnectionException occurred when processing request: [GET] /tasks/3b28ac7f-8ca2-45ab-b3c7-a422798ed7b7
RedisConnection@1674996143 [redisClient=[addr=non-prod-cache-dev.dkmn9o.0001.use1.cache.amazonaws.com/10.10.41.103:6379], channel=[id: 0x0248d945, L:0.0.0.0/0.0.0.0:57512]] is not active!. Stacktrace follows:
org.redisson.client.RedisConnectionException: RedisConnection@1674996143 [redisClient=[addr=non-prod-cache-dev.dkmn9o.0001.use1.cache.amazonaws.com/10.10.41.103:6379], channel=[id: 0x0248d945, L:0.0.0.0/0.0.0.0:57512]] is not active!
        at org.redisson.connection.pool.ConnectionPool.promiseFailure(ConnectionPool.java:314)
        at org.redisson.connection.pool.ConnectionPool.connectTo(ConnectionPool.java:251)
        at org.redisson.connection.pool.ConnectionPool.access$300(ConnectionPool.java:53)
        at org.redisson.connection.pool.ConnectionPool$3.run(ConnectionPool.java:216)
        at org.redisson.pubsub.AsyncSemaphore.acquire(AsyncSemaphore.java:76)
        at org.redisson.connection.ClientConnectionsEntry.acquireConnection(ClientConnectionsEntry.java:114)
        at org.redisson.connection.pool.ConnectionPool.acquireConnection(ConnectionPool.java:154)
        at org.redisson.connection.pool.ConnectionPool.acquireConnection(ConnectionPool.java:226)
        at org.redisson.connection.pool.ConnectionPool.get(ConnectionPool.java:168)
        at org.redisson.connection.pool.MasterConnectionPool.get(MasterConnectionPool.java:31)
        at org.redisson.connection.MasterSlaveEntry.connectionWriteOp(MasterSlaveEntry.java:409)
        at org.redisson.connection.MasterSlaveConnectionManager.connectionWriteOp(MasterSlaveConnectionManager.java:677)
        at org.redisson.command.CommandAsyncService.async(CommandAsyncService.java:503)
        at org.redisson.command.CommandAsyncService$7.run(CommandAsyncService.java:552)
        at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:661)
        at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:736)
        at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:464)
        at java.lang.Thread.run(Thread.java:748)

I am also seeing some RemoteServiceAckTimeException: No ACK response after 5000ms for request: RemoteServiceRequest.
Here is my configuration:
redisson {
    config {
        singleServerConfig {
            idleConnectionTimeout = 10000
            pingTimeout = 1000
            connectTimeout = 10000
            timeout = 3000
            retryAttempts = 3
            retryInterval = 1500
            reconnectionTimeout = 3000
            failedAttempts = 3
            password = null
            subscriptionsPerConnection = 5
            clientName = null
            address = 'redis://127.0.0.1:6379'
            subscriptionConnectionMinimumIdleSize = 1
            subscriptionConnectionPoolSize = 50
            connectionMinimumIdleSize = 10
            connectionPoolSize = 64
            database = 0
            dnsMonitoring = false
            dnsMonitoringInterval = 5000
        }
        threads = 0
        nettyThreads = 0
        codec = null
        useLinuxNativeEpoll = false
    }
}

Is there any config setting I could change to help with this? Am I doing something wrong?
thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1123
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am using redis with elastic cache in my spring application where i am using spring annotations for accessing cache.
I need to reset cache idle time and ttl on read so that i can keep my user active until user goes idle beyond timeout.
But read is not resetting the timeout and cache is evicted as per idle time and ttl set in configuration. Using below annotation in both the cases for creating and reading cache, the issue is same in both single and multiple server configuration.
@Cacheable(value = TEST_CACHE, key = CACHE_KEY)
config
"singleServerConfig":{
"idleConnectionTimeout":10000,
"pingTimeout":1000,
"connectTimeout":10000,
"timeout":3000,
"retryAttempts":3,
"retryInterval":1500,
"reconnectionTimeout":3000,
"failedAttempts":3,
"password":null,
"subscriptionsPerConnection":5,
"clientName":null,
"address": ["redis://127.0.0.1:6379"],
"subscriptionConnectionMinimumIdleSize":1,
"subscriptionConnectionPoolSize":50,
"connectionMinimumIdleSize":10,
"connectionPoolSize":64,
"database":0,
"dnsMonitoring":false,
"dnsMonitoringInterval":5000
},
"threads":0,
"nettyThreads":0,
"codec":null,
"useLinuxNativeEpoll":false
What is the configuration needed to reset idle time and ttl on read? please advise.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1124
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1125
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We're are struggling with basic persist function.
When have written a piece of code to persist a simple Customer object that is annotated as @REntity with its guid field marked as @RId.
package org.redisson.example.objects;

import org.redisson.api.annotation.REntity;
import org.redisson.api.annotation.RId;

@REntity
public class Customer {
	
	@RId
	private String guid;
	private int age;
	private String fname;
	private String lname;
	
        public Customer() {}
	
	public Customer(String guid) {
		super();
		this.guid = guid;
	}
	public String getGuid() {
		return guid;
	}
	public void setGuid(String guid) {
		this.guid = guid;
	}
       // other setter getters here...

}


The piece of code used to persist is as follows:
    Config config = new Config();
    config.useSingleServer().setAddress("127.0.0.1:9000");
    redissonClient = Redisson.create(config);

   RLiveObjectService service = redissonClient.getLiveObjectService();
   Customer customer1 = new Customer("1", 20, "A", "A", new Address(40001));
   service.persist(customer1);

Customer object is getting stored in Redis server with the key:
'redisson_live_object:{223122}:org.redisson.example.objects.Customer:guid:java.lang.String'
and value:
127.0.0.1:9000> HGETALL redisson_live_object:{223122}:org.redisson.example.objects.Customer:guid:java.lang.String
1) "\"redisson_live_object\""
2) "\"1\""
3) "\"age\""
4) "20"
5) "\"fname\""
6) "\"A\""
7) "\"lname\""
8) "\"A\""


We expected it to be saved using its field guid as the key. Nevertheless, now when we try to get this object back, it returns a object (which we believe is a proxy object) with all null values.
service.get(Customer.class, "1")
returns
Customer [guid=null, age=0, adress=null, fname=null, lname=null]
Can you please point us in the right direction for using redisson api? Further, we want objects to be searched not just by the @Rid field but also a combination of fields, say, Age and Name etc.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1126
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Parent -child is still not working for me. I am getting no such field exception when the RId is a part of the parent class. Can you please guide? What am I missing?
Redis loading failed.java.lang.NoSuchFieldException: No such field: guid
java.lang.IllegalArgumentException: java.lang.NoSuchFieldException: No such field: guid
at org.redisson.liveobject.misc.ClassUtils.getField(ClassUtils.java:105)
at org.redisson.RedissonLiveObjectService.persist(RedissonLiveObjectService.java:163)
at org.redisson.RedissonLiveObjectService.merge(RedissonLiveObjectService.java:152)
Use Case:
Here is my base class:
@rentity
public abstract class AbstractDo implements Serializable {
private static final long serialVersionUID = 7680440665187761533L;
private @Rid String guid;
public String getGuid() {
return guid;
}
public void setGuid(String guid) {
this.guid = guid;
}
@OverRide
public int hashCode() {
...
}
@OverRide
public boolean equals(Object obj) {
...
}
My Derived Class:
@rentity
public class UserProfile extends AbstractDo {
private static final long serialVersionUID = -7817007972557889495L;
private String enterpriseGuid;
@Auditable
private String defaultStoreGuid;
private @indexed Set roleGuids = new LinkedHashSet();
public static final String LOGIN_ID = "loginId";
private @indexed String  loginId;
// private String loginId;
public static final String USER_ASSIGNMENTS = "assignments";
@Auditable
private Set assignments = new LinkedHashSet();
public UserProfile(Set assignments) {
setAssignments(assignments);

}
public UserProfile() {
assignments.add(new UserProfileAssignment());

}
public String getEnterpriseGuid() {
return enterpriseGuid;
}
public void setEnterpriseGuid(String enterpriseGuid) {
this.enterpriseGuid = enterpriseGuid;
}
public String getDefaultStoreGuid() {
return defaultStoreGuid;
}
...
...
}
And this is how I invoke it:
public class UserProfileRedisRadisson {
@Autowired
private RedissonClient redissonClient;
public void loadData(Collection allRows) {
RLiveObjectService liveObjectService = redissonClient.getLiveObjectService();
System.out.println("START");
for(UserProfile ur:allRows) {
	if(liveObjectService.get(UserProfile.class, ur.getGuid()).getGuid() == null) {
		liveObjectService.persist(liveObjectService.attach(ur));
	} else {
		liveObjectService.merge(liveObjectService.attach(ur));
	}
}
System.out.println("END");

}
}
Thanks,
Salil
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1127
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have a Spring Boot application and a Bean that implements org.springframework.boot.autoconfigure.cache.JCacheManagerCustomizer, i.e. there is a method that takes a javax.cache.CacheManager, and then follows the instructions provided here. Specifically, I have implemented a mixture of the code snippets for:

"Using config file with custom location"
"Using Redisson's config object:"

Essentially, I have the following that does create caches as I would expect on my local Redis instance:
@Override
public void customize(javax.cache.CacheManager manager) {
    MutableConfiguration<String, String> jcacheConfig = new MutableConfiguration<>();
    Config redissonCfg = getClass().getResource(expectedRedissonCacheConfigLocation);
    Configuration<String, String> config = RedissonConfiguration.fromConfig(redissonCfg, jcacheConfig);
    Cache<String, String> cache = manager.createCache("namedCache", config);
}

However, when I run tests or start/stop the Spring boot application, I always receive the following Log message and the Redis caches are not cleared.  Note that the caches are reset if multiple tests are run in sequence but the data cached in the last test is still present in the Redis instance after the test has been run.
WARN 10556 --- [           main] o.s.b.f.support.DisposableBeanAdapter    : Invocation of destroy method 'close' failed on bean with name 'jCacheCacheManager': java.lang.NullPointerException
After debugging, it seems that there is no org.redisson.Redisson object created. This appears to be caused by the checks for either a redisson-jcache.json and redisson-jcache.yaml being on the classpath in org.redisson.jcache.JCachingProvider#loadConfig(URI uri). If these files are not found, the config returned is null which means that org.redisson.jcache.JCachingProvider#getCacheManager(URI uri, ClassLoader classLoader, Properties properties) does not invoke the code inside the if conditional below:
Redisson redisson = null;
if (config != null) {
    redisson = (Redisson) Redisson.create(config);
}
manager = new JCacheManager(redisson, classLoader, this, properties, uri);

I do not have either a redisson-jcache.json and redisson-jcache.yaml file on the classpath since my team are trying to develop a way of loading different Redisson configuration files based upon the Spring Boot profile that is used to launch a Spring Boot application.  Configuration files are instead searched for in a specified location with a specified file name (the name of a Spring Boot profile).
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1128
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have a Customer object as below
            @REntity
            public class Customer {
               @RId
               private String guid;
               private String name;
 
               //Required getter-setter and constructors here...
          }

I store this object in Redis using the persist method as below:
                Config config = new Config();
		config.useSingleServer().setAddress("redis://127.0.0.1:9000");
		redissonClient = Redisson.create(config);
		RLiveObjectService service = redissonClient.getLiveObjectService();
                service.persist(new Customer("1", "Tom");

I can use the service.get(Customer.class, "1")  method to retrieve this object based on the guid we pass to it. However, I have following requirements:

retrieving Customer objects based on the name field, which is not @Rid
retrieving Customer objects based on combination of guid and name field.

Can you point me to the right api for such requirement?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1129
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello,
I was testing the behavior of Redis/Redisson when a network failure happens (say for few minutes) and then recovers. I observed the following unexpected behavior and wondering if there is a way to avoid this scenario.
Observation:

SADD command was issued at 14:46 PM and failed due to RedisTimeoutException. This seems to have happened just about when network failure just started.
At 14:50 (A full 4 minutes later), it looks like Redisson heard back from Redis master node but due to client side timeout set, just skipped the response.

Here are the logs:
03 Nov 2017 14:46:39,438 [WARN] ...... org.redisson.client.RedisTimeoutException: Redis server response timeout (25 ms) occured for command: (SADD) with params: [AKC-590000000707, 78af13d0-d00b-4898-9da3-8410236dcfb9] channel: [id: 0x845c3d76, L:/10.0.19.60:39336 - R:/10.1.48.182:6379]

03 Nov 2017 14:50:08,771 [WARN]  (redisson-netty-5-15) org.redisson.client.handler.CommandDecoder: response has been skipped due to timeout! channel: [id: 0x845c3d76, L:/10.0.19.60:39336 - R:/10.1.48.182:6379], command: CommandData [promise=org.redisson.misc.RedissonPromise@3742b67c[Completed exceptionally], command=(SADD), params=[AKC-590000000707, 78af13d0-d00b-4898-9da3-8410236dcfb9], codec=org.redisson.codec.JsonJacksonCodec@438dd2b6], result: true

Redis Version:
Redisson Version: 3.4.1
Client configuration: (For ElastiCache cluster)
    Config config = new Config();
    config.useClusterServers()
        .addNodeAddress(endpoint.getAddress() + ":" + endpoint.getPort())
        .setConnectTimeout(1000)
        .setTimeout(25)
        .setRetryAttempts(1) // client creation fails when set to 0
        .setRetryInterval(25);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1130
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Tried following config
initially copied from the document at https://github.com/redisson/redisson/wiki/2.-Configuration#27-sentinel-mode before changing readMode from "SLAVE" to "MASTER_SLAVE"

{
"sentinelServersConfig":{
... ,
"loadBalancer":{
"class":"org.redisson.connection.balancer.RoundRobinLoadBalancer"
},
"readMode":"MASTER_SLAVE",
"sentinelAddresses":[
"redis://192.168.1.101:26379",
"redis://192.168.1.101:26379",
"redis://192.168.1.102:26379"
],
...
}
}

I wish both master and 2 slaves could be read (33% chance on RoundRobin algo). But I see the master never got read.
Tried different Balancer and dug into the source, seems that the LB seems only be applied to slaves. The master server is setFreezed(true) and it won't get read unless both slaves get disconnected.
Looks like ReadMode of "MASTER_SLAVE" is actually same as ReadMode of "SLAVE".
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1131
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1132
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
it used to accept "localhost:6379", but now the address seems have to be: "redis://127.0.0.1:6379"
this is because the change in org.redisson.misc.URIBuilder.java.
Should it more developer friendly?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1133
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi, i'm using redisson with a Replicated Mode configuration (1 master and 2 slaves).
When attempting to debug an issue, i found that apparently the timeout configuration parameter is not being used in the implementation as documented.
I was receiving a fair amount of unexpected RedisTimeoutException: Command execution timeout messages.
Changing the retryAttempts and retryInterval allowed to circumvent the issue - but not changing timeout - which seemed odd to me, so i decided to dig further.
In ReplicatedConnectionManager#L123,
the parameter passed for connectionTimeout is cfg.getRetryInterval() * cfg.getRetryAttempts() (and not timeout).

    RedisClient client = createClient(
        NodeType.MASTER, addr,
         cfg.getConnectTimeout(), 
          cfg.getRetryInterval() * cfg.getRetryAttempts()  // shouldn't it be cfg.getTimeout() (?)
    );


A value of 0 for retryAttempts, or even a higher number matched with a relatively low retryInterval always causes the RedissonClient instantiation to fail (due toCommand execution timeout).
Raising these values can bypass the error on the initial connection and allow the instantiation.
Still, the same applies to subsequent calls: they also won't also use the timeout provided in the configuration.
Am i observing this correctly or is there something i'm missing here?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1134
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
One of our teams has been running some load tests that involve calling deleting keys from a redis cluster among other things. And when they run a profiler they observed that top hot spot was actually related to collection management (ConcurrentHashMap and HashSet) on redisson when getting connection info and copying it for every operation.
As seen on the following hotspot analysis

This was tested with redisson 3.4.3, haven't tried with the latest one yet
Is there anything that could be changed from config or improved on the code in future versions?
I believe the same scenario might show up on other operations besides delete
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1135
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I was trying to use your library with AWS Clustered mode and figured out it does not work with SSL.
I figured out the problem and fixed it in my fork  but it's a hack what I did.
Basically everywhere you create an address like "redis://" -- you need a way to know if it's SSL and put "rediss://" instead. Since those places have no access to config, unfortunately I changed all to force SSL everywhere.
Do you have in plan a fix for this, or I can do it if you point me to the right way. I am trying to understand your logic and how can I be least invasive to pass a config. The simplest way would be to put a static public flag somewhere -- but that's also a hack I guess, and will only allow one type at one time, or pass a jvm property ...what do you suggest?
Thanks in advance,
Florin Moisa
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1136
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
We have a usecase where we store Java objects in cache and search them by multiple fields. Is there a way to achieve it in Redisson liveObjects? Spring-data-redis provides such functionality but does not support redisson.
Thanks,
Salil Gandhi
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1137
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1138
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1139
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1140
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1141
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1142
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1143
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1144
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1145
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1146
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1147
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1148
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1149
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1150
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1151
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1152
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1153
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1154
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1155
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1156
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1157
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1158
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1159
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1160
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1161
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1162
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1163
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1164
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1165
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1166
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1167
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1168
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1169
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1170
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1171
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1172
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1173
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1174
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1175
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1176
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1177
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1178
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1179
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1180
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1181
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1182
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1183
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1184
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1185
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1186
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1187
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1188
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1189
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1190
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1191
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1192
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1193
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1194
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1195
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1196
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1197
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1198
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1199
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1200
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1201
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1202
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1203
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1204
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1205
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1206
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1207
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1208
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1209
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1210
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1211
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1212
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1213
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1214
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1215
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1216
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1217
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1218
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1219
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1220
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1221
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1222
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1223
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1224
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1225
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1226
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1227
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1228
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1229
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1230
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1231
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1232
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1233
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1234
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1235
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1236
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1237
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1238
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1239
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1240
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1241
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1242
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1243
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1244
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1245
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1246
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1247
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1248
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1249
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1250
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1251
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1252
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1253
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1254
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1255
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1256
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1257
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1258
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1259
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello,
I'm following https://github.com/redisson/redisson/wiki/14.-Integration-with-frameworks#146-spring-session guide, but I get NPE
Caused by: java.lang.NullPointerException: null at org.redisson.spring.session.config.RedissonHttpSessionConfiguration.sessionRepository(RedissonHttpSessionConfiguration.java:54) ~[redisson-2.10.7.jar:na]
I tried to use @EnableRedissonHttpSession(maxInactiveIntervalInSeconds = 360) but still the same NPE. Is this annotation usable or the only option I have to use is xml ? Tried  3.5.7 version.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1260
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am using Redisson as Redis client to store a key-value pair <String, LocalDateTime>. It's configured to be used through the JCache API (JSR-107).
It's storing values like 2018-01-23T11:59:34.997834 but in the cache#get invocation is trying to return a String giving a ClassCastException . It compiles perfectly, cache#get returning LocalDateTime, but if fails in execution.
Am I missing something here or is there some problem using it with the JCache API?
    @Test
    public void getCacheInline() {
        // Configuration
        Config redissonCfg = new Config();
        redissonCfg
            .setCodec(new JsonJacksonCodec(buildObjectMapper()))
            .useSingleServer()
            .setAddress("redis://redis:6379");

        MutableConfiguration<String, LocalDateTime> jcacheConfig = new MutableConfiguration<String, LocalDateTime>()
            .setTypes(String.class, LocalDateTime.class)
            .setExpiryPolicyFactory((Factory<ExpiryPolicy>) () -> new CreatedExpiryPolicy(new Duration(SECONDS, 100)));

        Configuration<String, LocalDateTime> configuration = RedissonConfiguration.fromConfig(redissonCfg, jcacheConfig);

        // Cache creation
        Cache<String, LocalDateTime> cache = cacheManager.createCache(CACHE_NAME, configuration);

        // Put
        LocalDateTime expectedDateTime = LocalDateTime.now();
        cache.put("testKey", expectedDateTime);

        // Get
        // In this line: java.lang.ClassCastException: java.base/java.lang.String cannot be cast to java.base/java.time.LocalDateTime
        LocalDateTime actualDateTime = cache.get("testKey");
        assertThat(actualDateTime, is(equalTo(expectedDateTime)));
    }

    private ObjectMapper buildObjectMapper() {
        ObjectMapper objectMapper = new ObjectMapper();
        objectMapper.registerModule(new JavaTimeModule());
        objectMapper.configure(FAIL_ON_UNKNOWN_PROPERTIES, false);
        objectMapper.configure(WRITE_DATES_AS_TIMESTAMPS, false);
        objectMapper.configure(READ_DATE_TIMESTAMPS_AS_NANOSECONDS, false);
        objectMapper.setSerializationInclusion(NON_NULL);
        return objectMapper;
    }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1261
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1262
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I use Redisson (sentinel mode), and everything was working fine until I added an EntryExpiredListener.
After adding the listener I started getting the following errors
[CommandAsyncService] - acquired connection for command (EVAL) and params [if redis.call('setnx', KEYS[6], ARGV[4]) == 0 then return 0;end;redis.call('expire', KEYS[6], ARGV[3]); local expiredKeys1 = redis.call('zrangebyscore', KEYS[2], 0, ARGV[1], 'limit', 0, ARGV[2]); for i, key in ipairs(expiredKeys1) do local v = redis.call('hget', KEYS[1], key); if v ~= false then local t, val = struct.unpack('dLc0', v); local msg = struct.pack('Lc0Lc0', string.len(key), key, string.len(val), val); local listeners = redis.call('publish', KEYS[4], msg); if (listeners == 0) then break;end; end;end;if #expiredKeys1 > 0 then redis.call('zrem', KEYS[4], unpack(expiredKeys1)); redis.call('zrem', KEYS[3], unpack(expiredKeys1)); redis.call('zrem', KEYS[2], unpack(expiredKeys1)); redis.call('hdel', KEYS[1], unpack(expiredKeys1)); end; local expiredKeys2 = redis.call('zrangebyscore', KEYS[3], 0, ARGV[1], 'limit', 0, ARGV[2]); for i, key in ipairs(expiredKeys2) do local v = redis.call('hget', KEYS[1], key); if v ~= false then local t, val = struct.unpack('dLc0', v); local msg = struct.pack('Lc0Lc0', string.len(key), key, string.len(val), val); local listeners = redis.call('publish', KEYS[4], msg); if (listeners == 0) then break;end; end;end;if #expiredKeys2 > 0 then redis.call('zrem', KEYS[4], unpack(expiredKeys2)); redis.call('zrem', KEYS[3], unpack(expiredKeys2)); redis.call('zrem', KEYS[2], unpack(expiredKeys2)); redis.call('hdel', KEYS[1], unpack(expiredKeys2)); end; return #expiredKeys1 + #expiredKeys2;, 6, <MAP_CACHE_NAME>, redisson__timeout__set:{<MAP_CACHE_NAME>}, redisson__idle__set:{<MAP_CACHE_NAME>}, redisson_map_cache_expired:{<MAP_CACHE_NAME>}, redisson__map_cache__last_access__set:{<MAP_CACHE_NAME>}, redisson__execute_task_once_latch:{<MAP_CACHE_NAME>}, 1516811165744, 100, 33, 1] from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=org.redisson.connection.MasterSlaveEntry@50487e86] using node /<NODE_HOST_AND_PORT>... RedisConnection@795684401 [redisClient=[addr=redis://<NODE_HOST_AND_PORT>], channel=[id: <channelId>, L:/... - R:/<NODE_HOST_AND_PORT>]]

[CommandAsyncService] - connection released for command (EVAL) and params [if redis.call('setnx', KEYS[6], ARGV[4]) == 0 then return 0;end;redis.call('expire', KEYS[6], ARGV[3]); local expiredKeys1 = redis.call('zrangebyscore', KEYS[2], 0, ARGV[1], 'limit', 0, ARGV[2]); for i, key in ipairs(expiredKeys1) do local v = redis.call('hget', KEYS[1], key); if v ~= false then local t, val = struct.unpack('dLc0', v); local msg = struct.pack('Lc0Lc0', string.len(key), key, string.len(val), val); local listeners = redis.call('publish', KEYS[4], msg); if (listeners == 0) then break;end; end;end;if #expiredKeys1 > 0 then redis.call('zrem', KEYS[4], unpack(expiredKeys1)); redis.call('zrem', KEYS[3], unpack(expiredKeys1)); redis.call('zrem', KEYS[2], unpack(expiredKeys1)); redis.call('hdel', KEYS[1], unpack(expiredKeys1)); end; local expiredKeys2 = redis.call('zrangebyscore', KEYS[3], 0, ARGV[1], 'limit', 0, ARGV[2]); for i, key in ipairs(expiredKeys2) do local v = redis.call('hget', KEYS[1], key); if v ~= false then local t, val = struct.unpack('dLc0', v); local msg = struct.pack('Lc0Lc0', string.len(key), key, string.len(val), val); local listeners = redis.call('publish', KEYS[4], msg); if (listeners == 0) then break;end; end;end;if #expiredKeys2 > 0 then redis.call('zrem', KEYS[4], unpack(expiredKeys2)); redis.call('zrem', KEYS[3], unpack(expiredKeys2)); redis.call('zrem', KEYS[2], unpack(expiredKeys2)); redis.call('hdel', KEYS[1], unpack(expiredKeys2)); end; return #expiredKeys1 + #expiredKeys2;, 6, <MAP_CACHE_NAME>, redisson__timeout__set:{<MAP_CACHE_NAME>}, redisson__idle__set:{<MAP_CACHE_NAME>}, redisson_map_cache_expired:{<MAP_CACHE_NAME>}, redisson__map_cache__last_access__set:{<MAP_CACHE_NAME>}, redisson__execute_task_once_latch:{<MAP_CACHE_NAME>}, 1516811165744, 100, 33, 1] from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=org.redisson.connection.MasterSlaveEntry@50487e86] using connection RedisConnection@795684401 [redisClient=[addr=redis://<NODE_HOST_AND_PORT>], channel=[id: <channelId>, L:/... - R:/<NODE_HOST_AND_PORT>]]

DefaultChannelPipeline] - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
io.netty.handler.codec.DecoderException: com.fasterxml.jackson.core.JsonParseException: Unexpected character ('b' (code 98)): Expected space separating root-level values
 at [Source: io.netty.buffer.ByteBufInputStream@5b82e39; line: 1, column: 3]
        at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:422)
        at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
        at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
        at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
        at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
        at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
        at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:138)
        at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
        at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
        at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
        at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:745)
Caused by: com.fasterxml.jackson.core.JsonParseException: Unexpected character ('b' (code 98)): Expected space separating root-level values
 at [Source: io.netty.buffer.ByteBufInputStream@5b82e39; line: 1, column: 3]
        at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1586)
        at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:521)
        at com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:450)
        at com.fasterxml.jackson.core.base.ParserMinimalBase._reportMissingRootWS(ParserMinimalBase.java:466)
        at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._verifyRootSpace(UTF8StreamJsonParser.java:1657)
        at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._parsePosNumber(UTF8StreamJsonParser.java:1394)
        at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:852)
        at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:748)
        at com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:3847)
        at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3792)
        at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2867)
        at org.redisson.codec.JsonJacksonCodec$2.decode(JsonJacksonCodec.java:87)
        at org.redisson.codec.MapCacheEventCodec.decode(MapCacheEventCodec.java:102)
        at org.redisson.codec.MapCacheEventCodec.access$100(MapCacheEventCodec.java:35)
        at org.redisson.codec.MapCacheEventCodec$1.decode(MapCacheEventCodec.java:44)
        at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:257)
        at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:287)
        at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:276)
        at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:93)
        at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
        at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:367)
        ... 28 more

Any hints?
Client Factory
public final class RedissonSentinelClientFactory {

	private static final String SEPARATOR = ",";

	private RedissonSentinelClientFactory() {
		throw new UnsupportedOperationException("Cannot instantiate");
	}

	public static RedissonClient create(String masterName, String hostsAndPorts, String password, int database) {
		if (database < 0) {
			log.error("Database provided is {}", database);
			throw new IllegalArgumentException("Database index cannot be less than 0");
		}

		String[] hostsAndPortsArr = splitHostsAndPorts(hostsAndPorts);
		log.info("Initializing redis sentinel configuration {master: {}, hosts/ports: {}, database: {} }", masterName, hostsAndPortsArr,
				database);

		Config config = new Config();
		config.useSentinelServers()
				.setMasterName(masterName)
				.addSentinelAddress(hostsAndPortsArr)
				.setDatabase(database)
				.setPassword(password);

		return Redisson.create(config);
	}

	private static String[] splitHostsAndPorts(String input) {
		return Arrays.stream(input.split(SEPARATOR))
				.map(RedissonSentinelClientFactory::appendPrefix)
				.toArray(String[]::new);
	}

	private static String appendPrefix(String hostAndPort) {
		return "redis://" + hostAndPort;
	}
}

Usage
	public RedisService(String name, RedissonClient client, long expiration, long lockTimeout) {
		this.key = name + "-key";
		this.mapCache = client.getMapCache(name);
		this.updateLock = client.getLock(name + "-lock");
		this.fundsExpiration = expiration;
		this.lockTimeout = lockTimeout;
	}
      // ....
        public void addExpiredListener(BiConsumer<String, List<Product>> consumer) {
		LOGGER.info("Registering listener for expired entries");
		this.mapCache.addListener((EntryExpiredListener<String, List<Product>>) event -> {
			String eventKey = event.getKey();
			if (eventKey.equals(key)) {
				consumer.accept(event.getKey(), event.getValue());
			}
		});
	}


       // in some other class in the code. 
       // handleExpire() just re-fetches the data from an external service and saves them back again
       this.redisService.addExpiredListener((key, value) -> this.handleExpire());
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1263
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1264
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@mrniko Currently ZREVRANGEBYLEX is not supported by redisson which can pull details in reverse order of the stored values on a key LEX sorted set data structure. Please support this function as soon as possible as we would like to use it. Without that the retrieval of data in reverse order is very cumbersome and not an easy way out. Even LUA script based on discussion with REDIS labs, they say it fecthes data only from one shard and cannot go and look for data in other shards... We want to use this function zrevrangebylex in redis batch execute to retrieve data from multiple sorted set keys at once
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1265
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
用JsonJacksonCodec来序列化的时候，当pojo对象为kotlin的时候，无法序列化，直接抛出异常
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1266
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello,
I'm using Redisson 3.6.0 and want to use the following:
https://github.com/redisson/redisson/wiki/14.-Integration-with-frameworks#147-jmx-and-dropwizard-metrics
Config config = ... // redisson config object
config.enableMetrics()
      .setRegistryName("myMetrics")
      // enable JMX
      .setJmxEnabled()
      // JMX domain name
      .setJmxDomain();
However, the org.redisson.config.Config class does not implement enableMetrics(). I can't find the implementation in Github source code.
How can one initialize the Metrics as described in the documentation ?
Thanks.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1267
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
version : 3.6.0
simple code:
@REntity()
@Data
public class TestEntry {

    @RId
    private String id;
    private String value;
    private XX xx;
    private int tem;

    public enum XX {
        A, B
    }


    public static void main(String[] args) throws IOException {
        RedissonClient redissonClient = Redisson.create();
        RLiveObjectService liveObjectService = redissonClient.getLiveObjectService();
        liveObjectService.registerClass(TestEntry.class);
        TestEntry entry = new TestEntry();

        entry.setXx(XX.A);
        entry.setId("xxx");
        entry.setValue("value");
        entry.setTem(10);
        liveObjectService.persist(entry);

        TestEntry liveEntry = liveObjectService.get(TestEntry.class, "xxx");
     //java.lang.ClassCastException: java.lang.String cannot be cast to  test.TestEntry$XX
        System.out.println(liveEntry.getXx());
  }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1268
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi there,
We hit an issue in one of our server using Redission as Redis Client. We do have a single thread executor handling subscribe/unsubscribe for multiple channels. But last week, we found this got blocked on one server . Below is the thread print
"pool-12-thread-1" #67 prio=5 os_prio=0 tid=0x00007f9f6c9e1000 nid=0x5091 waiting on condition [0x00007f9f6a2f6000]
java.lang.Thread.State: WAITING (parking)
at sun.misc.Unsafe.park(Native Method)
- parking to wait for  <0x00000006cc5406a8> (a java.util.concurrent.CountDownLatch$Sync)
at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231)
at org.redisson.pubsub.AsyncSemaphore.acquireUninterruptibly(AsyncSemaphore.java:49)
at org.redisson.RedissonTopic.removeAllListeners(RedissonTopic.java:89)
The org.redisson.RedissonTopic.removeAllListeners is unable to respond request, and blocked in the acquireUninterruptibly FOREVER. I tried to dig into logs, there was one exception thrown before this in CommandAsyncService.syncSubscription line 125 "Subscribe timeout 9500ms". This is possibly related since this was the only "Subscribe timeout" message I saw in last 30 days logs and then this issue happened. But I still don't find prove on this. Looks like this is a rare case since we just hit once. I tried to reproduce locally but with no luck.
I think the removeAllListeners should give an option to let caller pass in a timeout. But this is also not going to resolve the root cause. I am wondering if other people have observed this issue before. Please advise if you have any ideas on this, thanks.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1269
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
i want a  buckets.getAsync api
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1270
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RBlockingQueue blockingFairQueue = redisson.getBlockingQueue("delay_queue");
RDelayedQueue delayedQueue = redisson.getDelayedQueue(blockingFairQueue);
    delayedQueue.offer("1_1_1", 3, TimeUnit.SECONDS);
    delayedQueue.offer("1_1_2", 7, TimeUnit.SECONDS);

    assertThat(delayedQueue.contains("1_1_1")).isTrue();   // true   ???

    Thread.sleep(9000);
    
     assertThat(delayedQueue.contains("1_1_1")).isTrue();


pom.xml
		<dependency>
			<groupId>org.redisson</groupId>
			<artifactId>redisson</artifactId>
			<version>2.9.4</version>
		</dependency>
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1271
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RedissonClient redissonClient = redisService.getRedissonClient();
	RBlockingQueue blockingFairQueue = redissonClient.getBlockingQueue("delay_queue");
	RDelayedQueue delayedQueue = redissonClient.getDelayedQueue(blockingFairQueue);

    delayedQueue.offer("1_1_1", 3, TimeUnit.SECONDS);

     “1_1_1” will disappear  after 3 seconds  ?  

I got it!   Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1272
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello, I have a strange issue with redisson and sentinel fail-over
I have a SpringBoot application, I have multiple instance of this application, load balanced(HAproxy).
My http sessions is shared between these instances with Spring-session and Redisson.
I have a Redis cluster in "Master - Slave" configuration with 6 sentinel.
When I have a failure on my Redis master (I can reproduce with "redis-cli -p 6379 DEBUG sleep 30"), the sentinel fail-over is working well (in around 2 minutes) and the slave become a master.
This is the beginning of my problems :
First I can see many "org.redisson.client.RedisConnectionException"  during 10-15 minutes
RedisConnection@232881729 [redisClient=[addr=/57.190.13.39:6399], channel=[id: 0xed64ca68, L:0.0.0.0/0.0.0.0:47232 ! R:/57.190.13.39:6399]] is not active!

MasterConnectionPool no available Redis entries.  Disconnected hosts: [/57.190.13.40:6399]

I assume, it's probably due to connection switching.
But after during 1 hour, I still have lot of "org.redisson.client.RedisException"
READONLY You can't write against a read only slave.. channel: [id: 0x1b28f878, L:/172.17.0.4:60686 - R:/57.190.13.39:6399] command: (PEXPIRE), params: [redisson_spring_session:3a36d767-e939-47d0-b3a0-22d120a11e0a, 1800000]

Lot of user login in my application are failing and all the access to redis become slow become slow (jump from 2 ms to 100ms)
And I restarted my Spring Boot application and everything is back to normal
Do you have experienced similar issue ? or any hint ?
I'm using SpringBoot 1.5.8.RELEASE
Redisson 3.5.4
Spring Session 1.3.1.RELEASE
Here my Java configuration :
@EnableRedissonHttpSession
@Configuration
@ConfigurationProperties("redis")
public class RedissonConfig implements BeanClassLoaderAware
{
    private static final int THREAD_NUMBER = 4;

    @Autowired
    private ICommonConfigurationService commonConfigurationService;

    private ClassLoader loader;
    private String addresses;
    private String masterName;
    private String password;

    @Override
    public void setBeanClassLoader(final ClassLoader classLoader)
    {
        this.loader = classLoader;
    }

    private ObjectMapper mapper()
    {
        final ObjectMapper mapper = new ObjectMapper();

        mapper.disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS);
        mapper.disable(DeserializationFeature.ADJUST_DATES_TO_CONTEXT_TIME_ZONE);
        mapper.setSerializationInclusion(Include.NON_NULL);
        mapper.addMixIn(Throwable.class, JsonJacksonCodec.ThrowableMixIn.class);
        //Add mixin to save Locale with the @class into redis. Useful for LocaleResolver
        mapper.addMixIn(Locale.class, LocaleMixIn.class);

        mapper.registerModule(new JavaTimeModule());
        mapper.registerModules(SecurityJackson2Modules.getModules(this.loader));
        mapper.findAndRegisterModules();

        return mapper;
    }

    @Bean
    public CookieSerializer cookieSerializer()
    {
        final DefaultCookieSerializer serializer = new DefaultCookieSerializer();
        serializer.setCookieName(commonConfigurationService.getSessionCookieName());
        serializer.setCookiePath(commonConfigurationService.getSessionCookiePath());
        return serializer;
    }

    @Bean(destroyMethod = "shutdown")
    public RedissonClient redissonClient()
    {
        return Redisson.create(sentinelServers());
    }

    private Config baseConfig()
    {
        return new Config()
                .setNettyThreads(THREAD_NUMBER)
                .setThreads(THREAD_NUMBER)
                .setCodec(new JsonJacksonCodec(mapper()));
    }

    private Config sentinelServers()
    {
        final Config config = baseConfig();
        config.useSentinelServers()
                .addSentinelAddress(split(addresses, ", "))
                .setMasterName(masterName)
                .setPassword(password)
                .setTimeout(30000)
                .setConnectTimeout(30000);

        return config;
    }

    public String getAddresses()
    {
        return addresses;
    }

    public void setAddresses(final String addresses)
    {
        this.addresses = addresses;
    }

    public String getMasterName()
    {
        return masterName;
    }

    public void setMasterName(final String masterName)
    {
        this.masterName = masterName;
    }

    public String getPassword()
    {
        return password;
    }

    public void setPassword(final String password)
    {
        this.password = password;
    }

}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1273
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
We are using redisson-client 3.6.0 with cluster mode enabled with elasticache, redis=3.2.6(encryption-at-rest enabled). These are the configurations for 2 separate clusters,
{
  "clusterServersConfig": {
    "idleConnectionTimeout": 60000,
    "pingTimeout": 1000,
    "connectTimeout": 10000,
    "timeout": 5000,
    "retryAttempts": 3,
    "retryInterval": 1500,
    "reconnectionTimeout": 3000,
    "failedAttempts": 3,
    "subscriptionsPerConnection": 5,
    "clientName": "RegularCluster",
    "sslEnableEndpointIdentification": true,
    "sslProvider": "JDK",
    "pingConnectionInterval": 0,
    "keepAlive": false,
    "tcpNoDelay": false,
    "loadBalancer": {
      "class": "org.redisson.connection.balancer.RoundRobinLoadBalancer"
    },
    "slaveConnectionMinimumIdleSize": 50,
    "slaveConnectionPoolSize": 150,
    "masterConnectionMinimumIdleSize": 50,
    "masterConnectionPoolSize": 150,
    "readMode": "MASTER",
    "subscriptionMode": "SLAVE",
    "subscriptionConnectionMinimumIdleSize": 1,
    "subscriptionConnectionPoolSize": 50,
    "dnsMonitoringInterval": 5000,
    "nodeAddresses": [
      "redis://elastic-cache-config-end-point:6379"
    ],
    "scanInterval": 5000,
    "slaveSubscriptionConnectionPoolSize": 50,
    "slaveSubscriptionConnectionMinimumIdleSize": 1
  },
  "threads": 25,
  "nettyThreads": 50,
  "codec": {
    "class": "org.redisson.codec.SnappyCodec"
  },
  "referenceCodecProvider": {
    "class": "org.redisson.codec.DefaultReferenceCodecProvider"
  },
  "referenceEnabled": true,
  "transportMode": "NIO",
  "lockWatchdogTimeout": 30000,
  "keepPubSubOrder": true,
  "useLinuxNativeEpoll": false
}

{
  "clusterServersConfig": {
    "idleConnectionTimeout": 60000,
    "pingTimeout": 1000,
    "connectTimeout": 10000,
    "timeout": 5000,
    "retryAttempts": 3,
    "retryInterval": 1500,
    "reconnectionTimeout": 3000,
    "failedAttempts": 3,
    "subscriptionsPerConnection": 5,
    "clientName": "HighAvailCluster",
    "sslEnableEndpointIdentification": true,
    "sslProvider": "JDK",
    "pingConnectionInterval": 0,
    "keepAlive": false,
    "tcpNoDelay": false,
    "loadBalancer": {
      "class": "org.redisson.connection.balancer.RoundRobinLoadBalancer"
    },
    "slaveConnectionMinimumIdleSize": 50,
    "slaveConnectionPoolSize": 150,
    "masterConnectionMinimumIdleSize": 50,
    "masterConnectionPoolSize": 150,
    "readMode": "MASTER",
    "subscriptionMode": "SLAVE",
    "subscriptionConnectionMinimumIdleSize": 1,
    "subscriptionConnectionPoolSize": 50,
    "dnsMonitoringInterval": 5000,
    "nodeAddresses": [
      "redis://elastic-cache-config-end-point:6379"
    ],
    "scanInterval": 5000,
    "slaveSubscriptionConnectionPoolSize": 50,
    "slaveSubscriptionConnectionMinimumIdleSize": 1
  },
  "threads": 25,
  "nettyThreads": 50,
  "codec": {
    "class": "org.redisson.codec.SnappyCodec"
  },
  "referenceCodecProvider": {
    "class": "org.redisson.codec.DefaultReferenceCodecProvider"
  },
  "referenceEnabled": true,
  "transportMode": "NIO",
  "lockWatchdogTimeout": 30000,
  "keepPubSubOrder": true,
  "useLinuxNativeEpoll": false
}


We see a degraded performance on all our apis and the bottle-neck seems to be from redisson. We are using spring caching and noticed that all the keys with a particular cacheName are being stored in a single shard instead of being distributed. How do we solve for actually distributing this across different shards?
We are contemplating switching to redisson.pro if it's going to help. But does the configuration look good and will redisson.pro help with the issues?
Please find attached screenshots that is showing the bottle-neck
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1274
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am using redisson pro trial version(3.6.0) in cluster config with elasticache(redis=3.2.6), I see NPE in get and evict operations using spring cache framework. I don't see this issue with the community version(3.6.0) and same configuration
It basically just gives this error and hangs. I think the exception is being swallowed by DefaultPromise
WARN io.netty.util.concurrent.DefaultPromise - An exception was thrown by org.redisson.command.CommandAsyncService$9.operationComplete()
java.lang.NullPointerException: channel
	at io.netty.util.internal.ObjectUtil.checkNotNull(ObjectUtil.java:31)
	at io.netty.channel.DefaultChannelPromise.<init>(DefaultChannelPromise.java:53)
	at org.redisson.connection.t.b.send(ac:148)
	at org.redisson.command.CommandAsyncService$9.operationComplete(oj:389)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:163)
	at org.redisson.misc.RedissonPromise.addListener(RedissonPromise.java:123)
	at org.redisson.misc.RedissonPromise.addListener(RedissonPromise.java:41)
	at org.redisson.command.CommandAsyncService.async(oj:503)
	at org.redisson.command.CommandAsyncService.evalAsync(oj:599)
	at org.redisson.command.CommandAsyncService.evalWriteAsync(oj:307)
	at org.redisson.RedissonMapCache.getOperationAsync(wf:288)
	at org.redisson.RedissonMap.getAsync(ko:800)
	at org.redisson.RedissonMap.get(ko:409)
	at org.redisson.spring.cache.RedissonCache.get(RedissonCache.java:73)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:71)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:536)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedItem(CacheAspectSupport.java:502)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:388)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:326)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:61)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at com.safepage.user.data.impl.UserFeatureTypeMapDaoImpl$$EnhancerBySpringCGLIB$$8924d657.getUserFeatureTypeByUserId(<generated>)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1275
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have the following code:
RedissonClient redisson = Redisson.create();

RMap<Object, Object> mymap = redisson.getMap("mymap");
mymap.put("field1", "value1");
mymap.put("field1", "value2");

redisson.shutdown();

logger.info("Here but JVM still runs after this line");
And the output is:
2018-02-01 15:24:14 INFO  Version:41 - Redisson 3.6.0
2018-02-01 15:24:14 INFO  MasterPubSubConnectionPool:144 - 1 connections initialized for /127.0.0.1:6379
2018-02-01 15:24:14 INFO  MasterConnectionPool:144 - 10 connections initialized for /127.0.0.1:6379
2018-02-01 15:24:17 INFO  RedisTest:21 - Here but JVM still runs after this line

What is other than shutdown needed for graceful shutdown?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1276
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi I have read about the redissonspringlocalcache manager that it is keeping a local cache backed by redis. Please correct me if I am wrong. Please tell me how it works in distributed mode.
Eg. If we have 10 ec2 instances deployed connecting to same redis. Suppose there is a case which has been invalidated by one machine. How early can the other 9 machines would be knowing that their local cache is invalid and they need to call the redis to update it.
Do it use background polling to check if it is enabled.?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1277
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I want to use RedissonSpringLocalCachedCacheManager  for spring cache.But I can not find RedissonSpringLocalCachedCacheManager and LocalCachedCacheConfig in redisson 3.6.0 version. Is something wrong？
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1278
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1279
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1280
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Guys,
I'm facing na issue I'd like to share and get insights from you.
We run a sentinel cluster which is composed by (3 sentinels, 1 master and 2 slaves). The application can have dozens of instances and is connected to to this cluster via redisson 2.10.7 and redis 3.2.10
Eventually in an event of failover pub/sub messages seems to not be delivered to redisson clients (I say that because SentinelConnectionManager logs for failover are not present in system logs).
The only log after that is:
RedisConnection# [redisClient=[addr=redis://#:#], channel=[id: #x#, L:#/#:# ! R:/#:#]] is not active!

After that, redisson becomes irresponsive and seems to never recover and the only way to fix it is to restart the application node.
Redis cluster is confirmed to be working properly (as restart of application nodes alone fixes the issue)
According to redis client guideline pub/sub messages are not guaranteed to be delivery and should not replace the pooling mechanism to check the cluster status.  I need to dig a little bit into the redisson code but it seems to strongly rely on pub/sub only.
I'm trying to reproduce it locally and build a test case, but it is being tricky.
Have you ever experienced this problem before?
redisson config as follows:
sentinelServersConfig:
 idleConnectionTimeout: 10000
 pingTimeout: 1000
 connectTimeout: 5000
 timeout: 3000
 retryAttempts: 3
 retryInterval: 1500
 reconnectionTimeout: 3000
 failedAttempts: 3
 clientName: "shop"
 loadBalancer: !<org.redisson.connection.balancer.RoundRobinLoadBalancer> {}
 slaveConnectionMinimumIdleSize: 0
 slaveConnectionPoolSize: 0
 masterConnectionMinimumIdleSize: 16
 masterConnectionPoolSize: 256
 readMode: "MASTER"
 subscriptionMode: "MASTER"
 sentinelAddresses: ["redis://sentinel1.dev.foo.net:30050",
     "redis://sentinel2.foo.net:30050",
     "redis://sentinel3.foo.net:30050"]
 masterName: "sandbox"
codec: !<org.redisson.codec.FstCodec> {}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1281
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Add support of PING for pub/sub channels
redis/redis@70e3948
Discussion about this Redis feature: redis/redis#420
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1282
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We are using redisson 3.5.2 with spring cache.
When I put the debug on the method,
@Override public ValueWrapper get(Object key) { Object value = map.get(key); if (value == null) { addCacheMiss(); }else{ addCacheHit(); } return toValueWrapper(value); }
I get the following requests when using Monitor on the redis server.
1517915720.885427 [0 127.0.0.1:58162] "HLEN" "client_test"
1517915720.891805 [0 127.0.0.1:58163] "HLEN" "client_test"
1517915720.910285 [0 127.0.0.1:58164] "HLEN" "client_test"
1517915720.914924 [0 127.0.0.1:58165] "HLEN" "client_test"
1517915720.919594 [0 127.0.0.1:58167] "HLEN" "client_test"
1517915720.927470 [0 127.0.0.1:58166] "HLEN" "client_test"
1517915722.923863 [0 127.0.0.1:58179] "EVAL" "local value = redis.call('hget', KEYS[1], ARGV[2]); if value == false then return nil; end; local t, val = struct.unpack('dLc0', value); local expireDate = 92233720368547758; local expireDateScore = redis.call('zscore', KEYS[2], ARGV[2]); if expireDateScore ~= false then expireDate = tonumber(expireDateScore) end; if t ~= 0 then local expireIdle = redis.call('zscore', KEYS[3], ARGV[2]); if expireIdle ~= false then if tonumber(expireIdle) > tonumber(ARGV[1]) then local value = struct.pack('dLc0', t, string.len(val), val); redis.call('hset', KEYS[1], ARGV[2], value); redis.call('zadd', KEYS[3], t + tonumber(ARGV[1]), ARGV[2]); end; expireDate = math.min(expireDate, tonumber(expireIdle)) end; end; if expireDate <= tonumber(ARGV[1]) then return nil; end; local maxSize = tonumber(redis.call('hget', KEYS[5], 'max-size')); if maxSize ~= nil and maxSize ~= 0 then    redis.call('zadd', KEYS[4], tonumber(ARGV[1]), ARGV[2]); end; return val; " "5" "client_test" "redisson__timeout__set:{client_test}" "redisson__idle__set:{client_test}" "redisson__map_cache__last_access__set:{client_test}" "{client_test}:redisson_options" "1517915722922" ""ims_CLIENT_WITH_FR""
1517915722.924041 [0 lua] "hget" "client_test" ""ims_CLIENT_WITH_FR""
1517915722.924057 [0 lua] "zscore" "redisson__timeout__set:{client_test}" ""ims_CLIENT_WITH_FR""
1517915722.924074 [0 lua] "zscore" "redisson__idle__set:{client_test}" ""ims_CLIENT_WITH_FR""
1517915722.924090 [0 lua] "hset" "client_test" ""ims_CLIENT_WITH_FR"" "\x00\x00\x00\x00p\x99\x94AR\x01\x00\x00\x00\x00\x00\x00{"@Class":"com.db.qo.ClientQO","createdTime":["java.sql.Timestamp",1511531395000],"createdUserId":"amit","description":"Uber JLT","executorType":"IMS","id":4,"imsClientId":"client_with_fr","modifiedTime":["java.sql.Timestamp",1511531397000],"name":"Uber JLT","pollInterval":350,"productCode":"PS","productVersion":"V2"}"
1517915722.924167 [0 lua] "zadd" "redisson__idle__set:{client_test}" "1518002122922" ""ims_CLIENT_WITH_FR""
1517915722.924185 [0 lua] "hget" "{client_test}:redisson_options" "max-size"
I am unable to understand why the eval and hset command is sent from redisson when I am getting a key.
This is creating an issue for us to scale our services since these eval and hset calls will only go to master. Even if, we increase our redis slaves we wont be able to scale our reads since each read results into two writes to redis master.
Other issues are:
The eval command is taking a lock on redis master.
The hset command is setting the same response in redis master which is being replicated by all the redis slaves. This is resulting in wastage of redis server resources since they are wasting them to replicate the exact same data.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1283
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1284
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Set Up
Redisson version: 2.9.1
Redis Version: 2.8.17  Mode: Sentinel
Found this issue in our production, not sure if self-healing is supported by redisson during disaster like all redis servers are down, if it is supported, any specific version ?
Basic Configuration
       public RedissonClient redissonClient() { 
                Config config = new Config();
		config.setThreads(4);
		SentinelServersConfig sentinelServersConfig = config.useSentinelServers()
					.setMasterName(sentinelClusterName)
					.setTimeout(responseTimeout);
		for (String addr : sentinelAddresses) {
			sentinelServersConfig.addSentinelAddress(addr);			
		}
		return Redisson.create(config);
	   }

We initialize the subscriber once as following during server startup
protected void init() {
		RTopic<HeartbeatEvent> topic = redisson.getTopic("test_topic");
		topic.addListener(new MessageListener<HeartbeatEvent>() {
			@Override
			public void onMessage(String channel, HeartbeatEvent message) {
				String host = (String) ((Map) 
                                     SerializationUtils.deserialize(message.getExtraState()))
						.get(CommonConstants.IMAS_SERVER_INTERNAL_ADDRESS);
				if (host != null) {
					SipURI imasUri = createImasSipUri(host);
				}
			}
		});
	}

Steps to recreate:
Scenario A:

stop all redis-sentinel service
stop all redis-server service
wait for 2 min
start all redis-server service
start all redis-sentinel service

Scenario B:
(order is  2, 1, 3, 5, 4)
After this, the client is no longer listening to "test_topic"
Interesting Finding:

Redisson 2.2.27 is performing better than 2.9.1 in the sense of re-subscribe
Even all Client in 2.9.1 version, sharing the same config as above, some clients are able to re-subscribe

I went through the implementation of 2.9.1, found out that if following Scenario B, while doing MasterSlaveEntry. reattachPubSubListeners(), the unsubscribe and resubscribe process is trying in best-effort, which is prone to lose listener for a channel, leading clients unable to resubscribe. What is confusing is in Scenario A, some of the clients were able to reconnect somehow.
Is there any way for redisson to survive a redis disaster failure like this ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1285
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Cool! I have never used it! Finally my mass search and replace action has gone. Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1286
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
As I described in the title, I am trying to utilize Key Hash Tags to accumulate data on the same ClusterNode.
I am using a Multimap and noticed the Key for the Lists/Sets are wrapped in the Key Hash Tags and so they may be placed on another Node.
For example:
The MultiMap key is "{multi.map}.some.key".
An entry in it would be saved in the List/Set "{{multi.map}.some.key}:ADJ...".
So the Hash is not "multi.map" but rather "{multi.map".
For further information see the "Key Hash Tag" section on https://redis.io/topics/cluster-spec
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1287
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We have an RMI running on Redission 3.5.7.  Each RMI is fire-and-forget with no ack or completion time
This particular RMI is invoked about once every 2 minutes.  After about 3 days, the server side of the RMI simply stops processing.  The client is still producing messages.  Other Redis features such as client caches seem to still be working correctly on the same APP that is supposed to be processing the RMI calls.
1-2 minutes after the last processed RMI call on the server side, we get the warning below.  This is the only error or warning that we are getting.  The rest of the java application works fine.  Once the the java application is restarted, all the remote calls are processed as expected.
We are running Redis on AWS with Redis 3.2.4 in cluster mode.
WARN |redisson-netty-1-2|i.n.u.c.DefaultPromise|An exception was thrown by org.redisson.RedissonRemoteService$1$1.operationComplete()
java.lang.NullPointerException: null
at org.redisson.RedissonRemoteService$1$1.operationComplete(RedissonRemoteService.java:206)
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:500)
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:479)
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)
at org.redisson.misc.RedissonPromise.trySuccess(RedissonPromise.java:88)
at org.redisson.command.CommandAsyncService.handleReference(CommandAsyncService.java:849)
at org.redisson.command.CommandAsyncService.checkAttemptFuture(CommandAsyncService.java:836)
at org.redisson.command.CommandAsyncService.access$200(CommandAsyncService.java:82)
at org.redisson.command.CommandAsyncService$10.operationComplete(CommandAsyncService.java:629)
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:500)
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:479)
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)
at org.redisson.misc.RedissonPromise.trySuccess(RedissonPromise.java:88)
at org.redisson.client.handler.CommandDecoder.handleResult(CommandDecoder.java:320)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:259)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:101)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:367)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1342)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:934)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:134)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1288
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When I use Reentrant Lock in my application, this exception  ERR max number of clients reached occurs.
Redisson version is 2.10.7, and redis version is 3.2
Here is my usage: I create a singleton RedissonLock to manage the lock and unlock operations.
public class RedissonLock {
    private RedissonClient redisson;
    private RedissonLock() {
        Config config = new Config();
        config.useMasterSlaveServers()
                .setMasterAddress(MASTER_ADDRESS)
                .addSlaveAddress(SLAVE_ADDRESS)
                .setPassword(PASSWORD);
        redisson = Redisson.create(config);
    }

    public static RedissonLock getInstance() {
        return SingletonHolder.INSTANCE;
    }

    private static class SingletonHolder {
        private static final RedissonLock INSTANCE = new RedissonLock();
    }

    public RLock getLock(String key) {
        return redisson.getLock(key);
    }

    public RLock getLock(Long id) {
        return getLock(id.toString());
    }

    public Boolean tryLock(RLock lock) {
        Boolean ret = false;
        try {
            ret = lock.tryLock(WAIT_TIME, LEASE_TIME, TimeUnit.SECONDS);
        } catch (InterruptedException e) {
            log.error(e);
        }
        return ret;
    }

    public void lock(RLock rLock) {
        rLock.lock(LEASE_TIME, TimeUnit.SECONDS);
    }

    public void unlock(RLock lock) {
        lock.unlock();
    }

    public void close() {
        redisson.shutdown();
    }

}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1289
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We have a spring application running in 3 different servers/jvms. Those services receives an event notification with an eventID.
In order to avoid event processing duplication we are trying to use redis lock, to process only one event each time. We have multiple requests with same eventID coming from other services, so this is a very common scenario.
The lock is centralized in one Spring Bean
public class RedisDistributedLock implements DistributedLock {

	private static final String PREFIX = "bucketName:";
	private static final int TIMEOUT = 1;

	@Autowired
	private RedissonClient redissonClient;

	public boolean lock(String action, String lockKey) {
		try {
			return redissonClient.getLock( PREFIX + action + ":" + lockKey ).tryLock( 0, TIMEOUT, TimeUnit.MINUTES );
		} catch (InterruptedException e) {
			log.error( "Failed to lock " + lockKey + " for action " + action, e );
			return false;
		}
	}

	public void unlock(String action, String lockKey) {
		redissonClient.getLock( PREFIX + action + ":" + lockKey ).unlock();
	}

}

Each time an event comes we first verify if we can lock
if (redisDistributedLock.lock(action,eventId))
      eventProcessor.process("eventId")
else
      log.info("cant use, someone else is already processing this event")


Our redissonClient is injected by spring

       @Bean
 	public RedissonClient buildRedissonClient(@Value("${redis.url}") String url) {
		final Config config = new Config();
		config.useMasterSlaveServers().setMasterAddress( url );
		//config.useSingleServer().setAddress( "redis://master:6666" );
		return Redisson.create( config );
	}


We also the singleServer approach (commented above). But in both scenarios events are processed twice, eventually.
We don´t understand what its wrong. Can someone give us a clue?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1290
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
clear() method is implemented properly on RedissonMap; but it is not overridden on RedissonLocalCachedMap. RedissonLocalCachedMap should override the parent implementation by clearing the local cache, clearing the Redis map, and broadcasting a LocalCachedMapClear event on the invalidationTopic.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1291
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Problem:
We are evaluating Redisson as a distributed task queue manager and as a result the expected behaviour for failure scenario is:
-- If a worker starts working on a task and if worker goes down before completing the task then task should be resumed on another worker.
As per our observation this doesn't happen.
For SIGINT and SIGQUIT signal - Most of the times it finished the running tasks. (We found couple of instances where it didn't happen)
For SIGKILL (when worker is killed using kill -9), executing tasks are lost.
Can you please help us understanding that is the above mentioned 'expected behaviour' correct? Does redisson provide this guarantee? If yes are we missing some configuration? If no, please indicate what is the best practice for using Redisson in this case?
Environment & Setup details:
Mac OS X 10.10.5
Java version: 1.8.0_141
Redis Version : 2.8.24
Redisson Version : 3.6.0
Redis used in Single Server mode
We have two Redisson Nodes running with the config:

Here is the code of the the Task :
`
import org.redisson.api.RedissonClient;
import org.redisson.api.annotation.RInject;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import java.util.concurrent.Callable;
public class SleepTask implements Callable {
@RInject
private RedissonClient redissonClient;

private long sleepDurationInMillis;
public final static Logger logger = LoggerFactory.getLogger(SleepTask.class);

int threadNo;

public SleepTask() {
}

public SleepTask(long sleepDurationInMillis, int threadNo) {
    this.sleepDurationInMillis = sleepDurationInMillis;
    this.threadNo = threadNo;
}


@Override
public String call() throws Exception {
    try {
        logger.info("Executing  the task for sleep duration of: "+threadNo+" " +sleepDurationInMillis);
        Thread.sleep(sleepDurationInMillis);
        logger.info("Done executing  the task for sleep duration of: "+threadNo+" " +sleepDurationInMillis);
    }
    catch(InterruptedException e) {
        logger.error(e.getMessage());
        e.printStackTrace();
        return  "FAILURE:"+sleepDurationInMillis;
    }
    return "SUCCESS:"+sleepDurationInMillis;
}

}
`
Here is the main code which is invoking it:
`public static void main(String [] args) throws IOException, ExecutionException, InterruptedException {
App app = new App();
Config config = Config.fromJSON(app.getConfigFile());
    RedissonClient client = Redisson.create(config);
    RExecutorService executorService = client.getExecutorService("myExecutor1");

    BufferedReader br= new BufferedReader(new InputStreamReader(System.in));
    String input;
    int i=1;
    logger.info("App has moved out of connection phase and active workers are: "+ executorService.countActiveWorkers());
    while((input = br.readLine()) != null) {
        long sleepDuration = Long.parseLong(input);
        logger.info("Adding the task for sleep duration of: "+" " +sleepDuration);
        Future<String> result = executorService.submitAsync(new SleepTask(sleepDuration,i++));
        try {
            logger.info("Added the task for sleep duration of - with result: "+" " +sleepDuration+" ");
        } catch (Exception e) {
            logger.error(e.getMessage());
            e.printStackTrace();
        }
        //executorService.submit(new Producer(sleepDuration,i++));
    }
    //result.get(35000, TimeUnit.MILLISECONDS)
}`

Commands with which I start two Redisson Nodes are:
java -jar ~/Downloads/redisson-all-3.6.0.jar /Users/xyz/POCs/src/main/resources/redisson_config.json
Please let me know if any more details are needed.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1292
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
reference from the issue #1175 after it is closed.
I change the test case in RedissonRedLockTest.testLockSuccess() like this:
        RedisProcess redis1 = redisTestMultilockInstance();
        RedisProcess redis2 = redisTestMultilockInstance();

        RedissonClient client1 = createClient(redis1.getRedisServerAddressAndPort());
        RedissonClient client2 = createClient(redis2.getRedisServerAddressAndPort());

        RLock lock1 = client1.getLock("lock1");
        RLock lock2 = client1.getLock("lock2");
        RLock lock3 = client2.getLock("lock3");
        
        Thread t1 = new Thread() {
            public void run() {
                lock2.lock();
            };
        };
        t1.start();
        t1.join();
        
        RedissonMultiLock lock = new RedissonRedLock(lock1, lock2, lock3);

        try {
            assertThat(lock.tryLock(500, 5000, TimeUnit.MILLISECONDS)).isTrue();
            Thread.sleep(3000);
        } catch (InterruptedException e) {
        }
        lock.unlock();

        client1.shutdown();
        client2.shutdown();
        
        assertThat(redis1.stop()).isEqualTo(0);
        assertThat(redis2.stop()).isEqualTo(0);

The test case above will fail in case of that lock1/lock2 is locked first in thread t1. However, it will pass in case of lock3 is locked first in thread t1.
The expected behavior is as follows:

No matter which lock is locked first in thread t1, the Red Lock will always can be locked or cannot.
In this case, the Red Lock should always be locked for most of the lock is available.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1293
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I opened a ticket on the jackson databind project but I think this issue could use some visibility here.
FasterXML/jackson-databind#1932
The code below can replicate the exception I am seeing. I ran into this when calling operations on  a RScoredSortedSet, but the code below is stripped to just the Codec.
import java.util.EnumMap;

import org.redisson.codec.JsonJacksonCodec;

import io.netty.buffer.Unpooled;

public class JacksonIssueTest {

    public static class EventTest {

        private EnumMap<EnumMapTestEnum, String> enumMapTest;

        public EventTest() {
        }

        public EventTest(EnumMap<EnumMapTestEnum, String> enumMapTest) {
            this.enumMapTest = enumMapTest;
        }

        public EnumMap<EnumMapTestEnum, String> getEnumMapTest() {
            return enumMapTest;
        }

        public void setEnumMapTest(EnumMap<EnumMapTestEnum, String> enumMapTest) {
            this.enumMapTest = enumMapTest;
        }
    }

    public enum EnumMapTestEnum {
        A, B, C;
    }

    public static void main(String args[]) throws Exception {

        EnumMap<EnumMapTestEnum, String> enumMap = new EnumMap(EnumMapTestEnum.class);
        enumMap.put(EnumMapTestEnum.A, "Test");
        EventTest eventTest = new EventTest(enumMap);

        byte[] bytes = JsonJacksonCodec.INSTANCE.getValueEncoder().encode(eventTest);
        JsonJacksonCodec.INSTANCE.getValueDecoder().decode(Unpooled.wrappedBuffer(bytes), null);
    }
}
Exception in thread "main" com.fasterxml.jackson.databind.JsonMappingException: Can not deserialize instance of java.util.EnumMap out of FIELD_NAME token
 at [Source: io.netty.buffer.ByteBufInputStream@229c6181; line: 1, column: 135] (through reference chain: JacksonIssueTest$EventTest["enumMapTest"])
	at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:270)
	at com.fasterxml.jackson.databind.DeserializationContext.reportMappingException(DeserializationContext.java:1247)
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1122)
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1075)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer._deserializeFromEmpty(StdDeserializer.java:892)
	at com.fasterxml.jackson.databind.deser.std.EnumMapDeserializer.deserialize(EnumMapDeserializer.java:130)
	at com.fasterxml.jackson.databind.deser.std.EnumMapDeserializer.deserialize(EnumMapDeserializer.java:17)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedForId(AsPropertyTypeDeserializer.java:129)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:97)
	at com.fasterxml.jackson.databind.deser.std.EnumMapDeserializer.deserializeWithType(EnumMapDeserializer.java:182)
	at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:502)
	at com.fasterxml.jackson.databind.deser.impl.FieldProperty.deserializeAndSet(FieldProperty.java:111)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:276)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:178)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:150)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedForId(AsPropertyTypeDeserializer.java:129)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:97)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromAny(AsPropertyTypeDeserializer.java:182)
	at com.fasterxml.jackson.databind.deser.std.UntypedObjectDeserializer$Vanilla.deserializeWithType(UntypedObjectDeserializer.java:553)
	at com.fasterxml.jackson.databind.deser.impl.TypeWrappedDeserializer.deserialize(TypeWrappedDeserializer.java:63)
	at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3814)
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2924)
	at org.redisson.codec.JsonJacksonCodec$2.decode(JsonJacksonCodec.java:81)
	at JacksonIssueTest.main(JacksonIssueTest.java:40)

I believe this is a bug but I apologize if I am misusing the library.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1294
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1295
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[redisson-netty-4-26] WARN io.netty.channel.DefaultChannelPipeline - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
io.netty.handler.codec.DecoderException: CommandDecoder.decode() must consume the inbound data or change its state if it did not decode anything.
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:380)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1412)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:943)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:141)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:886)
[ajp-nio-8009-exec-10] ERROR com.personalcapital.server.change.aspect.ServerChangeAspect - getServerChangesAdvice failed due to: Unexpected exception while processing command for user :0d2ec4e0b72941c68ee665d93536712f, fromServerChangeId :72, toServerChangeId :76 failed due to:
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Unknown Source)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1296
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have got CertificateException when Redisson try to connect.
Caused by: java.security.cert.CertificateException: No subject alternative names matching IP address 12.34.567.89 found
at sun.security.util.HostnameChecker.matchIP(HostnameChecker.java:167)
at sun.security.util.HostnameChecker.match(HostnameChecker.java:93)
at sun.security.ssl.X509TrustManagerImpl.checkIdentity(X509TrustManagerImpl.java:455)
at sun.security.ssl.X509TrustManagerImpl.checkIdentity(X509TrustManagerImpl.java:436)
at sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:252)
at sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:136)
at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1501)
... 28 more
When i disabled the setSslEnableEndpointIdentification the connection was successfully established.
The scenario is when I'm using useClusterServers config
the Redisson client sends cluster nodes command to Azure Redis,
the server responses with a list of IP and port of cluster nodes, then Redisson client try to connect to newly discovered masters, but now the target is IP and Azure doesn't sign the certificate.
Important note:
all the discovered IPs are the same IP resolved by endpoint URL (which provided by Azure).
I saw that other redis clients separate the endpointIdentification for the base connection and cluster node connection.
If we are able to do node cluster endpointIdentification with the base connection verification it will solve the issue.
Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1297
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
It clears all local cache across all RLocalCachedMap instances.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1298
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Any reason RBatch does have a getSortedSet() method?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1299
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
After the fix of #1280 which improved greatly the resilience of Sentinel setup, it would be great to have dnsMonitoring  feature as well because in failover scenarios of sentinels instances, the box can get a different IP and the current implementation caches the dns resolution forever.  It means it never reconnects to new sentinels in the cluster.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1300
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1301
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am trying to create a singleton bean of RScheduledExecutorService in Spring 4. I have not yet autowired this bean anywhere. I am always ending up with error. I am working with Redisson 2.11.
Unable to find any kind of solution or any instances of problem with anyone else here. Is this a bug ?
Since it is a JsonMappingException I also tried using different codes but nothing helped.
SEVERE: StandardWrapper.Throwable java.lang.IllegalArgumentException: com.fasterxml.jackson.databind.JsonMappingException: (was java.lang.NullPointerException) (through reference chain: org.springframework.scheduling.concurrent.ReschedulingRunnable["cancelled"]) at org.redisson.RedissonExecutorService.encode(RedissonExecutorService.java:317) at org.redisson.RedissonExecutorService.scheduleAsync(RedissonExecutorService.java:741) at org.redisson.RedissonExecutorService.schedule(RedissonExecutorService.java:700) at org.redisson.RedissonExecutorService.schedule(RedissonExecutorService.java:92) at org.springframework.scheduling.concurrent.ReschedulingRunnable.schedule(ReschedulingRunnable.java:73) at org.springframework.scheduling.concurrent.ConcurrentTaskScheduler.schedule(ConcurrentTaskScheduler.java:170) at org.springframework.scheduling.config.ScheduledTaskRegistrar.scheduleTasks(ScheduledTaskRegistrar.java:306) at org.springframework.scheduling.config.ScheduledTaskRegistrar.afterPropertiesSet(ScheduledTaskRegistrar.java:284) at org.springframework.scheduling.annotation.ScheduledAnnotationBeanPostProcessor.finishRegistration(ScheduledAnnotationBeanPostProcessor.java:208) at org.springframework.scheduling.annotation.ScheduledAnnotationBeanPostProcessor.onApplicationEvent(ScheduledAnnotationBeanPostProcessor.java:162) at org.springframework.scheduling.annotation.ScheduledAnnotationBeanPostProcessor.onApplicationEvent(ScheduledAnnotationBeanPostProcessor.java:85) at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:151) at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:128) at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:331) at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:773) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:483) at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:664) at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:536) at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:490) at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:136) at javax.servlet.GenericServlet.init(GenericServlet.java:158)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1302
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We are trying to use updateMode=AFTER_REQUEST to make sure all the session data will be saved into Redis server. After reviewing the source code, looks it may cause performance issues since we keep a lot of data in the session, and store function will be called on every request no matter there is session changes or not.


Currently when updateMode=AFTER_REQUEST is on, session data will be saved twice in the Redis server if session.setAttribute(..) is called. First time is triggered by setAttribute() method, second time is triggered by AFTER_REQUEST. Can the first insert/update can be removed when AFTER_REQUEST is set?


Is it possible put save session data to Redis after tomcat request code to a separate thread?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1303
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1304
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I found that in master-slave mode, the redis connections on slave servers may not get closed properly.
Caused by: org.redisson.client.RedisException: ERR max number of clients reached
After reading the source code, I found that the reason is that RedisClient does not override hashcode and equals.
Consider the following situation：

One hostname slave-hostname maps to two ip-addresses: ip1, ip2
Firstly, slave-hostname  maps to ip1, client2Entry will cache new RedisClient and ClientConnectionsEntry instances: RedisClient-ip1 and ClientConnectionsEntry-ip1

public RFuture<Void> add(final ClientConnectionsEntry entry) {
        RPromise<Void> result = new RedissonPromise<Void>();
        
        CountableListener<Void> listener = new CountableListener<Void>(result, null) {
            public void operationComplete(io.netty.util.concurrent.Future<Object> future) throws Exception {
                super.operationComplete(future);
                if (this.result.isSuccess()) {
                    client2Entry.put(entry.getClient(), entry);
                }
            };
        };

        RFuture<Void> slaveFuture = slaveConnectionPool.add(entry);
        listener.incCounter();
        slaveFuture.addListener(listener);
        
        RFuture<Void> pubSubFuture = pubSubConnectionPool.add(entry);
        listener.incCounter();
        pubSubFuture.addListener(listener);
        return result;
    }


DNS  changes from ip1 to ip2, all the connections of ClientConnectionsEntry-ip1 were closed properly.
DNS  changes from ip2 to ip1, client2Entry will cache another RedisClient and ClientConnectionsEntry instances: RedisClient-ip1-1 and ClientConnectionsEntry-ip1-1. RedisClient-ip1-1 was different from RedisClient-ip1 as they were not the same instance.
DNS  changes from ip1 to ip2 again,
All the connections of ClientConnectionsEntry-ip1-1 should get closed properly.  When san client2Entry values, it is possible to find ClientConnectionsEntry-ip1 or ClientConnectionsEntry-ip1-1

    protected ClientConnectionsEntry getEntry(InetSocketAddress address) {
        for (ClientConnectionsEntry entry : client2Entry.values()) {
            InetSocketAddress addr = entry.getClient().getAddr();
            if (addr.getAddress().equals(address.getAddress()) && addr.getPort() == address.getPort()) {
                return entry;
            }
        }
        return null;
    }

The connections of ClientConnectionsEntry-ip1-1 may not get closed properly.

Our master-slave model

one master server
two slave servers, with one slave hostname, DNS changes every twenty seconds.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1305
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Problem
If I initialize a bloom filter like this
RBloomFilter<String> filter = redissonClient.getBloomFilter("test");
filter.tryInit(10000, 0.01);
filter.expire(1l, TimeUnit.MINUTES);

The String test is the only thing that gets deleted from Redis after expiration time. The config hash {test}:config remains even after expiration.
Env details
Mac OS X 10.13.2
Java version: 1.8.0_151
Redis server v=4.0.7
Redisson Version : 3.6.0
Redis used in Single Server mode
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1306
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1307
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I transfer redis cluster server from local host to virtual host recently, then some interesting things happened.
The cluster worked fine itself, but as soon as I used redisson as client, it went wrong.
They can registry by using remote address.However,they cant recognize each other with remote external address, but with local internal address. I dont know how to deal with it, can anyone help me, thanks a lot.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1308
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1309
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
This is very likely a bug.
in https://github.com/redisson/redisson/blob/master/redisson/src/main/java/org/redisson/client/RedisPubSubConnection.java#L118
Set up:
Redis: Sentinel Mode
Redisson: version 2.9.1   read from slave
Steps to Recreate:

shut down all redis-sentinels
shut down all redis-servers
wait for some time (redisson client initiates enough "GET" command, and connection_pool reset cause maximum failed attempts reached)
restart all redis-server
restart all redis-sentinel

in step3: slaveDown happens when maximum attempts reached, but it was unable to send "Unsubscribe"
but in https://github.com/redisson/redisson/blob/master/redisson/src/main/java/org/redisson/client/RedisPubSubConnection.java#L118, when "UNSUBSCRIBE" failure happens, it removes the channel and remove all the listeners.
my thoughts is when "UNSUBSCRIBE" failure, we should readd the channel, and not executing onMessage()
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1310
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Today I had a lot of work to bind embedded Redisson Node with Spring Boot. Here are the final thoughts and conclusions. In short I believe creating own codec in TasksRunnerService using TasksRunnerService class loader is a bug. Please review the article for more details.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1311
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi!
I'm using Redisson 3.6.0 with redisson-tomcat 3.5.6 with:

Elasticache Redis Cluster
Spring App deployed on two instances EC2 Tomcat (instance 1 and instance 2)
Load Balance with non-sticky session

My session timeout is configured to 30min.
The steps to reproduce the issue:
a. User logged in on instance 1 (a new session is created with timeout of 30 min);
b. After 15 min, an ajax request was made by the application which was managed by 'instance 2' refreshing the session to more 30min;
c. After more 20min the user reload the page, and the load  balance send some requests to 'instance1' and to 'instance 2', but the instance 1 has been idle  for 35minutes and because of that, delete the session that was renewed 20 min ago!
This issue is only reproducible using at least two instances behind a load balance with non-sticky session because the action to delete the session ignores if the session was renewed by other instances.
Is there anything I can do to prevent this behavior?
I think this is related with #972
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1312
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Sorry to open so many issues for the same problem, feel free to close it if you think this is not appropriate.
#1284
#1309
We are trying to have the best availability of our service when redis servers in Sentinel mode run into disaster situations (like all redis-server, redis-sentinel are down)
Currently, what we are trying is when Redisson client last received ping is too old, it will try to re-subscribe to the same channel. However, this introduced new problems, when the QPS is high, we added multiple listeners for the same client to the same channel, which is not optimal.
In following two places, there is no duplicate check (if the listener already in the PubsubConnection, don't add the listener)
https://github.com/redisson/redisson/blob/master/redisson/src/main/java/org/redisson/connection/PubSubConnectionEntry.java#L91
https://github.com/redisson/redisson/blob/master/redisson/src/main/java/org/redisson/client/RedisPubSubConnection.java#L61
Is it possible to add a duplicate check that only when the listener is not there, we add the listener to the connection ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1313
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello,
I try to upgrade redisson from 3.5.7 to 3.6.1 but I get this exception :
java.lang.AbstractMethodError: org.redisson.spring.session.RedissonSessionRepository.getSession(Ljava/lang/String;)Lorg/springframework/session/Session;
	at org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper.getSession(SessionRepositoryFilter.java:327)
	at org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper.getSession(SessionRepositoryFilter.java:344)
	at org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper.getSession(SessionRepositoryFilter.java:217)
	at javax.servlet.http.HttpServletRequestWrapper.getSession(HttpServletRequestWrapper.java:270)
	at org.springframework.security.web.context.HttpSessionSecurityContextRepository.loadContext(HttpSessionSecurityContextRepository.java:110)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:100)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)
	at org.springframework.security.web.access.channel.ChannelProcessingFilter.doFilter(ChannelProcessingFilter.java:157)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegatatingFilterProxy.java:347)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263)
	at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)
	at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)
	at org.springframework.session.web.http.SessionRepositoryFilter.doFilterInternal(SessionRepositoryFilter.java:167)
	at org.springframework.session.web.http.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:80)
	at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)
	at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)
	at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)
	at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)
	at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)
	at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84)
	at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62)
	at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:64)
	at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36)
	at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:131)
	at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handlt(ServletAuthenticationCallHandler.java:57)
	at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43)
	at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46)
	at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64)
	at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60)
	at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77)
	at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43)
	at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43)
	at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43)
	at io.undertow.servlet.handlers.SessionRestoringHandler.handleRequest(SessionRestoringHandler.java:119)
	at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292)
	at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81)
	at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138)
	at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135)
	at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48)
	at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43)
	at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272)
	at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81)
	at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104)
	at io.undertow.server.Connectors.executeRoor(Connectors.java:332)
	at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

I'm using theses dependencies :
compile group: 'org.springframework.boot', name: 'spring-boot-starter-data-redis', version: '1.5.9.RELEASE'
compile group: 'org.springframework.session', name: 'spring-session', version: '1.3.2.RELEASE'
compile group: 'org.redisson', name: 'redisson', version: '3.6.1'
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1314
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Using Jackson 2.9.2 and 2.9.4 (tried both), trying to upgrade from Redisson 3.3.2 to 3.6.1 I get this:
Caused by: java.lang.IllegalStateException: Failed copy(): org.msgpack.jackson.dataformat.MessagePackFactory (version: 2.9.2) does not override copy(); it has to
        at com.fasterxml.jackson.core.JsonFactory._checkInvalidCopy(JsonFactory.java:333)
        at com.fasterxml.jackson.core.JsonFactory.copy(JsonFactory.java:320)
        at com.fasterxml.jackson.databind.ObjectMapper.<init>(ObjectMapper.java:499)
        at com.fasterxml.jackson.databind.ObjectMapper.copy(ObjectMapper.java:617)
        at org.redisson.codec.JsonJacksonCodec.<init>(JsonJacksonCodec.java:107)

Redisson 3.5.7 does not have this issue.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1315
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We're having trouble spinning up redisson (3.6.1) when the minimum number of connections is high.
Steps to reproduce:

Run a local redis server. We used the official docker image:

docker container run -d --name redis -p 6379:6379 redis

Try to create a redisson client with a high number of idle connections, short retry interval and some client name:

public static void main(String[] args) {
    Config config = new Config();
    config.useSingleServer()
            .setAddress("redis://127.0.0.1:6379")
            .setClientName("client")
            .setConnectionMinimumIdleSize(1000)
            .setConnectionPoolSize(2000)
            .setRetryInterval(100);
    RedissonClient client = Redisson.create(config);
    System.out.println("Done!");
}

More often than not, we're getting the following exception after a few seconds, with a varying number if successful connections:
Exception in thread "main" org.redisson.client.RedisConnectionException: Unable to init enough connections amount! Only 440 from 1000 were initialized. Redis server: /127.0.0.1:6379
	at org.redisson.connection.pool.ConnectionPool$2$1.operationComplete(ConnectionPool.java:138)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:512)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:486)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:425)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:108)
	at org.redisson.connection.pool.ConnectionPool.promiseFailure(ConnectionPool.java:307)
	at org.redisson.connection.pool.ConnectionPool.access$400(ConnectionPool.java:54)
	at org.redisson.connection.pool.ConnectionPool$4.operationComplete(ConnectionPool.java:277)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:512)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:505)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:484)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:425)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:108)
	at org.redisson.client.RedisClient$2$1$1$1.run(RedisClient.java:215)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:886)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.redisson.client.RedisTimeoutException: Command execution timeout for /127.0.0.1:6379
	at org.redisson.client.RedisConnection$2.run(RedisConnection.java:212)
	at io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38)
	at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:125)
	... 6 more
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1316
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@Bean
public CacheManager cacheManager(RedissonClient redissonClient) throws IOException {
    Map<String, CacheConfig> config = new HashMap<String, CacheConfig>();
    config.put(CacheNames.XinLianService_getAllAgentData, new CacheConfig(60 * 1000, 60 * 1000));
    config.put(CacheNames.XinlianRoleService_getById, new CacheConfig(2 * 60 * 1000, 60 * 1000));
    return new RedissonSpringCacheManager(redissonClient, config);
}

I hava set the ttl and idleTime for cache, the cache can be remove when the app is running, however when I restart app the EvictionScheduler may not work for cache, the cache can not be clear when ttl approach. Does it problem have any solution?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1317
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello, I'm re-opening the issue #1272 for me it's not fixed in 3.6.1, I get lot of errors long time after a fail-over.

My setup :

Spring boot 1.5.9 with Spring session 2.0.1 and redisson 3.6.1 like in this sample repo : https://github.com/DevWantJustHaveFun/spring-boot-session-redisson

The logs :
[2018-02-27 08:06:19,646] [WARN] [i.n.u.i.l.Slf4JLogger] [Null|127.0.0.1|Null|Null] - An exception was thrown by org.redisson.command.CommandAsyncService$15.operationComplete()
java.lang.NullPointerException: null
[2018-02-27 08:06:19,832] [WARN] [i.n.u.i.l.Slf4JLogger] [Null|127.0.0.1|Null|Null] - An exception was thrown by org.redisson.command.CommandAsyncService$15.operationComplete()
java.lang.NullPointerException: null
[2018-02-27 08:06:19,834] [WARN] [i.n.u.i.l.Slf4JLogger] [Null|127.0.0.1|Null|Null] - An exception was thrown by org.redisson.command.CommandAsyncService$15.operationComplete()
java.lang.NullPointerException: null
[2018-02-27 08:06:20,031] [WARN] [i.n.u.i.l.Slf4JLogger] [Null|127.0.0.1|Null|Null] - An exception was thrown by org.redisson.command.CommandAsyncService$15.operationComplete()
java.lang.NullPointerException: null
[2018-02-27 08:06:20,035] [WARN] [i.n.u.i.l.Slf4JLogger] [Null|127.0.0.1|Null|Null] - An exception was thrown by org.redisson.command.CommandAsyncService$15.operationComplete()
java.lang.NullPointerException: null
[2018-02-27 08:06:20,133] [WARN] [i.n.u.i.l.Slf4JLogger] [Null|127.0.0.1|Null|Null] - An exception was thrown by org.redisson.command.CommandAsyncService$15.operationComplete()
java.lang.NullPointerException: null
[2018-02-27 08:06:20,232] [WARN] [i.n.u.i.l.Slf4JLogger] [Null|127.0.0.1|Null|Null] - An exception was thrown by org.redisson.command.CommandAsyncService$15.operationComplete()
java.lang.NullPointerException: null
[2018-02-27 08:06:20,308] [WARN] [o.r.c.SentinelConnectionManager] [Null|127.0.0.1|Null|Null] - Skipped slave up 57.190.12.71:6399 for master redis://?:0 differs from current redis://57.190.12.72:6399

[2018-02-27 08:06:14,360] [ERROR] [i.u.s.a.LoggingExceptionHandler] [651d4b3e-6b90-4ab5-909e-46120aa1bcf8|10.4.0.2|Null|UAE10] - UT005023: Exception handling request to /connect
java.lang.IllegalArgumentException: session cannot be null
        at org.springframework.session.web.http.HttpSessionAdapter.<init>(HttpSessionAdapter.java:51)
        at org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper$HttpSessionWrapper.<init>(SessionRepositoryFilter.java:372)
        at org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper.getSession(SessionRepositoryFilter.java:308)
        at org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper.getSession(SessionRepositoryFilter.java:196)
        at javax.servlet.http.HttpServletRequestWrapper.getSession(HttpServletRequestWrapper.java:270)
        at org.springframework.security.web.context.HttpSessionSecurityContextRepository.loadContext(HttpSessionSecurityContextRepository.java:110)
        at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:100)
        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)
        at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)
        at org.springframework.security.web.access.channel.ChannelProcessingFilter.doFilter(ChannelProcessingFilter.java:157)
        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)
        at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214)
        at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177)
        at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347)
        at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263)
        at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)
        at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)
        at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
        at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)
        at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)
        at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
        at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)
        at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)
        at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
        at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)
        at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)
        at org.springframework.session.web.http.SessionRepositoryFilter.doFilterInternal(SessionRepositoryFilter.java:146)
        at org.springframework.session.web.http.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:81)
        at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)
        at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)
        at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
        at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)
        at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)
        at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
        at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)
        at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)
        at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84)
        at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62)
        at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:64)
        at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36)
        at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:131)
        at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57)
        at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43)
        at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46)
        at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64)
        at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60)
        at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77)
        at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43)
        at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43)
        at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43)
        at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292)
        at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81)
at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138)
        at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135)
        at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48)
        at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43)
        at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272)
        at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81)
        at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104)
        at io.undertow.server.Connectors.executeRootHandler(Connectors.java:332)
        at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:748)```
  

[2018-02-27 08:06:57,834] [ERROR] [i.u.s.a.LoggingExceptionHandler] [24b62c4f-f833-4463-bdab-ada972beeb49|10.4.0.2|Null|UAE9] - UT005023: Exception handling request to /connect/login
org.redisson.client.RedisTimeoutException: Unable to send command: (HGETALL) with params: [redisson_spring_session:cb50538c-5244-4cb2-953d-77b733fe5814] after 3 retry attempts
        at org.redisson.command.CommandAsyncService$8.run(CommandAsyncService.java:562)
        at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:663)
        at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:738)
        at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:466)
        at java.lang.Thread.run(Thread.java:748)

[2018-02-27 08:07:02,365] [ERROR] [o.r.c.SentinelConnectionManager$8] [Null|127.0.0.1|Null|Null] - Can't add slave: redis://57.190.12.71:6399
org.redisson.client.RedisConnectionException: Unable to init enough connections amount! Only 31 from 32 were initialized. Redis server: /57.190.12.71:6399
        at org.redisson.connection.pool.ConnectionPool$2$1.operationComplete(ConnectionPool.java:138)
        at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:512)
        at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:486)
        at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:425)
        at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
        at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:108)
        at org.redisson.connection.pool.ConnectionPool.promiseFailure(ConnectionPool.java:307)
        at org.redisson.connection.pool.ConnectionPool.access$400(ConnectionPool.java:54)
        at org.redisson.connection.pool.ConnectionPool$4.operationComplete(ConnectionPool.java:277)
        at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:512)
        at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:505)
        at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:484)
        at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:425)
        at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
        at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:108)
        at org.redisson.client.RedisClient$2$1$2.run(RedisClient.java:225)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
        at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:886)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
Caused by: io.netty.channel.ConnectTimeoutException: connection timed out: /57.190.12.71:6399
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:267)
        at io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38)
        at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:125)
        ... 6 common frames omitted
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1318
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
018-02-28 19:56:31,534:io.netty.util.ResourceLeakDetector.reportTracedLeak(ResourceLeakDetector.java:311).LEAK: ByteBuf.release() was not called before it's garbage-collected. See http://netty.io/wiki/reference-counted-objects.html for more information.
Recent access records: .
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1319
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
This issue is to implement RBloomFilter with the RBatch batch commands. I do not see a getBloomFilter() option with the batch commands, it would be incredibly helpful to have.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1320
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RedissonSessionManager uses "redisson_tomcat_session:"  as key prefix, so if multiple tomcat instances are using same "redis" server for storing session data. So need a mechanism to configure default key prefix.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1321
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi! Thank you for your contribution. Could you change keySpace to keyPrefix?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1322
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
While reading the Redisson tutorial and examples, I am under the impression that I need to always call redisson.getMap() in order to get the latest data from the cache . Right ?
I have a storm bolt which calls getmap(key) for millions of incoming records
Looks like millions of instances of RedisonMap being created , leading to pressure on GC
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1323
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1324
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
After upgrading from 3.5.7 to 3.6.1 I can see a lot of warnings every 3 seconds:
2018-03-05 13:12:44.197  WARN 5 --- [isson-netty-1-2] o.r.c.SentinelConnectionManager          : Skipped slave up 10.2.42.12:6379 for master redis://?:0 differs from current redis://10.2.96.31:6379
I use SentinelServersConfig.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1325
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks a lot!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1326
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I'm using RLock and seeing memory leak via org.redisson.client.handler.CommandPubSubDecoder

Retained objects delta between heap dumps taken apart

Around 10MB leak per day
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1327
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We configured a Redisson cached based on Jcr-107. Most operations are working fine but the getAndRemove implementation is throwing a null pointer exception. When removing the key with cache.remove("key"); instead, it works fine. We could do it in two operations but it will lose the free Atomicity.
Unfortunately, I'm not fluent in the LUA scripting used in order to propose a solution at the moment
javax.cache.CacheException: org.redisson.client.RedisException: Unexpected exception while processing command

	at org.redisson.jcache.JCache.evalWrite(JCache.java:342)
	at org.redisson.jcache.JCache.getAndRemoveValue(JCache.java:1445)
	at org.redisson.jcache.JCache.getAndRemove(JCache.java:1521)
	at com.jive.jci.cache.redisson.RedissonDefaultResourceIT.getAndRemoveTest(RedissonDefaultResourceIT.java:207)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.testcontainers.containers.FailureDetectingExternalResource$1.evaluate(FailureDetectingExternalResource.java:30)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
Caused by: org.redisson.client.RedisException: Unexpected exception while processing command
	at org.redisson.command.CommandAsyncService.convertException(CommandAsyncService.java:338)
	at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:169)
	at org.redisson.RedissonObject.get(RedissonObject.java:74)
	at org.redisson.jcache.JCache.evalWrite(JCache.java:340)
	... 27 more
Caused by: java.lang.NullPointerException
	at org.redisson.client.handler.CommandDecoder.selectDecoder(CommandDecoder.java:401)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:302)
	at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:345)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:329)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:104)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:367)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1414)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:945)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:141)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:886)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)

Code that show the issue:
    String host = REDIS.getContainerIpAddress();
    int port = REDIS.getMappedPort(6379);
    MutableConfiguration<String, String> jcacheConfig = new MutableConfiguration<>();

    Config redissonConfig = new Config();
    redissonConfig.setCodec(new JsonJacksonCodec());

    redissonConfig.useSingleServer()
        .setAddress("redis://" + host + ":" + port);

    Configuration<String, String> jConfig = RedissonConfiguration.fromConfig(
        redissonConfig, jcacheConfig);


    CacheManager manager = Caching.getCachingProvider("org.redisson.jcache.JCachingProvider")
        .getCacheManager();

    try (Cache<String, String> cache = manager.createCache("strings", jConfig);)
    {
      cache.put("key", "value");
      String result = cache.getAndRemove("key");

      Assert.assertEquals("value", result);
      Assert.assertNull(cache.get("key"));

      cache.put("key", "value");
      cache.remove("key");
      Assert.assertNull(cache.get("key"));
    }
Dependencies:
Redisson: 3.6.1
Redis: Vanilla docker image version 4.0.8
JDK: 1.8.0_151
[INFO] +- org.ehcache:ehcache:jar:3.4.0:compile
[INFO] +- org.cache2k:cache2k-all:jar:1.0.1.Final:compile
[INFO] +- org.cache2k:cache2k-api:jar:1.0.1.Final:provided
[INFO] +- org.redisson:redisson:jar:3.6.1:provided
[INFO] |  +- io.netty:netty-common:jar:4.1.21.Final:provided
[INFO] |  +- io.netty:netty-codec:jar:4.1.21.Final:provided
[INFO] |  +- io.netty:netty-buffer:jar:4.1.21.Final:provided
[INFO] |  +- io.netty:netty-transport:jar:4.1.21.Final:provided
[INFO] |  |  \- io.netty:netty-resolver:jar:4.1.21.Final:provided
[INFO] |  +- io.netty:netty-resolver-dns:jar:4.1.21.Final:provided
[INFO] |  |  \- io.netty:netty-codec-dns:jar:4.1.21.Final:provided
[INFO] |  +- io.netty:netty-handler:jar:4.1.21.Final:provided
[INFO] |  +- io.projectreactor:reactor-core:jar:3.1.1.RELEASE:provided
[INFO] |  |  \- org.reactivestreams:reactive-streams:jar:1.0.1:provided
[INFO] |  +- com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:jar:2.9.1:provided
[INFO] |  |  \- org.yaml:snakeyaml:jar:1.18:provided
[INFO] |  +- com.fasterxml.jackson.core:jackson-core:jar:2.9.1:compile
[INFO] |  +- net.bytebuddy:byte-buddy:jar:1.7.10:provided
[INFO] |  \- org.jodd:jodd-bean:jar:3.7.1:provided
[INFO] |     \- org.jodd:jodd-core:jar:3.7.1:provided
[INFO] +- javax.cache:cache-api:jar:1.0.0:compile
[INFO] +- org.projectlombok:lombok:jar:1.16.18:provided
[INFO] +- org.slf4j:slf4j-api:jar:1.7.25:compile
[INFO] +- org.slf4j:jcl-over-slf4j:jar:1.7.25:runtime
[INFO] +- org.slf4j:jul-to-slf4j:jar:1.7.25:runtime
[INFO] \- org.slf4j:log4j-over-slf4j:jar:1.7.25:runtime```
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1328
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
我希望redisson能提供一些连接效率和查询效率的统计功能，
并且把这些统计导出到jmx上面，
alibaba开源的druid连接池也有这个功能。
很多开发不清楚他们应该配什么参数，比如connectionPoolSize，
因为各家环境不同，没有1个统一的配置能包打天下
我想，如果提供这个功能，应该能够帮助开发 优化redisson参数配置、诊断线上问题。
@jackygurui
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1329
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Keeps redirecting me to this page.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1330
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When trying to implement a healthcheck for a Redis Cluster I'm using code similar to the below to get the list of nodes and ping them to see if they're up.
NodesGroup nodesGroup = redisson.getNodesGroup();
Collection<Node> allNodes = nodesGroup.getNodes();
for (Node n : allNodes) {
    n.ping();
}

If I redeploy a node and it gets a new IP, the new node is returned by redisson.getNodesGroup(); but the old one remains and we get an error:
Unable to send command! Node source: NodeSource [slot=null, addr=null, redisClient=[addr=redis://OLD.IP.ADD.RESS:6379], redirect=null, entry=null], connection: [id: 0x511b46ea, L:0.0.0.0/0.0.0.0:39616], command: (PING), params: []
If I failover a slave node then the slave node will be returned by redisson.getNodesGroup(); as a master (which is correct) but the original master will appear twice as both a master and a slave. If I then failover back to the original master, that node will be returned as a master twice and still as a slave.
When digging into the code it looks like this list/map lives in MasterSlaveConnectionManager as clientEntries which only gets cleared or removed from during a shutdown.
What I'd expect is for old or stale nodes to be cleared up from this list/map.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1331
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We are Trying to add a mechanism to re-subscribe to topics after restarting redis.
Setting UP:

Redis version:  2.8.17
Redis Mode: Sentinel   1 Master, 2 Slave
Redisson Version:  2.11.1  (Comparison With Redisson 2.9.1 see later section)
Read.Mode: Slave, Subscribe: Slave

Steps to recreate:


shut down sentinel
--- --- wait 10 seconds------


shut down server


Redisson send multiple "GET" "SET" commands attempting more than maxFailAttemp, make sure redisson regards all the redis server box down


restart redis server


restart redis sentinel


remove listener to the topic


resubscribe to the topics



See Following Error, Redis MasterConnectionPool is not re-established.

org.redisson.client.RedisTimeoutException: Subscribe timeout: (5000ms)
at org.redisson.command.CommandAsyncService.syncSubscription(CommandAsyncService.java:130) ~[redisson-2.11.1.jar!/:?]
at org.redisson.RedissonTopic.addListener(RedissonTopic.java:107) ~[redisson-2.11.1.jar!/:?]
at org.redisson.RedissonTopic.addListener(RedissonTopic.java:102) ~[redisson-2.11.1.jar!/:?]
at jibe.common.pubsub.monitor.RedisSubMonitor.reSubscribetoTopic(RedisSubMonitor.java:47) ~[jibe-common-base-4.1-SNAPSHOT.jar!/:?]
at jibe.common.pubsub.monitor.RedisSubMonitor.checkSubscriptionStatus(RedisSubMonitor.java:76) ~[jibe-common-base-4.1-SNAPSHOT.jar!/:?]
at sun.reflect.GeneratedMethodAccessor22.invoke(Unknown Source) ~[?:?]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_73]
at java.lang.reflect.Method.invoke(Method.java:497) ~[?:1.8.0_73]
at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:65) ~[spring-context-5.0.0.RC3.jar!/:5.0.0.RC3]
at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54) [spring-context-5.0.0.RC3.jar!/:5.0.0.RC3]
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_73]
at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_73]
at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_73]
at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_73]
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_73]
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_73]
at java.lang.Thread.run(Thread.java:745) [?:1.8.0_73]
[2018-03-08 22:42:48.305] [ERROR] [hydrogen-app-pool-1] TaskUtils$LoggingErrorHandler - Unexpected error occurred in scheduled task.
org.redisson.client.RedisConnectionException: MasterConnectionPool no available Redis entries.  Disconnected hosts: [/10.240.24.19:6379]
at org.redisson.connection.pool.ConnectionPool.get(ConnectionPool.java:199) ~[redisson-2.11.1.jar!/:?]
at org.redisson.connection.pool.MasterConnectionPool.get(MasterConnectionPool.java:31) ~[redisson-2.11.1.jar!/:?]
at org.redisson.connection.MasterSlaveEntry.connectionWriteOp(MasterSlaveEntry.java:534) ~[redisson-2.11.1.jar!/:?]
at org.redisson.connection.MasterSlaveConnectionManager.connectionWriteOp(MasterSlaveConnectionManager.java:845) ~[redisson-2.11.1.jar!/:?]
at org.redisson.command.CommandAsyncService.async(CommandAsyncService.java:498) ~[redisson-2.11.1.jar!/:?]
at org.redisson.command.CommandAsyncService$8.run(CommandAsyncService.java:577) ~[redisson-2.11.1.jar!/:?]
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:663) ~[netty-all-4.1.16.Final.jar!/:4.1.16.Final]
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:738) ~[netty-all-4.1.16.Final.jar!/:4.1.16.Final]
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:466) ~[netty-all-4.1.16.Final.jar!/:4.1.16.Final]
at java.lang.Thread.run(Thread.java:745) [?:1.8.0_73]
=====================================================================
We were initially at Redisson version 2.9.1, but when we following the previous steps, in step 5, we encountered the same issue as in #1268, which is removeListener thread blocks forever, so make the switch to 2.11.1
We also simulate the scenario with 2.9.1 version,  without doing removeListener (we found out there is pubsub Listener leak issue with 2.9.1, that is why we remove the old listener first), the MasterConnectionPool was able to re-establish.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1332
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
We have detect an issue on our redis (sentinel) cluster when there is a redis master switching .
During a performance test, we use PriorityQueue (~ 10 calls / seconds). All transaction are closed on 20-50 milli-seconds.
When master switching, on JConsole we have seen Redisson place some locks on redis databases, and all application are slow down... All transaction are closed on 3-10 seconds !
On our Redis cluster we have, 1 master, 5 slaves.
This is our using components versions :

redis 3.2.11
redisson 2.11.0

Also, we have test, redisson 2.11.1, we have the same issue.
We have issue with this config :
{
   "sentinelServersConfig":{
      "sentinelAddresses":[
         "redis://***.92:26379","redis://***.93:26379","redis://***.94:26379","redis://***.95:26379","redis://***.96:26379","redis://***.97:26379"
      ],
      "clientName":"***",
      "readMode":"MASTER",
      "timeout":"10000",
      "masterName":"***",
      "database":1,
      "password":null
   }
}

And we have apply a fix (work around), it's better running, but it's a huge configuration (on system : lot of connection and open file issue)
{
   "sentinelServersConfig":{
      "sentinelAddresses":[
         "redis://***.92:26379","redis://***.93:26379","redis://***.94:26379","redis://***.95:26379","redis://***.96:26379","redis://***.97:26379"
      ],
      "clientName":"***",
      "readMode":"MASTER",
      "timeout":"10000",
      "masterName":"***",
      "database":1,
      "password":null,
      "masterConnectionPoolSize":1024,
      "masterConnectionMinimumIdleSize":256,
      "slaveConnectionPoolSize":256,
      "slaveConnectionMinimumIdleSize":24
   }
}

Can you help us please ?
Thanks you
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1333
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
we should implement a distributed lock system for our clustered Spring Boot application.
We have a Redis "cluster" (no cluster mode enabled) with Sentinel.
Now, reading the documentation it seems that RedissonRedLock should be used as locks wrapper class to use lock/unlock api.
It seems that RedissonRedLock should be used with different RedissonInstance e multiple RLock's.
But what kind of lock should we use to implement single distributed lock with single redisson instance per-node?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1334
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am using lib version: 3.6.2
When trying to connect AWS Elastic cache(i.e rediss://clustercfg.xxx-test-sample.ttt.usw2.cache.amazonaws.com:6379) over ssl in cluster mode getting below exception:
io.netty.handler.codec.DecoderException: javax.net.ssl.SSLHandshakeException: General SSLEngine problem
                at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:459)
                at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
                at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
                at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
                at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
                at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1414)
                at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
                at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
                at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:945)
                at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:146)
                at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
                at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
                at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
                at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
                at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:886)
                at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
                at java.lang.Thread.run(Thread.java:748)
Caused by: javax.net.ssl.SSLHandshakeException: General SSLEngine problem
                at sun.security.ssl.Handshaker.checkThrown(Handshaker.java:1529)
                at sun.security.ssl.SSLEngineImpl.checkTaskThrown(SSLEngineImpl.java:535)
                at sun.security.ssl.SSLEngineImpl.readNetRecord(SSLEngineImpl.java:813)
                at sun.security.ssl.SSLEngineImpl.unwrap(SSLEngineImpl.java:781)
                at javax.net.ssl.SSLEngine.unwrap(SSLEngine.java:624)
                at io.netty.handler.ssl.SslHandler$SslEngineType$3.unwrap(SslHandler.java:292)
                at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1257)
                at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1159)
                at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1203)
                at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
                at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:428)
                ... 16 common frames omitted
Caused by: javax.net.ssl.SSLHandshakeException: General SSLEngine problem
                at sun.security.ssl.Alerts.getSSLException(Alerts.java:192)
                at sun.security.ssl.SSLEngineImpl.fatal(SSLEngineImpl.java:1728)
                at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:330)
                at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:322)
                at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1614)
                at sun.security.ssl.ClientHandshaker.processMessage(ClientHandshaker.java:216)
                at sun.security.ssl.Handshaker.processLoop(Handshaker.java:1052)
                at sun.security.ssl.Handshaker$1.run(Handshaker.java:992)
                at sun.security.ssl.Handshaker$1.run(Handshaker.java:989)
                at java.security.AccessController.doPrivileged(Native Method)
                at sun.security.ssl.Handshaker$DelegatedTask.run(Handshaker.java:1467)
                at io.netty.handler.ssl.SslHandler.runDelegatedTasks(SslHandler.java:1417)
                at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1325)
                ... 20 common frames omitted
Caused by: java.security.cert.CertificateException: No subject alternative names matching IP address 10.82.141.245 found
                at sun.security.util.HostnameChecker.matchIP(HostnameChecker.java:168)
                at sun.security.util.HostnameChecker.match(HostnameChecker.java:94)
                at sun.security.ssl.X509TrustManagerImpl.checkIdentity(X509TrustManagerImpl.java:455)
                at sun.security.ssl.X509TrustManagerImpl.checkIdentity(X509TrustManagerImpl.java:436)
                at sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:252)
                at sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:136)
                at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1601)

Not sure whats going wrong here, as per documents AWS manages the SSL certs so ideally this exception shouldn't have arrises.
I see this was closed as part of the issue #1135 . How ever single server mode with SSL is working fine. Could you please help me on this?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1335
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am using org.redisson.codec.SerializationCodec and   redisson 3.6.0
I have a child Rmap inside a parent Rmap.
Facing an Exception while fetching the stored Rmap

java.io.NotSerializableException: org.redisson.RedissonReference

Is Rmap serializable ?
How can I use a codec for fetching (get) and storing (put) Rmap from inside a parent Rmap ?
/////////////////
// onetime-initialization
RMap<String,Map<String,Long> parentMap = redisson.getMap("parentMap");
/////////////
if(parentMap.containsKey("child") == null) {
parentMap.put("child",redisson.getMapCache("childMapCache"));
}
RMap childCache = parentMap.get("child");
childCache.put("test1", 1000));
///////////////////////////////////
as long as I don't restart the application , it works fine
upon subsequent restart, it fails in the step -> parentMap.get("child");
[ERROR] Exception : Unexpected exception while processing command
org.redisson.client.RedisException: Unexpected exception while processing command
at org.redisson.command.CommandAsyncService.convertException(CommandAsyncService.java:322) ~[stormjar.jar:?]
at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:165) ~[stormjar.jar:?]
at org.redisson.RedissonObject.get(RedissonObject.java:69) ~[stormjar.jar:?]
at org.redisson.RedissonMap.put(RedissonMap.java:191) ~[stormjar.jar:?]
////////
Caused by: java.io.NotSerializableException: org.redisson.RedissonReference
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1184) ~[?:1.8.0_72]
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348) ~[?:1.8.0_72]
at org.redisson.codec.SerializationCodec$2.encode(SerializationCodec.java:64) ~[stormjar.jar:?]
at org.redisson.client.handler.CommandEncoder.encode(CommandEncoder.java:103) ~[stormjar.jar:?]
at org.redisson.client.handler.CommandEncoder.encode(CommandEncoder.java:45) ~[stormjar.jar:?]
at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107) ~[stormjar.jar:?]
////////////
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1336
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1337
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
master-slave有bug
触发条件


redisson 版本选3.6.2


采用redisson推荐的默认配置，其中retryInterval=1500，负载均衡策略为RoundRobinLoadBalancer


readMode 设置为 SLAVE


slaveAddresses配至少1个，masterAddress也配上


JDK 版本为1.8x


bug表现
有时候get操作非常缓慢，需要1500毫秒以上（等1个retryInterval周期）才能完成
bug发生的原因


debug发现slaveConnectionPool会持有写连接池，它持有的写连接池为冻结状态


所以，在这段代码中，一旦负载均衡到写连接池，就会进入抛异常重试逻辑


重试获取连接至少要1500毫秒


//代码位置为org.redisson.connection.pool.ConnectionPool#get(org.redisson.client.protocol.RedisCommand<?>)

    public RFuture<T> get(RedisCommand<?> command) {
        for (int j = entries.size() - 1; j >= 0; j--) {
            final ClientConnectionsEntry entry = getEntry();
            if ((!entry.isFreezed() || 
                    (entry.getFreezeReason() == FreezeReason.SYSTEM && config.getReadMode() == ReadMode.MASTER_SLAVE)) && 
        		    tryAcquireConnection(entry)) {
                return acquireConnection(command, entry);
            }
        }
        
        List<InetSocketAddress> failedAttempts = new LinkedList<InetSocketAddress>();
        List<InetSocketAddress> freezed = new LinkedList<InetSocketAddress>();
        for (ClientConnectionsEntry entry : entries) {
            if (entry.isFreezed()) {
                freezed.add(entry.getClient().getAddr());
            } else {
                failedAttempts.add(entry.getClient().getAddr());
            }
        }

        StringBuilder errorMsg = new StringBuilder(getClass().getSimpleName() + " no available Redis entries. ");
        if (!freezed.isEmpty()) {
            errorMsg.append(" Disconnected hosts: " + freezed);
        }
        if (!failedAttempts.isEmpty()) {
            errorMsg.append(" Hosts disconnected due to `failedAttempts` limit reached: " + failedAttempts);
        }

        RedisConnectionException exception = new RedisConnectionException(errorMsg.toString());
        return RedissonPromise.newFailedFuture(exception);
    }
@jackygurui
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1338
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RListMultimapCache<String, RuleHit> test = redissonClient.getListMultimapCache("test");
test.put("key1",new RuleHit("value1","title1","info1"));
test.put("key1",new RuleHit("value2","title2","info2"));

System.out.println(test.getAll("key1").size());

test.removeAll("key1");
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1339
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Getting error when calling readAllKeySet() operation.
org.redisson.client.RedisException: ERR Error running script (call to f_8770695dc269722cd5368a1e08ca936b4ccbb0b7): @user_script:1: user_script:1: bad argument #2 to 'unpack' (data string too short) . channel: [id: 0x0f03b43a, L:/192.168.1.66:57481 - R:/192.168.1.159:6379] command: (EVAL), params: [local s = redis.call('hgetall', KEYS[1]); local maxSize = tonumber(redis.call('hget', KEYS[5], 'max-..., 5, userDataCache, redisson__timeout__set:{userDataCache}, redisson__idle__set:{userDataCache}, redisson__map_cache__last_access__set:{userDataCache}, {userDataCache}:redisson_options, 1521112711284]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:241)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:101)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:367)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:138)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
at java.lang.Thread.run(Thread.java:748)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1340
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1341
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1342
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1343
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1344
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1345
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1346
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1347
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1348
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1349
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1350
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1351
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1352
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1353
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1354
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1355
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1356
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1357
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1358
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1359
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1360
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1361
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1362
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1363
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1364
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1365
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1366
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1367
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1368
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1369
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1370
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1371
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1372
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1373
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1374
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1375
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1376
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1377
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1378
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1379
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1380
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1381
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1382
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1383
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1384
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1385
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1386
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1387
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1388
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1389
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1390
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1391
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1392
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1393
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1394
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1395
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1396
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1397
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1398
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1399
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1400
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1401
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1402
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1403
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1404
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1405
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1406
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1407
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1408
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1409
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1410
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1411
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1412
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1413
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1414
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1415
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1416
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1417
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1418
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1419
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1420
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1421
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1422
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1423
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1424
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1425
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1426
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1427
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1428
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1429
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1430
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1431
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1432
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1433
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1434
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1435
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1436
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1437
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1438
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1439
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1440
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1441
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1442
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1443
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1444
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1445
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1446
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1447
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1448
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1449
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1450
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1451
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1452
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1453
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1454
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1455
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1456
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1457
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1458
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1459
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1460
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1461
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@alishtory you need to invoke setTransactionHolder in doResume don't you?
like this:
ConnectionHolder conHolder = (ConnectionHolder) suspendedResources;
TransactionSynchronizationManager.bindResource(this.getResourceFactory(), conHolder);

RedissonTransactionHolder holder = (RedissonTransactionHolder) TransactionSynchronizationManager.getResource(redisson);
RedissonTransactionObject txObject = (RedissonTransactionObject) transaction;
txObject.setTransactionHolder(holder);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1462
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am seeing below error while using RedissonSessionManager with tomcat. I have followed the default configuration that was provided at https://github.com/redisson/redisson/tree/master/redisson-tomcat.
Configuration is working fine in multi node environment with session replication at redis, but for every request I am seeing this error. Can you one please help on this.

JSON file:
{
"singleServerConfig":{
"password":null,
"address": "redis://localhost:6379",
"database":0
},
"codec":{
"class":"org.redisson.codec.SerializationCodec"
},
"transportMode": "EPOLL"
}
My redissona-all jar version is 3.7.1
redisson-tomcat-8:3.7.1
Tomcat version: 8.5.23
java.io.IOException: java.lang.ClassNotFoundException: org.springframework.webflow.conversation.impl.ConversationContainer
at org.redisson.codec.SerializationCodec$1.decode(SerializationCodec.java:54)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:330)
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:372)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:356)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:111)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965)
at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:808)
at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:408)
at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:308)
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassNotFoundException: org.springframework.webflow.conversation.impl.ConversationContainer
at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
at java.lang.Class.forName0(Native Method)
at java.lang.Class.forName(Class.java:348)
at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:677)
at org.redisson.codec.CustomObjectInputStream.resolveClass(CustomObjectInputStream.java:43)
at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1826)
at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713)
at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000)
at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
at org.redisson.codec.SerializationCodec$1.decode(SerializationCodec.java:50)
... 32 more
[redisson-netty-4-3] WARN io.netty.channel.DefaultChannelPipeline - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
io.netty.handler.codec.DecoderException: java.io.IOException: java.lang.ClassNotFoundException: org.springframework.webflow.conversation.impl.ConversationContainer
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:421)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965)
at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:808)
at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:408)
at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:308)
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: java.lang.ClassNotFoundException: org.springframework.webflow.conversation.impl.ConversationContainer
at org.redisson.codec.SerializationCodec$1.decode(SerializationCodec.java:54)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:330)
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:372)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:356)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:111)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
... 26 more
Caused by: java.lang.ClassNotFoundException: org.springframework.webflow.conversation.impl.ConversationContainer
at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
at java.lang.Class.forName0(Native Method)
at java.lang.Class.forName(Class.java:348)
at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:677)
at org.redisson.codec.CustomObjectInputStream.resolveClass(CustomObjectInputStream.java:43)
at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1826)
at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713)
at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000)
at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
at org.redisson.codec.SerializationCodec$1.decode(SerializationCodec.java:50)
... 32 more
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1463
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
我在使用@Scheduler注解的时候，这样配置了下ScheduledExecutorService，期望使用redisson 的ScheduledExecutorService，
 @Bean public ScheduledExecutorService scheduledExecutorService(RedissonClient redissonClient){ return redissonClient.getExecutorService("executer"); }
但是跟踪到private byte[] encode(Object task) ；方法的这行
buf = codec.getValueEncoder().encode(task);抛出了异常。
Caused by: java.lang.StackOverflowError: null
序列化使用的是jackson，异常信息太多不方便贴出 。请问是否这样的使用方式不可行？
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1464
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
i used redisson in tomcat8 to mange session.and i have a problem that: site real visitor count only 100,but redis save session count is 1700.i don't understand the reason.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1465
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
hi：
i have a problem when i use redssion manager session and shiro save data.problem description is under:
if i want to change the jackson,how i can do?
Caused by: com.fasterxml.jackson.databind.JsonMappingException: Invalid type id 'org.apache.shiro.subject.SimplePrincipalCollection' (for id type 'Id.class'): no such class found (through reference chain: org.redisson.tomcat.AttributeUpdateMessage["value"])
at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:379)
at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:339)
at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.wrapAndThrow(BeanDeserializerBase.java:1514)
at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:262)
at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:163)
at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:135)
at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedForId(AsPropertyTypeDeserializer.java:120)
at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:91)
at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromAny(AsPropertyTypeDeserializer.java:163)
at com.fasterxml.jackson.databind.deser.std.UntypedObjectDeserializer$Vanilla.deserializeWithType(UntypedObjectDeserializer.java:554)
at com.fasterxml.jackson.databind.deser.impl.TypeWrappedDeserializer.deserialize(TypeWrappedDeserializer.java:63)
at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3807)
at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2867)
at org.redisson.codec.JsonJacksonCodec$2.decode(JsonJacksonCodec.java:89)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:330)
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:372)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:356)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:111)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
... 28 more
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1466
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
No exceptions
Actual behavior
Subscribe timeout: (41000ms)org.redisson.client.RedisTimeoutException: Subscribe timeout: (41000ms)
	at org.redisson.command.CommandAsyncService.syncSubscription(CommandAsyncService.java:130)
	at org.redisson.RedissonLock.lockInterruptibly(RedissonLock.java:122)
	at org.redisson.RedissonLock.lock(RedissonLock.java:100)
	at com.zeppelinen.carsharing.dataprocessor.registry.manager.locker.RegistryLocker.lock(RegistryLocker.java:39)
	at com.zeppelinen.carsharing.dataprocessor.registry.manager.lifecycle.LifeCycleManager.getRentIdAttachedToCar(LifeCycleManager.java:195)
	at com.zeppelinen.carsharing.dataprocessor.workunit.core.carserver.service.impl.TrackMessageProcessorImpl.processTrackMessage(TrackMessageProcessorImpl.java:60)
	at com.zeppelinen.carsharing.dataprocessor.workunit.periphery.io.carserver.listener.TrackMessageListener.receiveTrackData(TrackMessageListener.java:55)
	at sun.reflect.GeneratedMethodAccessor61.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:181)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:114)
	at org.springframework.amqp.rabbit.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:51)
	at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:182)
	at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.onMessage(MessagingMessageListenerAdapter.java:120)
	at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:1414)
	at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.actualInvokeListener(AbstractMessageListenerContainer.java:1337)
	at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.invokeListener(AbstractMessageListenerContainer.java:1324)
	at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.executeListener(AbstractMessageListenerContainer.java:1303)
	at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doReceiveAndExecute(SimpleMessageListenerContainer.java:785)
	at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.receiveAndExecute(SimpleMessageListenerContainer.java:769)
	at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$700(SimpleMessageListenerContainer.java:77)
	at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1010)
	at java.lang.Thread.run(Thread.java:748)

Steps to reproduce or test case
Redis version
4.0.6
Redis Replication
role:slave
master_host:10.233.80.95
master_port:6379
master_link_status:up
master_last_io_seconds_ago:1
master_sync_in_progress:0
slave_repl_offset:4327166295
slave_priority:100
slave_read_only:1
connected_slaves:0
master_replid:610cea4395c4ccb2f4d42620e5b40be23f42a28f
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:4327166295
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:4326117720
repl_backlog_histlen:1048576
Redisson version
3.7.0
Redisson configuration
Sentinel configuration.
setRetryAttempts  (7)
setRetryInterval (3000 ms)
setSubscriptionConnectionPoolSize (200)
setSubscriptionConnectionMinimumIdleSize (10)
setSlaveConnectionPoolSize(200)
setMasterConnectionPoolSize(200)
other: default
Why is I keep getting these subscribe timeouts? After restarting service it works allright for, like, 24 hours, then I get a lot of subscribe errors. I have a pretty big connection pool, so I don't see why I keep getting it.
I mostly receive this error with RLock, which I use to synchronize. Should I tune my configuration somehow?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1467
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RedissonLocalCachedMap can not init with NullPointerException when ReconnectionStrategy is ReconnectionStrategy.LOAD
I think the LocalCacheListener is null ;The line 160 in source code org.redisson.RedissonLocalCachedMap.java ,listener is null because it create in line 164;
Redis version 4.0
Redisson version 3.7.1
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1468
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
public class Main {

    private final static int NO_OF_JOBS = 5;

    public static void main(String[] args) {

        Config config = new Config();
        config.useClusterServers()
                .addNodeAddress("http://127.0.0.1:7000", "http://127.0.0.1:7001", "http://127.0.0.1:7002");
        RedissonClient redisson = Redisson.create(config);
        RExecutorService e =  redisson.getExecutorService("w1");//redisson.getExecutorService("w1");
        
        for (int j = 0; j < NO_OF_JOBS; j++) {
            Calendar calendar = Calendar.getInstance();
            int hour = calendar.get(Calendar.HOUR_OF_DAY);
            int minute = calendar.get(Calendar.MINUTE) + 1;
            //System.out.println("hour, minute" + hour + ", " + minute);
            ((RScheduledExecutorService) e).schedule(new RunnableTask(j + 1), CronSchedule.dailyAtHourAndMinute(hour, minute));
        }
    }
}
//new  job
public class RunnableTask implements Runnable {
    private int job_no;
    RunnableTask(int job_no) {
        this.job_no = job_no;
    }
    public void run() {
        try {
            Thread.sleep(10);
            System.out.println("This is task no " + job_no);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}
//old Job
public class RunnableTask implements Runnable {
    private static volatile int i = 0;
    private long anyParam;
    public RunnableTask() {
    }
    RunnableTask(long anyParam) {
        this.anyParam = anyParam;
    }
    public void run() {
        try {
            Thread.sleep(10);
            i++;
            System.out.println(i);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}

I previously scheduled 5 jobs (old jobs) they executed successfully. After that I scheduled another 5 jobs(new job) but this time the previous 5 jobs got executed on the schedule I gave for new job. Can anyone explain me this behaviour of redisson and point where I am making the mistake.
For this experiment I runned 4 redissonnodes in standalone mode with configuration as described below.
{
   "clusterServersConfig":{
      "nodeAddresses":[
         "redis://127.0.0.1:7001",
         "redis://127.0.0.1:7002",
         "redis://127.0.0.1:7003"
      ],
   },
   "threads":10,
   "executorServiceWorkers": {"w1":10},

}	

Redis version
4.0.9
Redisson version
3.7.0
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1469
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1470
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redisson API to get the number of subscribers subscribed to a particular channel.
PUBSUB numsub test

"test"
(integer) 1

How can we get the number of subscribers subscribed to a particular topic in redis as it was possible using the above command.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1471
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I scheduled some jobs first then I run one RedissonNode in standalone mode. and I got this error.
I have used the below code for scheduling the jobs.
public class Main {

    private final static int NO_OF_JOBS = 50;
    static int i = 1;

    public static void main(String[] args) {
        AtomicInteger a = new AtomicInteger(0);
        Config config = new Config();
        config.useClusterServers()
                .addNodeAddress("http://127.0.0.1:7000", "http://127.0.0.1:7001", "http://127.0.0.1:7002");
        RedissonClient redisson = Redisson.create(config);
        RExecutorService e = redisson.getExecutorService("d1");//redisson.getExecutorService("w1");
        for (int j = 0; j < NO_OF_JOBS; j++) {
            Calendar calendar = Calendar.getInstance();
            int hour = calendar.get(Calendar.HOUR_OF_DAY);
            int minute = calendar.get(Calendar.MINUTE) + 1;
            //System.out.println("hour, minute" + hour + ", " + minute);
            ((RScheduledExecutorService) e).schedule(new RunnableTask(j + 1), CronSchedule.dailyAtHourAndMinute(hour, minute));
        }
    }
}
public class RunnableTask implements Runnable {

    private int job_no;
    
    RunnableTask(int job_no) {
        this.job_no = job_no;
    }

    public void run() {
        try {
            Thread.sleep(10);
            System.out.println("This is task no " + job_no);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}
Previously it was working fine but I have suddenly started getting this issue.
I am running 3 node redis cluster, with one replica
redis version 4.0.9
redisson version 3.7.0
[redisson-3-20] ERROR org.redisson.RedissonRemoteService - Can't execute: RemoteServiceRequest [requestId=52033463679a97be9bc4248e13a5c090, methodName=schedule, signatures=[[java.lang.String, [B, [B, long, java.lang.String, java.lang.String, java.lang.String]], args=[com.webengage.RunnableTask, [B@b02600d, [B@6703129b, 1528125840000, 0 54 20 ? * *, b00d5604-0e02-4a1a-8ea2-82ece6424caf, 52033463679a97be9bc4248e13a5c090], options=RemoteInvocationOptions[ackTimeoutInMillis=null, executionTimeoutInMillis=null], date=1528125782651] java.lang.reflect.InvocationTargetException at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.redisson.RedissonRemoteService.invokeMethod(RedissonRemoteService.java:340) at org.redisson.RedissonRemoteService.access$400(RedissonRemoteService.java:66) at org.redisson.RedissonRemoteService$2.run(RedissonRemoteService.java:305) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138) at java.lang.Thread.run(Thread.java:748) Caused by: org.redisson.client.RedisException: CROSSSLOT Keys in request don't hash to the same slot. channel: [id: 0xada13228, L:/127.0.0.1:59757 - R:localhost/127.0.0.1:7003] command: (EVAL), params: [if redis.call('zrem', KEYS[2], ARGV[1]) > 0 then redis.call('hdel', KEYS[6], ARGV[1]); if redis.call..., 6, {{d1:org.redisson.executor.RemoteExecutorService}:org.redisson.executor.RemoteExecutorService}, {d1:org.redisson.executor.RemoteExecutorService}:scheduler, {d1:org.redisson.executor.RemoteExecutorService}:counter, {d1:org.redisson.executor.RemoteExecutorService}:status, {d1:org.redisson.executor.RemoteExecutorService}:termination-topic, {d1:org.redisson.executor.RemoteExecutorService}:tasks, 52033463679a97be9bc4248e13a5c090, 1, ...]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1472
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
As requested in #1470 by @Himanshu4
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1473
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am seeing below error while using RedissonSessionManager with tomcat. I have followed the default configuration that was provided at https://github.com/redisson/redisson/tree/master/redisson-tomcat.
Configuration is working fine in multi node environment with session replication at redis, but for every request I am seeing this error. Can you one please help on this.
Context.xml
Manager className="org.redisson.tomcat.RedissonSessionManager" configPath="${catalina.base}/lib/redisson.json"
JSON file:
{
"singleServerConfig":{
"password":null,
"address": "redis://localhost:6379",
"database":0
},
"codec":{
"class":"org.redisson.codec.SerializationCodec"
},
"transportMode": "EPOLL"
}
My redissona-all jar version is 3.7.1
redisson-tomcat-8:3.7.1
Tomcat version: 8.5.23
java.io.IOException: java.lang.ClassNotFoundException: org.springframework.webflow.conversation.impl.ConversationContainer
at org.redisson.codec.SerializationCodec$1.decode(SerializationCodec.java:54)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:330)
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:372)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:356)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:111)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965)
at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:808)
at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:408)
at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:308)
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassNotFoundException: org.springframework.webflow.conversation.impl.ConversationContainer
at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
at java.lang.Class.forName0(Native Method)
at java.lang.Class.forName(Class.java:348)
at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:677)
at org.redisson.codec.CustomObjectInputStream.resolveClass(CustomObjectInputStream.java:43)
at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1826)
at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713)
at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000)
at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
at org.redisson.codec.SerializationCodec$1.decode(SerializationCodec.java:50)
... 32 more
[redisson-netty-4-3] WARN io.netty.channel.DefaultChannelPipeline - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
io.netty.handler.codec.DecoderException: java.io.IOException: java.lang.ClassNotFoundException: org.springframework.webflow.conversation.impl.ConversationContainer
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:421)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965)
at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:808)
at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:408)
at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:308)
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: java.lang.ClassNotFoundException: org.springframework.webflow.conversation.impl.ConversationContainer
at org.redisson.codec.SerializationCodec$1.decode(SerializationCodec.java:54)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:330)
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:372)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:356)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:111)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
... 26 more
Caused by: java.lang.ClassNotFoundException: org.springframework.webflow.conversation.impl.ConversationContainer
at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
at java.lang.Class.forName0(Native Method)
at java.lang.Class.forName(Class.java:348)
at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:677)
at org.redisson.codec.CustomObjectInputStream.resolveClass(CustomObjectInputStream.java:43)
at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1826)
at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713)
at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000)
at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
at org.redisson.codec.SerializationCodec$1.decode(SerializationCodec.java:50)
... 32 more
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1474
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Score/element order has been changed around in RC2. See: redis/redis@0a698e4
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1475
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
TestBean is
@Data
@EqualsAndHashCode(of = "id") //use lombok  .This annotation means use **id**  for hashing
public class TestBean {
    long id;
    String name;
}

        RSet<TestBean> set = mRedisClient.getSet("testSet");
        TestBean t1=new TestBean();
        t1.setId(1);
        t1.setName("1");

        TestBean t2=new TestBean();
        t2.setId(1);
        t2.setName("2");

        set.add(t1);
        set.add(t2);
﻿###  Expected behavior
set's size is 1
Actual behavior
set's size is 2, contains {"@Class":"com.meta.po.TestBean","id":1,"name":"2"} and
{"@Class":"com.meta.po.TestBean","id":1,"name":"1"}
Redis version
3.2.100
Redisson version
2.12.1
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1476
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
setPingConnectionInterval should ping redis Pub/Sub channel periodically and re-subscribe if pong is not received during specified interval. No exceptions should be thrown or logged by sending PING or receiving PONG messages.
Actual behavior
There is NullPointerException thrown and logged as error when pong is received.
Not sure if connection check and recovery would even work in this case.
This is copy/paste from our error log:
2018-06-08 14:39:53,778 ERROR [redisson-netty-1-3] o.r.c.handler.CommandPubSubDecoder  - Unable to decode data. channel: [id: 0x23e24825, L:/10.116.40.44:46628 - R:10.116.172.14/10.116.172.14:6379] message: *2 $4 pong $0 java.lang.NullPointerException: null 2018-06-08 14:39:53,779 WARN  [redisson-netty-1-3] i.n.channel.DefaultChannelPipeline  - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception. io.netty.handler.codec.DecoderException: java.lang.NullPointerException at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:421) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:647) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:582) at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:499) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:461) at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.lang.Thread.run(Thread.java:748) Caused by: java.lang.NullPointerException: null
This is also logged as WARN by redisson, related to the same event:
2018-06-08 15:04:50,296 WARN  [redisson-netty-1-2] i.n.channel.DefaultChannelPipeline  - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception. io.netty.handler.codec.DecoderException: java.lang.NullPointerException at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:421) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:647) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:582) at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:499) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:461) at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.lang.Thread.run(Thread.java:748) Caused by: java.lang.NullPointerException: null at org.redisson.client.handler.CommandPubSubDecoder.messageDecoder(CommandPubSubDecoder.java:179) at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:378) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:356) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:111) at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489) at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) ... 32 common frames omitted
Steps to reproduce or test case
Application uses SerializationCodec for all channels, currently using 2 channels for pub/sub. Enable setPingConnectionInterval, in my case set to 5000 ms. After this NPE will be logged in error log.
Redis version
Server
redis_version:4.0.6
redis_git_sha1:00000000
redis_git_dirty:0
redis_build_id:f1060815dd32471a
redis_mode:standalone
os:Linux 3.10.0-514.26.1.el7.x86_64 x86_64

Sentinels

Server
redis_version:4.0.6
redis_git_sha1:00000000
redis_git_dirty:0
redis_build_id:f1060815dd32471a
redis_mode:sentinel
os:Linux 3.10.0-693.21.1.el7.x86_64 x86_64
Using 2 redis servers with master/slave + 3 sentinels of the same version
Redisson version
3.7.0, 3.7.1
Redisson configuration

sentinel mode
setConnectTimeout(10000)
setPingConnectionInterval(5000)
setSubscriptionMode(SubscriptionMode.MASTER)
setFailedSlaveReconnectionInterval(15000)
redis.connection.pool.size(10)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1477
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
The codec specified in the constructor should be used only for values, not for scores.
Redis commands : RedisCommands.ZSCORE and RedisCommands.ZSCORE_CONTAINS
Actual behavior
Codec for scores sometimes uses LongCodec sometimes uses "codec". For backward data compatibility should always use LongCodec when accessing scores.
Steps to reproduce or test case
Create a ScoredSortedSet with non default codec and use getScoreAsync / containsAsync methods
Redis version
4.0.6
Redisson version
3.7.1
Used to work fine with Redisson Version 3.5.7, when upgraded to 3.7.1 ScoredSortedSet stopped working. Codec
Works fine with this change:
 @Override
        public @Nullable RFuture<Double> getScoreAsync(final @Nullable V o) {
            return commandExecutor.readAsync(getName(), LongCodec.INSTANCE, RedisCommands.ZSCORE, getName(), encode(o));
        }
@Override
        public @Nullable RFuture<Boolean> containsAsync(final @Nullable Object o) {
            return commandExecutor.readAsync(getName(), LongCodec.INSTANCE, RedisCommands.ZSCORE_CONTAINS, getName(), encode(o));
        }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1478
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
How can I get control over already scheduled jobs in redisson and do operation such as delete/modify on them.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1479
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Current implementation of RBatch object accumulates all method invocations in memory on Redisson side before send them to Redis. This approach may lead to OOM exception if accumulated batch is too big.
Introduce executionMode setting to allow accumulation of all method invocations on Redis side.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1480
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Call Redis INFO on a given node in a cluster and it should return a blob of info for that given node.
Actual behavior
When the redisson client is preparing to send the redis INFO call, client2key returns null for the given redisClient which only happened to me during INFO calls, not any writes or reads. This is the commit that I believe caused this behavior. fe98d0a#diff-bb90b8f5c06abce59014861b02cecd93
06/04/2018 16:18:59 PDT DEBUG redisson-netty-1-4 ClusterConnectionManager:391 - cluster nodes state from 10.73.128.146/10.73.128.146:6379:
03de98146f0038a9a04587dd6ef102f48c54aeab 10.73.128.76:6379 slave 0cba7b1e954e4235a9ac86e0306608e97e04e404 0 1528154338964 98 connected
0cba7b1e954e4235a9ac86e0306608e97e04e404 10.73.128.146:6379 myself,master - 0 0 98 connected 10922-16383
117b100e765b5af972dd7d3f96b9541d7c7aba24 10.73.128.138:6379 slave a3e0502ebb14d9b6c4eb0d600e05e15d30adb387 0 1528154337463 79 connected
d78a886e8fb890bb98ed740f8908b222874a164a 10.73.129.85:6379 slave 178153b9fdc7b8314ef3a26f269395d4ec6597ca 0 1528154338464 93 connected
987c581e9b11b72d9e17c4e58d8c66abce653dd6 10.73.128.93:6379 slave 0cba7b1e954e4235a9ac86e0306608e97e04e404 0 1528154337963 98 connected
178153b9fdc7b8314ef3a26f269395d4ec6597ca 10.73.128.68:6379 master - 0 1528154336962 93 connected 5461-10921
a3e0502ebb14d9b6c4eb0d600e05e15d30adb387 10.73.128.91:6379 master - 0 1528154337463 79 connected 0-5460


org.redisson.client.RedisConnectionException: Can't find entry for [addr=redis://10.73.128.68:6379]
    at org.redisson.connection.balancer.LoadBalancerManager.getConnection(LoadBalancerManager.java:241)
    at org.redisson.connection.MasterSlaveEntry.connectionReadOp(MasterSlaveEntry.java:507)
    at org.redisson.connection.MasterSlaveConnectionManager.connectionReadOp(MasterSlaveConnectionManager.java:583)
    at org.redisson.command.CommandAsyncService.async(CommandAsyncService.java:497)
    at org.redisson.command.CommandAsyncService$8.run(CommandAsyncService.java:589)
    at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:668)
    at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:743)
    at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:471)
    at java.lang.Thread.run(Thread.java:745)
Can't find entry for [addr=redis://10.73.128.68:6379]

It seems the issue is the hashcodes are different only when making the INFO call (That i know of) because the channels value changes.

So when doing the get for client2key, it gets nothing. For Writes and reads that i tried, the hashcodes for the clients are the same
Steps to reproduce or test case
Spin up any redis cluster and simply call .info() on a node in the .getNodesGroup()
Redis version
3.2.11
Redisson version
3.7.1
Redisson configuration
default redis cluster config with 7 nodes in the cluster. 3 Master and 4 Slave
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1481
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Redisson is able to send read and write commands to the 2nd newly elected Master.
Actual behavior
This is the topology:
71a80a4554db9893e194545a45e4caeaf159a726 10.45.248.93:6379 master - 0 1527887027479 76 connected 0-5460 01f30ae68e733f9b6394efd05577c4d1d6ab011a 10.45.247.71:6379 slave 22b3f1ec6e436d206c2757a9fbf97b325d753486 0 1527887028983 93 connected 22b3f1ec6e436d206c2757a9fbf97b325d753486 10.45.247.72:6379 master - 0 1527887027981 80 connected 10922-16383 dfa03dc3fdcb917641a8d4e85e8373ee19e1fda8 10.45.248.80:6379 master - 0 1527887028482 93 connected 5461-10921 b7695f9238909af61f158deafe7f4f33ffd2eae4 10.45.248.134:6379 slave dfa03dc3fdcb917641a8d4e85e8373ee19e1fda8 0 1527887028983 93 connected a6a42df404d5adac79203eb9bc3fc49bcc03fd19 10.45.248.106:6379 myself,slave 71a80a4554db9893e194545a45e4caeaf159a726 0 0 61 connected 5c421bf7466e8702bbf344de9ae528fa8fbea1d7 10.45.247.74:6379 slave dfa03dc3fdcb917641a8d4e85e8373ee19e1fda8 0 1527887029482 93 connected 9640188f1b2214faa6c26a1755179803ebafad7c 10.45.247.75:6379 slave 71a80a4554db9893e194545a45e4caeaf159a726 0 1527887027981 76 connected
When testing various failover situations, I ran into a situation which causes the redisson client to get stuck using a bad connection when making the write calls, however the thread that is polling for the topology is fine. The situation is the redis process dies on a Master node I am writing to, a slave is then promoted to master. The redisson client is still in a GOOD state. The redis process dies on the new Master, a floating slave is then promoted to Master. At this point, the redisson client is now STUCK using a bad connection to a dead master.
Steps to reproduce or test case
Run 7 node cluster, I believe this is the minimum to reproduce this as you need an extra floating slave to promote after the first Master/Slave pair dies. For Master 1 slots 0-5460 (M1), kill the redis process. This should cause it's slave (S1) to promote to master and the floating slave (FS2) to attach to this new master. Then repeat kill the redis process on S1 which was promoted to master and FS1 should be promoted to master. The redisson client will now fail reads/writes because the redisson client connections are to the old S1 node despite FS1 now being the new master but does not fail to poll for CLUSTER NODES because I believe it is using a separate connection pool/thread to do that.
Redis version
3.2.11
Redisson version
3.7.0
Redisson configuration
Default redis cluster config with 7 nodes. 3 Master 4 Slave.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1482
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
SingleServerConfig serverConfig = config.useSingleServer()
.setAddress("redis://" + redissonProperties.getHost() + ":" + redissonProperties.getPort())
.setTimeout(redissonProperties.getTimeout())
.setConnectionPoolSize(redissonProperties.getConnectionPoolSize()).setDatabase(0);
config.setLockWatchdogTimeout(redissonProperties.getLockWatchdogTimeout());配置
lock.lock(“ceshifangfa”）
TODO
lock.unlock
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1483
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The performance benefit of using RedissonLocalCachedMap over RedissonMap is negligible when getting all data from the map via readAllKeySet*(), readAllValues*(), readAllEntrySet*() and values(). The readAll*() methods still gets data from server, values() method is not overriden in RedissonLocalCachedMap.
Would it be possible to read data only from the local cache in these cases?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1484
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
the code blow:
config:
@bean
public RRateLimiter rRateLimiter(RedissonClient redissonClient){
RRateLimiter rateLimiter = redissonClient.getRateLimiter("myRateLimiter");
System.err.println("初始化流速10设置:"+rateLimiter.trySetRate(RateType.OVERALL, 10, 1,  RateIntervalUnit.SECONDS));
return rateLimiter;
}
call function:
@Autowired
private RRateLimiter rateLimiter;
@ApiOperation(value = "列表",notes = "进入列表页", httpMethod = "GET")
@RequestMapping(value = "init",method = RequestMethod.GET)
public String init(){
if(rateLimiter.tryAcquire(1,0, TimeUnit.SECONDS)){//获取令牌成功，尝试一次，直接返回
try {
System.err.println("获取令牌成功，确定执行时刻:" + new SimpleDateFormat("yyyy-MM-dd hh:mm:ss S").format(new Date()));
// 模拟执行耗时5秒
TimeUnit.SECONDS.sleep(5);
} catch (InterruptedException e) {
e.printStackTrace();
}
}else{
System.err.println("获取令牌失败，拒绝执行时刻:"+new SimpleDateFormat("yyyy-MM-dd hh:mm:ss S").format(new Date()));
}
return "solr/selectSolr";
}
the RedissonClient init success with cluster model,the console always print
1.初始化流速10设置:false,
this function "rateLimiter.trySetRate(RateType.OVERALL, 10, 1, RateIntervalUnit.SECONDS)",return false  why?
need code demo for RateLimiter,thanks !
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1485
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
hello, I have test the tryLock with waitTime, but find it has bug. My test is as follows:
class MyThread2 extends Thread {
public void run() {
RLock lock = null;
try {
lock = redisson.getLock(lockName);
if (lock.tryLock(5,10,TimeUnit.SECONDS)) {
System.out.println(Thread.currentThread().getName() + "正在执行...");
TimeUnit.SECONDS.sleep(2);
System.out.println("2s结束....");
} else {
System.out.println(Thread.currentThread().getName() + "获取锁失败...");
}
} catch (InterruptedException e) {
e.printStackTrace();
} finally {
if (lock != null) {
lock.unlock();
System.out.println("释放锁...");
} else {
System.out.println("null");
}
}
}
Two threads run the above,the result is as follows:
Thread-512正在执行...
2s结束....
释放锁...
Thread-513获取锁失败...
释放锁...
As you can see, the second thread faild to acquire lock but the lock is released during 2 seconds...please tell me ,thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1486
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
项目能够顺利启动。
Actual behavior
偶尔会抛出Search domain query failed.异常信息导致项目启动不了
Steps to reproduce or test case
项目采用的spring boot1.5.3。
Redis version
redis 4.0.2
Redisson version
Redisson 3.6.5
Redisson configuration
application.yml
redisson:
  address: redis://www.chasel.com:6279
  timeout: 3000
  connectionPoolSize: 64
  connectionMinimumIdleSize: 10
  reconnectionTimeout: 3000
  threads: 10
  codec: org.redisson.codec.JsonJacksonCodec
  nettyThreads: 10
  transportMode: NIO
  idleConnectionTimeout: 10000
  pingTimeout: 1000
  connectTimeout: 10000
  database: 0
Java Code
public class RedissonConfig {

	private String address;
	private int connectionMinimumIdleSize;
	private int idleConnectionTimeout;
	private int pingTimeout;
	private int connectTimeout;
	private int timeout;
	private int reconnectionTimeout;
	private int connectionPoolSize;
	private int database;
	private int threads; // 当前处理核数量 * 2
	private int nettyThreads;
	private String codec;
	@ConditionalOnProperty(name = "redisson.address")
	@Bean(destroyMethod = "shutdown")
	RedissonClient redisson() throws Exception {
		Config config = new Config();
		config.useSingleServer().setAddress(address)
				.setConnectionMinimumIdleSize(connectionMinimumIdleSize).setIdleConnectionTimeout(idleConnectionTimeout)
				.setPingTimeout(pingTimeout).setConnectTimeout(connectTimeout).setTimeout(timeout)
				.setConnectionPoolSize(connectionPoolSize).setDatabase(database)
				;
		config.setThreads(threads);
		config.setTransportMode(TransportMode.NIO);
		config.setNettyThreads(nettyThreads);
		// SingleServerConfig singleServerConfig =
		// config.useSingleServer().setAddress();
		// Config config = Config.fromJSON(new
		// ClassPathResource(RedisContants.RedissonConstants.REDISSON_JSON_CONFIG_FILE_NAME).getFile());
		return Redisson.create(config);
	}

	@ConditionalOnProperty(name = "redisson.address")
	@Bean
	RedissonReactiveClient RedissonReactive() throws IOException {
		Config config = new Config();
		config.useSingleServer().setAddress(address)
				.setConnectionMinimumIdleSize(connectionMinimumIdleSize).setIdleConnectionTimeout(idleConnectionTimeout)
				.setPingTimeout(pingTimeout).setConnectTimeout(connectTimeout).setTimeout(timeout)
				.setConnectionPoolSize(connectionPoolSize).setDatabase(database)
				;
		config.setThreads(threads);
		config.setTransportMode(TransportMode.NIO);
		config.setNettyThreads(nettyThreads);
		return Redisson.createReactive(config);
	}

Excpetion:
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'redissonUtil': Unsatisfied dependency expressed through method 'setRedissonReactiveClient' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'RedissonReactive' defined in class path resource [com/sst/common/config/RedissonConfig.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.redisson.api.RedissonReactiveClient]: Factory method 'RedissonReactive' threw exception; nested exception is io.netty.resolver.dns.DnsNameResolverContext$SearchDomainUnknownHostException: Search domain query failed. Original hostname: 'www.chasel.com' failed to resolve 'www.chasel.com' after 2 queries 
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:667)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151)
	at com.sst.AdminApiApplication.main(AdminApiApplication.java:13)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'RedissonReactive' defined in class path resource [com/sst/common/config/RedissonConfig.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.redisson.api.RedissonReactiveClient]: Factory method 'RedissonReactive' threw exception; nested exception is io.netty.resolver.dns.DnsNameResolverContext$SearchDomainUnknownHostException: Search domain query failed. Original hostname: 'www.chasel.com' failed to resolve 'www.chasel.com' after 2 queries 
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:599)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:659)
	... 19 common frames omitted
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.redisson.api.RedissonReactiveClient]: Factory method 'RedissonReactive' threw exception; nested exception is io.netty.resolver.dns.DnsNameResolverContext$SearchDomainUnknownHostException: Search domain query failed. Original hostname: 'www.chasel.com' failed to resolve 'www.chasel.com' after 2 queries 
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:189)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
	... 31 common frames omitted
Caused by: io.netty.resolver.dns.DnsNameResolverContext$SearchDomainUnknownHostException: Search domain query failed. Original hostname: 'www.chasel.com' failed to resolve 'www.chasel.com' after 2 queries 
	at io.netty.resolver.dns.DnsNameResolverContext.finishResolve(DnsNameResolverContext.java:728)
	at io.netty.resolver.dns.DnsNameResolverContext.tryToFinishResolve(DnsNameResolverContext.java:670)
	at io.netty.resolver.dns.DnsNameResolverContext.query(DnsNameResolverContext.java:306)
	at io.netty.resolver.dns.DnsNameResolverContext.query(DnsNameResolverContext.java:295)
	at io.netty.resolver.dns.DnsNameResolverContext.access$700(DnsNameResolverContext.java:60)
	at io.netty.resolver.dns.DnsNameResolverContext$3.operationComplete(DnsNameResolverContext.java:346)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:485)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:121)
	at io.netty.resolver.dns.DnsQueryContext.setFailure(DnsQueryContext.java:223)
	at io.netty.resolver.dns.DnsQueryContext.access$300(DnsQueryContext.java:42)
	at io.netty.resolver.dns.DnsQueryContext$4.run(DnsQueryContext.java:162)
	at io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38)
	at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:125)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:886)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: io.netty.resolver.dns.DnsNameResolverTimeoutException: [/10.3.0.28:53] query timed out after 5000 milliseconds (no stack trace available)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1487
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
question
java project springboot+redission only, RedisCluster scanInterval 1000ms，jvm create too many HashMap.Node, cause YGC quickly, I see ClusterConnectionManager.java source
private void scheduleClusterChangeCheck(...){
}
private void checkSlotsChange(cfg, newPartitions) {
Collection newPartitionsSlots = slots(newPartitions);
...
}
private Collection<Integer> slots(Collection<ClusterPartition> partitions) {
   // **** create 16384 capacity HashMap.Node ***//
    Set<Integer> result = new HashSet<Integer>(MAX_SLOT);
    for (ClusterPartition clusterPartition : partitions) {
        result.addAll(clusterPartition.getSlots());
    }
    return result;
}


$ sudo /usr/local/java/jdk/bin/jstat -gc 6623
﻿ S0C    S1C    S0U    S1U      EC	EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT
17920.0 19456.0 15506.0  0.0   772608.0 189177.1  165888.0   42155.6   52352.0 51221.4 6528.0 6239.4     14    0.102   2      0.081    0.183
Expected behavior
null
Actual behavior
num     instances         bytes  class name
1:       4719787	 151033184  java.util.HashMap$Node
2:         23692	 118076728  [Ljava.util.HashMap$Node;
3:        571827	  99347520  [C
4:        165795	  89233304  [I
5:       1192658	  19082528  java.lang.Integer
6:         16348	  16425592  [B
7:        357968        8591232  java.lang.String
8:         37014        5820136  [Ljava.lang.Object;
9:         43160        3798080  java.lang.reflect.Method
10:         80343        2570976  java.util.concurrent.ConcurrentHashMap$Node
11:         34579        2213056  java.net.URL
Steps to reproduce or test case
watch -n1 "sudo /usr/local/java/jdk/bin/jmap -histo pid"
Redis version
4.0.0+
Redisson version
3.7.1
Redisson configuration
// redis-cluster,3M-3S
Config config = new Config();
config.useClusterServers()
.setScanInterval(1000)
.addNodeAddress("redis://127.0.0.1:7001", "redis://127.0.0.1:7002")
.addNodeAddress("redis://127.0.0.1:7003", "redis://127.0.0.1:7004")
.addNodeAddress("redis://127.0.0.1:7005", "redis://127.0.0.1:7006")；
RedissonClient redisson = Redisson.create(config);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1488
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
How can I provide timezone in scheduled tasks according to which tasks should be executed.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1489
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
I imported Redission in spring boot using distributedLock,but the log always show this WARN
Actual behavior
collection-web 2018-06-13 20:50:24.428 WARN  --- [Thread-7] org.springframework.beans.factory.support.DisposableBeanAdapter Line:371 - Invocation of destroy method 'close' failed on bean with name 'jCacheCacheManager'
java.lang.NullPointerException: null
at org.redisson.jcache.JCacheManager.close(JCacheManager.java:368)
at org.redisson.jcache.JCachingProvider.close(JCachingProvider.java:183)
at org.redisson.jcache.JCacheManager.close(JCacheManager.java:360)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:497)
at org.springframework.beans.factory.support.DisposableBeanAdapter.invokeCustomDestroyMethod(DisposableBeanAdapter.java:364)
at org.springframework.beans.factory.support.DisposableBeanAdapter.destroy(DisposableBeanAdapter.java:287)
at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroyBean(DefaultSingletonBeanRegistry.java:578)
at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingleton(DefaultSingletonBeanRegistry.java:554)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingleton(DefaultListableBeanFactory.java:961)
at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingletons(DefaultSingletonBeanRegistry.java:523)
at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.destroySingletons(FactoryBeanRegistrySupport.java:230)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingletons(DefaultListableBeanFactory.java:968)
at org.springframework.context.support.AbstractApplicationContext.destroyBeans(AbstractApplicationContext.java:1030)
at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:1006)
at org.springframework.context.support.AbstractApplicationContext.close(AbstractApplicationContext.java:958)
at org.springframework.boot.actuate.endpoint.ShutdownEndpoint$1.run(ShutdownEndpoint.java:74)
at java.lang.Thread.run(Thread.java:745)
Steps to reproduce or test case
Redis version
Redisson version
3.7.0
Redisson configuration
this is my configuration class:
/**
*
* @return
*/
@bean
RedissonClient redissonClient() {
List nodeList = redisClusterConfigProperties.getNodes();
Config config = new Config();
ClusterServersConfig clusterServersConfig = config.useClusterServers();
for (String node : nodeList) {
clusterServersConfig = config.useClusterServers().addNodeAddress("redis://" + node);
}
clusterServersConfig.setScanInterval(2000);
return Redisson.create(config);
}
@Bean
CacheManager cacheManager(RedissonClient redissonClient) {
    Map<String, CacheConfig> config = new HashMap<>();
    config.put("testMap", new CacheConfig(24*60*1000, 12*60*1000));
    return new RedissonSpringCacheManager(redissonClient, config);
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1490
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
New feature of upcoming Redis 5.0
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1491
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have one RunnableTask which makes a HTTP request and hence needs a dependency of HTTP client. This job looks like this.
import com.mashape.unirest.http.Unirest;
import com.mashape.unirest.http.exceptions.UnirestException;

public class RunnableTask implements Runnable {
    private int job_no;
    RunnableTask(int job_no) {
        this.job_no = job_no;
    }
    public RunnableTask() {}
    public void run() {
        try {
            System.out.println(Unirest.get("http://192.168.1.108:3000").asString().getBody() + " " + job_no);
        } catch (UnirestException e) {
            e.printStackTrace();
        }
    }
}
Now I am scheduling some jobs using this code.
public class Main {
    private final static int NO_OF_JOBS = 10;
    static int i = 1;
    public static void main(String[] args) {
        //initUnirest();
        Config config = new Config();
        config.useClusterServers()
                .addNodeAddress("http://127.0.0.1:7000", "http://127.0.0.1:7001", "http://127.0.0.1:7002");
        RedissonClient redisson = Redisson.create(config);

//Block-1
       /* RedissonNodeConfig nodeConfig = new RedissonNodeConfig(config);
        nodeConfig.setThreads(100);
        nodeConfig.setExecutorServiceWorkers(Collections.singletonMap("d1", 1));
        RedissonNode.create(nodeConfig).start();
*/
        RExecutorService e = redisson.getExecutorService("d1");
        //redisson.getExecutorService("d1").registerWorkers(10, Executors.newFixedThreadPool(10));
        for (int j = 0; j < NO_OF_JOBS; j++) {
            Calendar calendar = Calendar.getInstance();
            int hour = calendar.get(Calendar.HOUR_OF_DAY);
            int minute = calendar.get(Calendar.MINUTE) + 1;
            //System.out.println("hour, minute" + hour + ", " + minute);
            RExecutorFuture r = (RExecutorFuture) ((RScheduledExecutorService) e).schedule(new RunnableTask(j + 1), CronSchedule.dailyAtHourAndMinute(hour, minute));
            //System.out.println(r.getTaskId());
        }
    }
}
After this I launched a RedissonNode in standalone mode. Now when the time for the execution of this jobs come, I am getting following error.
[redisson-3-30] ERROR org.redisson.RedissonRemoteService - Can't execute: RemoteServiceRequest [requestId=01ff7d044609fe82f2a85d5eb665839f45, methodName=schedule, signatures=[[java.lang.String, [B, [B, long, java.lang.String, java.lang.String, java.lang.String]], args=[com.webengage.MRunnableTask, [B@3f8166bd, [B@7a83ef29, 1529334600000, 0 40 20 ? * *, cf987ea1-4e2b-4335-93f1-02baaccfca19, 01ff7d044609fe82f2a85d5eb665839f45], options=RemoteInvocationOptions[ackTimeoutInMillis=null, executionTimeoutInMillis=null], date=1529334573532]
java.lang.reflect.InvocationTargetException
	at sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.redisson.RedissonRemoteService.invokeMethod(RedissonRemoteService.java:347)
	at org.redisson.RedissonRemoteService.access$400(RedissonRemoteService.java:66)
	at org.redisson.RedissonRemoteService$2.run(RedissonRemoteService.java:312)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NoClassDefFoundError: com/mashape/unirest/http/exceptions/UnirestException
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:348)
	at com.fasterxml.jackson.databind.type.TypeFactory.classForName(TypeFactory.java:278)
	at com.fasterxml.jackson.databind.type.TypeFactory.findClass(TypeFactory.java:258)
	at com.fasterxml.jackson.databind.jsontype.impl.ClassNameIdResolver._typeFromId(ClassNameIdResolver.java:68)
	at com.fasterxml.jackson.databind.jsontype.impl.ClassNameIdResolver.typeFromId(ClassNameIdResolver.java:51)
	at com.fasterxml.jackson.databind.jsontype.impl.TypeDeserializerBase._findDeserializer(TypeDeserializerBase.java:158)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedForId(AsPropertyTypeDeserializer.java:106)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:91)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromAny(AsPropertyTypeDeserializer.java:163)
	at com.fasterxml.jackson.databind.deser.std.UntypedObjectDeserializer$Vanilla.deserializeWithType(UntypedObjectDeserializer.java:554)
	at com.fasterxml.jackson.databind.deser.impl.TypeWrappedDeserializer.deserialize(TypeWrappedDeserializer.java:63)
	at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3807)
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2867)
	at org.redisson.codec.JsonJacksonCodec$2.decode(JsonJacksonCodec.java:92)
	at org.redisson.executor.TasksRunnerService.decode(TasksRunnerService.java:246)
	at org.redisson.executor.TasksRunnerService.executeRunnable(TasksRunnerService.java:268)
	at org.redisson.executor.TasksRunnerService.schedule(TasksRunnerService.java:126)
	... 12 more
Caused by: java.lang.ClassNotFoundException: com.mashape.unirest.http.exceptions.UnirestException
	at java.lang.ClassLoader.findClass(ClassLoader.java:530)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 30 more

But when I uncomment the part of code described below, i.e., I launch the RedissonNodes from the same process and not in standalone mode, jobs get executed successfully.
RedissonNodeConfig nodeConfig = new RedissonNodeConfig(config);
        nodeConfig.setThreads(100);
        nodeConfig.setExecutorServiceWorkers(Collections.singletonMap("d1", 1));
        RedissonNode.create(nodeConfig).start();
@mrniko @jackygurui
Anyone please explain why this is happening and resolution for this issue.
Redis version
4.0.9
Redisson version
3.7.2
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1492
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I'm using the Redis Cell module for keeping track of rate limits on certain keys. Unfortunately with Redisson this means I have to use the low level client for now but it would be nice to include a method for the CL.THROTTLE command used in Redis Cell module with the high level client.
This is not related to RRateLimiter which to my understanding is for throttling calls to Redis itself.
Redis Cell
https://github.com/brandur/redis-cell
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1493
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Issue since Redisson 3.7.1
Line 125 of RedissonRateLimiter.java throws a null pointer exception when the time unit  parameter is null. When you call the acquire methods it passes a null for that parameter. Basic unit tests for the acquire method would have caught this.
 @Override public RFuture<Boolean> tryAcquireAsync(long permits, long timeout, TimeUnit unit) { RPromise<Boolean> promise = new RedissonPromise<Boolean>(); tryAcquireAsync(permits, promise, unit.toMillis(timeout)); return promise;  }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1494
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
public class Main {

    private final static int NO_OF_JOBS = 10;
    static int i = 1;

    public static void main(String[] args) {
        Config config = new Config();
        config.useClusterServers()
                .addNodeAddress("http://127.0.0.1:7000", "http://127.0.0.1:7001", "http://127.0.0.1:7002");
        RedissonClient redisson = Redisson.create(config);
        RExecutorService e = redisson.getExecutorService("d1");
        for (int j = 0; j < NO_OF_JOBS; j++) {
            Calendar calendar = Calendar.getInstance();
            int hour = calendar.get(Calendar.HOUR_OF_DAY);
            int minute = calendar.get(Calendar.MINUTE) + 1;
            RExecutorFuture r = (RExecutorFuture) ((RScheduledExecutorService) e).schedule(new MRunnableTask(j + 1), CronSchedule.dailyAtHourAndMinute(hour, minute));//line-1
            //RExecutorFuture r = (RExecutorFuture) ((RScheduledExecutorService) e).schedule(new MRunnableTask(j + 1), CronSchedule.of("0 44 12 19 JUN ? 2018"));//line-2
        }
    }
}
I have used two methods to schedule the jobs. In method-1 I have used line-1 to schedule the job and in method-2 I have used line-2 to schedule the job. The problem I am facing is that method-1 is working fine but when I comment the line-1 and use method-2 instead the jobs doesn't get executed and I get the error as described below.
[redisson-3-52] ERROR org.redisson.RedissonRemoteService - Can't execute: RemoteServiceRequest [requestId=010c22ce1141604daa2fbe2c7d8254f5b0, methodName=schedule, signatures=[[java.lang.String, [B, [B, long, java.lang.String, java.lang.String, java.lang.String]], args=[com.webengage.MRunnableTask, [B@746aebd, [B@9815025, 1529393160000, 0 56 12 19 JUN ? 2018, 5ede66a4-83f0-4a19-b742-f126e7173a4d, 010c22ce1141604daa2fbe2c7d8254f5b0], options=RemoteInvocationOptions[ackTimeoutInMillis=null, executionTimeoutInMillis=null], date=1529393122775]
java.lang.reflect.InvocationTargetException
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.redisson.RedissonRemoteService.invokeMethod(RedissonRemoteService.java:347)
	at org.redisson.RedissonRemoteService.access$400(RedissonRemoteService.java:66)
	at org.redisson.RedissonRemoteService$2.run(RedissonRemoteService.java:312)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.redisson.executor.TasksRunnerService.schedule(TasksRunnerService.java:124)
	... 12 more

@jackygurui @mrniko kindly look into this.
I am using redisson 3.7.2 in standalone mode and redis 4.0.9.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1495
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When I am sure that I will be definitely having a class already loaded in memory, is there any way to avoid serialization and deserialization of whole class.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1496
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
As per my understanding, Redisson serializes the class at the time of scheduling the job and deserializes it at the time of execution of the job. If the class is already in memory at the time of execution of the job  then what does redisson do.
Kindly explain me this in details and also correct me if my understanding is not correct.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1497
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
setPingConnectionInterval should send periodic ping messages and keep channels alive, but this must not affect any other type of messages on channels.
Actual behavior
When using setPingConnectionInterval some messages will not be delivered to listeners after being published. I have a test code which can reliably reproduce this issue:
import org.redisson.Redisson;
import org.redisson.api.RTopic;
import org.redisson.api.RedissonClient;
import org.redisson.codec.SerializationCodec;
import org.redisson.config.Config;
import org.redisson.config.SubscriptionMode;

import java.util.UUID;
import java.util.concurrent.ConcurrentSkipListSet;

public class PlainPubSubTest {

    public static void main(String[] args) throws InterruptedException {
        ConcurrentSkipListSet<String> sentItems = new ConcurrentSkipListSet<>();
        ConcurrentSkipListSet<String> receivedItems = new ConcurrentSkipListSet<>();

        System.out.println("Staring test");

        RedissonClient redissonClient = redissonClient(configSentinel());

        RTopic<String> eventsTopic = redissonClient.getTopic("eventsTopic");
        eventsTopic.addListener((channel, msg) -> receivedItems.add(msg));

        System.out.println("Starting sending loop");
        for(int i = 0; i<1000; i++){
            final String message = UUID.randomUUID().toString();
            eventsTopic.publish(message);
            sentItems.add(message);
            Thread.sleep(10);
        }

        System.out.println("Sent: " + sentItems.size() + ", got: " + receivedItems.size());
        Thread.sleep(1000);
        System.out.println("Sent: " + sentItems.size() + ", got: " + receivedItems.size());
    }

    private static RedissonClient redissonClient(Config config){
        return Redisson.create(config);
    }

    private static Config configSentinel(){
        Config config = new Config();
        config.setCodec(new SerializationCodec());
        String password = "*****************";
        String masterName = "my-master-name";
        String[] sentinelAddresses = new String[]{"redis://localhost:26001", "redis://localhost:26002", "redis://localhost:26003"};
        Integer connectionTimeout = 10000;
        int pingTimeout = 5000;
        int reconnectionTimeout = 5000;
        int connectionPoolSize = 10;
        int connectionPoolMinSize = 10;
        int connectionPingInterval = 50; //Changing to 0 eliminates issue
        config.useSentinelServers()
                .setPassword(password)
                .setMasterName(masterName)
                .addSentinelAddress(sentinelAddresses)
                .setConnectTimeout(connectionTimeout)
                .setPingTimeout(pingTimeout)
                .setPingConnectionInterval(connectionPingInterval)
                .setSubscriptionMode(SubscriptionMode.MASTER)
                .setFailedSlaveReconnectionInterval(reconnectionTimeout)
                .setMasterConnectionMinimumIdleSize(connectionPoolMinSize)
                .setMasterConnectionPoolSize(connectionPoolSize);
        return config;
    }
}

Output of this code will produce varying results each time, but it will never get all sent messages, like this:
Staring test
Starting sending loop
Sent: 1000, got: 640
Sent: 1000, got: 640

However if connectionPingInterval is set to 0 (disabled) issue is completely eliminated, like this:
Staring test
Starting sending loop
Sent: 1000, got: 1000
Sent: 1000, got: 1000

Redis version
redis_version:4.0.6
redis_git_sha1:00000000
redis_git_dirty:0
redis_build_id:f1060815dd32471a
redis_mode:standalone
os:Linux 3.10.0-514.26.1.el7.x86_64 x86_64

Redisson version
3.7.2
Redisson configuration
Visible in test case
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1498
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Code
//过滤第二个finishCall事件
RSet<String> finishedCallSet = cacheService.getFinishedCallSet();
RLock callIdLock = finishedCallSet.getLock(callId);
callIdLock.lock();
try {
    if (finishedCallSet.contains(callId)) {
        log.info("receive finishCall second time, callId is: {}", callId);
        return;
    }
    log.info("receive finishCall first time, callId is: {}", callId);
    finishedCallSet.add(callId);
} finally {
    callIdLock.unlock();
}﻿
Expected behavior
finishedCallSet.add(callId);只被调用一次
Actual behavior
finishedCallSet.add(callId);被调用了两次
原因猜想
redis slave是readonly的，lock可能也起作用了，但是在slave和master之间同步数据时调用了contains方法，而这时slave还没有同步完数据，返回了false，finishedCallSet.add(callId)被调用了两次。
Redis version
3.2.11
Redisson version
3.6.4
Redisson configuration
@Bean(destroyMethod = "shutdown")
public RedissonClient prodRedisson() {
    String[] sentinelAddress = sentinelServers.values().stream()
            .map(sentinelServer -> "redis://" + sentinelServer.getHost() + ":" + sentinelServer.getPort())
            .collect(Collectors.toList())
            .toArray(new String[0]);
    Config config = new Config();
    config.useSentinelServers()
            .setDatabase(database)
            .setClientName(clientName)
            .setMasterName(masterName)
            .setPassword(password)
            .setSlaveConnectionMinimumIdleSize(slaveConnectionMinimumIdleSize)
            .setSlaveConnectionPoolSize(slaveConnectionPoolSize)
            .setMasterConnectionMinimumIdleSize(masterConnectionMinimumIdleSize)
            .setMasterConnectionPoolSize(masterConnectionPoolSize)
            .setIdleConnectionTimeout(idleConnectionTimeout)
            .setTimeout(timeout)
            .setRetryAttempts(retryAttempts)
            .setRetryInterval(retryInterval)
            .addSentinelAddress(sentinelAddress);
    return Redisson.create(config);
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1499
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1500
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@mrniko @jackygurui
If I want to schedule a job with certain cron expression, how do I specify that job should only run between some start and end time, whenever its execution according to the cron occurs. Like it is provided in quartz.
@mrniko
I also feel there should be support for cron expression with delay as well.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1501
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
How can I perform some task after execution of some job?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1502
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
Redisson version
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1503
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Since I get taskId after scheduling the task, how can I provide taskId to the RunnableTask, so that I can have taskId during execution of task.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1504
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
How to schedule a task that would run at particular time, currently I tried to do this with cron expression but it is giving error as described here.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1505
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi I have a distributed application that servers user requests. I want to implement distributed locking to synchronize access to user's data if multiple requests for the same user come in.
I'm using redisson with azure redis cache in cluster mode with 3 masters, 3 slaves for this purpose. My incoming request rate is 700/s, with total request processing times ~30-40ms. I've set the redisson cluster config as below (pool size=320, lock_wait_time=3000ms, lock_expiry_time=3000ms). However, I notice that in spite of tuning the connection pool size from 250-700, a small portion of requests fail while waiting to acquire the lock.
Questions:

Is my usage of redisson redlock below correct?
Any recommendations on how I can tune the config to resolve the "failed to acquire lock" errors?
The average redisson lock times i'm seeing are ~20-30ms. Is that expected? I also write user data to redis with JedisCluster in the same application and the cache get/set times are ~1-2ms.

Application algorithm
//acquire lock (lockname="Lock_"+userid)
//process user's data
//unlock "Lock_"+userid
My Spring config
<redisson:client
				id="redissonClient"
				name="redissonClient"
				threads="0"
				netty-threads="0"
		>
				<redisson:cluster-servers
				    idle-connection-timeout="10000"
				    ping-timeout="1000"
				    connect-timeout="5000"
				    timeout="3000"
				    retry-attempts="1"
				    retry-interval="1500"
				    password="<my_pwd>"
				    subscriptions-per-connection="0"
				    client-name="none"
				    slave-connection-minimum-idle-size="0"
				    slave-connection-pool-size="0"
				    master-connection-minimum-idle-size="50"
				    master-connection-pool-size="320"
				    read-mode="MASTER"
				    scan-interval="1000"
				>
				    <redisson:node-address value="redis://my_azure_rediscache.windows.net:6379" />
				</redisson:cluster-servers>
		</redisson:client>

Application code snippet for locking
RedissonRedLock redLock = null; 
		RLock rLock = null;
		try
		{
                       String lockName = "Lock_" + userId;
			rLock = redissonClient.getLock(lockName);
			redLock = new RedissonRedLock(rLock);
			if(!redLock.tryLock(3000, 3000, TimeUnit.MILLISECONDS))
			{
	        	throw new MyException("Cannot acquire cache lock for " + lockName);
			}
		}
		catch (InterruptedException e)
		{
			throw new MyException (Lock operation interrupted for " + lockName));
		}

Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1506
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Why would you even schedule a job thats never going to be executed?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1507
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
When using redisson MapCache expiration I would like a replace to refresh the idleTimeout, so that a field does not expire as long as it is replaced within the idleTimeout period.  Note that replace returns the old value, so strictly speaking the value is accessed.
Actual behavior
Fields are expired after idleTimeout regardless of whether their values are replaced or not.
Steps to reproduce or test case
a test added to RedissonMapCacheTest, I would like it to pass:
@Test
public void testReplaceValueTTLIdleUpdate() throws InterruptedException {
    RMapCache<SimpleKey, SimpleValue> map = null;
	SimpleValue val1;
	try {
		map = redisson.getMapCache("simple");
		map.put(new SimpleKey("1"), new SimpleValue("2"), 1, TimeUnit.SECONDS, 500, TimeUnit.MILLISECONDS);

		Thread.sleep(300);
	
		// update value, would like idle timeout to be refreshed
		SimpleValue res = map.replace(new SimpleKey("1"), new SimpleValue("3"));
		assertThat(res).isNotNull();

		Thread.sleep(300);

		// if idle timeout has been updated val1 will be not be null, else it will be null
		val1 = map.get(new SimpleKey("1"));
		assertThat(val1).isNotNull(); // this throws an assertion error

		Thread.sleep(300);
		
		// val1 will have expired due to TTL
		val1 = map.get(new SimpleKey("1"));
		assertThat(val1).isNull();

	} catch (Exception e) {
		e.printStackTrace();
	} finally {
        map.remove(new SimpleKey("1"));
	}
}

Redis version
4.0.10
Redisson version
3.7.0, master
Redisson configuration
{
"singleServerConfig":{
"idleConnectionTimeout":10000,
"pingTimeout":3000,
"connectTimeout":10000,
"timeout":10000,
"retryAttempts":20,
"retryInterval":1500,
"password":null,
"subscriptionsPerConnection":15,
"clientName":null,
"subscriptionConnectionMinimumIdleSize":1,
"subscriptionConnectionPoolSize":50,
"connectionMinimumIdleSize":32,
"connectionPoolSize":64,
"database":3,
"address": "redis://xxx:6379"
},
"threads":40,
"nettyThreads": 40,
"codec":null,
"useLinuxNativeEpoll":false
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1508
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Redisson 3.7.0 shouldn't leak file handles.
Actual behavior
After upgrading from Redisson 3.5.5 to Redisson 3.7.0 With Elasticache cluster I noticed file handles are left open and within an hour all the handles are exhausted causing AWS ECS to terminate the service instance. The issue goes away once I revert back to 3.5.5
Steps to reproduce or test case
Use Redisson 3.7.0 with AWS ElasticCache Cluster.
Redis version
Elasticache 4.x
Redisson version
3.7.0
Redisson configuration
ElasticCache cluster. Following is the Spring code to configure redisson with cluster:
I've configured pool size at 20 and minimum pool size at 5. Scan interval is set at 2000 milliseconds.
	ClusterServersConfig clusterServersConfig = config.useClusterServers();
	clusterServersConfig.setScanInterval(<scan-interval>);
	for(String host: redisHostArr){
		clusterServersConfig.addNodeAddress("redis://"+host);
	}
	clusterServersConfig.setMasterConnectionPoolSize(<pool-size>);
	clusterServersConfig.setMasterConnectionMinimumIdleSize(<min-pool-size>);
	clusterServersConfig.setSlaveConnectionPoolSize(<pool-size>);
	clusterServersConfig.setSlaveConnectionMinimumIdleSize(<min-pool-size>);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1509
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
Redisson version
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1510
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
Redisson version
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1511
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is it any difference between this checks? I use getNodesGroup().pingAll() for pinging nodes with cluster config as well. Is it correct way or should I change check on getClusterNodesGroup().pingAll()?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1512
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
package src;
import org.redisson.api.RedissonClient;
import src.UserProfileStatus;
public class PresenceStore {
private static ConcurrentMap<String, ConcurrentHashMap<String, UserProfileStatus>> resourceStore = new ConcurrentHashMap<>();
public static RedissonClient redisson = Redisson.create();
private static RMap<String, RMap> resourcemap=  redisson.getMap("Anyone");
public  RLiveObjectService liveObjectService = redisson.getLiveObjectService();


public void AddResourceStore(String resourceId, ClientProfile clientProfile, String status) {

    UserProfile userProfile = clientProfile.getUserProfile();
    DeviceProfile deviceProfile = clientProfile.getDeviceProfile();
    userProfile = liveObjectService.merge(clientProfile.getUserProfile());
    deviceProfile = liveObjectService.merge(clientProfile.getDeviceProfile());
    // check userprofile and device profile class registered
    System.out.println(liveObjectService.isClassRegistered(UserProfile.class));
    System.out.println(liveObjectService.isClassRegistered(DeviceProfile.class));


   clientProfile = liveObjectService.merge(clientProfile);
    System.out.println("Client Profile Resistration State = " + liveObjectService.isClassRegistered(ClientProfile.class));

    RMap<String,UserProfileStatus> hmap= redisson.getMap(resourceId);
    UserProfileStatus userProfileStatus = new UserProfileStatus(clientProfile, status);
    // UserProfileStatus object is becoming "live" object
    userProfileStatus = liveObjectService.merge(userProfileStatus);
    System.out.println("UserProfile Registration Status = " + liveObjectService.isClassRegistered(UserProfileStatus.class));
    String key = clientProfile.getClientId();
    hmap.put(key, userProfileStatus);
    resourcemap.put(resourceId, hmap);
}

public  void GetResource(String resourceId){
    RMap<String,UserProfileStatus> hmap= resourcemap.get(resourceId);
    Set<Map.Entry<String,UserProfileStatus>>s= hmap.entrySet();
    Iterator i=s.iterator();

    hmap.forEach((K, V) -> {
        UserProfileStatus pstatus = V;
       (error line)---> System.out.println("Key: "+ K + "\nvalue : " + pstatus.getClientProfile());
    });

}

}



import org.redisson.api.annotation.REntity;
import org.redisson.api.annotation.RId;
import org.redisson.liveobject.resolver.LongGenerator;
import src.ClientProfile;
import src.DeviceProfile;
import src.UserProfile;
import java.util.Map;
@rentity
public class UserProfileStatus {
@RId(generator = LongGenerator.class)

private String status;
private ClientProfile clientProfile;

public UserProfileStatus(){System.out.println("my userprofilestatus");}

public UserProfileStatus(ClientProfile clientProfile, String status){
    System.out.println("in user profile status");
    this.setClientProfile(clientProfile);
    this.status=status;
}

public ClientProfile getClientProfile() {
    return clientProfile;
}

public void setClientProfile(ClientProfile clientProfile) {
    if (clientProfile == null) {
        throw new NullPointerException("clientProfile cannot be null");
    }
    this.clientProfile = clientProfile;
}

public String getStatus() {
    return status;
}

public void setStatus(String status) {
    this.status = status;
}

public void serializeToMap(Map<String, String> userData) {
    if(null == userData){

        return;
    }
    UserProfile userProfile = this.clientProfile.getUserProfile();
    userData.put("userId", userProfile.getUserId());
    userData.put("name", userProfile.getName());
    userData.put("displayName", userProfile.getDisplayName());
    userData.put("firstName", userProfile.getFirstName());
    userData.put("lastName", userProfile.getLastName());
    userData.put("emailId", userProfile.getEmailId());

    DeviceProfile deviceProfile = this.clientProfile.getDeviceProfile();
    userData.put("deviceId", deviceProfile.getDeviceId());
    userData.put("deviceDescription", deviceProfile.getDeviceDescription());

    userData.put("state", status);
}

}



package src;
import org.redisson.api.annotation.REntity;
import org.redisson.api.annotation.RId;
import org.redisson.liveobject.resolver.LongGenerator;
import org.redisson.liveobject.resolver.UUIDGenerator;
@rentity
public class ClientProfile {
@Rid
private String clientId;
private UserProfile userProfile;
private DeviceProfile deviceProfile;
public ClientProfile(UserProfile userProfile, DeviceProfile deviceProfile) {
    this.setUserProfile(userProfile);
    this.setDeviceProfile(deviceProfile);
    this.clientId = userProfile.getKey()+ "_" + deviceProfile.getKey();
}

public ClientProfile(){System.out.println("my client call");}

public ClientProfile(ClientProfile otherProfile){
    this.clientId = otherProfile.clientId;
    this.userProfile = otherProfile.userProfile;
    this.deviceProfile = otherProfile.deviceProfile;
}

public UserProfile getUserProfile() {
    return userProfile;
}

public void setUserProfile(UserProfile userProfile) {
    if (userProfile == null) {
        throw new NullPointerException("userProfile cannot be null");
    }
    this.userProfile = userProfile;
}

public DeviceProfile getDeviceProfile() {
    System.out.println("getdeviceprofile");return deviceProfile;
}

public void setDeviceProfile(DeviceProfile deviceProfile) {
    if (deviceProfile == null) {
        throw new NullPointerException("deviceProfile cannot be null");
    }
    this.deviceProfile = deviceProfile;
}

public String getClientId(){
    System.out.println("getting key");
    return this.clientId;
}

public static String getKey(String userId, String deviceId) {
    return userId + "_" + deviceId;
}

}
I am getting "java.lang.ClassCastException: org.redisson.RedissonMap cannot be cast to src.ClientProfile" error. can someone tell me why?(client profile also have 2 classes inside it).
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1513
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I was wondering what the standard approach is to Mitigate possible Concurrency issues when using Redisson as a spring data source.
I am working on an application that gets information from a source application and then layers updated over the top before delivering the updated information to the client.
The updates in this case are built for several sources, each one has its own queue.
When a new message is placed on any given queue my app reads the message from the queue, and attempts to create or update an updateObject in my redis cache.
My problem stems form the fact that messages are constantly being placed on these queues and updates to the updateObject are likely to come in quick succession.
Im concerned that this will lead to concurrent read write issues:
existing updateObject[id:1, foo:false, bar:false]
msg 1[foo:true]---> get existing updateObject[id:1, foo:false, bar:false]
msg2[bar:true]--> get existing updateObject[id:1, foo:false, bar:false]
msg 1[foo:true]---> update existing updateObject[id:1, foo:true, bar:false]
msg2[bar:true]--> get existing updateObject[id:1, foo:false, bar:true]
resulting updateObject[id:1, foo:false, bar:true]
I have attempted to solve this using @transactional and the RedissonTransactionManager but it doesn't seem to be halting the second messages update while the first message is still updating.
Any advice would be really appreciated,
Thank you
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1514
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Exception in thread "main" java.lang.NoSuchMethodError: io.netty.util.internal.StringUtil.indexOfNonWhiteSpace(Ljava/lang/CharSequence;I)I at io.netty.resolver.dns.UnixResolverDnsServerAddressStreamProvider.parse(UnixResolverDnsServerAddressStreamProvider.java:171) at io.netty.resolver.dns.UnixResolverDnsServerAddressStreamProvider.<init>(UnixResolverDnsServerAddressStreamProvider.java:90) at io.netty.resolver.dns.UnixResolverDnsServerAddressStreamProvider.<init>(UnixResolverDnsServerAddressStreamProvider.java:124) at io.netty.resolver.dns.UnixResolverDnsServerAddressStreamProvider.parseSilently(UnixResolverDnsServerAddressStreamProvider.java:66) at io.netty.resolver.dns.DnsServerAddressStreamProviders.<clinit>(DnsServerAddressStreamProviders.java:32) at org.redisson.connection.MasterSlaveConnectionManager.<init>(MasterSlaveConnectionManager.java:195) at org.redisson.connection.MasterSlaveConnectionManager.<init>(MasterSlaveConnectionManager.java:158) at org.redisson.connection.SingleConnectionManager.<init>(SingleConnectionManager.java:34) at org.redisson.config.ConfigSupport.createConnectionManager(ConfigSupport.java:192) at org.redisson.Redisson.<init>(Redisson.java:121) at org.redisson.Redisson.create(Redisson.java:158) at com.vanwardsmart.tools.RedisTool.init(RedisTool.java:53) at com.vanwardsmart.cloud.SmartServer.main(SmartServer.java:49)
设置了断点调试，发觉redission会读取/etc/resolv.conf文件，大概就说格式错误吧
可是这些地址格式是系统自动生成的，怎么回事
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1515
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
While building the redisson locally, I am getting the following error:
[ERROR] /Users/mehul/projects/redisson/redisson/src/test/java/org/redisson/RedissonLiveObjectServiceTest.java:[57,5] error: cannot find symbol
[ERROR]   symbol:   class REntity
[ERROR]   location: class RedissonLiveObjectServiceTest
[ERROR] 
[ERROR] -> [Help 1]
org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.7.0:testCompile (default-testCompile) on project redisson: Compilation failure
/Users/mehul/projects/redisson/redisson/src/test/java/org/redisson/RedissonLiveObjectServiceTest.java:[57,5] error: cannot find symbol
  symbol:   class REntity
  location: class RedissonLiveObjectServiceTest

    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:213)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:154)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:146)
    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)
    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)
    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)
    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)
    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:305)
    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)
    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)
    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:956)
    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:290)
    at org.apache.maven.cli.MavenCli.main (MavenCli.java:194)
    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke (Method.java:498)
    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289)
    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229)
    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:415)
    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:356)
Caused by: org.apache.maven.plugin.compiler.CompilationFailureException: Compilation failure
/Users/mehul/projects/redisson/redisson/src/test/java/org/redisson/RedissonLiveObjectServiceTest.java:[57,5] error: cannot find symbol
  symbol:   class REntity
  location: class RedissonLiveObjectServiceTest

    at org.apache.maven.plugin.compiler.AbstractCompilerMojo.execute (AbstractCompilerMojo.java:1161)
    at org.apache.maven.plugin.compiler.TestCompilerMojo.execute (TestCompilerMojo.java:176)
    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:137)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:208)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:154)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:146)
    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)
    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)
    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)
    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)
    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:305)
    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)
    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)
    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:956)
    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:290)
    at org.apache.maven.cli.MavenCli.main (MavenCli.java:194)
    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke (Method.java:498)
    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289)
    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229)
    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:415)
    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:356)
[ERROR] 
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException

In stable release version I can see 2.12.2 and 3.7.2, I am using 3.7.2 what is the purpose of other release 2.12.2, what is the difference between both.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1516
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
When we use addAndGetAsync the value of key is incremented or decremented.
Actual behavior
RMap.readAllValues() should return values as 0-> 1, 1- >2 but instead returns values in the form og
0->"0", 1->"2" where the Number class is a string value.
Iterating through this collection causes a class cast exception.
Redis version
4.0.10
Redisson version
3.7.2
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1517
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Currently when we schedule the job with scheduleWithFixedDelay() method, it takes only initial delay and delay. But if I do this then this will keep running the job forever. I think there should be version of scheduleWithFixedDelay() method which supports endTime as well.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1518
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Classloader passed into CustomObjectInputStream is not used to load proxied classes.
In my case redisson cant deserialize org.springframework.security.oauth2.client.token.AccessTokenRequest class
Actual behavior
Following exception is thrown during class loading:
Caused by: java.lang.ClassNotFoundException: org.springframework.security.oauth2.client.token.AccessTokenRequest
at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
at java.lang.Class.forName0(Native Method)
at java.lang.Class.forName(Class.java:348)
at java.io.ObjectInputStream.resolveProxyClass(ObjectInputStream.java:698)
at java.io.ObjectInputStream.readProxyDesc(ObjectInputStream.java:1559)
at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1515)
at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1774)
at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2000)
at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1924)
at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801)
at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
at java.io.ObjectInputStream.readObject(ObjectInputStream.java:371)
Steps to reproduce or test case
Redis version
4.x
Redisson version
3.6.5
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1519
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1520
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
这个我的配置
@bean
public RedissonClient singleRedissonLock () throws URISyntaxException {
Config config = new Config();
config.useSingleServer()
.setAddress("redis://" + ip + ":" + port)
.setConnectTimeout(500)
.setPassword(StringUtils.defaultIfEmpty(password, null));
return Redisson.create(config);
}
获取锁
`@Resource
private RedissonClient redisson;
@Override
public WorPtLock lockWaitAMoment(int workOrderId, String itemId, String tenantId, Long millisecond) {
    if (millisecond == null || millisecond <= 0) {
        millisecond = A_MOMENT;
    }
    WorPtLock worPtLock = new WorPtLock(workOrderId, itemId, tenantId);
    try {
        RLock lock = redisson.getLock(worPtLock.buildLockKey());
        boolean b = lock.tryLock(millisecond, TimeUnit.MILLISECONDS);
        if (b) {
            worPtLock.setLock(lock);
            worPtLock.setSuccess(true);
            logger.error("加锁中=====threadname:【{}】。。。。。key【{}】---{}", Thread.currentThread().getName(), worPtLock.buildLockKey(), i);
        } else {
            logger.error("加锁失败=====threadname:【{}】。。。。。key【{}】---{}", Thread.currentThread().getName(), worPtLock.buildLockKey(), i);
            worPtLock.setSuccess(false);
        }
    } catch (Exception e) {
        logger.error("获取锁失败,生产单id:{},itemID:{}", workOrderId, itemId);
        worPtLock.setSuccess(false);
    }
    return worPtLock;
}`
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1521
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I was working with multimaps and wondered, while they have a cache variant, why don't they have a locally cached variant?
If nothing speaks against it, could one be added?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1522
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
no expcetion
Actual behavior
java.lang.NumberFormatException: For input string: "QUEUED"
at org.redisson.command.CommandAsyncService.convertException(CommandAsyncService.java:343)
at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:170)
at org.redisson.command.CommandBatchService.execute(CommandBatchService.java:361)
at org.redisson.RedissonBatch.execute(RedissonBatch.java:267)
at som.executors.basic.RedissonTest.transactionTest(RedissonTest.java:38)
Caused by: java.lang.NumberFormatException: For input string: "QUEUED"
at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
at java.lang.Double.parseDouble(Double.java:538)
at java.lang.Double.valueOf(Double.java:502)
at org.redisson.client.protocol.convertor.DoubleReplayConvertor.convert(DoubleReplayConvertor.java:25)
at org.redisson.client.protocol.convertor.DoubleNullSafeReplayConvertor.convert(DoubleNullSafeReplayConvertor.java:27)
at org.redisson.client.protocol.convertor.DoubleNullSafeReplayConvertor.convert(DoubleNullSafeReplayConvertor.java:23)
at org.redisson.client.handler.CommandDecoder.handleResult(CommandDecoder.java:434)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:295)
at org.redisson.client.handler.CommandDecoder.decodeCommandBatch(CommandDecoder.java:229)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:135)
Steps to reproduce or test case
    RBatch batch = redissonClient.createBatch(BatchOptions.defaults().executionMode(BatchOptions.ExecutionMode.REDIS_WRITE_ATOMIC));

    batch.getScoredSortedSet("myZKey").addScoreAsync("abc", 1d);

    batch.execute();

Redis version
redis_version:4.0.7
Redisson version
Redisson 3.7.2
Redisson configuration
    Config config = new Config();
    config.setCodec(new StringCodec());
    config.useSingleServer()
            .setAddress("redis://localhost:6379")
            .setConnectionMinimumIdleSize(1)
            .setConnectionPoolSize(1);

    RedissonClient redissonClient = Redisson.create(config);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1523
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
一台物理机上多tomcat实例可用，多台物理机每台上一个Tomcat实例无法共享Session是怎么回事？
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1524
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The acquire method should block until a permit is available, but it blocks indefinitely instead of the remaining time until a new permit becomes available. From my testing I have found that it doesn't acquire a permit when one should be available based on the rate and interval I tested. If I set the rate to 1 every 5 seconds, it should take a loop of 10 single permit acquires approximately 50 seconds to complete. Instead it acquires the first permit, then blocks forever on the next acquires call.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1525
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
一台机器多tomcat实例可以，多台机器不行，请问应该如何实现
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1526
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
add new field to RLO, use get method will get default value.
Actual behavior
throw java.lang.NullPointerException: null
Steps to reproduce or test case
step 1:
@REntity
@Data
@NoArgsConstructor
@JsonIgnoreProperties(value = {"redisson_live_object"})
public class DeviceStatus {
  @RId
  @JsonIgnore
  private String uniqueId;
}
step 2:
use this object to store object to Redis
step 3:
add new private int temperature; to RLO,then call DeviceStatus.getTemperature() will throw a NullPointerException.
Redis version
latest
Redisson version
3.5.4
Redisson configuration
singleServerConfig:
    idleConnectionTimeout: 10000
    pingTimeout: 1000
    connectTimeout: 10000
    timeout: 3000
    retryAttempts: 3
    retryInterval: 1500
    reconnectionTimeout: 3000
    failedAttempts: 3
    password: 111111
    subscriptionsPerConnection: 5
    clientName: null
    address: "redis://ip:port"
    subscriptionConnectionMinimumIdleSize: 1
    subscriptionConnectionPoolSize: 50
    connectionMinimumIdleSize: 10
    connectionPoolSize: 64
    database: 0
    dnsMonitoring: false
    dnsMonitoringInterval: 5000
threads: 0
nettyThreads: 0
#codec: !<org.redisson.codec.JsonJacksonCodec> {}
codec: !<org.redisson.client.codec.StringCodec> {}
useLinuxNativeEpoll: false


Log
2018-06-29 18:38:58 ERROR [http-nio-8080-exec-3] o.a.c.c.C.[.[.[.[dispatcherServlet] 181 - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.NullPointerException] with root cause
java.lang.NullPointerException: null
	at com.parkbox.domain.DeviceStatus$ByteBuddy$BH8xEsX8.getDstSwitch(Unknown Source)
	at com.parkbox.service.impl.DeviceShadowServiceImpl.getDstSwitch(DeviceShadowServiceImpl.java:411)
	at com.parkbox.service.impl.DeviceStatusServiceImpl.handleTvAppSensor(DeviceStatusServiceImpl.java:139)
	at com.parkbox.service.impl.DeviceStatusServiceImpl$$FastClassBySpringCGLIB$$7118bd92.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:669)
	at com.parkbox.service.impl.DeviceStatusServiceImpl$$EnhancerBySpringCGLIB$$66332b32.handleTvAppSensor(<generated>)
	at com.parkbox.api.ReportController.tvAppSensor(ReportController.java:34)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:661)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:478)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1527
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
no exception
Actual behavior
19:40:15.066 [redisson-netty-1-2] ERROR o.r.c.handler.CommandPubSubDecoder - Unable to decode data. channel: [id: 0xcecad86a, L:/172.16.249.185:50579 - R:172.16.116.163/172.16.116.163:6379] message: *3
$11
unsubscribe
$18
redisson_sc:{test}
:0
java.util.concurrent.RejectedExecutionException: Task org.redisson.client.handler.CommandPubSubDecoder$2@7b1dcdb0 rejected from java.util.concurrent.ThreadPoolExecutor@44cda025[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 1]
at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
at org.redisson.client.handler.CommandPubSubDecoder.enqueueMessage(CommandPubSubDecoder.java:127)
at org.redisson.client.handler.CommandPubSubDecoder.decodeResult(CommandPubSubDecoder.java:90)
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:419)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:371)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:111)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
Steps to reproduce or test case
RSemaphore example
public static void main(String[] args) throws InterruptedException {
    Config config = new Config();
    config.useSingleServer()
            .setAddress("redis://172.16.116.163:" + REDIS_DEFAULT_PORT);

    RedissonClient redisson = Redisson.create(config);

    RSemaphore s = redisson.getSemaphore("test");
    s.trySetPermits(5);
    s.acquire(3);

    Thread t = new Thread() {
        @Override
        public void run() {
            RSemaphore s = redisson.getSemaphore("test");
            s.release();
            s.release();
        }
    };

    t.start();

    s.acquire(4);

    redisson.shutdown();
}

Redis version
4.0.7
Redisson version
Redisson 3.7.2
Redisson configuration
view example
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1528
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@mrniko @jackygurui
Job class
public class HttpJob implements Runnable {

    HttpClient client;

    public HttpJob() {

    }

    public HttpJob(HttpClient client) {
        this.client = client;
    }

    @Override
    public void run() {

        String url = "http://localhost:3000";
        HttpGet request = new HttpGet(url);

        HttpResponse response = null;
        try {
            response = client.execute(request);
            System.out.println("Response Code : " + response.getStatusLine().getStatusCode());
            System.out.println(response.getStatusLine());
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
I am running Redisson Nodes in standalone mode, at the time of execution of this job, I am getting following error.
[redisson-3-23] ERROR org.redisson.RedissonRemoteService - Can't execute: RemoteServiceRequest [requestId=010acb018185e3786b777fe305e192b32f, methodName=schedule, signatures=[[java.lang.String, [B, [B, long, java.lang.String, java.lang.String, java.lang.String]], args=[com.webengage.HttpJob, [B@1742e1f, [B@395ed74f, 1530533820000, 0 47 17 2 JUL ? 2018, 15728f50-6654-4c4e-b45a-39ccf60fa8f3, 010acb018185e3786b777fe305e192b32f], options=RemoteInvocationOptions[ackTimeoutInMillis=null, executionTimeoutInMillis=null], date=1530533769834]
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.redisson.RedissonRemoteService.invokeMethod(RedissonRemoteService.java:347)
	at org.redisson.RedissonRemoteService.access$400(RedissonRemoteService.java:66)
	at org.redisson.RedissonRemoteService$2.run(RedissonRemoteService.java:312)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: java.lang.IllegalStateException: Unable to initialize codec with ClassLoader parameter
	at org.redisson.executor.TasksRunnerService.executeRunnable(TasksRunnerService.java:281)
	at org.redisson.executor.TasksRunnerService.schedule(TasksRunnerService.java:130)
	... 13 more
Caused by: java.lang.IllegalStateException: Unable to initialize codec with ClassLoader parameter
	at org.redisson.executor.TasksRunnerService.decode(TasksRunnerService.java:256)
	at org.redisson.executor.TasksRunnerService.executeRunnable(TasksRunnerService.java:274)
	... 14 more
Caused by: com.fasterxml.jackson.databind.JsonMappingException: No suitable constructor found for type [simple type, class org.apache.http.impl.client.InternalHttpClient]: can not instantiate from JSON object (missing default constructor or creator, or perhaps need to add/enable type information?)
 at [Source: io.netty.buffer.ByteBufInputStream@63e0c28d; line: 1, column: 103] (through reference chain: HttpJob["client"])
	at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:256)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromObjectUsingNonDefault(BeanDeserializerBase.java:1134)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeFromObject(BeanDeserializer.java:298)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:168)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:135)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedForId(AsPropertyTypeDeserializer.java:120)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:91)
	at com.fasterxml.jackson.databind.deser.AbstractDeserializer.deserializeWithType(AbstractDeserializer.java:142)
	at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:493)
	at com.fasterxml.jackson.databind.deser.impl.FieldProperty.deserializeAndSet(FieldProperty.java:101)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:260)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:163)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:135)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedForId(AsPropertyTypeDeserializer.java:120)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:91)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromAny(AsPropertyTypeDeserializer.java:163)
	at com.fasterxml.jackson.databind.deser.std.UntypedObjectDeserializer$Vanilla.deserializeWithType(UntypedObjectDeserializer.java:554)
	at com.fasterxml.jackson.databind.deser.impl.TypeWrappedDeserializer.deserialize(TypeWrappedDeserializer.java:63)
	at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3807)
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2867)
	at org.redisson.codec.JsonJacksonCodec$2.decode(JsonJacksonCodec.java:92)
	at org.redisson.executor.TasksRunnerService.decode(TasksRunnerService.java:252)
	... 15 more

How can I inject such dependencies in redisson, I think this use case is quite natural, and should be definitely be accommodated.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1529
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1530
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
实际通过nginx在一台机器上模拟多服务测试﻿
Expected behavior
多应用服务可以实现session共享，redis记录session数据，正常访问系统
Actual behavior
可以实现session共享redis记录数据，但是访问系统速度变慢
Steps to reproduce or test case
实际操作按照下面操作配置
https://github.com/redisson/redisson/wiki/14.-%E7%AC%AC%E4%B8%89%E6%96%B9%E6%A1%86%E6%9E%B6%E6%95%B4%E5%90%88#145-tomcat%E4%BC%9A%E8%AF%9D%E7%AE%A1%E7%90%86%E5%99%A8tomcat-session-manager
Redis version
4.0.9
Redisson version
3.4.3
Tomcat version
8.5.28
Redisson configuration
Tomcat config配置文件
singleServerConfig:
  address: redis://127.0.0.1:6379
  password: asd123qwe

redisson config
redisson:
    address: redis://127.0.0.1:6379
    password: asd123qwe
    thread: 4
    codec: org.redisson.client.codec.StringCodec
    connectionMinimumIdleSize: 12
    idleConnectionTimeout: 10000
    pingTimeout: 1000
    connectTimeout: 10000
    timeout: 3000
    retryAttempts: 2
    retryInterval: 1500
    reconnectionTimeout: 3000
    failedAttempts: 2
    subscriptionsPerConnection: 5
    clientName: firstClient
    subscriptionConnectionMinimumIdleSize: 1
    subscriptionConnectionPoolSize: 5
    connectionPoolSize: 64
    database: 0
    dnsMonitoring: false
    dnsMonitoringInterval: 5000
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1531
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior

'readonly' command should not go to master everytime i send read operation.
'readonly' command is going to master or slave only onetime at first when making connection.

Actual behavior

'readonly' command is going to master everytime when i send read operation.
because of added 'readonly' command, master is not distributed throughput

Steps to reproduce or test case

make Redissonclient with ReadMode.MasterSlave
send read operation
redissonClient.eval(Mode.ReadOnly, "return redis.call('get', 'something')"...
'monitor' in redis console.
master node=>
'readonly'
[lua] return redis.call('get'.....
slave node =>
[lua] return redis.call('get'.....

Redis version
4.0.10
Redisson version
2.12.3  6/28 latest version with java7
Redisson configuration
AWS elasticache redis cluster enabled
Shard : 1 master / 1 slave
useClusterMode()
ReadMode : Master_Slave
command : eval(Mode.ReadOnly, "return redis.call('get',......
** actually, read operation is distributed propery, but master node get plus 'readonly' command. even though 'readonly' comman is not working at master node and not affecting anything functionally.
however this is big problem which increase throughput and cpu utilization on master node. finally, it is same as not distributed
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1532
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1533
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1534
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case

ReadMode : Slave
userClusterServer
ElastiCache Redis Cluster Enabled.
1 Master / 1 Slave

SourceCode------------------------------------------------------------

i make RedissClient when servlet server start up at frist like below.
i store redissonClient to static variable.

Config config = new Config();
config.setCodec(new StringCodec());
config.useClusterServers()
.setScanInterval(2000)
.addNodeAddress(clusterNodesAddress)
.setReadMode(ReadMode.SLAVE);
redissonClient = Redisson.create(config);


on each servlet request, i send read command like below to redis, in this case, it is problem.
result = redissonClient.getScript().eval(Mode.READ_ONLY, script, RScript.ReturnType.VALUE), keyList, argvList.toArray());


on each servlet request, i send read or write command like below to redis,  in this case, it is ok
result = redissonClient.getScript().eval(Mode.READ_WRITE, script, RScript.ReturnType.VALUE), keyList, argvList.toArray());




send read operation each reqeuest on servlet server continusly.
read operation is going slave well
start failover.
master redis is down.
occured error for 60 seconds.
slave is changed to master.
'cluster nodes' info is changed 1 master.  no slave.
redisson recognize changed master correctly and read from master instedad of slave.
read operation is going master well.
previous down master is up as slave.
'cluster nodes' info is changed 1 master and 1 slave.
redisson recognize new slave
------------------problem is started.
slave is loading data for syncing with master. it takes 10 minutes to load all data completely.
during 10 minutes, servlet server is going strange behavior and throuput is very lower and don't return any exception. i think some threads is hanging around Redisson connection with new slave loading data.
actually i expected returning error with timeout. why it is not returning any error until slave is completed loading data.
after 10 minutes which completed load data from slave. it is going back to normal and throuput become higer.
however, read operation with Mode.ReadOnly is going both master and slave not going to slave only.


problem.


when loading data at slave, redisson is sending read operation to slave. and read opeartion thread is hanging aroud somewhere in redisson.
read operation with Mode.ReadOnly is going well to slave only. however after failover, read operation is going both master and slave not going to slave only.

Redis version
4.0.10
Redisson version
java 7 latest version 2.12.3
Redisson configuration

ReadMode : Slave
userClusterServer
-ElastiCache Redis Cluster Enabled.
1 Master / 1 Slave
default options
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1535
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1536
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
I want to create a simple scheduled task with redisson & kotlin.
My Task:
class IncrementRunnableTask(private var counterName: String) : Runnable {

    @RInject
    lateinit var redisson: RedissonClient

    override fun run() {
        redisson.getAtomicLong(counterName).incrementAndGet()
    }

}

My Test:
    @Autowired
    lateinit var redissonClient: RedissonClient

    private lateinit var node: RedissonNode

    @Before
    fun setup() {
        val nodeConfig = RedissonNodeConfig(this.redissonClient.config)
        nodeConfig.executorServiceWorkers = Collections.singletonMap("test", 1)
        node = RedissonNode.create(nodeConfig);
        node.start()
    }

    @After
    fun after() {
        node.shutdown();
    }

    @Test
    @Throws(Exception::class)
    fun testRedisson() {
        val executor = redissonClient.getExecutorService("test", ExecutorOptions.defaults().taskRetryInterval(10, TimeUnit.SECONDS))
        val f = executor.schedule(IncrementRunnableTask("counter"), 1, TimeUnit.SECONDS)
        f.get()
        assertThat(redissonClient.getAtomicLong("counter").get()).isEqualTo(1)
    }


Actual behavior
I get an exception everytime
java.lang.reflect.InvocationTargetException: null
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_171]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_171]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_171]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_171]
	at org.redisson.RedissonRemoteService.invokeMethod(RedissonRemoteService.java:347) [redisson-3.7.3.jar:na]
	at org.redisson.RedissonRemoteService.access$400(RedissonRemoteService.java:66) [redisson-3.7.3.jar:na]
	at org.redisson.RedissonRemoteService$2.run(RedissonRemoteService.java:312) [redisson-3.7.3.jar:na]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_171]
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266) [na:1.8.0_171]
	at java.util.concurrent.FutureTask.run(FutureTask.java) [na:1.8.0_171]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_171]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_171]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-common-4.1.25.Final.jar:4.1.25.Final]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_171]
Caused by: java.lang.IllegalArgumentException: java.lang.IllegalStateException: Unable to initialize codec with ClassLoader parameter
	at org.redisson.executor.TasksRunnerService.executeRunnable(TasksRunnerService.java:281) ~[redisson-3.7.3.jar:na]
	at org.redisson.executor.TasksRunnerService.scheduleRunnable(TasksRunnerService.java:174) ~[redisson-3.7.3.jar:na]
	... 14 common frames omitted
Caused by: java.lang.IllegalStateException: Unable to initialize codec with ClassLoader parameter
	at org.redisson.executor.TasksRunnerService.decode(TasksRunnerService.java:256) ~[redisson-3.7.3.jar:na]
	at org.redisson.executor.TasksRunnerService.executeRunnable(TasksRunnerService.java:274) ~[redisson-3.7.3.jar:na]
	... 15 common frames omitted
Caused by: com.fasterxml.jackson.databind.exc.InvalidTypeIdException: Missing type id when trying to resolve subtype of [simple type, class java.lang.Object]: missing type id property '@class'
 at [Source: (io.netty.buffer.ByteBufInputStream); line: 1, column: 25]
	at com.fasterxml.jackson.databind.exc.InvalidTypeIdException.from(InvalidTypeIdException.java:43) ~[jackson-databind-2.9.6.jar:2.9.6]
	at com.fasterxml.jackson.databind.DeserializationContext.missingTypeIdException(DeserializationContext.java:1638) ~[jackson-databind-2.9.6.jar:2.9.6]
	at com.fasterxml.jackson.databind.DeserializationContext.handleMissingTypeId(DeserializationContext.java:1217) ~[jackson-databind-2.9.6.jar:2.9.6]
	at com.fasterxml.jackson.databind.jsontype.impl.TypeDeserializerBase._handleMissingTypeId(TypeDeserializerBase.java:300) ~[jackson-databind-2.9.6.jar:2.9.6]
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedUsingDefaultImpl(AsPropertyTypeDeserializer.java:164) ~[jackson-databind-2.9.6.jar:2.9.6]
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:105) ~[jackson-databind-2.9.6.jar:2.9.6]
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromAny(AsPropertyTypeDeserializer.java:193) ~[jackson-databind-2.9.6.jar:2.9.6]
	at com.fasterxml.jackson.databind.deser.std.UntypedObjectDeserializer$Vanilla.deserializeWithType(UntypedObjectDeserializer.java:712) ~[jackson-databind-2.9.6.jar:2.9.6]
	at com.fasterxml.jackson.databind.deser.impl.TypeWrappedDeserializer.deserialize(TypeWrappedDeserializer.java:68) ~[jackson-databind-2.9.6.jar:2.9.6]
	at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4013) ~[jackson-databind-2.9.6.jar:2.9.6]
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3070) ~[jackson-databind-2.9.6.jar:2.9.6]
	at org.redisson.codec.JsonJacksonCodec$2.decode(JsonJacksonCodec.java:92) ~[redisson-3.7.3.jar:na]
	at org.redisson.executor.TasksRunnerService.decode(TasksRunnerService.java:252) ~[redisson-3.7.3.jar:na]
	... 16 common frames omitted


Steps to reproduce or test case
Redis version
4.0.10
Redisson version
3.7.3
Redisson configuration
    fun redissonClient(): RedissonClient {
        return Redisson.create()
    }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1537
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1538
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1539
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1540
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1541
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1542
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1543
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1544
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1545
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1546
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1547
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1548
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1549
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1550
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1551
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1552
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1553
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1554
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1555
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1556
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1557
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1558
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1559
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1560
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1561
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1562
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1563
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1564
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1565
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1566
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1567
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1568
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1569
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1570
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1571
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1572
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1573
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1574
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1575
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1576
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1577
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1578
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1579
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1580
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1581
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1582
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1583
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1584
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1585
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1586
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1587
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1588
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1589
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1590
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1591
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1592
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1593
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1594
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1595
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1596
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1597
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1598
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1599
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1600
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1601
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1602
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1603
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1604
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1605
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1606
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1607
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1608
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1609
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1610
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1611
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1612
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1613
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1614
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1615
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1616
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1617
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1618
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1619
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1620
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1621
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1622
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1623
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1624
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1625
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1626
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1627
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1628
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1629
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1630
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1631
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1632
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1633
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1634
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1635
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1636
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1637
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1638
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1639
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1640
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1641
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1642
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1643
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1644
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1645
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1646
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1647
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1648
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1649
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1650
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1651
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1652
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1653
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1654
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1655
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1656
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1657
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1658
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1659
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1660
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1661
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1662
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1663
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1664
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1665
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1666
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1667
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1668
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1669
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1670
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1671
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1672
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1673
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1674
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1675
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1676
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1677
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1678
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1679
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1680
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1681
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1682
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1683
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1684
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1685
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
一个应用节点的连接数最多应该13个（主节点或者从节点）
Actual behavior
总连接数除以节点数，平均连接到170了
Steps to reproduce or test case
Redis version
4.0.2
Redisson version
3.7.2
Redisson configuration
集群模式
setMasterConnectionPoolSize(10)
setMasterConnectionMinimumIdleSize(1)
setSlaveConnectionPoolSize(10)
setSlaveConnectionMinimumIdleSize(1)
setSubscriptionConnectionPoolSize(3)
setSubscriptionConnectionMinimumIdleSize(1)
问题描述
线上出现redis单节点连接数超过4000，但每秒命令数只有700左右，通过client list发现3000多的连接最后执行命令是client，所以推测redisson客户端在执行client命令时单独开了连接，并且未释放
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1686
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi I am trying to use redis-graph with redisson and have trouble figuring out how to read the result set that redis-graph (https://github.com/RedisLabsModules/redis-graph) returns.
A typical result set can look like this.

(empty list or set)


Labels added: 1
Nodes created: 1
"Query internal execution time: 0.625300 milliseconds"



Ive tried a regular bytearray but get only the last line and then it times out.
Any tips?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1687
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
What are default values for the mentioned below properties?
Are these values from LocalCachedMapOptions::defaults()?
I see that local caches work, but only ttl, idle and maxSize are defined.
 localCacheOptions:
    evictionPolicy: "LRU"
    reconnectionStrategy: "CLEAR"
    syncStrategy: "UPDATE"
    writeMode: "WRITE_THROUGH"
    cacheSize: 1000
    timeToLiveInMillis: 300000
    maxIdleInMillis: 300000
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1688
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior : redisson-all-2.13.2.jar should be compatible with jdk 1.7 version as per publication .
Actual behavior : redisson-all-2.13.2.jar not compatible with jdk 1.7 version . It is giving following error when try to run the same with jdk 1.7 version
java.lang.UnsupportedClassVersionError: org/redisson/api/listener/MessageListener : Unsupported major.minor version 52.0
Steps to reproduce or test case : redisson-all-2.13.2.jar should work with jdk 1.7
execute the redisson-all-2.13.2.jar under jdk 1.7 version.
Redis version : Redis 3.2 (For windows machine)
Please provide same redisson-all-2.13.2.jar
with jdk 1.7 compiled.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1689
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1690
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
When we pass an executor in the redisson config, redisson should never shut it down.
Actual behavior
ReplicatedConnectionManager calls stopThreads from the parent class MasterSlaveConnectionManager.  The stopThreads method calls executor.shutdown() without checking who owns it.
Steps to reproduce or test case
This example should call stopThreads in the ReplicatedConnectionManager constructor because the config doesn't have any node addresses:
ExecutorService es = Executors.newCachedThreadPool();
Config config = new Config().setExecutor(executorService);
config.useReplicatedServers();
Redisson.create(config);

assert !es.isTerminated();
Redis version
3.2.6
Redisson version
3.8.2
Redisson configuration
config.setExecutor(executorService).useReplicatedServers()
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1691
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
actually our real application is running on Azure but I was able to compile a small application to demonstrate this issue locally. The main issue is that the reconnect behaviour of Redisson seems to be unreliable. Sometimes it works and sometimes it doesn't which seems to be rather independet of the choosen configuration options except for the retryAttempt and retryTimeout options. If those two options are too low the application is not able to recover in any case but this is expected behaviour of Redisson as far as I can tell.
Example project: redissondemo.zip
Am I missing something here?
Any help is appreciated!
Expected behavior
Redisson is trying to reconnect after a failure / failover of the Redis server.
Actual behavior
Redisson seems to be trying to reconnect but fails always except on a few non-reproducible occasions.
Steps to reproduce or test case
Used code to demonstrate the behaviour:
  public static void main(String... args) throws InterruptedException {

    RedissonClient redis = createClient();

    for (int i = 0; ; i++) {
      System.out.printf("%d. Reading queue...\n", i);
      RScoredSortedSet<String> queue = redis.getScoredSortedSet("queue");
      queue.readAll();

      Thread.sleep(2000);
    }
  }
Docker command to run a local instance of Redis:
docker run -p 6379:6379 redis:4.0.1-alpine redis-server --appendonly yes --requirepass 12345
Steps:

Start Redis
Start the test app
If everything seems to be running fine, stop the docker container with "docker stop ".
Wait some time and then start Redis again. I tried different intervals but it didn't seem to matter that much.

Depending on the set of choosen configuration options 1 - 3 the DEBUG log output varies but the end result is the same: no reconnect is going to happen. I tried it with option combinations "1;2;3", "1;3", "2;3" and with significantly lower values for the retryAttempts (option 3.1) such as 3 e.g.. As soon as the connection is lost any retry attempt seems to fail.
Although there seem to be exceptions from this behaviour. Sometimes the ConnectionWatchdog is taking action and is actually able to reconnect to the Redis server (Used configuration options: 1;2;3):
10:53:18.781 [pool-1-thread-1] DEBUG org.redisson.command.CommandAsyncService - connection released for command (ZRANGE) and params [queue, 0, -1] from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=50, freeConnectionsAmount=32, freeConnectionsCounter=64, freezed=false, freezeReason=null, client=[addr=redis://localhost:6379], nodeType=MASTER, firstFail=0]]] using connection RedisConnection@594558943 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xa539c9d3, L:/127.0.0.1:64254 ! R:localhost/127.0.0.1:6379]]
10:53:18.781 [pool-1-thread-1] DEBUG org.redisson.command.CommandAsyncService - attempt 2 for command (ZRANGE) and params [queue, 0, -1]
10:53:18.782 [pool-1-thread-1] DEBUG org.redisson.command.CommandAsyncService - acquired connection for command (ZRANGE) and params [queue, 0, -1] from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=50, freeConnectionsAmount=31, freeConnectionsCounter=63, freezed=false, freezeReason=null, client=[addr=redis://localhost:6379], nodeType=MASTER, firstFail=0]]] using node localhost/127.0.0.1:6379... RedisConnection@1820828774 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x2d49db0e, L:/127.0.0.1:64256 ! R:localhost/127.0.0.1:6379]]
10:53:19.080 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@1628212742 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x427ca2d0, L:/127.0.0.1:64252 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:19.081 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@2102139180 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x0ab1cf13, L:/127.0.0.1:64247 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:19.082 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@616106585 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xdd2417b7, L:/127.0.0.1:64248 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:19.083 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@237478270 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x5dc987ee, L:/127.0.0.1:64260 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:19.084 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@945308439 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x623e0129, L:/127.0.0.1:64246 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:19.085 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@1912870382 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xa6099b94, L:/127.0.0.1:64267 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:19.086 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@594558943 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xa539c9d3, L:/127.0.0.1:64254 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:19.088 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@422317778 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xc17d9f88, L:/127.0.0.1:64253 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:19.180 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@402279343 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xca894742, L:/127.0.0.1:64250 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:19.182 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@1888870336 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xb28bb7d7, L:/127.0.0.1:64257 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:19.183 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@2015163104 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xb55afe09, L:/127.0.0.1:64249 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:19.184 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@1820828774 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x2d49db0e, L:/127.0.0.1:64256 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:19.185 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@1900298624 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xcd907f69, L:/127.0.0.1:64266 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:22.180 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@1628212742 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x427ca2d0, L:/127.0.0.1:64252 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:22.181 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@2102139180 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x0ab1cf13, L:/127.0.0.1:64247 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:22.182 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@616106585 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xdd2417b7, L:/127.0.0.1:64248 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:22.184 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@237478270 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x5dc987ee, L:/127.0.0.1:64260 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:22.184 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@945308439 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x623e0129, L:/127.0.0.1:64246 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:22.185 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@1912870382 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xa6099b94, L:/127.0.0.1:64267 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:22.186 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@594558943 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xa539c9d3, L:/127.0.0.1:64254 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:22.187 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@422317778 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xc17d9f88, L:/127.0.0.1:64253 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:22.279 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@1888870336 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xb28bb7d7, L:/127.0.0.1:64257 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:22.280 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@402279343 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xca894742, L:/127.0.0.1:64250 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:22.282 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@2015163104 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xb55afe09, L:/127.0.0.1:64249 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:22.284 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@1900298624 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xcd907f69, L:/127.0.0.1:64266 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:22.285 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@1820828774 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x2d49db0e, L:/127.0.0.1:64256 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:23.881 [pool-1-thread-1] DEBUG org.redisson.command.CommandAsyncService - connection released for command (ZRANGE) and params [queue, 0, -1] from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=50, freeConnectionsAmount=32, freeConnectionsCounter=64, freezed=false, freezeReason=null, client=[addr=redis://localhost:6379], nodeType=MASTER, firstFail=0]]] using connection RedisConnection@1820828774 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x2d49db0e, L:/127.0.0.1:64256 ! R:localhost/127.0.0.1:6379]]
10:53:23.881 [pool-1-thread-1] DEBUG org.redisson.command.CommandAsyncService - attempt 3 for command (ZRANGE) and params [queue, 0, -1]
10:53:23.881 [pool-1-thread-1] DEBUG org.redisson.command.CommandAsyncService - acquired connection for command (ZRANGE) and params [queue, 0, -1] from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=50, freeConnectionsAmount=31, freeConnectionsCounter=63, freezed=false, freezeReason=null, client=[addr=redis://localhost:6379], nodeType=MASTER, firstFail=0]]] using node localhost/127.0.0.1:6379... RedisConnection@402279343 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xca894742, L:/127.0.0.1:64250 ! R:localhost/127.0.0.1:6379]]
10:53:27.381 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@2102139180 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x0ab1cf13, L:/127.0.0.1:64247 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:27.382 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@616106585 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xdd2417b7, L:/127.0.0.1:64248 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:27.383 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@1628212742 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x427ca2d0, L:/127.0.0.1:64252 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:27.385 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@237478270 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x5dc987ee, L:/127.0.0.1:64260 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:27.386 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@945308439 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x623e0129, L:/127.0.0.1:64246 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:27.387 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@1912870382 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xa6099b94, L:/127.0.0.1:64267 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:27.388 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@594558943 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xa539c9d3, L:/127.0.0.1:64254 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:27.389 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@422317778 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xc17d9f88, L:/127.0.0.1:64253 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:27.480 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@402279343 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xca894742, L:/127.0.0.1:64250 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:27.481 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@1888870336 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xb28bb7d7, L:/127.0.0.1:64257 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:27.482 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@2015163104 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xb55afe09, L:/127.0.0.1:64249 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:27.484 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@1900298624 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xcd907f69, L:/127.0.0.1:64266 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:27.485 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@1820828774 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x2d49db0e, L:/127.0.0.1:64256 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:28.982 [pool-1-thread-1] DEBUG org.redisson.command.CommandAsyncService - connection released for command (ZRANGE) and params [queue, 0, -1] from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=50, freeConnectionsAmount=32, freeConnectionsCounter=64, freezed=false, freezeReason=null, client=[addr=redis://localhost:6379], nodeType=MASTER, firstFail=0]]] using connection RedisConnection@402279343 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xca894742, L:/127.0.0.1:64250 ! R:localhost/127.0.0.1:6379]]
10:53:28.982 [pool-1-thread-1] DEBUG org.redisson.command.CommandAsyncService - attempt 4 for command (ZRANGE) and params [queue, 0, -1]
10:53:28.982 [pool-1-thread-1] DEBUG org.redisson.command.CommandAsyncService - acquired connection for command (ZRANGE) and params [queue, 0, -1] from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=50, freeConnectionsAmount=31, freeConnectionsCounter=63, freezed=false, freezeReason=null, client=[addr=redis://localhost:6379], nodeType=MASTER, firstFail=0]]] using node localhost/127.0.0.1:6379... RedisConnection@711012218 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x2135b4fc, L:/127.0.0.1:64263 ! R:localhost/127.0.0.1:6379]]
10:53:34.080 [pool-1-thread-1] DEBUG org.redisson.command.CommandAsyncService - connection released for command (ZRANGE) and params [queue, 0, -1] from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=50, freeConnectionsAmount=32, freeConnectionsCounter=64, freezed=false, freezeReason=null, client=[addr=redis://localhost:6379], nodeType=MASTER, firstFail=0]]] using connection RedisConnection@711012218 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x2135b4fc, L:/127.0.0.1:64263 ! R:localhost/127.0.0.1:6379]]
10:53:34.081 [pool-1-thread-1] DEBUG org.redisson.command.CommandAsyncService - attempt 5 for command (ZRANGE) and params [queue, 0, -1]
10:53:34.081 [pool-1-thread-1] DEBUG org.redisson.command.CommandAsyncService - acquired connection for command (ZRANGE) and params [queue, 0, -1] from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=50, freeConnectionsAmount=31, freeConnectionsCounter=63, freezed=false, freezeReason=null, client=[addr=redis://localhost:6379], nodeType=MASTER, firstFail=0]]] using node localhost/127.0.0.1:6379... RedisConnection@945308439 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x623e0129, L:/127.0.0.1:64246 ! R:localhost/127.0.0.1:6379]]
10:53:36.580 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@2102139180 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x0ab1cf13, L:/127.0.0.1:64247 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:36.680 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@616106585 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xdd2417b7, L:/127.0.0.1:64248 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:36.682 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@422317778 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xc17d9f88, L:/127.0.0.1:64253 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:36.684 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@945308439 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x623e0129, L:/127.0.0.1:64246 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:36.688 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@594558943 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xa539c9d3, L:/127.0.0.1:64254 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:36.693 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@1628212742 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x427ca2d0, L:/127.0.0.1:64252 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:36.698 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@1912870382 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xa6099b94, L:/127.0.0.1:64267 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:36.699 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@237478270 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x5dc987ee, L:/127.0.0.1:64260 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:36.701 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@1888870336 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xb28bb7d7, L:/127.0.0.1:64257 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:36.704 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@2015163104 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xb55afe09, L:/127.0.0.1:64249 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:36.707 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@1900298624 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xcd907f69, L:/127.0.0.1:64266 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:36.708 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@402279343 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xca894742, L:/127.0.0.1:64250 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:36.780 [pool-1-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@1820828774 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x2d49db0e, L:/127.0.0.1:64256 ! R:localhost/127.0.0.1:6379]] to localhost/127.0.0.1:6379 
10:53:37.619 [redisson-netty-1-6] DEBUG org.redisson.client.handler.ConnectionWatchdog - RedisConnection@2102139180 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xbdb55f94, L:/127.0.0.1:64464 - R:localhost/127.0.0.1:6379]] connected to localhost/127.0.0.1:6379, command: CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@5032b572(success: PONG)], command=(PING), params=[], codec=null]
10:53:37.703 [redisson-netty-1-2] DEBUG org.redisson.client.handler.ConnectionWatchdog - RedisConnection@594558943 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xd658ef5c, L:/127.0.0.1:64468 - R:localhost/127.0.0.1:6379]] connected to localhost/127.0.0.1:6379, command: CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@b1f479c(success: PONG)], command=(PING), params=[], codec=null]
10:53:37.704 [redisson-netty-1-4] DEBUG org.redisson.client.handler.ConnectionWatchdog - RedisConnection@422317778 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x425c25e1, L:/127.0.0.1:64466 - R:localhost/127.0.0.1:6379]] connected to localhost/127.0.0.1:6379, command: CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@5b5e4ff9(success: PONG)], command=(PING), params=[], codec=null]
10:53:37.704 [redisson-netty-1-6] DEBUG org.redisson.client.handler.ConnectionWatchdog - RedisConnection@1888870336 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x4c602033, L:/127.0.0.1:64472 - R:localhost/127.0.0.1:6379]] connected to localhost/127.0.0.1:6379, command: CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@127581ef(success: PONG)], command=(PING), params=[], codec=null]
10:53:37.706 [redisson-netty-1-7] DEBUG org.redisson.client.handler.ConnectionWatchdog - RedisConnection@402279343 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x1716d128, L:/127.0.0.1:64475 - R:localhost/127.0.0.1:6379]] connected to localhost/127.0.0.1:6379, command: CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@d308e5b(success: PONG)], command=(PING), params=[], codec=null]
10:53:37.707 [redisson-netty-1-5] DEBUG org.redisson.client.handler.ConnectionWatchdog - RedisConnection@1628212742 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x19561a14, L:/127.0.0.1:64469 - R:localhost/127.0.0.1:6379]] connected to localhost/127.0.0.1:6379, command: CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@331f1710(success: PONG)], command=(PING), params=[], codec=null]
10:53:37.709 [redisson-netty-1-8] DEBUG org.redisson.client.handler.ConnectionWatchdog - RedisConnection@2015163104 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xc3506c57, L:/127.0.0.1:64473 - R:localhost/127.0.0.1:6379]] connected to localhost/127.0.0.1:6379, command: CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@4747ca26(success: PONG)], command=(PING), params=[], codec=null]
10:53:37.711 [redisson-netty-1-8] DEBUG org.redisson.client.handler.ConnectionWatchdog - RedisConnection@616106585 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xd96f4e8e, L:/127.0.0.1:64465 - R:localhost/127.0.0.1:6379]] connected to localhost/127.0.0.1:6379, command: CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@31f0445d(success: PONG)], command=(PING), params=[], codec=null]
10:53:37.711 [redisson-netty-1-3] DEBUG org.redisson.client.handler.ConnectionWatchdog - RedisConnection@237478270 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x4225feb3, L:/127.0.0.1:64471 - R:localhost/127.0.0.1:6379]] connected to localhost/127.0.0.1:6379, command: CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@362fed26(success: PONG)], command=(PING), params=[], codec=null]
10:53:37.712 [redisson-netty-1-4] DEBUG org.redisson.client.handler.ConnectionWatchdog - RedisConnection@1900298624 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xe7de785b, L:/127.0.0.1:64474 - R:localhost/127.0.0.1:6379]] connected to localhost/127.0.0.1:6379, command: CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@703d4570(success: PONG)], command=(PING), params=[], codec=null]
10:53:37.712 [redisson-netty-1-2] DEBUG org.redisson.client.handler.ConnectionWatchdog - RedisConnection@1820828774 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xabb6a7f6, L:/127.0.0.1:64476 - R:localhost/127.0.0.1:6379]] connected to localhost/127.0.0.1:6379, command: CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@5b448656(success: PONG)], command=(PING), params=[], codec=null]
10:53:37.715 [redisson-netty-1-7] DEBUG org.redisson.client.handler.ConnectionWatchdog - RedisConnection@945308439 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xc4161bb2, L:/127.0.0.1:64467 - R:localhost/127.0.0.1:6379]] connected to localhost/127.0.0.1:6379, command: CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@3bfb8088(success: PONG)], command=(PING), params=[], codec=null]
10:53:37.716 [redisson-netty-1-6] DEBUG org.redisson.client.handler.ConnectionWatchdog - RedisConnection@1912870382 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xa9f59a80, L:/127.0.0.1:64470 - R:localhost/127.0.0.1:6379]] connected to localhost/127.0.0.1:6379, command: CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@583bbe8e(success: PONG)], command=(PING), params=[], codec=null]
10:53:39.181 [pool-1-thread-1] DEBUG org.redisson.command.CommandAsyncService - connection released for command (ZRANGE) and params [queue, 0, -1] from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=50, freeConnectionsAmount=32, freeConnectionsCounter=64, freezed=false, freezeReason=null, client=[addr=redis://localhost:6379], nodeType=MASTER, firstFail=0]]] using connection RedisConnection@945308439 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xc4161bb2, L:/127.0.0.1:64467 - R:localhost/127.0.0.1:6379]]
10:53:39.181 [pool-1-thread-1] DEBUG org.redisson.command.CommandAsyncService - attempt 6 for command (ZRANGE) and params [queue, 0, -1]
10:53:39.181 [pool-1-thread-1] DEBUG org.redisson.command.CommandAsyncService - acquired connection for command (ZRANGE) and params [queue, 0, -1] from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=50, freeConnectionsAmount=31, freeConnectionsCounter=63, freezed=false, freezeReason=null, client=[addr=redis://localhost:6379], nodeType=MASTER, firstFail=0]]] using node localhost/127.0.0.1:6379... RedisConnection@1888870336 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x4c602033, L:/127.0.0.1:64472 - R:localhost/127.0.0.1:6379]]
10:53:39.186 [redisson-netty-1-6] DEBUG org.redisson.command.CommandAsyncService - connection released for command (ZRANGE) and params [queue, 0, -1] from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=50, freeConnectionsAmount=32, freeConnectionsCounter=64, freezed=false, freezeReason=null, client=[addr=redis://localhost:6379], nodeType=MASTER, firstFail=0]]] using connection RedisConnection@1888870336 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x4c602033, L:/127.0.0.1:64472 - R:localhost/127.0.0.1:6379]]
6. Reading queue...
10:53:41.186 [main] DEBUG org.redisson.command.CommandAsyncService - acquired connection for command (ZRANGE) and params [queue, 0, -1] from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=50, freeConnectionsAmount=31, freeConnectionsCounter=63, freezed=false, freezeReason=null, client=[addr=redis://localhost:6379], nodeType=MASTER, firstFail=0]]] using node localhost/127.0.0.1:6379... RedisConnection@1912870382 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xa9f59a80, L:/127.0.0.1:64470 - R:localhost/127.0.0.1:6379]]
10:53:41.188 [redisson-netty-1-6] DEBUG org.redisson.command.CommandAsyncService - connection released for command (ZRANGE) and params [queue, 0, -1] from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=50, freeConnectionsAmount=32, freeConnectionsCounter=64, freezed=false, freezeReason=null, client=[addr=redis://localhost:6379], nodeType=MASTER, firstFail=0]]] using connection RedisConnection@1912870382 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xa9f59a80, L:/127.0.0.1:64470 - R:localhost/127.0.0.1:6379]]
7. Reading queue...
10:53:43.188 [main] DEBUG org.redisson.command.CommandAsyncService - acquired connection for command (ZRANGE) and params [queue, 0, -1] from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=50, freeConnectionsAmount=31, freeConnectionsCounter=63, freezed=false, freezeReason=null, client=[addr=redis://localhost:6379], nodeType=MASTER, firstFail=0]]] using node localhost/127.0.0.1:6379... RedisConnection@2102139180 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xbdb55f94, L:/127.0.0.1:64464 - R:localhost/127.0.0.1:6379]]
10:53:43.190 [redisson-netty-1-6] DEBUG org.redisson.command.CommandAsyncService - connection released for command (ZRANGE) and params [queue, 0, -1] from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=50, freeConnectionsAmount=32, freeConnectionsCounter=64, freezed=false, freezeReason=null, client=[addr=redis://localhost:6379], nodeType=MASTER, firstFail=0]]] using connection RedisConnection@2102139180 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xbdb55f94, L:/127.0.0.1:64464 - R:localhost/127.0.0.1:6379]]
8. Reading queue...

Unfortunatelly I wasn't able to reproduce this constistently. I tried killing the Redis server at different points in the programm and restarting it but without any success...
Redis version
4.0.1
Redisson version
3.8.2
Redisson configuration
  private static RedissonClient createClient() {

    Security.setProperty("networkaddress.cache.ttl", "0");

    Config config = new Config();

    config.useSingleServer()
        .setAddress("redis://localhost:6379")
        .setPassword("12345")
        .setTimeout(10000)
        .setPingConnectionInterval(5000)  // Config option 1
        .setKeepAlive(true)   // Config option 2
        .setRetryAttempts(200000)   // Config option 3.1
        .setRetryInterval(5000);   // Config option 3.2

    return Redisson.create(config);
  }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1692
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
I would like to be able to set the max and min delay times for the EvictionTask job, so i can ensure that the task will run every 5 seconds for example.
Actual behavior
The task will increase the time between checks to until a max of 1800 seconds.
Redis version
4.0.10
Redisson version
3.8.2
Redisson configuration
Single service configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1693
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Since version 3.8.2 Redisson failed to resolve short DNS name.
Steps to reproduce or test case

Configure redis full host name (in our case
redis-test.domain.com)
Add search domain "domain.com" to  /etc/resolv.conf
Verify that short name can be resolved with nslookup:
nslookup redis-test
Server:		192.168.20.167
Address:	192.168.20.167#53

Non-authoritative answer:
Name:	redis-test.domain.com
Address: 135.17.72.111
3) Configure redisson client to connect to "redis-test"
4) Client can't connect to server:
{"time":"2018-10-24T10:36:45.969-07:00","@Version":1,"msg":"failed to resolve 'redis-test' after 3 queries ","logger_name":"org.redisson.cluster.ClusterConnectionManager","thread_name":"main","level":"WARN","level_value":30000,"name":"gws-core-auth","pid":66459}
Redisson version
3.8.2
Redisson configuration
Default config used
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1694
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am running redisson in AWS Lambda functions connecting to a Elasticache redis cluster. The worflow of each lambda consist in 3 batch requests on average (2 read and 1 write).
Expected behavior
No command execution timeout errors
Actual behavior
Every once in a while redisson returns command execution timeout while fetching the cluster status through the command CLUSTER_NODES. Stacktrace is:
   ERROR ClusterConnectionManager:383 - Can't execute CLUSTER_NODES with /10.108.113.3:6379
   org.redisson.client.RedisTimeoutException: Command execution timeout for /10.108.113.3:6379
   at org.redisson.client.RedisConnection$2.run(RedisConnection.java:212) [redisson-3.6.5.jar:?]
   at io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38) [netty-common-4.1.22.Final.jar:4.1.22.Final]
   at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:125) [netty-common-4.1.22.Final.jar:4.1.22.Final]
   at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163) [netty-common-4.1.22.Final.jar:4.1.22.Final]
   at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404) [netty-common-4.1.22.Final.jar:4.1.22.Final]
   at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463) [netty-transport-4.1.22.Final.jar:4.1.22.Final]
   at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:886) [netty-common-4.1.22.Final.jar:4.1.22.Final]
   at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-common-4.1.22.Final.jar:4.1.22.Final]
   at java.lang.Thread.run(Thread.java:748) [?:1.8.0_141]

   WARN CommandDecoder:392 - response has been skipped due to timeout! channel: [id: 0x33ab875c, L:/169.254.76.21:40804 - R:/10.108.113.3:6379], command: (CLUSTER NODES), params: [], result: [ClusterNodeInfo [nodeId=2593fecf77f003f46743b1acc1cd08b136bbc04a, address=redis://10.108.37.191:6379, flags=[MASTER], slaveOf=null, slotRanges=[[0-3276]]], ClusterNodeInfo [nodeId=1a9e1046]

Worth mentioning that this happens with few concurrent execution at the time and I cannot understand why this is happening.
Redis version
3.2.10, cluster mode (5 shards)
Redisson version
3.6.5
Redisson configuration
Default cluster configuration apart for:

transportMode=NIO
readMode=MASTER_SLAVE
retryAttempts=1
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1695
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have an AWS ElastiCache for Redis server running in non-cluster configuration. The connection is TLS enabled. Once in a while, we get this error when servers try to establish the connection with Redis server.
Steps to reproduce or test case
Once in a while whenever the services tried to connect to Redis server, I'm getting this error.
Redis version
4.0.10
Redisson version
3.8.2
Redisson configuration
AWS Master-Slave Configuration with TLS enabled.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1696
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redisson版本
 <dependency>
            <groupId>org.redisson</groupId>
            <artifactId>redisson</artifactId>
            <version>3.8.2</version>
</dependency>
redis信息
# Server
redis_version:3.2.9
redis_git_sha1:00000000
redis_git_dirty:0
redis_build_id:d837dd4aae3a6933
redis_mode:standalone
os:Linux 4.9.27-moby x86_64
arch_bits:64
multiplexing_api:epoll
gcc_version:4.9.2
process_id:1
run_id:3c1a4fd32e311a07d2d9c5ece9b937580467a241
tcp_port:6379
uptime_in_seconds:7678
uptime_in_days:0
hz:10
lru_clock:13324804
executable:/data/redis-server
config_file:

# Clients
connected_clients:83
client_longest_output_list:0
client_biggest_input_buf:0
blocked_clients:0

# Memory
used_memory:2539056
used_memory_human:2.42M
used_memory_rss:4964352
used_memory_rss_human:4.73M
used_memory_peak:3540152
used_memory_peak_human:3.38M
total_system_memory:2095890432
total_system_memory_human:1.95G
used_memory_lua:37888
used_memory_lua_human:37.00K
maxmemory:0
maxmemory_human:0B
maxmemory_policy:noeviction
mem_fragmentation_ratio:1.96
mem_allocator:jemalloc-4.0.3

# Persistence
loading:0
rdb_changes_since_last_save:0
rdb_bgsave_in_progress:0
rdb_last_save_time:1540050984
rdb_last_bgsave_status:ok
rdb_last_bgsave_time_sec:0
rdb_current_bgsave_time_sec:-1
aof_enabled:0
aof_rewrite_in_progress:0
aof_rewrite_scheduled:0
aof_last_rewrite_time_sec:-1
aof_current_rewrite_time_sec:-1
aof_last_bgrewrite_status:ok
aof_last_write_status:ok

# Stats
total_connections_received:3548
total_commands_processed:8491
instantaneous_ops_per_sec:0
total_net_input_bytes:2401890
total_net_output_bytes:21135836
instantaneous_input_kbps:0.00
instantaneous_output_kbps:0.00
rejected_connections:0
sync_full:0
sync_partial_ok:0
sync_partial_err:0
expired_keys:0
evicted_keys:0
keyspace_hits:263
keyspace_misses:2
pubsub_channels:1
pubsub_patterns:0
latest_fork_usec:410
migrate_cached_sockets:0

# Replication
role:master
connected_slaves:0
master_repl_offset:0
repl_backlog_active:0
repl_backlog_size:1048576
repl_backlog_first_byte_offset:0
repl_backlog_histlen:0

# CPU
used_cpu_sys:17.84
used_cpu_user:3.51
used_cpu_sys_children:0.00
used_cpu_user_children:0.01

# Cluster
cluster_enabled:0

# Keyspace
db0:keys=3,expires=0,avg_ttl=0

复现代码
import org.redisson.Redisson;
import org.redisson.api.RTopic;
import org.redisson.api.RedissonClient;

import java.util.UUID;
import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicLong;
import java.util.function.Consumer;

public class RedissonSubErrorTest {

    static RedissonClient redissonClient = Redisson.create();
    static ScheduledExecutorService executorService = new ScheduledThreadPoolExecutor(Runtime.getRuntime().availableProcessors() * 2);


    public static RTopic<String> getRequestTopic() {
        return redissonClient.getTopic("request-topic");
    }

    public static RTopic<String> getResponseTopic(String msgId) {
        return redissonClient.getTopic("response-topic-" + msgId);
    }

    public static void consume(String msgId, Consumer<String> consumer) {
        RTopic<String> topic = getResponseTopic(msgId);
        topic.addListener((channel, msg) -> {
            consumer.accept(msg);

            //*********[删除本行可解决此问题]**********
            topic.removeAllListeners();
        });

    }

    public static void main(String[] args) {
        AtomicLong responseCounter = new AtomicLong();
        AtomicLong requestCounter = new AtomicLong();

        executorService.submit(() -> {
            try {
                getRequestTopic()
                        .addListener((channel, msg) -> {
                            System.out.print("accept [" + msg + "] publish result: ");
                            getResponseTopic(msg).publish("response-" + msg + "(" + responseCounter.incrementAndGet() + ")");
                            System.out.println("ok");
                        });
            } catch (Exception e) {
                e.printStackTrace();
            }
        });

        executorService.scheduleAtFixedRate(() -> {
            String msgId = UUID.randomUUID().toString();
            try {
                System.out.print("consume [" + msgId+"] times "+requestCounter.incrementAndGet());
                consume(msgId, msg->{

                });
                System.out.println(" ok");
                System.out.print("publish request [" + msgId+"]");
                getRequestTopic().publish(msgId);
                System.out.println(" ok");
            } catch (Exception e) {
                e.printStackTrace();
            }

        }, 100, 100, TimeUnit.MILLISECONDS);
    }
}

输出
consume [b00ca1ff-f7f4-4c57-994e-66c569ccef59] times 1 ok
publish request [b00ca1ff-f7f4-4c57-994e-66c569ccef59] ok
accept [b00ca1ff-f7f4-4c57-994e-66c569ccef59] publish result: ok
consume [fd3e8c42-6544-46a2-aeb8-fb2e7fff4677] times 2 ok
publish request [fd3e8c42-6544-46a2-aeb8-fb2e7fff4677] ok
accept [fd3e8c42-6544-46a2-aeb8-fb2e7fff4677] publish result: ok
consume [58337154-1947-4429-bd46-ed16c8293cc2] times 3 ok
publish request [58337154-1947-4429-bd46-ed16c8293cc2] ok
accept [58337154-1947-4429-bd46-ed16c8293cc2] publish result: ok
consume [f89b7327-360e-4f1e-ab21-3207e5d1f979] times 4 ok
publish request [f89b7327-360e-4f1e-ab21-3207e5d1f979] ok
accept [f89b7327-360e-4f1e-ab21-3207e5d1f979] publish result: ok
consume [b81afdb8-fe94-4a70-8232-6f8eb5fde86a] times 5 ok
publish request [b81afdb8-fe94-4a70-8232-6f8eb5fde86a] ok
accept [b81afdb8-fe94-4a70-8232-6f8eb5fde86a] publish result: ok
consume [7c294875-7fc6-40c8-a4ce-2fcf9700b83c] times 6 ok
publish request [7c294875-7fc6-40c8-a4ce-2fcf9700b83c] ok
accept [7c294875-7fc6-40c8-a4ce-2fcf9700b83c] publish result: ok
consume [9d3b8e9f-7fdc-440d-84d9-84e915d7a3f6] times 7 ok
publish request [9d3b8e9f-7fdc-440d-84d9-84e915d7a3f6] ok
accept [9d3b8e9f-7fdc-440d-84d9-84e915d7a3f6] publish result: ok
consume [30cf5df0-7da0-461a-a9c9-b87aecd9a0bd] times 8 ok
publish request [30cf5df0-7da0-461a-a9c9-b87aecd9a0bd] ok
accept [30cf5df0-7da0-461a-a9c9-b87aecd9a0bd] publish result: ok
consume [4b5ff736-8728-4a39-af27-a1e6e9cfddb8] times 9 ok
publish request [4b5ff736-8728-4a39-af27-a1e6e9cfddb8] ok
accept [4b5ff736-8728-4a39-af27-a1e6e9cfddb8] publish result: ok
consume [dbbc3354-b3bd-4ab6-8557-f6821ec09948] times 10 ok
publish request [dbbc3354-b3bd-4ab6-8557-f6821ec09948] ok
accept [dbbc3354-b3bd-4ab6-8557-f6821ec09948] publish result: ok
consume [048072d4-8c28-46a2-954e-c05d6577f4db] times 11 ok
publish request [048072d4-8c28-46a2-954e-c05d6577f4db] ok
accept [048072d4-8c28-46a2-954e-c05d6577f4db] publish result: ok
consume [16d10170-58cf-40b3-bb45-187b7bb82da3] times 12 ok
publish request [16d10170-58cf-40b3-bb45-187b7bb82da3] ok
accept [16d10170-58cf-40b3-bb45-187b7bb82da3] publish result: ok
consume [1eecc1db-f479-45c7-9a43-d98b87c2cd7b] times 13 ok
publish request [1eecc1db-f479-45c7-9a43-d98b87c2cd7b] ok
accept [1eecc1db-f479-45c7-9a43-d98b87c2cd7b] publish result: ok
consume [3562cf2e-211e-4ec3-ba29-fa19f28f0159] times 14 ok
publish request [3562cf2e-211e-4ec3-ba29-fa19f28f0159] ok
accept [3562cf2e-211e-4ec3-ba29-fa19f28f0159] publish result: ok
consume [2a30a36e-4144-4619-b4d9-a9a9b2e3b22e] times 15 ok
publish request [2a30a36e-4144-4619-b4d9-a9a9b2e3b22e] ok
accept [2a30a36e-4144-4619-b4d9-a9a9b2e3b22e] publish result: ok
consume [bf85d4bb-f6d3-49e8-ad8c-22154de7f526] times 16 ok
publish request [bf85d4bb-f6d3-49e8-ad8c-22154de7f526] ok
accept [bf85d4bb-f6d3-49e8-ad8c-22154de7f526] publish result: ok
consume [fbd0e428-09bc-466e-a981-c317cc67649f] times 17 ok
publish request [fbd0e428-09bc-466e-a981-c317cc67649f] ok
accept [fbd0e428-09bc-466e-a981-c317cc67649f] publish result: ok
consume [2c38c431-c22d-463e-bbd5-601648dde4d3] times 18 ok
publish request [2c38c431-c22d-463e-bbd5-601648dde4d3] ok
accept [2c38c431-c22d-463e-bbd5-601648dde4d3] publish result: ok
consume [0bd47020-0039-4b66-9485-2a171d0f8b24] times 19 ok
publish request [0bd47020-0039-4b66-9485-2a171d0f8b24] ok
accept [0bd47020-0039-4b66-9485-2a171d0f8b24] publish result: ok
consume [5de00553-50d5-4340-ae18-76951cbc78d4] times 20 ok
publish request [5de00553-50d5-4340-ae18-76951cbc78d4] ok
accept [5de00553-50d5-4340-ae18-76951cbc78d4] publish result: ok
consume [55a7312b-f1ab-49a3-a49a-de7d18f58c02] times 21 ok
publish request [55a7312b-f1ab-49a3-a49a-de7d18f58c02] ok
accept [55a7312b-f1ab-49a3-a49a-de7d18f58c02] publish result: ok
consume [43e1361e-5806-42dc-a6fd-b0efb22c5cc1] times 22 ok
publish request [43e1361e-5806-42dc-a6fd-b0efb22c5cc1] ok
accept [43e1361e-5806-42dc-a6fd-b0efb22c5cc1] publish result: ok
consume [a749aa68-57ea-40fc-8c95-30b5bf7a1a9d] times 23 ok
publish request [a749aa68-57ea-40fc-8c95-30b5bf7a1a9d] ok
accept [a749aa68-57ea-40fc-8c95-30b5bf7a1a9d] publish result: ok
consume [df33ba6a-60ea-4e64-8e9b-69d9fbfe2b81] times 24 ok
publish request [df33ba6a-60ea-4e64-8e9b-69d9fbfe2b81] ok
accept [df33ba6a-60ea-4e64-8e9b-69d9fbfe2b81] publish result: ok
consume [9062568f-5c30-429b-8f46-b65ae7a5a711] times 25 ok
publish request [9062568f-5c30-429b-8f46-b65ae7a5a711] ok
accept [9062568f-5c30-429b-8f46-b65ae7a5a711] publish result: ok
consume [1ff12c28-1586-4086-ab61-b80ad11a2de9] times 26 ok
publish request [1ff12c28-1586-4086-ab61-b80ad11a2de9] ok
accept [1ff12c28-1586-4086-ab61-b80ad11a2de9] publish result: ok
consume [69472202-1aba-492b-ac1c-f9f4554b79a5] times 27 ok
publish request [69472202-1aba-492b-ac1c-f9f4554b79a5] ok
accept [69472202-1aba-492b-ac1c-f9f4554b79a5] publish result: ok
consume [5a75099e-1b9b-4f36-9706-690435ed8048] times 28 ok
publish request [5a75099e-1b9b-4f36-9706-690435ed8048] ok
accept [5a75099e-1b9b-4f36-9706-690435ed8048] publish result: ok
consume [043e5df4-0601-447b-9d99-bf8e388d6d91] times 29 ok
publish request [043e5df4-0601-447b-9d99-bf8e388d6d91] ok
accept [043e5df4-0601-447b-9d99-bf8e388d6d91] publish result: ok
consume [21b57a16-e865-4005-ad4e-14675f7ee729] times 30 ok
publish request [21b57a16-e865-4005-ad4e-14675f7ee729] ok
accept [21b57a16-e865-4005-ad4e-14675f7ee729] publish result: ok
consume [5514e4e6-a5c7-41e1-adac-27103e763c90] times 31 ok
publish request [5514e4e6-a5c7-41e1-adac-27103e763c90] ok
accept [5514e4e6-a5c7-41e1-adac-27103e763c90] publish result: ok
consume [56b41d0f-8b29-4045-8db9-327f4be42f65] times 32 ok
publish request [56b41d0f-8b29-4045-8db9-327f4be42f65] ok
accept [56b41d0f-8b29-4045-8db9-327f4be42f65] publish result: ok
consume [1b231538-79b4-47cd-9599-078c79ae5d17] times 33 ok
publish request [1b231538-79b4-47cd-9599-078c79ae5d17] ok
accept [1b231538-79b4-47cd-9599-078c79ae5d17] publish result: ok
consume [afcb6ad2-8daf-4b19-9850-a7c40a664bf7] times 34 ok
publish request [afcb6ad2-8daf-4b19-9850-a7c40a664bf7] ok
accept [afcb6ad2-8daf-4b19-9850-a7c40a664bf7] publish result: ok
consume [843e0d65-d5d5-41c5-bfc3-933e475faae1] times 35 ok
publish request [843e0d65-d5d5-41c5-bfc3-933e475faae1] ok
accept [843e0d65-d5d5-41c5-bfc3-933e475faae1] publish result: ok
consume [07b2d9f9-631e-4807-84a7-977a737e2e36] times 36 ok
publish request [07b2d9f9-631e-4807-84a7-977a737e2e36] ok
accept [07b2d9f9-631e-4807-84a7-977a737e2e36] publish result: ok
consume [ed5e3995-bee6-4595-8e8a-71c394b88c7d] times 37 ok
publish request [ed5e3995-bee6-4595-8e8a-71c394b88c7d] ok
accept [ed5e3995-bee6-4595-8e8a-71c394b88c7d] publish result: ok
consume [c26ee613-6baf-4b20-ad6c-d77889d64e72] times 38 ok
publish request [c26ee613-6baf-4b20-ad6c-d77889d64e72] ok
accept [c26ee613-6baf-4b20-ad6c-d77889d64e72] publish result: ok
consume [fdb01678-19af-4cc3-a280-a363223d2a2c] times 39 ok
publish request [fdb01678-19af-4cc3-a280-a363223d2a2c] ok
accept [fdb01678-19af-4cc3-a280-a363223d2a2c] publish result: ok
consume [1f6ac25b-537c-45c1-8741-35498c68a9d6] times 40 ok
publish request [1f6ac25b-537c-45c1-8741-35498c68a9d6] ok
accept [1f6ac25b-537c-45c1-8741-35498c68a9d6] publish result: ok
consume [df1cb753-137b-4e41-b2b1-f8993d9042e8] times 41 ok
publish request [df1cb753-137b-4e41-b2b1-f8993d9042e8] ok
accept [df1cb753-137b-4e41-b2b1-f8993d9042e8] publish result: ok
consume [e7e0b01c-d1cc-4d3d-ad77-194679119013] times 42 ok
publish request [e7e0b01c-d1cc-4d3d-ad77-194679119013] ok
accept [e7e0b01c-d1cc-4d3d-ad77-194679119013] publish result: ok
consume [6cc2e099-5a1b-4c1e-90fb-d75d8010d0dd] times 43 ok
publish request [6cc2e099-5a1b-4c1e-90fb-d75d8010d0dd] ok
accept [6cc2e099-5a1b-4c1e-90fb-d75d8010d0dd] publish result: ok
consume [151136a5-2204-40ec-a31b-c0942a362b06] times 44 ok
publish request [151136a5-2204-40ec-a31b-c0942a362b06] ok
accept [151136a5-2204-40ec-a31b-c0942a362b06] publish result: ok
consume [43b1a2f4-b652-4a2f-bd23-3902d00ae3bb] times 45 ok
publish request [43b1a2f4-b652-4a2f-bd23-3902d00ae3bb] ok
accept [43b1a2f4-b652-4a2f-bd23-3902d00ae3bb] publish result: ok
consume [db015885-d6b5-42bc-b953-9af535335190] times 46 ok
publish request [db015885-d6b5-42bc-b953-9af535335190] ok
accept [db015885-d6b5-42bc-b953-9af535335190] publish result: ok
consume [9aa892aa-91b3-41d3-b761-c4cb80263bc7] times 47 ok
publish request [9aa892aa-91b3-41d3-b761-c4cb80263bc7] ok
accept [9aa892aa-91b3-41d3-b761-c4cb80263bc7] publish result: ok
consume [4edc10ed-53b0-412a-98f5-995b1d4bf9f4] times 48 ok
publish request [4edc10ed-53b0-412a-98f5-995b1d4bf9f4] ok
accept [4edc10ed-53b0-412a-98f5-995b1d4bf9f4] publish result: ok
consume [1146df16-f8c1-489b-9be4-5949ad87f787] times 49 ok
publish request [1146df16-f8c1-489b-9be4-5949ad87f787] ok
accept [1146df16-f8c1-489b-9be4-5949ad87f787] publish result: ok
consume [a3e6b48a-4799-4b1f-9933-e874bb2ba6b1] times 50 ok
publish request [a3e6b48a-4799-4b1f-9933-e874bb2ba6b1] ok
accept [a3e6b48a-4799-4b1f-9933-e874bb2ba6b1] publish result: ok
consume [3b43ede5-1bce-45ee-b3c8-16829b09a982] times 51
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1697
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
3.x
Redisson version
3.8.2
Redisson configuration
@Bean(name = "redisSingleClient", destroyMethod = "shutdown")
    RedissonClient redisSingleClientInit() {
        Config config = new Config();
        config.setCodec(StringCodec.INSTANCE);
        SingleServerConfig singleConfig = config.useSingleServer();
        singleConfig.setAddress("redis://" + url);
        return Redisson.create(config);
    }

默认选中的数据库是0库，想在代码中动态切换6/7/8库，怎么操作？
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1698
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
3.x
Redisson version
3.8.2
Redisson configuration
@Bean(name = "redisSingleClient", destroyMethod = "shutdown")
    RedissonClient redisSingleClientInit() {
        Config config = new Config();
        config.setCodec(StringCodec.INSTANCE);
        SingleServerConfig singleConfig = config.useSingleServer();
        singleConfig.setAddress("redis://" + url);
        return Redisson.create(config);
    }

How to dynamically switch other databases?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1699
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redis version  4.0.0
Redisson version 3.7.5
Redisson configuration 单机
延时放入到队列，执行多次
RBlockingQueue blockingQueue = redissonClient.getBlockingQueue("blockQueue");
RDelayedQueue delayedQueue = redissonClient.getDelayedQueue(blockingQueue);
CallCdr groupCallCdr = new CallCdr();
delayedQueue.offer(groupCallCdr, 60, TimeUnit.SECONDS);
多次测试后，发现
当1分钟过去后，从阻塞队列获取元素，有时可以获取到，有时则获取不到
RBlockingQueue blockingQueue=redissonClient.getBlockingQueue(“blockQueue”);
while (true) {
CallCdr callCdr = blockingQueue.take();
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1700
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
The value associated with the key
Actual behavior
org.redisson.client.RedisConnectionClosedException: Command succesfully sent, but channel [xyz] has been closed!
When I debug happy case I am seeing the actual redisClients in connectionFutures in async method of CommandAsyncService have keepAlive = false. I suspect this may the root cause.
The connections seem to go stale after an unknown duration (verified that the server timeout is not affecting this)
Looking in more detail, I see MasterSlaveServersConfig create(BaseMasterSlaveServersConfig<?> cfg)
in MasterSlaveConnectionManager.java file is not setting keepAlive flag.
This is extremely hard to repro and I couldn't debug a failure case yet; but it seems like we cannot rely on redisClient abstracting connection handling unless we are missing a config.
Please advise.
Steps to reproduce or test case
Connect to a redis cluster by setting keepAlive = true
Not performing any actions for a long time ranges between 1h to 10h.
Trigger a getMap with existing key value.
Redis version
4.0.9
Redisson version
3.8.2
Redisson configuration
redissonConfig.useClusterServers()
.addNodeAddress("host")
.setMasterConnectionMinimumIdleSize(8)
.setMasterConnectionPoolSize(1924)
.setSlaveConnectionMinimumIdleSize(8)
.setSlaveConnectionPoolSize(1924)
.setTimeout(20000)
.setDnsMonitoringInterval(-1)
.setKeepAlive(true);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1701
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
怎样获得集群中，每台机器的slot的range？
由于在使用mget或者mset的时候，多个key如果不在一个slot中，会出错，所以想通过slot的range判断一下，将在一台机器上的key放到一块查询
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1702
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
多线程读写是否有可能 fail-fast  错误？
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1703
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redisClusterClient.getKeys().getKeysByPattern(pattern);
众所周知redis的keys方法，会卡住整个数据库，生产环境中不允许使用keys，
所以想问一下，redisson的keys方法，是不是单独实现的scan操作来模拟keys，源码没太看懂
跟踪源码，发现最终调用了
public RFuture<ListScanResult<Object>> scanIteratorAsync(RedisClient client, MasterSlaveEntry entry, long startPos, String pattern, int count) {
        if (pattern == null) {
            return commandExecutor.readAsync(client, entry, StringCodec.INSTANCE, RedisCommands.SCAN, startPos, "COUNT", count);
        }
        return commandExecutor.readAsync(client, entry, StringCodec.INSTANCE, RedisCommands.SCAN, startPos, "MATCH", pattern, "COUNT", count);
    }

感觉上，是调用了scan的方式。
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1704
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior: Transactional put Should take slightly more time than normal put
Actual behavior: Taking almost 3000 times more time
Steps to reproduce or test case:
public final void putInCache(Object key, Object value) {
RTransaction transaction = redisson.createTransaction(redissonTransactionOptions);
RLocalCachedMap<Object, Object> cache = transaction
.getLocalCachedMap(redisson.getLocalCachedMap(this.getNeutrinoCacheName(), localCachedMapOptions));
cache.fastPut(key, value);
transaction.commit();
}
Redis version: 4.0.9
Redisson version: 3.7.2
Redisson configuration:
config.useSingleServer().setAddress("redis://10.0.50.128:6379");
config.useSingleServer().setRetryAttempts(3);
config.useSingleServer().setConnectionPoolSize(500);
config.useSingleServer().setRetryInterval(2000);
config.useSingleServer().setConnectTimeout(30000);
FstCodec codec = new FstCodec();
config.setCodec(codec);
redisson = (RedissonClient) Redisson.create(config);

options = TransactionOptions.defaults()

		.syncSlavesTimeout(10, TimeUnit.SECONDS).responseTimeout(10, TimeUnit.SECONDS)
		.retryInterval(5, TimeUnit.SECONDS).retryAttempts(5).timeout(40, TimeUnit.SECONDS);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1705
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for PR!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1706
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is it correct if Redis cache ttl is the same as timeToLiveInMillis for local cache?
MY_CACHE:
ttl: 300000
maxIdleTime: 300000
maxSize: 1000
localCacheOptions:
evictionPolicy: "LRU"
reconnectionStrategy: "CLEAR"
syncStrategy: "INVALIDATE"
writeMode: "WRITE_THROUGH"
cacheSize: 1000
timeToLiveInMillis: 300000
maxIdleInMillis: 300000
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1707
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior: Should provide multiple strategies to choose from like whether to allow reads or not while disconnected
Actual behavior: Reads are allowed by default
Redis version: 4.0.9
Redisson version: 3.8.2
Redisson configuration:
config = new Config();
	config.useSingleServer().setAddress("redis://10.0.50.128:6222");
	config.useSingleServer().setPassword("shivendra");
	config.useSingleServer().setDatabase(0);

	config.useSingleServer().setRetryAttempts(3);
	config.useSingleServer().setConnectionPoolSize(500);
	config.useSingleServer().setRetryInterval(2000);
	config.useSingleServer().setConnectTimeout(30000);
	config.useSingleServer().setPingConnectionInterval(5000);
	config.useSingleServer().setPingTimeout(5000);
	FstCodec codec = new FstCodec();
	config.setCodec(codec);
	redisson = (Redisson) Redisson.create(config);

	options = TransactionOptions.defaults()

			.syncSlavesTimeout(5, TimeUnit.SECONDS).responseTimeout(3, TimeUnit.SECONDS)
			.retryInterval(5, TimeUnit.SECONDS).retryAttempts(3).timeout(40, TimeUnit.SECONDS);


	map = redisson.getLocalCachedMap("lock_test", LocalCachedMapOptions.defaults().syncStrategy(SyncStrategy.INVALIDATE).reconnectionStrategy(ReconnectionStrategy.CLEAR));
	rMap = redisson.getMap("lock_test");
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1708
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
ERROR [2018-10-27 18:08:43,504] [redisson-netty-4-1] ClusterConnectionManager: Can't add slave: redis://100.101.26.91:6379
! org.redisson.client.RedisException: ERR max number of clients reached. channel: [id: 0x03f718df, L:/100.111.217.190:53733 - R:100.101.26.91/100.101.26.91:6379] command: (READONLY), params: []
! at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:331) ~[app.jar:1.0.25]
! at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:128) ~[app.jar:1.0.25]
! at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:108) ~[app.jar:1.0.25]
! at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489) ~[app.jar:1.0.25]
! at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) ~[app.jar:1.0.25]
! at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265) ~[app.jar:1.0.25]
! at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[app.jar:1.0.25]
! at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[app.jar:1.0.25]
! at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[app.jar:1.0.25]
! at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) ~[app.jar:1.0.25]
! at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[app.jar:1.0.25]
! at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[app.jar:1.0.25]
! at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[app.jar:1.0.25]
! at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) ~[app.jar:1.0.25]
! at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[app.jar:1.0.25]
! at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[app.jar:1.0.25]
! at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[app.jar:1.0.25]
! at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) ~[app.jar:1.0.25]
! at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[app.jar:1.0.25]
! at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[app.jar:1.0.25]
! at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[app.jar:1.0.25]
! at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434) ~[app.jar:1.0.25]
! at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[app.jar:1.0.25]
! at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[app.jar:1.0.25]
! at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965) ~[app.jar:1.0.25]
! at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) ~[app.jar:1.0.25]
! at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:647) [app.jar:1.0.25]
! at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:582) [app.jar:1.0.25]
! at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:499) [app.jar:1.0.25]
! at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:461) [app.jar:1.0.25]
! ... 3 common frames omitted
! Causing: org.redisson.client.RedisConnectionException: Unable to connect to Redis server: 100.101.26.91/100.101.26.91:6379
! at org.redisson.connection.pool.ConnectionPool$2$1.operationComplete(ConnectionPool.java:138) ~[app.jar:1.0.25]
! at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511) [app.jar:1.0.25]
! at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:485) [app.jar:1.0.25]
! at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424) [app.jar:1.0.25]
! at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:121) [app.jar:1.0.25]
! at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:83) [app.jar:1.0.25]
! at org.redisson.connection.pool.ConnectionPool.promiseFailure(ConnectionPool.java:301) [app.jar:1.0.25]
! at org.redisson.connection.pool.ConnectionPool.access$400(ConnectionPool.java:54) [app.jar:1.0.25]
! at org.redisson.connection.pool.ConnectionPool$4.operationComplete(ConnectionPool.java:266) [app.jar:1.0.25]
! at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511) [app.jar:1.0.25]
! at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:504) [app.jar:1.0.25]
! at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:483) [app.jar:1.0.25]
! at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424) [app.jar:1.0.25]
! at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:121) [app.jar:1.0.25]
! at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:83) [app.jar:1.0.25]
! at org.redisson.client.RedisClient$2$1$1$1.run(RedisClient.java:240) [app.jar:1.0.25]
! at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163) [app.jar:1.0.25]
! at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404) [app.jar:1.0.25]
! at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:465) [app.jar:1.0.25]
! at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884) [app.jar:1.0.25]
! at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [app.jar:1.0.25]
! at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]```

I have been using redisson in my application, since last couple of weeks, I have been getting this error. Kindly help me root cause this issue.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1709
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We use Reddison as a client for high load sharded Redis cluster consists of 8 nodes. Main use case -  big number of relatively small lua scripts. We use code like this to do it. (Used version is 3.7.5, but I believe same behavior is in trunk)
RScript script = redisson.getScript();
Long result = script.evalSha(RScript.Mode.READ_WRITE, loadedScript, RScript.ReturnType.VALUE, keys, values);
After some performance tests we noticed that load on Redis cluster nodes is uneven - CPU utilization on node which holds '0 slot' was two times higher then on other nodes. It happens because Reddison sends all scripts to '0 slot' and then this node have to 'MOVED' script to correct node for processing. This overloads '0 slot' node.
So we have to find a workaround to send scripts to correct node:
RedissonScript script = (RedissonScript) redisson.getScript(); // cast to class here to get right method 
Long result = script.evalSha(correctMessageKey, RScript.Mode.READ_WRITE, JsonJacksonCodec.INSTANCE,  loadedScript, RScript.ReturnType.VALUE, keys, values);
So I wonder if this a bug or feature?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1710
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
When I debugged the class MultiDnsAddressResolverGroup and compared with this commit:

  
    
      redisson/redisson/src/main/java/org/redisson/connection/dns/MultiDnsAddressResolverGroup.java
    
    
         Line 58
      in
      f08cac4
    
  
  
    

        
          
           groups.add(new DnsAddressResolverGroup(channelType, nameServerProvider)); 
        
    
  


I found that the code deployed to https://search.maven.org/artifact/org.redisson/redisson/3.8.2/bundle is missing this line (that is supposed solve the issue).
Maybe this code is missing in the compiled version too?
Expected behavior
Actual behavior
Steps to reproduce or test case
Redisson version
3.8.2
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1711
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
I am new redis and AWS elasticache and I am working on a legacy codebase which uses oracle coherent caching. I need to replace it with AWS elasticache and Redission does that. But me being new not able to find how to actually use Redisson for this. Elasticache endpoint is private so that cant be passed to redission client.
Please help me with providing an example so that i can actually progress on this
Thanks
Actual behavior
Steps to reproduce or test case
Redis version
Redisson version
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1712
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I'm playing with the Redisson's great feature for near cache, then did some benchmark testing on it.
It brings a huge performance boost compares to directly interacting with redis, however it's takes much longer than "real" local cache, especially for put operation, around 100~200 times longer. For instance, each Redisson fastPutAsync takes around 175536ns, while real local cache finishes in 1060ns; Redisson get takes 9737ns, real local cache takes 151ns. This can become quite noticeable for read/write intensive applications.
From the reading on document/wiki on RLocalCachedMap, it essentially keeps a local copy of the cache in application's memory, performance should be roughly the same as real local cache. Any thoughts / suggestions on the slowness of RLocalCachedMap please?
Thanks.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1713
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
I got some classCastException :
Exception in thread "redisson-3-38" java.lang.ClassCastException: java.lang.Integer cannot be cast to java.lang.Long at org.redisson.spring.session.RedissonSessionRepository$RedissonSession.load(RedissonSessionRepository.java:103) at org.redisson.spring.session.RedissonSessionRepository.findById(RedissonSessionRepository.java:310) at org.redisson.spring.session.RedissonSessionRepository.onMessage(RedissonSessionRepository.java:252) at org.redisson.spring.session.RedissonSessionRepository.onMessage(RedissonSessionRepository.java:52) at org.redisson.PubSubPatternMessageListener.onPatternMessage(PubSubPatternMessageListener.java:80) at org.redisson.client.RedisPubSubConnection.onMessage(RedisPubSubConnection.java:87) at org.redisson.client.handler.CommandPubSubDecoder$2.run(CommandPubSubDecoder.java:181) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.lang.Thread.run(Thread.java:748) 
Here the payload that redisson trying to decode :
1) "\"session:maxInactiveInterval\"" 2) "1800" 3) "\"session:lastAccessedTime\"" 4) "[\"java.lang.Long\",1540985842940]" 5) "\"session:creationTime\"" 6) "[\"java.lang.Long\",1540985842937]"
If we check into the source code
https://github.com/redisson/redisson/blob/redisson-3.7.5/redisson/src/main/java/org/redisson/spring/session/RedissonSessionRepository.java
at l:103 with see that you are trying to cast into a Long. On older version you used to cast it into an Integer.
Unfortunately i cannot decrease my redisson version because i have updated spring session in 2.x.x .
I think you can keep a cast into an Integer. I don't think people will configure the session ttl to more than 2147483647 seconds.
Steps to reproduce or test case
Redisson version
redisson : 3.7.5
spring boot : 2.0.4.RELEASE
spring session: 2.0.5.RELEASE
Redisson configuration
`
@configuration
@EnableRedissonHttpSession
public class RedissonConfig implements BeanClassLoaderAware
{
@Autowired
private RedisProperties redisProperties;
private static final int CONNECTION_TIMEOUT = 3000;
private static final int TIMEOUT = 10000;
private static final int THREAD_NUMBER = 4;

private ClassLoader loader;

@Bean(destroyMethod = "shutdown")
public RedissonClient redissonClient()
{
    if (redisProperties.isSingleServer()) {
        return Redisson.create(singleServer());
    }
    return Redisson.create(sentinelServers());
}

private Config baseConfig()
{
    return new Config()
            .setNettyThreads(THREAD_NUMBER)
            .setThreads(THREAD_NUMBER)
            .setCodec(new JsonJacksonCodec(mapper()));
}

private Config sentinelServers()
{
    final Config config = baseConfig();
    config.useSentinelServers()
            .setConnectTimeout(CONNECTION_TIMEOUT)
            .setTimeout(TIMEOUT)
            .addSentinelAddress(split(redisProperties.getAddresses(), ", "))
            .setMasterName(redisProperties.getMasterName())
            .setPassword(redisProperties.getPassword());
    return config;
}

private Config singleServer()
{
    final Config config = baseConfig();
    config.useSingleServer()
            .setConnectTimeout(CONNECTION_TIMEOUT)
            .setTimeout(TIMEOUT)
            .setAddress(redisProperties.getAddresses())
            .setPassword(redisProperties.getPassword());
    return config;
}

@Override
public void setBeanClassLoader(final ClassLoader classLoader)
{
    this.loader = classLoader;
}

private ObjectMapper mapper()
{
    final ObjectMapper mapper = new ObjectMapper();
    mapper.registerModule(new JavaTimeModule());
    mapper.registerModules(SecurityJackson2Modules.getModules(this.loader));
    mapper.disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS);
    mapper.disable(DeserializationFeature.ADJUST_DATES_TO_CONTEXT_TIME_ZONE);
    mapper.setSerializationInclusion(Include.NON_NULL);
    mapper.addMixIn(Throwable.class, JsonJacksonCodec.ThrowableMixIn.class);
    mapper.findAndRegisterModules();
    return mapper;
}

}`
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1714
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
org.redisson.client.RedisException: ERR Error running script (call to f_c7545856d197b86a5f3527597afb440f1edcafa3): @enable_strict_lua:15: user_script:1: Script attempted to access unexisting global variable 'struct' . channel: [id: 0xf83f8de3, L:/172.18.0.10:55606 - R:10.107.48.9/10.107.48.9:6379] command: (EVAL), params: [local insertable = false; local v = redis.call('hget', KEYS[1], ARGV[5]); if v == false then inserta..., 8, UserBindDeviceMap, redisson__timeout__set:{UserBindDeviceMap}, redisson__idle__set:{UserBindDeviceMap}, redisson_map_cache_created:{UserBindDeviceMap}, redisson_map_cache_updated:{UserBindDeviceMap}, redisson__map_cache__last_access__set:{UserBindDeviceMap}, redisson_map_cache_removed:{UserBindDeviceMap},
Expected behavior
Actual behavior
Steps to reproduce or test case
使用带Cache字样的类都会触发,
Redis version
v2.8
Redisson version
3.7.5
Redisson configuration
        config.useSingleServer()
            .setAddress(redisServer);
        Redisson.create(config);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1715
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
public class RMapCacheMain6 {
private static RedissonClient client;

static {

    Config config = new Config();
    config.useSingleServer()
        .setTimeout(1000000)
        .setAddress("redis://127.0.0.1:6379").setPassword("passwd123");
    client = Redisson.create(config);
}

private static RMapCache<Date, Date> rMapCache = client.getMapCache("RMapCache");

@Before
public void before() {
    client.getKeys().flushall();
}

@After
public void after() {
    client.shutdown();
}

@Test
public void mapCompute() throws Exception {
    while (true) {
        rMapCache.put(new Date(), new Date(), 1, TimeUnit.SECONDS);
        RBatch batch = client.createBatch(BatchOptions.defaults());
        batch.getMapCache("RMapCache").sizeAsync().getNow();
        batch.execute().getResponses().forEach(System.out::println);
        TimeUnit.SECONDS.sleep(1);
    }
}

}
在 RMapCache 中存入数据 保留一秒，使用 RBatch 去获取这个 RMapCache 大小，并不能清除过期的数据。
Expected behavior
1
Actual behavior
1
2
3
4
5
2
3
4
5
6
Redis version
4.0.11
Redisson version
3.9.0
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1716
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
The issue happened on multiple servers minutes after deployment
Unable to send command! Node source: NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=0, freeSubscribeConnectionsCounter=49, freeConnectionsAmount=16, freeConnectionsCounter=64, freezed=false, freezeReason=null, client=[addr=redis://100.65.5.107:6379], nodeType=MASTER, firstFail=0]]], connection: RedisConnection@183817154 [redisClient=[addr=redis://100.65.15.190:6379], channel=[id: 0x2f13b04f, L:0.0.0.0/0.0.0.0:55402]], command: (HMGET), command params: [jlr:METADATA_CACHE_KEY, "CI_JOB_NAMES", "TEST_EXECUTION_OS", "TEST_EXECUTION_NAMES", "LATEST_TEST_EXECUTION_TIME", "TEST_EXECUTION_TAGS", "TEST_EXECUTION_DEVICES_V2", "LATEST_CI_JOB_TIME"] after 3 retry attempts org.redisson.client.WriteRedisConnectionException: Unable to send command! Node source: NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=0, freeSubscribeConnectionsCounter=49, freeConnectionsAmount=16, freeConnectionsCounter=64, freezed=false, freezeReason=null, client=[addr=redis://100.65.5.107:6379], nodeType=MASTER, firstFail=0]]], connection: RedisConnection@183817154 [redisClient=[addr=redis://100.65.15.190:6379], channel=[id: 0x2f13b04f, L:0.0.0.0/0.0.0.0:55402]], command: (HMGET), command params: [jlr:METADATA_CACHE_KEY, "CI_JOB_NAMES", "TEST_EXECUTION_OS", "TEST_EXECUTION_NAMES", "LATEST_TEST_EXECUTION_TIME", "TEST_EXECUTION_TAGS", "TEST_EXECUTION_DEVICES_V2", "LATEST_CI_JOB_TIME"] after 3 retry attempts at org.redisson.command.CommandAsyncService.checkWriteFuture(CommandAsyncService.java:837) ~[redisson-3.9.0.jar:?] at org.redisson.command.CommandAsyncService.access$200(CommandAsyncService.java:92) ~[redisson-3.9.0.jar:?] at org.redisson.command.CommandAsyncService$11$1.operationComplete(CommandAsyncService.java:794) ~[redisson-3.9.0.jar:?] at org.redisson.command.CommandAsyncService$11$1.operationComplete(CommandAsyncService.java:791) ~[redisson-3.9.0.jar:?] at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511) ~[netty-common-4.1.30.Final.jar:4.1.30.Final] at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:485) ~[netty-common-4.1.30.Final.jar:4.1.30.Final] at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424) ~[netty-common-4.1.30.Final.jar:4.1.30.Final] at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:121) ~[netty-common-4.1.30.Final.jar:4.1.30.Final] at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987) ~[netty-transport-4.1.30.Final.jar:4.1.30.Final] at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869) ~[netty-transport-4.1.30.Final.jar:4.1.30.Final] at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1391) ~[netty-transport-4.1.30.Final.jar:4.1.30.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738) ~[netty-transport-4.1.30.Final.jar:4.1.30.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730) ~[netty-transport-4.1.30.Final.jar:4.1.30.Final] at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38) ~[netty-transport-4.1.30.Final.jar:4.1.30.Final] at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081) ~[netty-transport-4.1.30.Final.jar:4.1.30.Final] at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128) ~[netty-transport-4.1.30.Final.jar:4.1.30.Final] at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070) ~[netty-transport-4.1.30.Final.jar:4.1.30.Final] at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163) ~[netty-common-4.1.30.Final.jar:4.1.30.Final] at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404) ~[netty-common-4.1.30.Final.jar:4.1.30.Final] at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:462) ~[netty-transport-4.1.30.Final.jar:4.1.30.Final] at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897) ~[netty-common-4.1.30.Final.jar:4.1.30.Final] at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.30.Final.jar:4.1.30.Final] at java.lang.Thread.run(Thread.java:844) [?:?] Caused by: java.nio.channels.ClosedChannelException at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source) ~[netty-transport-4.1.30.Final.jar:4.1.30.Final]``
Steps to reproduce or test case
Redis version
3.0.7
Redisson version
3.9.0
Redisson configuration
Our redisson configuration:
Sentinel cluster with 4 nodes
masterConnectionPoolMinSize=16
masterConnectionPoolMaxSize=64
slaveConnectionPoolMinSize=16
slaveConnectionPoolMaxSize=64
timeout=3000
keepAlive=false
idleConnectionTimeout=10000
connectTimeout=10000
pingConnectionInterval=0
pingTimeout=1000
with password auth
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1717
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
你好，我在测试关于RLocalCachedMap的功能，发现订阅数的配置数量会引发超时，并且此线程重试读取依然超时。
测试项目如下：
https://github.com/titus12/TestRedissonTemporary2.git
count = 100,会出问题，count < 50 正常，
redisson.yaml 配置中
subscriptionsPerConnection = 5，subscriptionConnectionPoolSize = 10
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1718
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redis version : 3.2.1
redisson: 3.5.4
jdk:1.8
redis cluster : 3 master, 3 slave
Below exception occurred until application restarts when redis cluster master-slave failover .
[ERROR] 2018-11-03 17:30:21.445 [http-nio-8080-exec-33] AppController: In getAddress Exception
org.redisson.client.RedisConnectionException: Can't aquire connection to [freeSubscribeConnectionsAmount=0, freeSubscribeConnectionsCounter=org.redisson.pubsub.AsyncSemaphore@794138c3, freeConnectionsAmount=0, freeConnectionsCounter=org.redisson.pubsub.AsyncSemaphore@6b32b3e8, freezed=true, freezeReason=MANAGER, client=[addr=/172.1.1.:16379], nodeType=SLAVE, failedAttempts=2]
at org.redisson.connection.pool.ConnectionPool.get(ConnectionPool.java:206)
at org.redisson.connection.pool.SlaveConnectionPool.get(SlaveConnectionPool.java:30)
at org.redisson.connection.balancer.LoadBalancerManager.getConnection(LoadBalancerManager.java:197)
at org.redisson.connection.MasterSlaveEntry.connectionReadOp(MasterSlaveEntry.java:433)
at org.redisson.connection.MasterSlaveConnectionManager.connectionReadOp(MasterSlaveConnectionManager.java:744)
at org.redisson.command.CommandAsyncService.async(CommandAsyncService.java:504)
at org.redisson.command.CommandAsyncService$8.run(CommandAsyncService.java:585)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:668)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:743)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:471)
at java.lang.Thread.run(Thread.java:745)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1719
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Per the main README:
https://github.com/redisson/redisson/blob/master/README.md
Redisson 2.14.0 should work on Java 1.6.
Actual behavior
Redisson 2.13.1 and above have the class files compiled with version 51.0 (Java 1.7), and will no longer work on 1.6.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1720
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
We use a score sorted set to store our user story timelines, these scores are in the form of timestamps
        RScoredSortedSet storyTimeLine = redissonClient.getScoredSortedSet("timeline");
        storyTimeLine.add(timestamp,storyId);

Actual behavior
Collection<String> stories = timeline.valueRangeReversed(startDate.intValue(), endDate.intValue());

should return the list of stories but it returns empty.
Steps to reproduce or test case
When i run the same command from the redis terminal it returns the values
ZREVRANGEBYSCORE timeline 1541425420 1540785105 withscores limit 0 100

Redis version
4.0.0
Redisson version
3.8.0
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1721
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for the contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1722
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I'm Using Jcache with AWS Redis in replicatedServersConfig, but observed jcache get / put operation is always using  master node to for both read and write operations.
in my view get request should go to slave (read) node, put request should go to master node.
Please suggest anything to be changed in my configuration / correct me if i'm wrong.
my cache config:
{
"replicatedServersConfig":{
"idleConnectionTimeout":600000,
"pingTimeout":1000,
"connectTimeout":10000,
"timeout":5000,
"retryAttempts":3,
"retryInterval":1500,
"failedSlaveReconnectionInterval":3000,
"failedSlaveCheckInterval":60000,
"password":null,
"subscriptionsPerConnection":5,
"clientName":null,
"loadBalancer":{
"class":"org.redisson.connection.balancer.RoundRobinLoadBalancer"
},
"subscriptionConnectionMinimumIdleSize":5,
"subscriptionConnectionPoolSize":50,
"slaveConnectionMinimumIdleSize":30,
"slaveConnectionPoolSize":50,
"masterConnectionMinimumIdleSize":30,
"masterConnectionPoolSize":50,
"readMode":"SLAVE",
"subscriptionMode":"SLAVE",
"nodeAddresses":[
"redis://...cache.amazonaws.com:6379",
"redis://...cache.amazonaws.com:6379"
],
"scanInterval":3000,
},
"threads":0,
"nettyThreads":0,
"codec":{
"class":"org.redisson.codec.SnappyCodec"
},
"transportMode":"NIO"
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1723
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I'm using jcache  implementation and using AWS Redis servers in "replicatedServersConfig", i'm getting response time out exception at "getLockedLock" method. raised another issue  related to jcache.
Please do the needful.
javax.cache.CacheException: org.redisson.client.RedisResponseTimeoutException: Redis server response timeout (5000 ms) occured for command: (EVAL) with params: [if (redis.call('exists', KEYS[1]) == 0) then redis.call('hset', KEYS[1], ARGV[2], 1); redis.call('pe..., 1, {test_ApplicationFormat}:WSFHEHaApjlCL5QG/Ng/dg:key, 30000, a225e312-e347-40ad-8c37-d4c0d9ef9800:120] channel: [id: 0x2519e10d, L:/172.17.0.3:49640 - R:..cache.amazonaws.com/10.0.0.181:6379]
at org.redisson.jcache.JCache.getLockedLock(JCache.java:746)
at org.redisson.jcache.JCache.get(JCache.java:177)
at CacheRedisCacheRedissonImpl.get(CacheRedisCacheRedissonImpl.java:57)
at ApplicationFormatServiceImpl.getApplicationFormatCache(ApplicationFormatServiceImpl.java:500)
at ApplicationFormatServiceImpl.getApplicationFormatCache(ApplicationFormatServiceImpl.java:309)
at sun.reflect.GeneratedMethodAccessor172.invoke(Unknown Source)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
at com.sun.proxy.$Proxy102.getApplicationFormatCache(Unknown Source)
at controllers.CCPlayUtils.getApplicationFormatCache(CCPlayUtils.java:102)
at controllers.CCPlayApplication.getResponseAsJson(CCPlayApplication.java:127)
at controllers.CCLocaleController$1.call(CCLocaleController.java:30)
at controllers.CCPlayUtils$1.apply(CCPlayUtils.java:974)
at controllers.CCPlayUtils$1.apply(CCPlayUtils.java:964)
at play.core.j.FPromiseHelper$$anonfun$promise$2.apply(FPromiseHelper.scala:34)
at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
at play.core.j.HttpExecutionContext$$anon$2.run(HttpExecutionContext.scala:37)
at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:42)
at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:386)
at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: org.redisson.client.RedisResponseTimeoutException: Redis server response timeout (5000 ms) occured for command: (EVAL) with params: [if (redis.call('exists', KEYS[1]) == 0) then redis.call('hset', KEYS[1], ARGV[2], 1); redis.call('pe..., 1, {test_ApplicationFormat}:WSFHEHaApjlCL5QG/Ng/dg:key, 30000, a225e312-e347-40ad-8c37-d4c0d9ef9800:120] channel: [id: 0x2519e10d, L:/172.17.0.3:49640 - R:.*.0001.use1.cache.amazonaws.com/10.0.0.181:6379]
at org.redisson.command.CommandAsyncService$11.run(CommandAsyncService.java:752)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:670)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:745)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:473)
at java.lang.Thread.run(Thread.java:745)
Thanks,
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1724
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1725
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
when i try to get all values in a map redisson return only 100 values
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1726
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1727
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
服务器是linux，两台机器，做的redis集群。ip是25和26.但是在使用redisson做batch查询的时候，有时候会出现Unable to send command! Node source: NodeSource [slot=null, addr=null, redisClient=[addr=redis://172.16.1.247:7002], redirect=null
这种问题，导致程序报错。
配置中，并没有配置247这个ip，这个ip是一个虚IP。不是真实ip。不清楚为什么，而且不是每次都出现这个错误。
Redis version
3.X
Redisson version
3.9.0
Redisson configuration
# Redis cluster config
spring.redis.cluster.nodes=\
  172.16.1.25:7001\
  ,172.16.1.25:7002\
  ,172.16.1.25:7003\
  ,172.16.1.26:7004\
  ,172.16.1.26:7005\
  ,172.16.1.26:7006

@Configuration
public class RedissonConfig {
    @Value("${spring.redis.cluster.nodes}")
    String nodes;
    @Bean(name = "redisClusterClient", destroyMethod = "shutdown")
    RedissonClient redisClusterClientInit() {
        Config config = new Config();
        config.setCodec(StringCodec.INSTANCE);
        ClusterServersConfig clusterConfig = config.useClusterServers();
        for (String node : nodes.split(",")) {
            clusterConfig.addNodeAddress("redis://" + node);
        }
        return Redisson.create(config);
    }
}

错误描述如下
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - Caused by: org.redisson.client.WriteRedisConnectionException: Unable to send command! Node source: NodeSource [slot=null, addr=null, redisClient=[addr=redis://172.16.1.247:7002], redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=50, freeConnectionsAmount=32, freeConnectionsCounter=64, freezed=false, freezeReason=null, client=[addr=redis://172.16.1.26:7004], nodeType=MASTER, firstFail=0]]], connection: RedisConnection@1417226931 [redisClient=[addr=redis://172.16.1.247:7002], channel=[id: 0x6e92dd06, L:0.0.0.0/0.0.0.0:2354]], command: (SCAN), command params: [253940, MATCH, ne:alarm:*:*:*, COUNT, 10] after 3 retry attempts
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at org.redisson.command.CommandAsyncService.checkWriteFuture(CommandAsyncService.java:837) ~[redisson-3.9.0.jar!/:na]
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at org.redisson.command.CommandAsyncService.access$200(CommandAsyncService.java:92) ~[redisson-3.9.0.jar!/:na]
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at org.redisson.command.CommandAsyncService$11$1.operationComplete(CommandAsyncService.java:794) ~[redisson-3.9.0.jar!/:na]
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at org.redisson.command.CommandAsyncService$11$1.operationComplete(CommandAsyncService.java:791) ~[redisson-3.9.0.jar!/:na]
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511) ~[netty-common-4.1.29.Final.jar!/:4.1.29.Final]
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:485) ~[netty-common-4.1.29.Final.jar!/:4.1.29.Final]
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424) ~[netty-common-4.1.29.Final.jar!/:4.1.29.Final]
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:121) ~[netty-common-4.1.29.Final.jar!/:4.1.29.Final]
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987) ~[netty-transport-4.1.29.Final.jar!/:4.1.29.Final]
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869) ~[netty-transport-4.1.29.Final.jar!/:4.1.29.Final]
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1391) ~[netty-transport-4.1.29.Final.jar!/:4.1.29.Final]
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738) ~[netty-transport-4.1.29.Final.jar!/:4.1.29.Final]
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730) ~[netty-transport-4.1.29.Final.jar!/:4.1.29.Final]
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38) ~[netty-transport-4.1.29.Final.jar!/:4.1.29.Final]
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081) ~[netty-transport-4.1.29.Final.jar!/:4.1.29.Final]
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128) ~[netty-transport-4.1.29.Final.jar!/:4.1.29.Final]
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070) ~[netty-transport-4.1.29.Final.jar!/:4.1.29.Final]
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163) ~[netty-common-4.1.29.Final.jar!/:4.1.29.Final]
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404) ~[netty-common-4.1.29.Final.jar!/:4.1.29.Final]
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:446) ~[netty-transport-4.1.29.Final.jar!/:4.1.29.Final]
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884) ~[netty-common-4.1.29.Final.jar!/:4.1.29.Final]
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.29.Final.jar!/:4.1.29.Final]
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_111]
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - Caused by: java.nio.channels.ClosedChannelException: null
08-11-2018 12:05:41 CST azkaban-redis-alarm-to-mysql INFO - 	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source) ~[netty-transport-4.1.29.Final.jar!/:4.1.29.Final]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1728
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In this issue#1333 (comment)  I found that RedissonRedLock supports Redis cluster mode. In the Redlock algorithm https://redis.io/topics/distlock,I don't think it supports  Master/Slave mode.The description is:

In the distributed version of the algorithm we assume we have N Redis masters. Those nodes are totally independent, so we don’t use replication or any other implicit coordination system.

For example:
The Redis cluster 1 is as follows:
Master1 Slave1
Master2 Slave2
Master3 Slave3
The Redis cluster 2 is as follows:
Master1
Master2
Master3
I am troubled. Does it support  type of  Redis cluster 1 ?
.If it supports then how do I add a configuration, whether the master and slave are added or only the master configuration is added.
For example :
Add as type1
Config config = new Config();
config.useClusterServers().addNodeAddress(Master1, Master2,Master3, Slave1,Slave2, Slave3);
RedissonClient redisson = Redisson.create(config);
RLock lock1 = redisson.getLock(lockName + "1");
RLock lock2 = redisson.getLock(lockName + "2");
RLock lock3 = redisson.getLock(lockName + "3");
RLock lock4 = redisson.getLock(lockName + "4");
RLock lock5 = redisson.getLock(lockName + "5");
RLock lock6 = redisson.getLock(lockName + "6");

Add as type2
Config config = new Config();
config.useClusterServers().addNodeAddress(Master1, Master2,Master3);
RedissonClient redisson = Redisson.create(config);
RLock lock1 = redisson.getLock(lockName + "1");
RLock lock2 = redisson.getLock(lockName + "2");
RLock lock3 = redisson.getLock(lockName + "3");

Add as type3
Config config = new Config();
config.useClusterServers().addNodeAddress(Master1, Master2,Master3, Slave1,Slave2, Slave3);
RedissonClient redisson = Redisson.create(config);
RLock lock1 = redisson.getLock(lockName + "1");
RLock lock2 = redisson.getLock(lockName + "2");
RLock lock3 = redisson.getLock(lockName + "3");


Which type should I choose,or they are all wrong?
Redis version
3.x
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1729
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Redisson should be able to connect to local redis running on port 6614.
Actual behavior
Redisson won't start and throws this error:
Caused by: org.redisson.client.RedisConnectionException: Unable to connect to Redis server: localhost/127.0.0.1:6614
        at org.redisson.connection.pool.ConnectionPool$2$1.operationComplete(ConnectionPool.java:160)
        at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511)
        at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:485)
        at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424)
        at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:121)
        at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:108)
        at org.redisson.connection.pool.ConnectionPool.promiseFailure(ConnectionPool.java:327)
        at org.redisson.connection.pool.ConnectionPool.access$400(ConnectionPool.java:53)
        at org.redisson.connection.pool.ConnectionPool$4.operationComplete(ConnectionPool.java:291)
        at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511)
        at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:504)
        at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:483)
        at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424)
        at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:121)
        at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:108)
        at org.redisson.client.RedisClient$2$1$2.run(RedisClient.java:250)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:462)
        at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalStateException: failed to create a new resolver
        at io.netty.resolver.AddressResolverGroup.getResolver(AddressResolverGroup.java:71)
        at org.redisson.connection.dns.MultiDnsAddressResolverGroup.getResolver(MultiDnsAddressResolverGroup.java:65)
        at io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:200)
        at io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:49)
        at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:188)
        at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:174)
        at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511)
        at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:485)
        at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424)
        at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:103)
        at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:978)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:512)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:423)
        at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:482)
        ... 6 common frames omitted
Caused by: io.netty.channel.ChannelException: Unable to create Channel from class class io.netty.channel.socket.nio.NioDatagramChannel
        at io.netty.channel.ReflectiveChannelFactory.newChannel(ReflectiveChannelFactory.java:40)
        at io.netty.bootstrap.AbstractBootstrap.initAndRegister(AbstractBootstrap.java:320)
        at io.netty.bootstrap.AbstractBootstrap.register(AbstractBootstrap.java:234)
        at io.netty.resolver.dns.DnsNameResolver.<init>(DnsNameResolver.java:394)
        at io.netty.resolver.dns.DnsNameResolverBuilder.build(DnsNameResolverBuilder.java:430)
        at io.netty.resolver.dns.DnsAddressResolverGroup.newNameResolver(DnsAddressResolverGroup.java:114)
        at io.netty.resolver.dns.DnsAddressResolverGroup.newResolver(DnsAddressResolverGroup.java:94)
        at io.netty.resolver.dns.DnsAddressResolverGroup.newResolver(DnsAddressResolverGroup.java:79)
        at io.netty.resolver.AddressResolverGroup.getResolver(AddressResolverGroup.java:69)
        ... 20 common frames omitted
Caused by: java.lang.reflect.InvocationTargetException: null
        at sun.reflect.GeneratedConstructorAccessor36.newInstance(Unknown Source)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
        at io.netty.channel.ReflectiveChannelFactory.newChannel(ReflectiveChannelFactory.java:38)
        ... 28 common frames omitted
Caused by: io.netty.channel.ChannelException: Failed to open a socket.
        at io.netty.channel.socket.nio.NioDatagramChannel.newSocket(NioDatagramChannel.java:88)
        at io.netty.channel.socket.nio.NioDatagramChannel.<init>(NioDatagramChannel.java:116)
        ... 32 common frames omitted
Caused by: java.net.SocketException: maximum number of DatagramSockets reached
        at sun.net.ResourceManager.beforeUdpCreate(ResourceManager.java:73)
        at sun.nio.ch.DatagramChannelImpl.<init>(DatagramChannelImpl.java:111)
        at sun.nio.ch.SelectorProviderImpl.openDatagramChannel(SelectorProviderImpl.java:42)
        at io.netty.channel.socket.nio.NioDatagramChannel.newSocket(NioDatagramChannel.java:86)
        ... 33 common frames omitted

Steps to reproduce or test case
Redis version
2.8.19
Redisson version
3.9.0
Redisson configuration
		final org.redisson.config.Config rConfig = new org.redisson.config.Config()
				.setTransportMode(TransportMode.NIO);
		rConfig.useSingleServer()
				.setAddress("redis://localhost:6614")
				.setPassword(password);
So a few things to note.
I'm only having this issue with 3.9.0. 3.8.2 works just fine.
I tried replacing the address with "redis://127.0.0.1:6614", and I got the same error:
Caused by: org.redisson.client.RedisConnectionException: Unable to connect to Redis server: 127.0.0.1/127.0.0.1:6614
        at org.redisson.connection.pool.ConnectionPool$2$1.operationComplete(ConnectionPool.java:160)
        at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511)
        at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:485)
        at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424)
        at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:121)
        at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:108)
        at org.redisson.connection.pool.ConnectionPool.promiseFailure(ConnectionPool.java:327)
        at org.redisson.connection.pool.ConnectionPool.access$400(ConnectionPool.java:53)
        at org.redisson.connection.pool.ConnectionPool$4.operationComplete(ConnectionPool.java:291)
        at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511)
        at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:504)
        at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:483)
        at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424)
        at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:121)
        at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:108)
        at org.redisson.client.RedisClient$2$1$2.run(RedisClient.java:250)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:462)
        at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalStateException: failed to create a new resolver
        at io.netty.resolver.AddressResolverGroup.getResolver(AddressResolverGroup.java:71)
        at org.redisson.connection.dns.MultiDnsAddressResolverGroup.getResolver(MultiDnsAddressResolverGroup.java:65)
        at io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:200)
        at io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:49)
        at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:188)
        at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:174)
        at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511)
        at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:485)
        at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424)
        at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:103)
        at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:978)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:512)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:423)
        at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:482)
        ... 6 common frames omitted
Caused by: io.netty.channel.ChannelException: Unable to create Channel from class class io.netty.channel.socket.nio.NioDatagramChannel
        at io.netty.channel.ReflectiveChannelFactory.newChannel(ReflectiveChannelFactory.java:40)
        at io.netty.bootstrap.AbstractBootstrap.initAndRegister(AbstractBootstrap.java:320)
        at io.netty.bootstrap.AbstractBootstrap.register(AbstractBootstrap.java:234)
        at io.netty.resolver.dns.DnsNameResolver.<init>(DnsNameResolver.java:394)
        at io.netty.resolver.dns.DnsNameResolverBuilder.build(DnsNameResolverBuilder.java:430)
        at io.netty.resolver.dns.DnsAddressResolverGroup.newNameResolver(DnsAddressResolverGroup.java:114)
        at io.netty.resolver.dns.DnsAddressResolverGroup.newResolver(DnsAddressResolverGroup.java:94)
        at io.netty.resolver.dns.DnsAddressResolverGroup.newResolver(DnsAddressResolverGroup.java:79)
        at io.netty.resolver.AddressResolverGroup.getResolver(AddressResolverGroup.java:69)
        ... 20 common frames omitted
Caused by: java.lang.reflect.InvocationTargetException: null
        at sun.reflect.GeneratedConstructorAccessor35.newInstance(Unknown Source)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
        at io.netty.channel.ReflectiveChannelFactory.newChannel(ReflectiveChannelFactory.java:38)
        ... 28 common frames omitted
Caused by: io.netty.channel.ChannelException: Failed to open a socket.
        at io.netty.channel.socket.nio.NioDatagramChannel.newSocket(NioDatagramChannel.java:88)
        at io.netty.channel.socket.nio.NioDatagramChannel.<init>(NioDatagramChannel.java:116)
        ... 32 common frames omitted
Caused by: java.net.SocketException: maximum number of DatagramSockets reached
        at sun.net.ResourceManager.beforeUdpCreate(ResourceManager.java:73)
        at sun.nio.ch.DatagramChannelImpl.<init>(DatagramChannelImpl.java:111)
        at sun.nio.ch.SelectorProviderImpl.openDatagramChannel(SelectorProviderImpl.java:42)
        at io.netty.channel.socket.nio.NioDatagramChannel.newSocket(NioDatagramChannel.java:86)
        ... 33 common frames omitted

I also tried removing the "redis://" part and only include "localhost:6614" or "127.0.0.1:6614", and I got a completely different error, which is:
Caused by: java.lang.IllegalArgumentException: Illegal character in scheme name at index 0: [localhost]:6614
        at java.net.URI.create(URI.java:852)
        at org.redisson.misc.URIBuilder.create(URIBuilder.java:39)
        at org.redisson.config.SingleServerConfig.setAddress(SingleServerConfig.java:119)

and
Caused by: java.lang.IllegalArgumentException: Illegal character in scheme name at index 0: 127.0.0.1:6614
        at java.net.URI.create(URI.java:852)
        at org.redisson.misc.URIBuilder.create(URIBuilder.java:31)
        at org.redisson.config.SingleServerConfig.setAddress(SingleServerConfig.java:119)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1730
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1731
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior

Actual behavior
spring.redis.sentinel.nodes=192.168.1.241:26379,192.168.1.241:36379,192.168.1.241:46379
Steps to reproduce or test case

Redis version
Redisson version
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1732
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Current 3rd party implementation https://github.com/debop/hibernate-redis seems is not developed anymore and doesn't support hibernate 5.3
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1733
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I would like to ask for your help because I experienced a lack of connection with the PaaS Azure element of Redis Cache last Saturday.
The exception thrown is related to CommandAsyncService, please find in the attachment.
I’m using version 3.6.5 of redisson, in the following you find redisson.conf.
It seems that in that day the tomcat running on a VM could not write on Redis with commands HMSET and DEL, throwing the exception mentioned before. The immediate solution was to restart tomcat service so that connection was re-established.
Do you know if this issue is fixed in later versions? What would you suggest to do in this circumstances?
{
"singleServerConfig":{
"idleConnectionTimeout":10000,
"pingTimeout":1000,
"connectTimeout":10000,
"timeout":3000,
"retryAttempts":3,
"retryInterval":1500,
"reconnectionTimeout":3000,
"failedAttempts":3,
"password":"TdyTFjnGmdscWoEUy/lgejuMeDD/jIUsWZeLeewHaDs=",
"subscriptionsPerConnection":5,
"clientName":"IOTIM-FE-01-PROD",
"address": "redis://iotim-sl-fe-prod-session.redis.cache.windows.net:6379",
"subscriptionConnectionMinimumIdleSize":1,
"subscriptionConnectionPoolSize":50,
"connectionMinimumIdleSize":10,
"connectionPoolSize":64,
"database":0,
"dnsMonitoring":false,
"dnsMonitoringInterval":5000
},
"threads":0,
"nettyThreads":0,
"codec":null,
"useLinuxNativeEpoll":false
}
reddison.log
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1734
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
If execution of the cron task takes longer than its period, then subsequent executions should start late, but not removed.
Actual behavior
When the cron task takes longer then its period, the subsequent scheduler is removed and the task is never run after.
Steps to reproduce or test case
public class Schedule {

	public static void main(String[] args) {
		RedissonClient client = Redisson.create();
		RScheduledExecutorService executorService = client.getExecutorService("JobA");
                // run JobA every 10 seconds
		executorService.schedule(new JobA() , CronSchedule.of("0/10 * * * * ?"));
	}

}

JobA class:
public class JobA implements Runnable {

	@Override
	public void run() {

		try {
			Thread.sleep(10000)
		} catch (InterruptedException e) {
			e.printStackTrace();
		}
		System.out.println("JOB A ran!!!!!!!!!!");
	}

}

Worker to run JobA:
public class Worker{
	public static void main(String[] args) {
		Config config = new Config();
		config.useSingleServer().setAddress("redis://127.0.0.1:6379");
		RedissonNodeConfig nodeConfig = new RedissonNodeConfig(config);
		nodeConfig.getExecutorServiceWorkers().put("JobA", 1);
		RedissonNode node = RedissonNode.create(nodeConfig);
		node.start();
	}

}

Redis version
Redis 3.0.503
Redisson version
3.9.0, 3.8.2, 3.8.1, 3.8.0
When the worker starts it will execute the JobA only once. I checked the Redis and the scheduler key under JobA is removed after. This happens when the task takes longer to complete than rate.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1735
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Our environment has 3 varieties:
S(SMALL): 1 sentinel + 1 redis master
M(MIDDLE): 3 sentinels + 1 master + 1 slave
L(LARGE): X sentinels + 1 master + Y slave
And our EVN has scaling path: S->M->L
Expected behavior
In each ENV, redisson works fine. I understand at least 2 sentinels can guarantee master->slave failover, but in our SMALL ENV, we only have 1 master, no HA required. we are forced to use redisson old version(3.6.0) as it allows 1 sentinel. The reason why keep sentinel here is to make it no difference with M and L environment, we can use very same redisson configuration and code in each ENV.
My suggestion is to make it configurable, so that redisson reject 1 sentinel configuration by default but allows user to enable it in case needed.
Actual behavior
When in SMALL ENV, redisson will throw below exception:
throw new RedisConnectionException("At least two sentinels should be defined in Redis configuration!")
Steps to reproduce or test case
Configure 1 sentinel + 1 redis master
Redis version
any
Redisson version
3.8.1
Redisson configuration
1 sentinel + 1 redis master
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1736
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
spring use:
@configuration
public class RedissonSpringDataConfig {
@Bean
public RedissonConnectionFactory redissonConnectionFactory(RedissonClient redisson) {
    return new RedissonConnectionFactory(redisson);
}

@Bean(destroyMethod = "shutdown")
public RedissonClient redisson(@Value("classpath:/redisson.yaml") Resource configFile) throws IOException {
    Config config = Config.fromYAML(configFile.getInputStream());
    return Redisson.create(config);
}

}
configuration:
clusterServersConfig:
idleConnectionTimeout: 10000
pingTimeout: 1000
connectTimeout: 10000
timeout: 3000
retryAttempts: 3
retryInterval: 1500
failedSlaveReconnectionInterval: 3000
failedSlaveCheckInterval: 60000
password: iMfnd14#ra66N0ep
subscriptionsPerConnection: 5
clientName: null
loadBalancer: !<org.redisson.connection.balancer.RoundRobinLoadBalancer> {}
subscriptionConnectionMinimumIdleSize: 1
subscriptionConnectionPoolSize: 50
slaveConnectionMinimumIdleSize: 32
slaveConnectionPoolSize: 64
masterConnectionMinimumIdleSize: 32
masterConnectionPoolSize: 64
readMode: "SLAVE"
subscriptionMode: "SLAVE"
nodeAddresses:

"redis://10.9.3.1:6344"
"redis://10.9.3.1:6355"
"redis://10.9.3.1:6366"
"redis://10.9.3.1:6377"
"redis://10.9.3.1:6388"
"redis://10.9.3.1:6399"
scanInterval: 1000
pingConnectionInterval: 0
keepAlive: false
tcpNoDelay: false
threads: 0
nettyThreads: 0
codec: !<org.redisson.codec.JsonJacksonCodec> {}
transportMode: "NIO"

when shutdown throw excetion:
2018-11-14 22:32:26.701 ERROR 12561 --- [       Thread-3] i.n.u.c.D.rejectedExecution              : Failed to submit a listener notification task. Event loop shut down?
java.util.concurrent.RejectedExecutionException: event executor terminated
at io.netty.util.concurrent.SingleThreadEventExecutor.reject(SingleThreadEventExecutor.java:842) ~[netty-common-4.1.29.Final.jar:4.1.29.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor.offerTask(SingleThreadEventExecutor.java:328) ~[netty-common-4.1.29.Final.jar:4.1.29.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor.addTask(SingleThreadEventExecutor.java:321) ~[netty-common-4.1.29.Final.jar:4.1.29.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor.execute(SingleThreadEventExecutor.java:765) ~[netty-common-4.1.29.Final.jar:4.1.29.Final]
at io.netty.util.concurrent.DefaultPromise.safeExecute(DefaultPromise.java:768) [netty-common-4.1.29.Final.jar:4.1.29.Final]
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:432) [netty-common-4.1.29.Final.jar:4.1.29.Final]
at io.netty.util.concurrent.DefaultPromise.setSuccess(DefaultPromise.java:94) [netty-common-4.1.29.Final.jar:4.1.29.Final]
at io.netty.channel.group.DefaultChannelGroupFuture.setSuccess0(DefaultChannelGroupFuture.java:205) [netty-transport-4.1.29.Final.jar:4.1.29.Final]
at io.netty.channel.group.DefaultChannelGroupFuture.(DefaultChannelGroupFuture.java:121) [netty-transport-4.1.29.Final.jar:4.1.29.Final]
at io.netty.channel.group.DefaultChannelGroup.newCloseFuture(DefaultChannelGroup.java:449) [netty-transport-4.1.29.Final.jar:4.1.29.Final]
at io.netty.channel.group.DefaultChannelGroup.newCloseFuture(DefaultChannelGroup.java:430) [netty-transport-4.1.29.Final.jar:4.1.29.Final]
at org.redisson.client.RedisClient.shutdownAsync(RedisClient.java:334) [redisson-3.9.0.jar:na]
at org.redisson.connection.MasterSlaveConnectionManager.closeNodeConnections(MasterSlaveConnectionManager.java:215) [redisson-3.9.0.jar:na]
at org.redisson.cluster.ClusterConnectionManager.shutdown(ClusterConnectionManager.java:802) [redisson-3.9.0.jar:na]
at org.redisson.Redisson.shutdown(Redisson.java:661) [redisson-3.9.0.jar:na]
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151]
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_151]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151]
at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151]
at org.springframework.beans.factory.support.DisposableBeanAdapter.invokeCustomDestroyMethod(DisposableBeanAdapter.java:337) [spring-beans-5.0.10.RELEASE.jar:5.0.10.RELEASE]
at org.springframework.beans.factory.support.DisposableBeanAdapter.destroy(DisposableBeanAdapter.java:271) [spring-beans-5.0.10.RELEASE.jar:5.0.10.RELEASE]
at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroyBean(DefaultSingletonBeanRegistry.java:571) [spring-beans-5.0.10.RELEASE.jar:5.0.10.RELEASE]
at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingleton(DefaultSingletonBeanRegistry.java:543) [spring-beans-5.0.10.RELEASE.jar:5.0.10.RELEASE]
at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingleton(DefaultListableBeanFactory.java:954) [spring-beans-5.0.10.RELEASE.jar:5.0.10.RELEASE]
at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingletons(DefaultSingletonBeanRegistry.java:504) [spring-beans-5.0.10.RELEASE.jar:5.0.10.RELEASE]
at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingletons(DefaultListableBeanFactory.java:961) [spring-beans-5.0.10.RELEASE.jar:5.0.10.RELEASE]
at org.springframework.context.support.AbstractApplicationContext.destroyBeans(AbstractApplicationContext.java:1039) [spring-context-5.0.10.RELEASE.jar:5.0.10.RELEASE]
at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:1015) [spring-context-5.0.10.RELEASE.jar:5.0.10.RELEASE]
at org.springframework.context.support.AbstractApplicationContext$1.run(AbstractApplicationContext.java:935) [spring-context-5.0.10.RELEASE.jar:5.0.10.RELEASE]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1737
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Spring Boot application using redisson-spring-boot-starter runs without exception and connects to Redis server.
Actual behavior
Spring Boot application fails to start with stacktrace due to NullPointerException in RedissonAutoconfiguration. The issue is that there is a reference to RedisProperties.timeout that calls timeoutValue.getClass() without first checking to see if the value returned is an Class and thus the NullPointerException is thrown. Added a spring.redis.timeout value to the configuration avoids the issue, but that shouldn't be required.
Steps to reproduce or test case
Redis version
Doesn't matter, but tested with 3.x
Redisson version
3.9.0
Redisson configuration
Only basic spring.redis.host and spring.redis.port configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1738
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1739
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1740
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Objects for values used in redisson classes such as RMap and RBucket can be  non-final classes without annotating explicitly.
Actual behavior
When serializing non-final classes using Jackson, the type id is not used.  When reading such classes, redisson always explicitly passes Object.class to Jackson for deserialization which requires type id in "@Class" field causing missing typeid exception.
This is more of a problem using Kotlin due to final being the default modifier for classes, and the only modifier for data classes.   The errors and solution are non obvious.    Registering modules or explicitly attempting to force enableTypeId via ObjectMapper configuration does not work.
Annotating  the classes with @JsonTypeInfo(use = JsonTypeInfo.Id.CLASS, include = JsonTypeInfo.As.PROPERTY)  or forcing non-final classes, and not using any kotlin 'data' class does work.
Steps to reproduce or test case
java:
use RBucket   where MyClass is final.p
kotlin:
use RBucket where MyClass is not 'open' or is a 'data class'
Looking at the raw redis values one can see when the typeid in @Class is used and when it is not
Redis version
5.0-rc-4
Redisson version
3.9.0
Redisson configuration
default configuration.
Or override codec with  JsonJacksonCodec( jacksonObjectMapper())   (for kotlin)

Suggestion:   The core cause is in the Redisson JsonJacksonCodec  Encoder and Decoder.
The Encoder calls objectMapper.writeValue() using the object instance supplied -- this internally will resolve to the instance class (not the declared class of Object).   The default Jackson encoding behaviour will only add type id if this is a non-final class.
The Decoder, on the other hand, explicitly passes in a Object.class as the type to deserialize.  Object.class is ALWAYS non-final so will always require type id.
This fundamentally cannot work without additional type information being stored in redisson.   Suggest, as Jackson APIs allow, to allow for passing in the and storing the class used when creating container objects and collections so that it may be explicitly passed instead of Object.class .    Creative use of generic class instantiation can partially solve this in pure java for generics.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1741
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
Redisson version
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1742
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
In MasterSlaveEntry, after switchover(changeMaster), all oldMaster connections are kicked off from writeConnectionPool.
Actual behavior
If changeMaster happens, meanwhile  old master connection is during reconnecting, old master connection will still exists in writeConnectionPool(even it becomes slave).
See below logs from example:
2018-11-17-T01:01:10.342+0200  | pool-27-thread-1 | DEBUG | org.redisson.client.handler.ConnectionWatchdog | reconnecting RedisConnection@285720286 [redisClient=[addr=redis://10.91.115.150:6379], channel=[id: 0x997b1f3a
, L:/10.91.115.149:39489 ! R:/10.91.115.150:6379]] to /10.91.115.150:6379
2018-11-17-T01:01:14.671+0200 | redisson-netty-1-1 | INFO  | org.redisson.connection.SingleEntry | master /10.91.115.150:6379 has changed to /10.91.115.149:6379
2018-11-17-T01:01:15.143+0200 | redisson-netty-1-1 | DEBUG | org.redisson.client.handler.ConnectionWatchdog | RedisConnection@285720286 [redisClient=[addr=redis://10.91.115.150:6379], channel=[id: 0x92fe504f, L:/10.91.115.149:39151 - R:/10.91.115.150:6379]] connected to /10.91.115.150:6379, command: CommandData [promise=org.redisson.misc.RedissonPromise@631cd234[Completed normally], command=(CLIENT SETNAME), params=[xxx], codec=null]
2018-11-17-T01:04:16.071+0200 | pool-1 | org.redisson.client.RedisException: READONLY You can't write against a read only slave.. channel: [id: 0x92fe504f, L:/10.91.115.149:39151 - R:/10.91.115.150:6379] command: (BLPOP), params: [xxx-queue, 10]
Steps to reproduce or test case
Redis version
any
Redisson version
3.6.0
Redisson configuration
sentinel
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1743
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
The stated purpose of the library behaves as documented and expected -- i.e. users should not need to be aware of implementation and it should "just work".   One stated goal/priority for reddison is that users can use existing or new java classes 'As Is' and simply use reddison as a transparent native object database.   This is a very compelling feature (which has been attempted many times over the last 30+ years).  Considering the maturity and feature rich nature of the product I nievely assumed that this would 'just work' as intended (of course accepting some edge cases that are problematic.)
In particular, with the variety of codecs, including Jackson -- which is if not the single most used JSON data mapper/serialization library, atleast in the top 3, that if a class could round-trip serialize with Jackson that class would be equally usable with Reddison -- this is explicitly stated (with some caveots).
By leveraging the work of existing encoders (like jackson) it is natural to assume that this is not magic -- it would work 'as good as' whatever encoder was configured, so if one has domain knowlege in that encoder and has created classes which behave nicely with that encoder then Reddison would indeed be a transparent 'Drop In' -- and be able to use the the other really awesome features provided.
Actual behavior
It simply does not work this way, and can not work as stated with the existing APIs.
I believe this is due to a fundamental difference in how various encoders/codecs work, and not fully understanding the subtleties.   Some encoders work by always storing the type information with data so that deserialization is possible from the data alone with no external context or special per-instance configuration.    Other encoders (such as Jackson) prioritize round trip to user controllable serialization formats.   The concept being that the codec can be configured such that the output (JSON in this case) is produced in a form that either pre-exists (must be matched exactly) or 'user friendly' (intentionally undefined -- but again, assumed to exist and must be matched).
To achieve this, the default mode, and in fact almost all features of Jackson are designed to NOT embed type into the JSON data itself, but rather to make use of the serialization or deserialization dynamic context (and other out-of-band configurations) to be able to parse 'arbitrary' JSON 'as is' into the expect type.   This is fundamentally different approach and goals then codecs which produce 'black box' output and instead focus on minimal or no out-of-band context needed to round trip Java objects.
The side effect is that in order for Jackson to function properly (i.e. in the use cases it was primarily designed for), type information MUST be provided out-of-band in order to deserialize.
The exception, which is not commonly used, and which recently has been shown to be a severe security problem,  is the special mode of embedding type information with each JSON element.
These modes are not interchangeable and have non-compatible requirements, and in general are 'all or nothing' -- you must code for one or the other mode explicitly and consistently.
The current Reddison APIs cannot handle either mode correctly in many cases.  For example, RBucket, without extreme hacks, cannot round trip most non-primitive objects -- even basic Java Bean or POJO.
This is NOT solvable by simply overriding the codec and tweaking it somehow -- because internally, in intentionally non-exposed implementation code, the necessary usage of the core Jackson APIs are incorrect and inconsistent in at least a few places.   The default Jackson codec uses a non-standard configuration of the ObjectMapper which is not able to round-trip consistently given the implementation of the deserializer (which in many places pasess a literal Object.class as the target type)
I have found that it is possible to hack this on a case by case basis by 'creative' (i.e. probably will break many other things) mangling of the codecs -- on a per use basis -- It still requires every API call to use a distinct codec taylored for the type,  and I have no idea what will happen with nested RObjects -- or other internal code -- What this demonstrates, in my opinion, is that the API itself needs to be enhanced slightly to accommodate the behaviour of codecs which need out of bound type information,
not by making this a burden on the users -- particularly since this relies on understanding many details of the private implementation of Reddison to work -- with no assurance that ones understanding is fully correct or that the undocumented internal implementation will not change.
This essentially makes Reddison unsuitable for large classes of its intended use cases.  That is sad, as I was looking forward to making use of the AWESOME features it does provide -- to be blocked by a few fundamental API flaws.
Recomendation:
Solving this problem is not complex, but it cannot be done cleanly by end users, it needs to be implemented internally and exposed through the APIs.
There are various other products which do this exact thing that can be used as a model for what is needed.
Essentially -- every API which deserializes a user defined object MUST have some mechanism of providing the target class explicitly.   For example:  Jackson itself has a Class argument for every method which does deserialization.   This is not just an 'advanced' feature, its necessary for all but a few special cases.
cache2k https://cache2k.org/  solves the problem by making use of a rarely known, subtle feature of Java which provides a way to prevent type erasure of generics.   E.g.
  Cache<String,String> cache = new Cache2kBuilder<String, String>() {}
This subtle 'trick' of creating a anonymous type explicitly (note the "{}" at the end -- critical), allows the cache to access the generic parameter types and use them later as needed for deserialization.
Using the first suggestion, I believe all it would take to make RBucket.get() to work properly is to add the class argument to get  (   RBucket.get( Type.class ) )
Yes this is ugly and yes this breaks some of the simplicity of implementing interfaces that do not have this signature -- but at least it works reliably and doesn't require the end user to have deep domain knowledge of both the codecs and reddison to handle basic simple java classes as the framework is designed to do.   This would have to be done likewise to all the methods which deserialize top level objects.   Once the top level class is properly deserialized, all its internal references will work fine (if you allow Jackson to do it for you)  -- Jackson will use the declared type of the parents reference variable to deserialize the children.   All the subtleties of how to get this to work are then defered to jackson and whatever customization one needs to do via annotations and configurations are all Jackson problems.
That way you could truly state that "If a class round trips through Jackson using the provided ObjectMapper then Reddison will work correctly for that class without changes or custom configurations needed"
I do not know the extent this affects internal code -- this is why I am not attempting to implement this as a PR -- I suspect that I would need to fully understand all the intricacies of Reddison to make sure I got all the cases correct -- I believe the author is the best source of this domain knowledge.   By the time I fully understood all the code enough to make this change, I would probably end up writing my own version -- which is exactly what I did NOT want to do when I discovered Redisson.
Note that these suggested approaches are NOT simply having the user customizing the codec -- the codec is not the right place to store per-type per-use information, that needs to come from the callsite directly, either in the creation of the R or in its methods -- One could still store the necessary class information in the codec as is done in the JsonJacksonMapCodec -- but 'hide' this from the user -- that is an implementation choice.
For JVM Languages which handle generics 'better' , such as Kotlin, one could write a wrapper around Reddison to provide the simpilier APIs and manage the explicit class arguments in the wrapper.
This is what the Jackson Kotlin module does
https://github.com/FasterXML/jackson-module-kotlin
Most of this module is a single source file that provides 'extension functions' which convert the generic template types into explicit class types to pass to Jackson.
E.g.
inline fun <reified T> ObjectMapper.readValue(src: File): T = readValue(src, jacksonTypeRef<T>()) 
This extension function exposes the intended user experience of
    val myclass = mapper.readValue<MyClass>(File("file.json"))
and under-the-hood converts this to roughly
mapper.readValue( File , MyClass.class )
This is not possible in pure Java, which is why cache2k uses its subtle 'trick' during the cache creation to extract the generics class types.
Note: that the problem exists in Reddison even without user supplied classes begin generic/templates --
this is an issue with even basic POJO type classes with no inheritance, generics, or other 'advanced' features -- Reddison simply does not supply the API's necessary to deserialize these properly using codecs like Jackson which require out of band (or context provided) type information.
You just cant get there from here ...
Note: I was very surprised that such a simple use case failed -- until I checked the test cases in the examples and all of them which would have triggered these problems were using basic types (String, Int, Long) not custom classes.  Those types do not need any out of band type information so they do work just fine.   Similarly, the Reference class handles this problem in its own way (and may in fact be unnecessary if the above suggestions are implemented -- not sure)
Steps to reproduce or test case
Redis version
Redisson version
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1744
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RedissonClient redissonClient = redisService.getRedissonClient();
RBlockingQueue readyQueue = redissonClient.getBlockingQueue("delay_queue");
RDelayedQueue delayedQueue = redissonClient.getDelayedQueue(readyQueue );

delayedQueue.offer("1111", -2515194, TimeUnit.SECONDS);

Expected behavior
offer an element with delay time (-2515194, "2018-11-20 20:00:52") when create time is "2018-11-20 20:42:08".
I expect that it transfers to readyQueue right now.
Actual behavior
but after a long time I got it from the readyQueue at "2018-11-20 21:00:10".
Steps to reproduce or test case
Redis version
Redisson version
3.9.0
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1745
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Add follow methods:
RedissonKeys.getKeysByPatternStream, RedissonKeys.getKeysStream, RedissonPriorityDeque.descendingStream, RedissonScoredSortedSet.stream, RedissonSet.stream, RedissonSetCache.stream, RedissonSetMultimapValues.stream
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1746
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In MASTER_SLAVE read mode, when redis master node closes, read will slow down. Is this a bug?
Here are my operations：
I started three redis server processes, (6379, 7379, 7380), 6379 as master and 7379, 7380 as slave.
Then I started three Sentinel processes (26379, 26380, 26381) to monitor the redis cluster.
Then I started redisson client by this config:
Config config = new Config();  
config.setTransportMode(TransportMode.NIO);
config.useSentinelServers()
.setReadMode(ReadMode.MASTER_SLAVE)
.setMasterName("mymaster")
.addSentinelAddress("redis://127.0.0.1:26379", "redis://127.0.0.1:26380", "redis://127.0.0.1:26381");

Then I read and write randomly to redis cluster：
RedissonClient redisson = Redisson.create(config);
for (; ; ) {
   try {
      RBucket<Object> test = redisson.getBucket("test");
      if (System.currentTimeMillis() % 5 == 0) {
         test.set(System.currentTimeMillis()+"");
      }
      System.out.println(test.get());
      Thread.sleep(50);
   } catch (Exception e) {
      e.printStackTrace();
   }
}

Then every 50 milliseconds I can get a result.
But when I kill redis master node (6379), the get command of redisson will become very slow, which is jstack information.
192 "main" #1 prio=5 os_prio=31 tid=0x00007febfc00c000 nid=0x1703 waiting on condition [0x0000700000218000]
193    java.lang.Thread.State: WAITING (parking)
194     at sun.misc.Unsafe.park(Native Method)
195     - parking to wait for  <0x000000076c40ab30> (a java.util.concurrent.CountDownLatch$Sync)
196     at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
197     at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
198     at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
199     at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
200     at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231)
201     at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:182)
202     at org.redisson.RedissonObject.get(RedissonObject.java:76)
203     at org.redisson.RedissonBucket.get(RedissonBucket.java:97)
204     at com.xxxx.main(RedisExpandClient.java:2135)
205     at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
206     at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
207     at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
208     at java.lang.reflect.Method.invoke(Method.java:498)
209     at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)

Redis version
redis-server --version
Redis server v=4.0.11 sha=00000000:0 malloc=libc bits=64 build=a57766d459574c0a

Redisson version
<dependency>
   <groupId>org.redisson</groupId>
   <artifactId>redisson</artifactId>
   <version>3.9.0</version>
</dependency>
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1747
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
Redisson version
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1748
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
org.redisson.client.RedisConnectionClosedException: Command (EVAL), params: [if (redis.call('exists', KEYS[1]) == 0) then
a2d70d0c-f520-4538-94c4-8dce7ced610a:57] succesfully sent, but channel [id: 0x9bcb4d06, L:/10.16.125.176:54326 ! R:10.208.53.13/10.208.53.13:1436] has been closed!
at org.redisson.client.handler.CommandsQueue.channelInactive(CommandsQueue.java:88)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224)
at org.redisson.client.handler.ConnectionWatchdog.channelInactive(ConnectionWatchdog.java:84)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224)
at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1429)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:947)
at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:822)
at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:462)
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:745)
]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1749
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
why redisson not support  redis command APPEND , decrBy?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1750
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Here is the other issue I created.
Just like the other ticket, as soon as I downgrade to 3.8.2, everything works just fine.
Expected behavior
Redisson should be able to connect to local redis running on port 6614.
Actual behavior
Redisson won't start and throws this error:
Caused by: org.redisson.client.RedisConnectionException: Unable to connect to Redis server: localhost/127.0.0.1:6614
        at org.redisson.connection.pool.ConnectionPool$2$1.operationComplete(ConnectionPool.java:160)
        at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511)
        at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:485)
        at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424)
        at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:121)
        at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:108)
        at org.redisson.connection.pool.ConnectionPool.promiseFailure(ConnectionPool.java:327)
        at org.redisson.connection.pool.ConnectionPool.access$400(ConnectionPool.java:53)
        at org.redisson.connection.pool.ConnectionPool$4.operationComplete(ConnectionPool.java:291)
        at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511)
        at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:504)
        at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:483)
        at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424)
        at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:121)
        at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:108)
        at org.redisson.client.RedisClient$2$1$2.run(RedisClient.java:250)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:466)
        at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalStateException: failed to create a new resolver
        at io.netty.resolver.AddressResolverGroup.getResolver(AddressResolverGroup.java:71)
        at io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:200)
        at io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:49)
        at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:188)
        at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:174)
        at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511)
        at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:485)
        at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424)
        at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:103)
        at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:978)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:512)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:423)
        at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:482)
        ... 6 common frames omitted
Caused by: java.lang.IllegalStateException: failed to create a new resolver
        at io.netty.resolver.AddressResolverGroup.getResolver(AddressResolverGroup.java:71)
        at org.redisson.connection.dns.MultiDnsAddressResolverGroup.newResolver(MultiDnsAddressResolverGroup.java:68)
        at io.netty.resolver.dns.DnsAddressResolverGroup.newResolver(DnsAddressResolverGroup.java:79)
        at io.netty.resolver.AddressResolverGroup.getResolver(AddressResolverGroup.java:69)
        ... 19 common frames omitted
Caused by: io.netty.channel.ChannelException: Unable to create Channel from class class io.netty.channel.socket.nio.NioDatagramChannel
        at io.netty.channel.ReflectiveChannelFactory.newChannel(ReflectiveChannelFactory.java:40)
        at io.netty.bootstrap.AbstractBootstrap.initAndRegister(AbstractBootstrap.java:320)
        at io.netty.bootstrap.AbstractBootstrap.register(AbstractBootstrap.java:234)
        at io.netty.resolver.dns.DnsNameResolver.<init>(DnsNameResolver.java:394)
        at io.netty.resolver.dns.DnsNameResolverBuilder.build(DnsNameResolverBuilder.java:430)
        at io.netty.resolver.dns.DnsAddressResolverGroup.newNameResolver(DnsAddressResolverGroup.java:114)
        at io.netty.resolver.dns.DnsAddressResolverGroup.newResolver(DnsAddressResolverGroup.java:94)
        at io.netty.resolver.dns.DnsAddressResolverGroup.newResolver(DnsAddressResolverGroup.java:79)
        at io.netty.resolver.AddressResolverGroup.getResolver(AddressResolverGroup.java:69)
        ... 22 common frames omitted
Caused by: java.lang.reflect.InvocationTargetException: null
        at sun.reflect.GeneratedConstructorAccessor33.newInstance(Unknown Source)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
        at io.netty.channel.ReflectiveChannelFactory.newChannel(ReflectiveChannelFactory.java:38)
        ... 30 common frames omitted
Caused by: io.netty.channel.ChannelException: Failed to open a socket.
        at io.netty.channel.socket.nio.NioDatagramChannel.newSocket(NioDatagramChannel.java:88)
        at io.netty.channel.socket.nio.NioDatagramChannel.<init>(NioDatagramChannel.java:116)
        ... 34 common frames omitted
Caused by: java.net.SocketException: maximum number of DatagramSockets reached
        at sun.net.ResourceManager.beforeUdpCreate(ResourceManager.java:73)
        at sun.nio.ch.DatagramChannelImpl.<init>(DatagramChannelImpl.java:111)
        at sun.nio.ch.SelectorProviderImpl.openDatagramChannel(SelectorProviderImpl.java:42)
        at io.netty.channel.socket.nio.NioDatagramChannel.newSocket(NioDatagramChannel.java:86)
        ... 35 common frames omitted

Steps to reproduce or test case
Redis version
2.8.19 with embedded-redis
Redisson version
3.9.1
Redisson configuration
	final org.redisson.config.Config rConfig = new org.redisson.config.Config()
			.setTransportMode(TransportMode.NIO);
	rConfig.useSingleServer()
			.setAddress("redis://localhost:6614")
			.setPassword(password);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1751
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am new to Redis and Redisson. I am trying to set a RMap<String,BitSet>. I call the put method on my RMap object, but when i do the get, I always get a empty BitSet. If i use RMap<String,RBitSet>, iterating over the map results in a "java.lang.ClassCastException: org.redisson.RedissonReference cannot be cast to org.redisson.api.RBitSet"
RMap<String,BitSet> data = redisson.getMap("data-00");
BitSet bs = new BitSet(10);
bs.set(5);
bs.set(7);
data.put("a", bs);
RMap<String,BitSet> data1 = redisson.getMap("data-00");
for (Map.Entry<String, BitSet> entry : data1.entrySet()) {
System.out.println(entry.getKey()+" = "+entry.getValue());
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1752
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
We have application using Redisson to access Redis cluster(3 masters+3 slaves).
We have a test case which is to shutdown one or more Redis slave nodes then take it up.
We don't expect there is any Redisson Connection broken on the master nodes since we only take action on the slave nodes.
Actual behavior
It is found after Redis slave node is shutdown and taken up, the Redisson connection to its master node will be broken.
By checking the Redisson 3.9.0(also the latest 3.9.1), it is found after a slave node is up, on its master node, Redisson will try to release the connection from all others except this slave node.
Here "all others" has included the connection from the application.
MasterSlaveEntry.java: Function "public boolean slaveUp(URI address, FreezeReason freezeReason)"
Not sure my understanding is correct or not.
Steps to reproduce or test case
Like above, in a Redis cluster, after restarting the slave nodes, the Redisson connections to the master nodes will be broken.
Redis version
4.0.8
Redisson version
3.9.0
Redisson configuration
clusterServersConfig:
idleConnectionTimeout: 10000
pingTimeout: 15000
connectTimeout: 10000
timeout: 60000
timeout: 30000
retryAttempts: 3
retryInterval: 1500
retryInterval: 1500
reconnectionTimeout: 1000
failedAttempts: 3
password: null
subscriptionsPerConnection: 5
clientName: null
loadBalancer: !<org.redisson.connection.balancer.RoundRobinLoadBalancer> {}
slaveSubscriptionConnectionMinimumIdleSize: 1
slaveSubscriptionConnectionPoolSize: 50
slaveConnectionMinimumIdleSize: 2
slaveConnectionPoolSize: 2
masterConnectionMinimumIdleSize: 3
masterConnectionPoolSize: 3
readMode: "MASTER_SLAVE"
nodeAddresses:

"redis://HOST1:6000"

- "redis://[HOST2]:5301"
- "redis://[HOST3]:5301"
scanInterval: 10000
threads: 32
nettyThreads: 32
codec: !<org.redisson.codec.JsonJacksonCodec> {}
useLinuxNativeEpoll: false
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1753
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
i try to use watch commond in a lua script，but it doesn't work,throw the exception like this
"This Redis command is not allowed from scripts"
so, does redisson have a way to support watch？
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1754
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
<!--
Please consider to take commercial 24x7 support included in PRO version https://redisson.pro
-->
RDelayedQueue在应用启动一段时间后，不再transfer队列中到期的元素到Destination Queue，必须得重启才行呀。
Expected behavior
重连后应该会继续Transfer才对
Actual behavior
可以正常获取RDelayedQueue中的元素个数，但是没有进行Transfer
Steps to reproduce or test case
Redis version
Redisson version
3.9.0
Redisson configuration
@jackygurui 麻烦帮忙看看，几天了都没有解决。
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1755
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1756
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I decided to drop further development of 2.x version by 1st February 2019. Its amount of downloads takes less than 5% of total downloads and decreasing each month, according to maven repo statistics. If you haven't yet moved to 3.x version then I recommend to plan such migration in the nearest time.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1757
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
having this config for the redissonclient and using @EnableRedissonHttpSession should not fail with ClassCastException
    final Config config = new Config();
    config.setCodec(new ByteArrayCodec());
    return Redisson.create(config);

Actual behavior
using above configuration and RedissonSession we get a ClassCastException
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to [B
		at org.redisson.client.codec.ByteArrayCodec$1.encode(ByteArrayCodec.java:39)
		at org.redisson.RedissonObject.encodeMapKey(RedissonObject.java:265)
		at org.redisson.RedissonMap.putAllOperationAsync(RedissonMap.java:396)
		at org.redisson.RedissonMap.putAllAsync(RedissonMap.java:338)
		at org.redisson.RedissonMap.putAll(RedissonMap.java:269)
		at org.redisson.spring.session.RedissonSessionRepository$RedissonSession.<init>(RedissonSessionRepository.java:69)
		at org.redisson.spring.session.RedissonSessionRepository.createSession(RedissonSessionRepository.java:293)
		at org.redisson.spring.session.RedissonSessionRepository.createSession(RedissonSessionRepository.java:51)
		at org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper.getSession(SessionRepositoryFilter.java:373)
		at org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper.getSession(SessionRepositoryFilter.java:217)
		at javax.servlet.http.HttpServletRequestWrapper.getSession(HttpServletRequestWrapper.java:270)

Steps to reproduce or test case
follow https://github.com/redisson/redisson/wiki/14.-Integration%20with%20frameworks#146-spring-session but also add ByteArrayCodec as the default codec
Redis version
3.2.6
Redisson version
2.14.1
Redisson configuration
    final Config config = new Config();
    config.setCodec(new ByteArrayCodec());
    return Redisson.create(config);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1758
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Summary

noticed heap memory slowly increases in service
service uses Redisson's 'getList' operation
heap dump analyzer shows ClusterConnectionManager as number 1 heap memory leak suspect due to 1 instance grew to 1.8GB size (screenshots below)

Question:

is this expected for one Redisson instance to have ClusterConnectionManager grow to 1.8GB?

Steps to reproduce or test case

use Redisson getList operation under load

Redis version
3.2.8
Redisson version
3.8.0
Redisson configuration
Config config = new Config();
config.setNettyThreads(50);
config.setCodec(StringCodec.INSTANCE);
ClusterServersConfig clusterServersConfig = config.useClusterServers();
clusterServersConfig.setTimeout(1000);
clusterServersConfig.setRetryAttempts(1);
clusterServersConfig.setRetryInterval(500);
clusterServersConfig.setConnectTimeout(1000);
clusterServersConfig.setMasterConnectionPoolSize(2000);
clusterServersConfig.setMasterConnectionMinimumIdleSize(100);
clusterServersConfig.setSlaveConnectionMinimumIdleSize(50);
clusterServersConfig.setSlaveConnectionPoolSize(1000);
RedissonClient redissonClient = create(config);

Heap Dump Screenshots
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1759
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Description
Hello,i am using spring boot redisson starter in version 3.8.2. I am confusing with the expire() method and remainTimeToLive(). I learned that the remainTimeToLive() method return -1 to indicate the key will never expire,-2 to indicate the key does not exist.However,in the method expire() ,when passing -1 will result in the key not exist,passing -2 will result in the key never expire.
I gets the result by my own test case.I want to know, if that is the design or is a bug?
Thank you!
Steps to reproduce or test case
Redis version
org.redisson:redisson-spring-boot-starter:3.8.2
Redisson version
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1760
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
ha 切换后，（可能短暂中断后），能正常地重新连接redis。
Actual behavior
ha 切换后，频繁出现RedisTimeoutException，有少量链接可以使用，调用方持续调用大约30分钟恢复正常。
疑似恢复路径
1、调用方调用redisson请求获取缓存
2、redisson从链接池中获取链接A
3、redisson使用链接A发送命令，发现不通，redisson断开链接A
4、redisson从链接池中获取链接B
5、redisson使用链接B发送命令，发现不通，redisson断开链接B
6、redisson从链接池中获取链接C
7、redisson使用链接C发送命令，发现不通，redisson断开链接C
8、重试三次后，报RedisTimeoutException异常。
9、等待链接池中的链接都被重置后，才会恢复正常。
PS：1-8期间偶尔有获取到正常的链接，可以正常访问，越往后几率越高。
Steps to reproduce or test case
应用通过ha（硬件）访问redis
1、启动redis、应用
2、应用中获取缓存，使链接池中的链接均已建立与redis的链接
3、ha-A宕机，等待1-2分钟，切换到ha-B
4、应用无法连接redis，报RedisTimeoutException
Redis version
4.0
Redisson version
3.6.5
Redisson configuration
<redission:client
id="redissonClient"
name="redisson1,redisson2"
threads="0"
netty-threads="0"
codec-ref="jdkCodec"
use-linux-native-epoll="false">
<redission:sentinel-servers
idle-connection-timeout="10000"
ping-timeout="1000"
connect-timeout="10000"
timeout="3000"
retry-attempts="3"
retry-interval="1500"
reconnection-timeout="3000"
failed-attempts="3"
subscriptions-per-connection="5"
client-name="none"
subscription-connection-minimum-idle-size="1"
subscription-connection-pool-size="50"
slave-connection-minimum-idle-size="10"
slave-connection-pool-size="64"
master-connection-minimum-idle-size="10"
master-connection-pool-size="64"
read-mode="SLAVE"
subscription-mode="SLAVE"
master-name="mymaster"
database="0">
<redission:sentinel-address value="redis://${redis.sentinel.hostname.1}:${redis.sentinel.port.1}"/>
<redission:sentinel-address value="redis://${redis.sentinel.hostname.2}:${redis.sentinel.port.2}"/>
<redission:sentinel-address value="redis://${redis.sentinel.hostname.3}:${redis.sentinel.port.3}"/>
</redission:sentinel-servers>
</redission:client>
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1761
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The redisson-1.2.xsd file dose not add the pingConnectionInterval(ping-connection-interval) attribute to "baseConfig" , so when using the spring xml can't set the pingConnectionInterval properties to BaseConfig. Can add the pingConnectionInterval attribute to the redisson-1.2.xsd file?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1762
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
pro版是收费的吗？给redisson.pro 提交了申请，一直没回复.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1763
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We are currently using redisson for, among other things, distributed locking. In our use case, we can have hundreds of unique fair locks being acquired many times, usually for short periods of time (~1-2 seconds).
During testing, we noticed that sustained load eventually, but consistently, results in threads failing to acquire the lock. To try to pinpoint the problem, we added extra logging in various places in code path used by RedissonLock. What we found was that it sometimes took a long time for the lock to subscribe to its pubsub channel, by which point the unlock message was already published. This results in the thread waiting on entry.getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS); until failure.
In other words, the sequence of events seems to be:

thread 1 acquires a lock
thread 2 tries and fails to acquire the lock, initiating pubsub subscription
thread 1 releases lock (semaphore is not released since nothing is waiting on it yet!)
thread 2 completes subscription connection and waits on semaphore, eventually timing out

There seem to be two places where this delay happens:

Acquiring an AsyncSemaphore in  the PublishSubscribe::subscribe method
The 'await' call in RedissonLock::tryLock

Configuration

Redisson 3.9.1
Redis 4.0 cluster with 6 nodes
masterConnectionPoolSize=200
masterIdleConnectionPoolSize=100
subscriptionConnectionPoolSize=100
subscriptionIdleConnectionPoolSize=50
subscriptionsPerConnection=5
retryInterval=3000
connectionTimeout=10000
numRetries=10

Are we missing something here? It seems strange that it can take upwards of several seconds for the lock to subscribe to its pubsub channel.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1764
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We've problem with redisson-tomcat 8-3.9.1. / redisson v3.9.1. After sime kind of classes modification, the session manager stops working consequently it stopped Tomcat. Tomca'st log contains following fragment:
Caused by: java.lang.NullPointerException
        at org.redisson.client.handler.CommandDecoder.selectDecoder(CommandDecoder.java:490)
        at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:351)
        at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:128)
        at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:108)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1765
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redisson中的lock，有没使用pexpire命令的方法吗？比如：服务器禁用了pexpire命令，用Redisson的分布式锁是不就不起作用了？
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1766
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1767
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Example of Spring Security config
package com.payneteasy.card2card.config;

import java.util.ArrayList;
import java.util.List;
import java.util.regex.Pattern;

import javax.servlet.http.HttpServletRequest;

import org.springframework.context.annotation.Configuration;
import org.springframework.security.config.annotation.web.builders.HttpSecurity;
import org.springframework.security.config.annotation.web.builders.WebSecurity;
import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;
import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;
import org.springframework.security.web.util.matcher.AntPathRequestMatcher;
import org.springframework.security.web.util.matcher.RequestMatcher;

@Configuration
@EnableWebSecurity
public class SecureConfig extends WebSecurityConfigurerAdapter {

    public SecureConfig() {
        super(true);
    }

    @Override
    public void configure(final WebSecurity web) {
        web.ignoring().antMatchers(
            "/css/**",
            "/img/**",
            "/js/**",
            "/management/**",
            "/pdf/**",
            "/**/*.html",
            "/robots.txt",
            "/sitemap.xml");
    }

    @Override
    protected void configure(HttpSecurity http) throws Exception {
        //@formatter:off
        http
            .sessionManagement()
                .sessionFixation().newSession()
                .and()
            .headers()
                .httpStrictTransportSecurity()
                    .and()
                .frameOptions()
                    .deny()
                    .and()
            .csrf()
                .requireCsrfProtectionMatcher(new CsrfRequestMatcher());
        //@formatter:on
    }

    private static class CsrfRequestMatcher implements RequestMatcher {

        private final Pattern allowedMethods = Pattern.compile("^(GET|HEAD|TRACE|OPTIONS)$");

        private final RequestMatcher ignoredMatcher = new AntMatchers(
            "/**/result",
            "/**/support-post",
            "/**/email");

        @Override
        public boolean matches(final HttpServletRequest request) {
            return !allowedMethods.matcher(request.getMethod()).matches() && !ignoredMatcher.matches(request);
        }

        private static class AntMatchers implements RequestMatcher {

            private final List<RequestMatcher> matchers;

            AntMatchers(final String... urls) {
                matchers = new ArrayList<>(urls.length);
                for (final String url : urls) {
                    matchers.add(new AntPathRequestMatcher(url));
                }
            }

            @Override
            public boolean matches(final HttpServletRequest request) {
                for (final RequestMatcher matcher : matchers) {
                    if (matcher.matches(request)) {
                        return true;
                    }
                }
                return false;
            }
        }
    }
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1768
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
A call to retrieve the items from a RGeo key based on radius should work in an AWS ElastiCache replicated setup using readMode SLAVE
Actual behavior
Since all these calls are considered read-only by Redisson as opposed to write by Redis/ElastiCache, they are all sent to read-only slaves. We get the exception below instead. Please note I've masked actual IP addresses and host names with x's, and replaced the key names and coordinates.
READONLY You can't write against a read only slave.. channel: [id: 0xad662a07, L:/xx.x.x.230:46140 - R:xxx-01.xxx.0001.use1.cache.amazonaws.com/xx.x.xx.xxx:6379] command: (GEORADIUS), params: [{geo}geoKey:coords, -100.000000, 30.000000, 50.0, mi, ASC]
Steps to reproduce or test case
Configure Redisson to use a replicated ElastiCache cluster with readMode=SLAVE and use radius() method for a RGeo object
Redis version
AWS ElastiCache
Redisson version
3.8.1
Redisson configuration
In Code
String[] redisNodes = { "xxx-01.xxx.0001.use1.cache.amazonaws.com:6379", "xxx-02.xxx.0001.use1.cache.amazonaws.com:6379", "xxx-03.xxx.0001.use1.cache.amazonaws.com:6379" }
config.useReplicatedServers().addNodeAddress(redisNodes);

In YAML
replicatedServersConfig:
    idleConnectionTimeout: 10000
    pingTimeout: 1000
    connectTimeout: 10000
    timeout: 3000
    retryAttempts: 3
    retryInterval: 1500
    failedSlaveReconnectionInterval: 3000
    failedSlaveCheckInterval: 60000
    password: null
    subscriptionsPerConnection: 5
    clientName: null
    loadBalancer: !<org.redisson.connection.balancer.RoundRobinLoadBalancer> {}
    subscriptionConnectionMinimumIdleSize: 1
    subscriptionConnectionPoolSize: 50
    slaveConnectionMinimumIdleSize: 10
    slaveConnectionPoolSize: 100
    masterConnectionMinimumIdleSize: 10
    masterConnectionPoolSize: 100
    readMode: "SLAVE"
    subscriptionMode: "MASTER"
    scanInterval: 1000
    pingConnectionInterval: 0
    keepAlive: false
    tcpNoDelay: false
    dnsMonitoringInterval: 5000
threads: 0
nettyThreads: 0
codec: !<org.redisson.codec.SerializationCodec> {}
transportMode: "NIO"
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1769
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
This error occurs regularly (about every 3-5 minutes), I’ve noticed that when it happens the freeSubscribeConnectionsAmount  is 0, could it be related to that?
Expected behavior
Actual behavior
org.redisson.client.WriteRedisConnectionException: Unable to send command! Node source: NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=0, freeSubscribeConnectionsCounter=47, freeConnectionsAmount=16, freeConnectionsCounter=112, freezed=false, freezeReason=null, client=[addr=redis://master.ip:6379], nodeType=MASTER, firstFail=0]]], connection: RedisConnection@213381393 [redisClient=[addr=redis://master.ip:6379], channel=[id: 0x377886d2, L:/client.ip:53212 ! R:master.ip/master.ip:6379]], command: (PUBLISH), command params: [Channel-Name:TEST:heartbeat, *****************] after 3 retry attempts
at org.redisson.command.CommandAsyncService.checkWriteFuture(CommandAsyncService.java:837) ~[redisson-3.9.1.jar:?]
at org.redisson.command.CommandAsyncService.access$200(CommandAsyncService.java:92) ~[redisson-3.9.1.jar:?]
at org.redisson.command.CommandAsyncService$11$1.operationComplete(CommandAsyncService.java:794) ~[redisson-3.9.1.jar:?]
at org.redisson.command.CommandAsyncService$11$1.operationComplete(CommandAsyncService.java:791) ~[redisson-3.9.1.jar:?]
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511) ~[netty-common-4.1.29.Final.jar:4.1.29.Final]
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:485) ~[netty-common-4.1.29.Final.jar:4.1.29.Final]
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424) ~[netty-common-4.1.29.Final.jar:4.1.29.Final]
at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:121) ~[netty-common-4.1.29.Final.jar:4.1.29.Final]
at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987) ~[netty-transport-4.1.29.Final.jar:4.1.29.Final]
at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869) ~[netty-transport-4.1.29.Final.jar:4.1.29.Final]
at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1391) ~[netty-transport-4.1.29.Final.jar:4.1.29.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738) ~[netty-transport-4.1.29.Final.jar:4.1.29.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730) ~[netty-transport-4.1.29.Final.jar:4.1.29.Final]
at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38) ~[netty-transport-4.1.29.Final.jar:4.1.29.Final]
at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081) ~[netty-transport-4.1.29.Final.jar:4.1.29.Final]
at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128) ~[netty-transport-4.1.29.Final.jar:4.1.29.Final]
at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070) ~[netty-transport-4.1.29.Final.jar:4.1.29.Final]
at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163) ~[netty-common-4.1.29.Final.jar:4.1.29.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404) ~[netty-common-4.1.29.Final.jar:4.1.29.Final]
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:446) ~[netty-transport-4.1.29.Final.jar:4.1.29.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884) ~[netty-common-4.1.29.Final.jar:4.1.29.Final]
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.29.Final.jar:4.1.29.Final]
at java.lang.Thread.run(Thread.java:748) [?:1.8.0_181]
Caused by: java.nio.channels.ClosedChannelException
at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source) ~[netty-transport-4.1.29.Final.jar:4.1.29.Final]
Steps to reproduce or test case
Redis version
3.2.12, 1 master, 2 slaves & 3 sentinels
Redisson version
3.9.1
Redisson configuration
sentinelServers.setPassword(*****);
sentinelServers.setSlaveConnectionPoolSize(128);
sentinelServers.setMasterConnectionPoolSize(128);
(everything else uses the default values)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1770
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is there anywhere I can read about how to use Redisson reactive collections, especially queues and maps?
I found practically nothing about it in the documentation.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1771
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redisson session manager is creating sessions which is getting expired after 30 minutes even if the user is actively making transaction. Who is controlling the session expiry?  in tomcat web.xml session timeout is set as 30 minutes.  when user is making active transaction, redis desktop manager is showing that the ttl value of the session is getting reset to 30 however still the session is getting expired exactly after 30 minutes of initial session creation. so definitely ttl value which is getting reset to 30 minutes is not deciding the session expire. which factor is expiring the session? How and where that parameter can be set for redisson session manager so that session does not expire when user is actively making transactions.
Expected behavior
If user is actively making transactions, same session should be active all the time since the time user is active.
Actual behavior
Session manager  expiring the session after 30 minutes since initial login/session creation time even if user is actively making transactions.
Steps to reproduce or test case
inside tomcat ${catalina_home}/conf/web.xml default session time out is set as.

30

Redis version
3.2
Redisson version
3.8
Redisson configuration
5 slave 1 master, 6 sentinel - sentinel replication and sentinel mode. Tomcat uses redissonsessionmanager as manager
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1772
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Run successfully
Actual behavior



Steps to reproduce or test case
Redis version
Redisson version
2.14.1
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1773
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We're using : Tomcat8.5
When develop it might happen, that serialized session is not able to deserialize due modification in Class
(add/remove fields), in such cases redisson throws java.lang.ClassCastException, it's quite OK. But session manager doesn't catch it in findSession() method:
2018.12.04 10:53:12     com.mailprofiler.app.xcampaign.appl.webfilters.Logout   doFilter()      java.lang.Long cannot be cast to java.util.Map
java.lang.ClassCastException: java.lang.Long cannot be cast to java.util.Map
at org.redisson.RedissonMap.readAllMap(RedissonMap.java:501)
at org.redisson.tomcat.RedissonSessionManager.findSession(RedissonSessionManager.java:148)
at org.apache.catalina.connector.Request.doGetSession(Request.java:2977)
at org.apache.catalina.connector.Request.getSession(Request.java:2434)
at org.apache.catalina.connector.RequestFacade.getSession(RequestFacade.java:896)
at javax.servlet.http.HttpServletRequestWrapper.getSession(HttpServletRequestWrapper.java:231)
would be better if it catch it and return no-session.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1774
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1775
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1776
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1777
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1778
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1779
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1780
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1781
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1782
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1783
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1784
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1785
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1786
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1787
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1788
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1789
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1790
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1791
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1792
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1793
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1794
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1795
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1796
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1797
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1798
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1799
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1800
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1801
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1802
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1803
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1804
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1805
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1806
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1807
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1808
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1809
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1810
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1811
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1812
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1813
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1814
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1815
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1816
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1817
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1818
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1819
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1820
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1821
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1822
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1823
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1824
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1825
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1826
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1827
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1828
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1829
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1830
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1831
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1832
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1833
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1834
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1835
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1836
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1837
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1838
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1839
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1840
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1841
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1842
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1843
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1844
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1845
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1846
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1847
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1848
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1849
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1850
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1851
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1852
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1853
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1854
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1855
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1856
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1857
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1858
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1859
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1860
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1861
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1862
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1863
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1864
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1865
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1866
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1867
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1868
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1869
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1870
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1871
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1872
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1873
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1874
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1875
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1876
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1877
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1878
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1879
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1880
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1881
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1882
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1883
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1884
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1885
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1886
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1887
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1888
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1889
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1890
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1891
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1892
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1893
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1894
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1895
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
以下范例展示了如何创建三主三从的Redis集群。
ClusterNodes clusterNodes = ClusterNodes.create()
.master("127.0.0.1:7000").withSlaves("127.0.0.1:7001", "127.0.0.1:7002")
.master("127.0.0.1:7003").withSlaves("127.0.0.1:7004")
.master("127.0.0.1:7005");
ClusterManagementTool.createCluster(clusterNodes);
主节点127.0.0.1:7000的从节点有127.0.0.1:7001和127.0.0.1:7002。
主节点127.0.0.1:7003的从节点是127.0.0.1:7003。（这里应该是7004）
主节点127.0.0.1:7005没有从节点。
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1896
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1897
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Actual behavior
Redisson Session exception:
{"time":"2019-01-31T20:49:46.279+00:00","level":"ERROR","msg":"Runtime error: [[org.redisson.client.RedisException: CROSSSLOT Keys in request don't hash to the same slot. channel: [id: 0x1bc3eb9e, L:/172.18.0.6:51190 - R:172.18.0.3/172.18.0.3:7002] command: (RENAME), params: [spring:session:afe9d89c-35fe-4cd5-949f-b6fc07426bbe, spring:session:b93a060f-331a-4bcb-839f-8f2d764941ff]]]","requestId":"98778a17-677b-453b-91a7-b520b1596458","X-B3-TraceId":"2cc7f5f9cc324dcf","requestURI":"/auth/v3/oauth/token","stackTrace":"org.redisson.client.RedisException: CROSSSLOT Keys in request don't hash to the same slot. channel: [id: 0x1bc3eb9e, L:/172.18.0.6:51190 - R:172.18.0.3/172.18.0.3:7002] command: (RENAME), params: [spring:session:afe9d89c-35fe-4cd5-949f-b6fc07426bbe, spring:session:b93a060f-331a-4bcb-839f-8f2d764941ff]\n\tat org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:314)\n\tat org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:130)\n\tat org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:110)\n\tat io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502)\n\tat io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)\n\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\n\tat io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\n\tat io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\n\tat io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:677)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:612)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:529)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:491)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:748)\n"
Redis version
Redis Cluster 3.2.7
Redisson version
3.10.1
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1898
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I was using Redisson 3.9.1 without any problem. I updated it to 3.10.1, and got this error.
Invalid request data: Exception while fetching data (/policy_example1) : Unexpected exception while processing command, Exception while fetching data (/policy_example2) : Unexpected exception while processing command, Exception while fetching data (/policy_example3) : Unexpected exception while processing command
I downgraded it to 3.9.1 and ran again, and it worked.
Why is it happening and how can I fix it?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1899
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
No exception
Actual behavior
2019-02-04 04:27:24,749-0800 [toe=009i5jwyj7erbk] [redisson-netty-1-2] ERROR - Unable to decode data. reply: *124
$4114
....
....
, channel: [id: 0xf3f268b3, L:/10.1.1.1:40115 - R:my.server.1/10.1.2.2:6379], command: CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@12ec0a16(failure: java.util.concurrent.CancellationException)], command=(HMGET), params=[mykey, param2, ...], codec=org.redisson.codec.CompositeCodec@d2717648] java.util.concurrent.CancellationException
	at java.util.concurrent.CompletableFuture.cancel(CompletableFuture.java:2263) ~[?:1.8.0_181]
	at org.redisson.misc.RedissonPromise.cancel(RedissonPromise.java:239) ~[redisson-3.10.1.jar:?]
	at org.redisson.command.CommandAsyncService$13.run(CommandAsyncService.java:941) ~[redisson-3.10.1.jar:?]
	at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:682) ~[netty-common-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:757) ~[netty-common-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:485) ~[netty-common-4.1.32.Final.jar:4.1.32.Final]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_181]

Steps to reproduce or test case
I don't have exact steps. but I have the following information:
It was working earlier with redisson 2.14.1 with Oracle java 7.
It is broken with redisson 3.10.1 with OpenJdk java 8.
Redis version
4.0.11
Redisson version
3.10.1
Redisson configuration
     {
     	"replicatedServersConfig": {
     		"idleConnectionTimeout": 10000,
     		"pingTimeout": 1000,
     		"connectTimeout": 10000,
     		"timeout": 10000,
     		"retryAttempts": 3,
     		"retryInterval": 1500,
     		"subscriptionsPerConnection": 5,
     		"sslEnableEndpointIdentification": true,
     		"sslProvider": "JDK",
     		"pingConnectionInterval": 0,
     		"keepAlive": false,
     		"tcpNoDelay": false,
     		"loadBalancer": {
     			"class": "org.redisson.connection.balancer.RoundRobinLoadBalancer"
     		},
     		"slaveConnectionMinimumIdleSize": 32,
     		"slaveConnectionPoolSize": 64,
     		"failedSlaveReconnectionInterval": 3000,
     		"failedSlaveCheckInterval": 180000,
     		"masterConnectionMinimumIdleSize": 32,
     		"masterConnectionPoolSize": 64,
     		"readMode": "MASTER_SLAVE",
     		"subscriptionMode": "MASTER",
     		"subscriptionConnectionMinimumIdleSize": 1,
     		"subscriptionConnectionPoolSize": 50,
     		"dnsMonitoringInterval": 5000,
     		"nodeAddresses": [
     			"redis://my.server.1:6379",
     			"redis://my.server.2:6379"
     		],
     		"scanInterval": 2000,
     		"database": 0,
     		"slaveSubscriptionConnectionPoolSize": 50,
     		"slaveSubscriptionConnectionMinimumIdleSize": 1
     	},
     	"threads": 0,
     	"nettyThreads": 0,
     	"referenceCodecProvider": {
     		"class": "org.redisson.codec.DefaultReferenceCodecProvider"
     	},
     	"referenceEnabled": true,
     	"transportMode": "NIO",
     	"lockWatchdogTimeout": 30000,
     	"keepPubSubOrder": true,
     	"useScriptCache": false,
     	"addressResolverGroupFactory": {
     		"class": "org.redisson.connection.DnsAddressResolverGroupFactory"
     	},
     	"useLinuxNativeEpoll": false
     }

How to fix this?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1900
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
org.redisson.Version - Redisson 3.8.0
Redis version 5.0.0
"io.netty" % "netty-tcnative-boringssl-static" % "2.0.20.Final"
This piece of code:
def clusterConfig = redissonConfig.useClusterServers()
clusterConfig.addNodeAddress(s"redis://clustercfg.rediscluster.XXXXX.use1.cache.amazonaws.com:6379")

works with Redis in Elasticache when is configured with
Encryption in-transit: No
Redis Auth: No

but when adding:
clusterConfig.setPassword("XXXXXXXXXXXXXXXX")
and then Redis in Elasticache is configured with:
Encryption in-transit: Yes
Redis Auth: Yes

Redisson returns:

Command execution timeout for command: (AUTH).

From the same instance that executed the code above, I can connect to the redis instance with redli:
redli --host=clustercfg.redis-cluster.XXXXX.use1.cache.amazonaws.com --port=6379 --auth=XXXXXXXXXXXXXXXX --tls
Connected to 5.0.0
>

to discard connection / environment problems.
I could not find in the documentation how to tell redisson that it should use tls. Is it supported at all?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1901
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
It must be called one of "onError | onComplete"
Actual behavior
Both of onError , onComplete not called
Steps to reproduce or test case
@Test
public void singleRead() {
	RMapCacheRx<Object, Object> mapCache = redisson.getMapCache(CACHE_NAME);
	mapCache.put(TEST_KEY, 12345L).subscribe(new Subscriber<Object>() {
		@Override
		public void onSubscribe(Subscription s) {
			System.out.println(">>>>>      onSubscribe!!!");
		}

		@Override
		public void onNext(Object o) {
			System.out.println(">>>>>      onNext!!!");
		}

		@Override
		public void onError(Throwable t) {
			fail();
		}

		@Override
		public void onComplete() {
			System.out.println(">>>>>>>> Never invoked!");
			Long testID = (Long) wmsFulfillmentInfraCacheService.singleRead(CACHE_NAME, TEST_KEY);
			assertThat(testID, is(12345L));
		}
	});

}

Redis version
5
Redisson version
'org.redisson:redisson:3.9.0'
Redisson configuration
config.useClusterServers()
		.addNodeAddress(clusterNodes)
		.setScanInterval(2000)
		.setMasterConnectionPoolSize(128)
		.setIdleConnectionTimeout(10000)
		.setTimeout(5000)
		.setRetryAttempts(5)
		.setRetryInterval(500);

   config.setCodec(new JsonJacksonCodec());

RedissonRxClient redissonClient = Redisson.createRx(config);
return redissonClient
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1902
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi
I am trying to use the new stream feature of Redis 5.
According to the documentation of Redis when I use xreadgroup and mark > I should get all messages that never sent to any other consumer regardless of the time the group was created.
On the example on Redisson wiki I get only  the messages that was added after I created the group.
I don’t see an option to call readGroup function in redisson with > sign to get all messages.
Can you help me with that?
Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1903
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi
When I use stream with Redis 5 on redisson I get an error of trying to convert the key of the stream message to Json.
Is there any possibility to try to decode only the value to json?
Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1904
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Both master or slave port can be configured at the config item [nodeAddresses].
Actual behavior
Should be slave(non-master) node port, but why? When I configure master node port, below exception stack block always appears, output the message saying that the configured master node port cannot be connected.
Steps to reproduce or test case

Redis server installation version is 5.0.3, start the cluster mode with command:
./create-cluster start
(3 master 3 slave nodes are now running..)

2.Check if all redis slots have been covered or not:
./redis-cli --cluster check localhost:30001
Command output log(everything is ok):



Performing Cluster Check (using node localhost:30001)
M: b76aae890a6726bf30e579d80112a11d7d21b857 localhost:30001
slots:[0-5460] (5461 slots) master
1 additional replica(s)
M: db3f19ac2c5fbae73812dfb77ddeecfb83962ed1 129.211.101.192:30002
slots:[5461-10922] (5462 slots) master
1 additional replica(s)
S: 3ead9fddc90a907baecc2401b63887aad9924223 129.211.101.192:30006
slots: (0 slots) slave
replicates db3f19ac2c5fbae73812dfb77ddeecfb83962ed1
S: 96789232ea1d4e913e4a00b86fbe4638d2d9375e 129.211.101.192:30005
slots: (0 slots) slave
replicates b76aae890a6726bf30e579d80112a11d7d21b857
S: b9d6332b52a488e462d6c17ddfac13f499011ab7 129.211.101.192:30004
slots: (0 slots) slave
replicates 63ab0571c2df794a6c4c45f13917e59c9952cf1a
M: 63ab0571c2df794a6c4c45f13917e59c9952cf1a 129.211.101.192:30003
slots:[10923-16383] (5461 slots) master
1 additional replica(s)
[OK] All nodes agree about slots configuration.
Check for open slots...
Check slots coverage...
[OK] All 16384 slots covered.



3.Configure the redission.yaml file:
clusterServersConfig:
...
readMode: "SLAVE"
subscriptionMode: "SLAVE"
nodeAddresses:

"redis://10.19.131.180:30001"  #30001 is master node port of redis cluster
(Though use another 2 master node port: 30002 and 30003, same exception result as below).

4.Run my Springboot service(from main() in Application), exception then occured:
2019-02-11 16:51:26 [redisson-netty-1-5] INFO  o.r.c.p.MasterPubSubConnectionPool:168 - 1 connections initialized for 129.211.101.192/129.211.101.192:30002
2019-02-11 16:51:26 [redisson-netty-1-3] INFO  o.r.c.pool.MasterConnectionPool:168 - 5 connections initialized for 129.211.101.192/129.211.101.192:30003
2019-02-11 16:51:26 [redisson-netty-1-8] INFO  o.r.cluster.ClusterConnectionManager:268 - master: redis://129.211.101.192:30003 added for slot ranges: [[10923-16383]]
2019-02-11 16:51:26 [redisson-netty-1-8] INFO  o.r.c.p.MasterPubSubConnectionPool:168 - 1 connections initialized for 129.211.101.192/129.211.101.192:30003
2019-02-11 16:51:26 [redisson-netty-1-5] INFO  o.r.cluster.ClusterConnectionManager:268 - master: redis://129.211.101.192:30002 added for slot ranges: [[5461-10922]]
2019-02-11 16:51:26 [redisson-netty-1-5] INFO  o.r.c.pool.MasterConnectionPool:168 - 5 connections initialized for 129.211.101.192/129.211.101.192:30002
2019-02-11 16:51:36 [redisson-netty-1-1] ERROR o.r.cluster.ClusterConnectionManager:203 - Can't connect to master: redis://172.17.16.9:30001 with slot ranges: [[0-5460]]
2019-02-11 16:51:36 [main] ERROR o.h.c.r.client.RedisClientFactory:50 - Fail to create RedisClient.
org.redisson.client.RedisConnectionException: Not all slots are covered! Only 10923 slots are avaliable
at org.redisson.cluster.ClusterConnectionManager.(ClusterConnectionManager.java:168)
at org.redisson.config.ConfigSupport.createConnectionManager(ConfigSupport.java:198)
at org.redisson.Redisson.(Redisson.java:123)
at org.redisson.Redisson.create(Redisson.java:162)
at org.hibernate.cache.redis.client.RedisClientFactory.createRedisClient(RedisClientFactory.java:47)
at org.hibernate.cache.redis.client.RedisClientFactory.createRedisClient(RedisClientFactory.java:64)
at org.hibernate.cache.redis.client.RedisClientFactory.createRedisClient(RedisClientFactory.java:83)
at org.hibernate.cache.redis.hibernate52.AbstractRedisRegionFactory.createRedisClient(AbstractRedisRegionFactory.java:65)
at org.hibernate.cache.redis.hibernate52.RedisRegionFactory.start(RedisRegionFactory.java:48)
at org.hibernate.cache.spi.RegionFactory.start(RegionFactory.java:63)
at org.hibernate.internal.CacheImpl.(CacheImpl.java:71)
at org.hibernate.engine.spi.CacheInitiator.initiateService(CacheInitiator.java:28)
at org.hibernate.engine.spi.CacheInitiator.initiateService(CacheInitiator.java:20)
at org.hibernate.service.internal.SessionFactoryServiceRegistryImpl.initiateService(SessionFactoryServiceRegistryImpl.java:59)
...
at com.sp.Application.main(Application.java:37)
Caused by: io.netty.channel.ConnectTimeoutException: connection timed out: 172.17.16.9/172.17.16.9:30001
at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:267)
at io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38)
at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:125)
at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:886)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:745)
2019-02-11 16:51:36 [main] ERROR o.h.c.r.h.RedisRegionFactory:53 - Fail to start RedisRegionFactory.
java.lang.RuntimeException: org.redisson.client.RedisConnectionException: Not all slots are covered! Only 10923 slots are avaliable
at org.hibernate.cache.redis.client.RedisClientFactory.createRedisClient(RedisClientFactory.java:51)
at org.hibernate.cache.redis.client.RedisClientFactory.createRedisClient(RedisClientFactory.java:64)
at org.hibernate.cache.redis.client.RedisClientFactory.createRedisClient(RedisClientFactory.java:83)
...
When I try to configure the port with slave port(30004,30005 or 30006), however, it worked well:
2019-02-11 17:35:59 [redisson-netty-1-1] INFO  o.r.c.pool.MasterConnectionPool:168 - 5 connections initialized for 129.211.101.192/129.211.101.192:30001
2019-02-11 17:36:09 [main] INFO  o.h.c.r.h.RedisRegionFactory:51 - RedisRegionFactory is started.
2019-02-11 17:36:09 [main] INFO  o.h.cache.spi.UpdateTimestampsCache:48 - HHH000250: Starting update timestamps cache at region: hibernate.org.hibernate.cache.spi.UpdateTimestampsCache
2019-02-11 17:36:09 [main] INFO  o.h.c.internal.StandardQueryCache:81 - HHH000248: Starting query cache at region: org.hibernate.cache.internal.StandardQueryCache
I'm curious about how this happened, since all slots have been already checked to be covered and the log says all nodes have had been connected before the exception message printed out. Hope someone can help to analyze this issue and discuss with me, thanks a lot!
Redis version
        <dependency>
            <groupId>com.github.debop</groupId>
            <artifactId>hibernate-redis</artifactId>
            <version>2.4.0</version>   
        </dependency>

Redis server installation version is 5.0.3.
Redisson version
        <dependency>
            <groupId>org.redisson</groupId>
            <artifactId>redisson</artifactId>
            <version>3.9.1</version>
        </dependency>

Redisson configuration
clusterServersConfig:
idleConnectionTimeout: 10000
pingTimeout: 1000
connectTimeout: 10000
timeout: 3000
retryAttempts: 3
retryInterval: 1500
reconnectionTimeout: 3000
failedAttempts: 3
password: null
subscriptionsPerConnection: 5
clientName: null
loadBalancer: !<org.redisson.connection.balancer.RoundRobinLoadBalancer> {}
subscriptionConnectionMinimumIdleSize: 1
subscriptionConnectionPoolSize: 50
slaveConnectionMinimumIdleSize: 5
slaveConnectionPoolSize: 128
masterConnectionMinimumIdleSize: 5
masterConnectionPoolSize: 128
readMode: "SLAVE"
subscriptionMode: "SLAVE"
nodeAddresses:

"redis://xxx.xxx.1x1.1xx:30004"    #Changed to slave node port, exception disappeared,WHY?
scanInterval: 1000
threads: 0
nettyThreads: 0
codec: !<org.redisson.codec.SnappyCodec> {}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1905
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We have been using a custom KryoCodec(overriding the built in one) for a while but after version 3.10.0 this no longer works. The change that affects us are introduced by the following commit: 37b58db
I've spent a little bit of time looking into what's going on and it looks like there are issues regarding classloading since we got all sorts of exceptions now, especially lots of com.esotericsoftware.kryo.KryoException: Unable to find class on classes that we have been serializing without problems til now. The root cause is of course  java.lang.ClassNotFoundException:x.y.z
I've attached the relevant code with the working and non working solution:
Working:
public class KryoCodec extends org.redisson.codec.KryoCodec {

    private static class KryoPoolImpl extends org.redisson.codec.KryoCodec.KryoPoolImpl {

        KryoPoolImpl(List<Class<?>> classes, ClassLoader classLoader) {
            super(classes, classLoader);
        }

        @Override
        protected Kryo createInstance() {
            Kryo kryo = super.createInstance();
            kryo.setReferences(true);
            UnmodifiableCollectionsSerializer.registerSerializers(kryo);
            kryo.setInstantiatorStrategy(
                    new Kryo.DefaultInstantiatorStrategy(new StdInstantiatorStrategy())
            );
            return kryo;
        }

    }

    public KryoCodec() {
        this(Collections.emptyList());
    }

    public KryoCodec(ClassLoader classLoader) {
        this(Collections.emptyList(), classLoader);
    }

    public KryoCodec(List<Class<?>> classes) {
        this(classes, null);
    }

    public KryoCodec(List<Class<?>> classes, ClassLoader classLoader) {
        this(new KryoPoolImpl(classes, classLoader));
    }

    public KryoCodec(KryoPoolImpl kryoPool) {
        super(kryoPool);
    }

}

Non-working:
public class KryoCodec extends org.redisson.codec.KryoCodec {

    private final KryoPoolImpl kryoPool;

    private static class KryoPoolImpl extends org.redisson.codec.KryoCodec.KryoPoolImpl {

        KryoPoolImpl(List<Class<?>> classes, ClassLoader classLoader) {
            super(classes, classLoader);
        }

        @Override
        protected Kryo createInstance() {
            Kryo kryo = super.createInstance();
            kryo.setReferences(true);
            UnmodifiableCollectionsSerializer.registerSerializers(kryo);
            kryo.setInstantiatorStrategy(
                    new Kryo.DefaultInstantiatorStrategy(new StdInstantiatorStrategy())
            );
            return kryo;
        }

    }

    public KryoCodec() {
        this(Collections.emptyList());
    }

    public KryoCodec(ClassLoader classLoader) {
        this(Collections.emptyList(), classLoader);
    }

    public KryoCodec(ClassLoader classLoader, KryoCodec kryoCodec) {
        this(kryoCodec.kryoPool.getClasses(), classLoader);
    }

    public KryoCodec(List<Class<?>> classes) {
        this(classes, null);
    }

    public KryoCodec(List<Class<?>> classes, ClassLoader classLoader) {
        this(new KryoPoolImpl(classes, classLoader));
    }

    public KryoCodec(KryoPoolImpl kryoPool) {
        super(kryoPool);
        this.kryoPool = kryoPool;
    }

}

The only change on the latter is the addition of the new constructor which now is required.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1906
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Motivation

Currently it requires some boilerplate work to acquire a desired object in remote tasks. It would be better if the desired object can be obtained via object injection.
Currently it is not very easy to inject a bean of collection type via Spring's autowire function.

The work is to overcome the above difficulties while provide an easy to access Redisson provided objects via injection methods.
Aim
Enhance the RInject annotation's capability in general:

to allow direct injections of RedissonClient, RObjects and RLOs
to allow specify codec used to create RObjects and RLOs
to allow RInject support object creation based on Redisson expression when target type is a super type or interface.

Enhance the RInject annotation's capability in Spring environment:

to have everything from above.
to allow RInject behaves similar to @Autowired that can provide lookup/creation and injection of RObjects and RLOs in Spring environment.
to allow RInject behaves similar to @value that can utilise SpEL expression and Spring property expression to provide dynamic runtime injection of RObjects and RLOs in Spring environment.
to allow RInject support object creation based on Redisson expression when target type is a super type or interface.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1907
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1908
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Should work fine
Actual behavior
RedisResponseTimeoutException
3.10.2:
2019-02-08 02:11:00,670-0800 [toe=0012bpqw2iqela] [Pool Worker - 18] ERROR - org.redisson.client.RedisResponseTimeoutException: Redis server response timeout (10000 ms) occured after 3 retry attempts. Command: (HMGET), params: [key-in-redis, PooledUnsafeDirectByteBuf(ridx: 0, widx: 92, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 93, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 98, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 74, cap: 256), PooledUnsafeDirectByteBuf(ridx: 0, widx: 93, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 99, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 105, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 72, cap: 256), PooledUnsafeDirectByteBuf(ridx: 0, widx: 54, cap: 256), ...], channel: [id: 0xb1175b78, L:/10.1.10.17:9350 - R:my.server.1.com/10.1.2.7:6379] org.redisson.client.RedisResponseTimeoutException: Redis server response timeout (10000 ms) occured after 3 retry attempts. Command: (HMGET), params: [key-in-redis, PooledUnsafeDirectByteBuf(ridx: 0, widx: 92, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 93, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 98, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 74, cap: 256), PooledUnsafeDirectByteBuf(ridx: 0, widx: 93, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 99, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 105, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 72, cap: 256), PooledUnsafeDirectByteBuf(ridx: 0, widx: 54, cap: 256), ...], channel: [id: 0xb1175b78, L:/10.1.10.17:9350 - R:my.server.1.com/10.1.2.7:6379]
	at org.redisson.command.CommandAsyncService$13.run(CommandAsyncService.java:960) ~[redisson-3.10.2.jar:?]
	at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:682) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:757) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:485) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_181]

2.15.2:
2019-02-12 00:14:31,505-0800 [toe=000tq6l5rb3ifx] [Pool Worker - 18] ERROR - org.redisson.client.RedisResponseTimeoutException: Redis server response timeout (10000 ms) occured after 3 retry attempts. Command: (HMGET), params: [key-in-redis, PooledUnsafeDirectByteBuf(ridx: 0, widx: 92, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 93, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 98, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 74, cap: 256), PooledUnsafeDirectByteBuf(ridx: 0, widx: 93, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 99, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 105, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 72, cap: 256), PooledUnsafeDirectByteBuf(ridx: 0, widx: 54, cap: 256), ...], channel: [id: 0xdcc6a81d, L:/10.1.10.17:49323 - R:my.server.1.com/10.1.2.7:6379] org.redisson.client.RedisResponseTimeoutException: Redis server response timeout (10000 ms) occured after 3 retry attempts. Command: (HMGET), params: [key-in-redis, PooledUnsafeDirectByteBuf(ridx: 0, widx: 92, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 93, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 98, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 74, cap: 256), PooledUnsafeDirectByteBuf(ridx: 0, widx: 93, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 99, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 105, cap: 512), PooledUnsafeDirectByteBuf(ridx: 0, widx: 72, cap: 256), PooledUnsafeDirectByteBuf(ridx: 0, widx: 54, cap: 256), ...], channel: [id: 0xdcc6a81d, L:/10.1.10.17:49323 - R:my.server.1.com/10.1.2.7:6379]
	at org.redisson.command.CommandAsyncService$13.run(CommandAsyncService.java:960) ~[redisson-2.15.2.jar:?]
	at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:682) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:757) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:485) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_181]

2.15.1:
2019-02-12 01:56:50,618-0800 [toe=00081ibjglswzd] [Pool Worker - 18] ERROR - org.redisson.client.RedisResponseTimeoutException: Redis server response timeout (10000 ms) occured after 3 retry attempts. Command: (HMGET), params: [key-in-redis, get-values-requested, ...], channel: [id: 0x0fb8c255, L:/10.1.10.17:64746 - R:my.server.1.com/10.1.2.7:6379] org.redisson.client.RedisResponseTimeoutException: Redis server response timeout (10000 ms) occured after 3 retry attempts. Command: (HMGET), params: [key-in-redis, get-values-requested, ...], channel: [id: 0x0fb8c255, L:/10.1.10.17:64746 - R:my.server.1.com/10.1.2.7:6379]
	at org.redisson.command.CommandAsyncService$13.run(CommandAsyncService.java:959) ~[redisson-2.15.1.jar:?]
	at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:682) ~[netty-common-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:757) ~[netty-common-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:485) ~[netty-common-4.1.32.Final.jar:4.1.32.Final]
	at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_181]

Steps to reproduce or test case
I have no exact steps. But, my code works fine with 2.14.1. With 2.15.1, 2.15.2, 3.10.2, it always fails.
Redis version
4.0.11
Redisson version
3.10.2
Redisson configuration for 2.14.1:
{
     	"replicatedServersConfig": {
     		"idleConnectionTimeout": 10000,
     		"pingTimeout": 1000,
     		"connectTimeout": 10000,
     		"timeout": 10000,
     		"retryAttempts": 3,
     		"retryInterval": 1500,
     		"subscriptionsPerConnection": 5,
     		"sslEnableEndpointIdentification": true,
     		"sslProvider": "JDK",
     		"pingConnectionInterval": 0,
     		"keepAlive": false,
     		"tcpNoDelay": false,
     		"loadBalancer": {
     			"class": "org.redisson.connection.balancer.RoundRobinLoadBalancer"
     		},
     		"slaveConnectionMinimumIdleSize": 32,
     		"slaveConnectionPoolSize": 64,
     		"failedSlaveReconnectionInterval": 3000,
     		"failedSlaveCheckInterval": 180000,
     		"masterConnectionMinimumIdleSize": 32,
     		"masterConnectionPoolSize": 64,
     		"readMode": "MASTER_SLAVE",
     		"subscriptionMode": "MASTER",
     		"subscriptionConnectionMinimumIdleSize": 1,
     		"subscriptionConnectionPoolSize": 50,
     		"dnsMonitoringInterval": 5000,
     		"nodeAddresses": [
     			"redis://my.server.1:6379",
     			"redis://my.server.2:6379"
     		],
     		"scanInterval": 2000,
     		"database": 0,
     		"slaveSubscriptionConnectionPoolSize": 50,
     		"slaveSubscriptionConnectionMinimumIdleSize": 1
     	},
     	"threads": 0,
     	"nettyThreads": 0,
     	"referenceCodecProvider": {
     		"class": "org.redisson.codec.DefaultReferenceCodecProvider"
     	},
     	"referenceEnabled": true,
     	"transportMode": "NIO",
     	"lockWatchdogTimeout": 30000,
     	"keepPubSubOrder": true,
     	"useScriptCache": false,
     	"addressResolverGroupFactory": {
     		"class": "org.redisson.connection.DnsAddressResolverGroupFactory"
     	},
     	"useLinuxNativeEpoll": false
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1909
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am getting the following error when starting the server:
Unable to create requested service [org.hibernate.cache.spi.RegionFactory]
build.gradle
implementation 'org.redisson:redisson-spring-boot-starter:3.10.2'
implementation 'org.redisson:redisson-hibernate-53:3.10.2'
implementation 'org.xerial.snappy:snappy-java:1.1.7.2'
runtime 'javax.cache:cache-api'
application.yml
spring:
jpa:
generate-ddl: false
show-sql: false
properties:
javax.persistence.sharedCache.mode: ALL
hibernate:
ddl-auto: create
dialect: com.codefish.model.hibernate.MySqlDialect
generate_statistics: false
show_sql: false
use_sql_comments: false
format_sql: true
cache:
use_second_level_cache: true
use_query_cache: false
region_prefix: hibernate
region.factory_class: org.redisson.hibernate.RedissonRegionFactory
current_session_context_class: org.springframework.orm.hibernate5.SpringSessionContext
hibernate.naming.physical-strategy: org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl
mvc.dispatch-options-request: true
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1910
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I'm interested in using the fair locking feature from Reddison. But it looks like it doesn't work properly when used from within multiple Java VMs. Unless I'm missing something.
The reason: Reddison uses the thread ID when acquiring a lock. A thread ID in Java is not a UUID, but an integer that's unique only within a single VM:
public void lockInterruptibly(long leaseTime, TimeUnit unit) throws InterruptedException {
  long threadId = Thread.currentThread().getId();
  Long ttl = tryAcquire(leaseTime, unit, threadId);
  ... 
}

Could anyone clarify this please?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1911
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
How can we provide a default TTL and MaxIdleTime to a set of Regions?
Specifically, I'm using Hibernate with Redisson and would like to have to Set of Cache Types
1- Domain ( TTL 30 Mins )
2- Constants ( TTL 1 Day )
Right now i would have to add every domain class manually in the SpringRedissonConfig.
CacheManager cacheManager(RedissonClient redissonClient) {
        Map<String, CacheConfig> config = new HashMap<>();
        // create "testMap" cache with ttl = 24 minutes and maxIdleTime = 12 minutes
        CacheConfig configItem = new CacheConfig(TimeUnit.MINUTES.toMillis(60), TimeUnit.MINUTES.toMillis(30));
        config.put("domainCache",configItem);
        return new RedissonSpringCacheManager(redissonClient, config);
    }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1912
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
So I recently noticed the existence of RedissonRxClient which returns RObjectRx with Flowables.
To me this is a missed opportunity. One of the biggest reasons I prefer RxJava2 over Reactor Core is that it has distinct types for 1 element, 0..1 element, and 0 element, instead of just having Mono.
IMO RObjectRx should be returning RxJava2 specific types. For example, Flowable<Void> restore(byte[] state); should be Completable restore(byte[] state);, and Flowable<Boolean> isExists(); should be Single<Boolean> isExists();. And if the user wants standard reactive streams types, they still have the option of using RedissonReactiveClient, or they can easily call methods like Single.toFlowable().
Steps to reproduce or test case
N/A
Redis version
N/A
Redisson version
3.9.1
Redisson configuration
N/A
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1913
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Config config = new Config();
        config.useSingleServer().setAddress("addrss").setPassword("passwd");
        RedissonClient client = Redisson.create(config);
        RMap<String, String> map = client.getMap("aaa");
        map.put("111","222");  // 1
        map.rename("bbb");
        map.put("222222","333333");   // 2
        client.shutdown();

the 1 will move into 'bbb' map, but the 2 will put in the 'aaa' map,not the new one 'bbb'.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1914
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello
I am trying to make the stream example work with new redisson version 3.10.2 .
I get ArrayIndexOutOfBounds in class StreamIdDecider.
While it assume having 3 parameters. First one number-number key value.
This is not true input to this class is not these arguments.
Can you take a look?
Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1915
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi
I think it would be nice and will be much better to give the user an option to use the mkstream when creating a group.
This option create the stream attached to the group if it does not exist.
Please take a look here:
redis/redis#4824
Thanks
Ziv
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1916
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
Redisson version
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1917
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
用官方的demo例子，在分布式环境下，scheduleAtFixedRate创建任务后，多个物理机的RedissonNode添加了setExecutorServiceWorkers来接收任务。
测试时发现不同物理机的节点每个都会收到任务并执行，同一个物理机不同端口启动的redissonNode，则只有一个会执行任务。
目前想要的效果是最好全局只有一个节点处理这个任务，请问该如何处理呢？
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1918
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
Redisson version
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1919
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Using hibernate.cache.keys_factory setting
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1920
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The scenario is a Spring based application deployed on top of Tomcat 8 configured to use the RedissonSessionManager.
At startup, Spring initialization try to discover on classloader the namespace handlers including the org.redisson.spring.support.RedissonNamespaceHandlerSupport provided with the reddisson-all.jar library.
At this point the init of this handler fails with a NoClassDefFoundError probably because the Tomcat classloader cannot see Spring dependencies that are loaded by webapp classloader.
Unfortunately, after this WARN, the RedissonSessionManager doesn't work properly and new sessions are not stored on Redis.
Here the complete stacktrace:
15-Feb-2019 15.48.23 [Appalti]|WARN |Ignoring namespace handler [org.redisson.spring.support.RedissonNamespaceHandlerSupport]: problem with handler class file or dependent class java.lang.NoClassDefFoundError: org/springframework/beans/factory/xml/NamespaceHandlerSupport at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:763) at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) at java.net.URLClassLoader.defineClass(URLClassLoader.java:468) at java.net.URLClassLoader.access$100(URLClassLoader.java:74) at java.net.URLClassLoader$1.run(URLClassLoader.java:369) at java.net.URLClassLoader$1.run(URLClassLoader.java:363) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:362) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at java.lang.Class.forName0(Native Method) at java.lang.Class.forName(Class.java:348) at org.apache.catalina.loader.WebappClassLoaderBase.loadClass(WebappClassLoaderBase.java:1315) at org.apache.catalina.loader.WebappClassLoaderBase.loadClass(WebappClassLoaderBase.java:1163) at org.springframework.util.ClassUtils.forName(ClassUtils.java:201) at org.springframework.beans.factory.xml.DefaultNamespaceHandlerResolver.initHandlerMappings(DefaultNamespaceHandlerResolver.java:117) at org.springframework.beans.factory.xml.DefaultNamespaceHandlerResolver.<init>(DefaultNamespaceHandlerResolver.java:96) at org.springframework.beans.factory.xml.DefaultNamespaceHandlerResolver.<init>(DefaultNamespaceHandlerResolver.java:82) at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.createDefaultNamespaceHandlerResolver(XmlBeanDefinitionReader.java:488) at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.createReaderContext(XmlBeanDefinitionReader.java:477) at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.registerBeanDefinitions(XmlBeanDefinitionReader.java:458) at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:353) at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:303) at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:280) at org.springframework.jdbc.support.SQLErrorCodesFactory.<init>(SQLErrorCodesFactory.java:112) at org.springframework.jdbc.support.SQLErrorCodesFactory.<clinit>(SQLErrorCodesFactory.java:70) at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.setDataSource(SQLErrorCodeSQLExceptionTranslator.java:133) at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.<init>(SQLErrorCodeSQLExceptionTranslator.java:98) at org.springframework.jdbc.support.JdbcAccessor.getExceptionTranslator(JdbcAccessor.java:99) at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:553) at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:587) at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:616) at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:624) at it.eldasoft.gene.db.dao.jdbc.SqlDaoJdbc.getVectorQuery(SqlDaoJdbc.java:603) at it.eldasoft.gene.bl.SqlManager.getVector(SqlManager.java:184) at it.eldasoft.gene.bl.SqlManager.isTable(SqlManager.java:433) at it.eldasoft.gene.bl.SqlManager$$FastClassByCGLIB$$9be41d47.invoke(<generated>) at net.sf.cglib.proxy.MethodProxy.invoke(MethodProxy.java:149) at org.springframework.aop.framework.Cglib2AopProxy$CglibMethodInvocation.invokeJoinpoint(Cglib2AopProxy.java:695) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:144) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:107) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:166) at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:630) at it.eldasoft.gene.bl.SqlManager$$EnhancerByCGLIB$$bf7df9b3.isTable(<generated>) at it.eldasoft.gene.bl.SqlManager.setUserStoriaModifiche(SqlManager.java:477) at it.eldasoft.gene.commons.web.spring.DataSourceTransactionManagerBase.doBegin(DataSourceTransactionManagerBase.java:65) at org.springframework.transaction.support.AbstractPlatformTransactionManager.getTransaction(AbstractPlatformTransactionManager.java:350) at org.springframework.transaction.interceptor.TransactionAspectSupport.createTransactionIfNecessary(TransactionAspectSupport.java:262) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:102) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:166) at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:630) at it.eldasoft.gene.bl.admin.AccountManager$$EnhancerByCGLIB$$bf386373.updateLogins(<generated>) at it.eldasoft.gene.commons.web.struts.GeneStartupPlugIn.initConfigurabile(GeneStartupPlugIn.java:94) at it.eldasoft.gene.commons.web.struts.PlugInBase.initApplicazione(PlugInBase.java:257) at it.eldasoft.gene.commons.web.struts.PlugInBase.init(PlugInBase.java:177) at org.apache.struts.action.ActionServlet.initModulePlugIns(ActionServlet.java:871) at org.apache.struts.action.ActionServlet.init(ActionServlet.java:359) at javax.servlet.GenericServlet.init(GenericServlet.java:158) at org.apache.catalina.core.StandardWrapper.initServlet(StandardWrapper.java:1199) at org.apache.catalina.core.StandardWrapper.loadServlet(StandardWrapper.java:1143) at org.apache.catalina.core.StandardWrapper.load(StandardWrapper.java:1032) at org.apache.catalina.core.StandardContext.loadOnStartup(StandardContext.java:5035) at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5345) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:147) at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:725) at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:701) at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:717) at org.apache.catalina.startup.HostConfig.deployDescriptor(HostConfig.java:586) at org.apache.catalina.startup.HostConfig$DeployDescriptor.run(HostConfig.java:1795) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Caused by: java.lang.ClassNotFoundException: org.springframework.beans.factory.xml.NamespaceHandlerSupport at java.net.URLClassLoader.findClass(URLClassLoader.java:382) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ... 75 more
After some tests, we try to solve this problem by removing the following files from redisson-all-3.10.2.jar:

META-INF/spring.factories
META-INF/spring.handlers
META-INF/spring.schemas
META-INF/spring.tooling

so there is no need of Sprint integration in our case.
There is any solution/configuration we can adopt to avoid this error and keep the original library?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1921
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
According to this commit org.redisson.config.BaseConfig#setPingTimeout became deprecated. But there is no migration or deprecation note.
Are there any notes on this? Maybe this config option became redundant?
Redisson version
3.10.2
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1922
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Support providing default values for environment variables in YAML.
For example:
singleServerConfig:
  address: "redis://${REDIS_URL:127.0.0.1}:6379"
  timeout: ${REDIS_TIMEOUT:300}
  connectTimeout: 1000
  keepAlive: true
  pingConnectionInterval: 3000
  pingTimeout: 300
  connectionMinimumIdleSize: 2
  connectionPoolSize: 4
Redisson version:
3.10.2
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1923
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1924
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Yesterday I upgraded the redisson version from 3.7.2 to 3.10.2, causing the decoding to fail. The investigation found that the default codec has changed and is completely incompatible with the original default codec.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1925
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Appeared since 2.12.2 / 3.7.2 version
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1926
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RedissonLocalCachedMap.clearLocalCache 方法只是publish一个清理消息，并未确保所有instance清理完成，甚至连当前实例也不能确保清理完成，只是一个异步方法，能否增强一下，加一个清理ack消息并等待清理完毕
LocalCachedMapOptions<String, Entry> options = LocalCachedMapOptions.<String, Entry>defaults()
        .syncStrategy(LocalCachedMapOptions.SyncStrategy.INVALIDATE)
        .reconnectionStrategy(LocalCachedMapOptions.ReconnectionStrategy.CLEAR)
        .evictionPolicy(LocalCachedMapOptions.EvictionPolicy.NONE)
        .timeToLive(builder.localExpireSeconds, TimeUnit.SECONDS);
RLocalCachedMap<String, Entry> cache = client.getLocalCachedMap(
        "entry_cache",
        JsonJacksonCodec.INSTANCE,
        options);

Entry entry1 = new Entry();
cache.put("1", entry1);

cache.map1.clearLocalCache();

Entry entry2 = cache.get("1");
assertFalse(entry1 == entry2);  // maybe true
如果影响比较大，是否可能新增一个方法
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1927
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
several puts (5-10) into a MapCache guarded with a Lock seems to accumulate the payloads in thread locals. The payload is large (several Mb) and the pod (dockered spring boot app with 700 Mb max) goes out of heap. The app running with redisson 3.7.5 has no such problems.
redisson 3.10.2
  config
    .useMasterSlaveServers()
    .setMasterAddress(redisHost)
    .addSlaveAddress(redisSlave)
    .setPassword(redisPassword)
    .setTimeout(10000);

redis 4.0.1 (master, slave)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1928
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1929
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
The TTL and MaxIdeltime once set should auto-evict the hibernate entity beans cached in redis.
Actual behavior
The beans are not auto-evicted when TTL expires and the idle time has elapsed.
Steps to reproduce or test case
Step 1)
Create a simple entity bean (Say - com.jhipster.demo.blog.domain.Tag)
Step 2)
Annotate the same with the following
@Cacheable(cacheNames = "com.jhipster.demo.blog.domain.Tag")
@Cache(usage = CacheConcurrencyStrategy.NONSTRICT_READ_WRITE)
Step 3)
Try to set the TTL and config via code
@configuration
@EnableCaching
public class CacheConfig {
@bean
CacheManager cacheManager(RedissonClient redissonClient) throws IOException {
config.put("com.jhipster.demo.blog.domain.Tag",
new CacheConfig(120000, 180000)); //2min TTL and 3min max idle time
return new RedissonSpringCacheManager(redissonClient, config);
}
}
NOTE: The auto-eviction with TTL set at code level works for Spring cache only not hibernate second level cache for entity.
Step 4)
I also tried to set the TTL and max idle time via application.properties file
spring.jpa.properties.hibernate.cache.redisson.entry.eviction.max_entries=2000
spring.jpa.properties.hibernate.cache.redisson.entry.eviction.time_to_live=120000
spring.jpa.properties.hibernate.cache.redisson.entry.eviction.max_idle_time=180000
NOTE: I thought of using the application.properties file (since I am using spring boot, this file is auto picked)
I got this idea of overriding the default from the following Redisson link -
https://github.com/redisson/redisson/tree/master/redisson-hibernate
In that link I see default properties being set for  all entity like -




So I thought I can set the same via spring boot application.properties file
Anyhow both Step 3/4 does not set the TTL correctly for me and the entity is not auto-evicted.
NOTE: The auto-eviction with TTL set at code level works for Spring cache only not hibernate second level cache.
Redis version
5.0.3
Redisson version
3.10.2
Redisson configuration
I am using the single server mode and the configuration is the defualt as outlined in the link below for "singleServerConfig"
https://github.com/redisson/redisson/wiki/2.-Configuration#26-single-instance-mode
NOTE: I am using Hibernate 5.3.7, Spring boot 2.1.2, Redisson 3.10.2 version.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1930
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
This is to avoid reading phatom local values.

Originally posted by @jackygurui in #1823 (comment)
However mrniko said If element has been added/removed then invalidation message sent to all LocalCachedMap instances and element evicted in all of them.(#592 (comment))
What mrniko said means local cache will be synced by Redis pub/sub mechnism. If so, why does jackygurui said LocalCachedMap.readAllValues() need to read redis value to avoid reading local phantom value? Since local cache value will be synced, I think there is no phantom local values.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1931
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
I have a method:
public Boolean compareAndSetTaskBuckets(List except ,List update){
RBucket<List> taskRunningBucket = redissonClient.getBucket(ROBOT_TASK_RUNNING);
return taskRunningBucket.compareAndSet(except, update);
}
I excpet return true,but it still return false;
Actual behavior
it still return false
Steps to reproduce or test case
just first set an list object, then call this compareAndSetTaskBuckets method，it always return false。
Redis version
Redisson version
3.9.1
Redisson configuration
singleServerConfig
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1932
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
My software is using JAXRS with AsyncResponse.
I tried to use Redisson to store sessions of Tomcat 9.x in Redis, but I always get an exception.
I checked this exception and the reason seems to be that the UpdateValve class seems to call the default constructor of the Tomcat ValveBase class without a boolean flag indicating that it should support Async servlets.
This is a big showstopper since all servlets in our software are async and we don't want to convert them to synchronous ones since that will have a big impact on thread use and overal performance!
Expected behavior
Session object properly deserialise
Actual behavior
22-Feb-2019 13:44:51.083 WARNING [http-nio-8080-exec-2] org.apache.catalina.connector.Request.startAsync Unable to start async because the following classes in the processing chain do not support async [org.apache.catalina.servlets.DefaultServlet,org.redisson.tomcat.UpdateValve]
java.lang.IllegalStateException: A filter or servlet of the current chain does not support asynchronous operations.
        at org.apache.catalina.connector.Request.startAsync(Request.java:1665)
        at org.apache.catalina.connector.RequestFacade.startAsync(RequestFacade.java:1050)
        at javax.servlet.ServletRequestWrapper.startAsync(ServletRequestWrapper.java:397)
        at javax.servlet.ServletRequestWrapper.startAsync(ServletRequestWrapper.java:397)
        at org.glassfish.jersey.servlet.async.AsyncContextDelegateProviderImpl$ExtensionImpl.getAsyncContext(AsyncContextDelegateProviderImpl.java:112)
        at org.glassfish.jersey.servlet.async.AsyncContextDelegateProviderImpl$ExtensionImpl.suspend(AsyncContextDelegateProviderImpl.java:96)
        at org.glassfish.jersey.servlet.internal.ResponseWriter.suspend(ResponseWriter.java:125)
        at org.glassfish.jersey.server.ServerRuntime$AsyncResponder.suspend(ServerRuntime.java:910)
        at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:327)
        at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:102)
        at org.glassfish.jersey.server.ServerRuntime$2.run(ServerRuntime.java:326)
        at org.glassfish.jersey.internal.Errors$1.call(Errors.java:271)
        at org.glassfish.jersey.internal.Errors$1.call(Errors.java:267)
        at org.glassfish.jersey.internal.Errors.process(Errors.java:315)
        at org.glassfish.jersey.internal.Errors.process(Errors.java:297)
        at org.glassfish.jersey.internal.Errors.process(Errors.java:267)
        at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:317)
        at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:305)
        at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:1154)
        at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:473)
        at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:427)
        at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:388)
        at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:341)
        at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:228)
        at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:290)
        at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:280)
        at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:184)
        at com.google.inject.servlet.ManagedServletPipeline.service(ManagedServletPipeline.java:89)
        at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85)
        at com.swift.cloud.platform.ui.framework.server.filter.NeverCacheFilter.doFilter(NeverCacheFilter.java:51)
        at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)
        at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:121)
        at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:133)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199)
        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
        at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:490)
        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139)
        at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
        at org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:668)
        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
        at org.redisson.tomcat.UpdateValve.invoke(UpdateValve.java:58)
        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
        at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:408)
        at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
        at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:791)
        at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1417)
        at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
        at java.base/java.lang.Thread.run(Thread.java:844)
Steps to reproduce or test case
Try to use redisson to access session objects from an async servlet
Redis version
5.0.3
Redisson version
3.10.2
Redisson configuration
singleServerconfig:
address: redis://redis:6379
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1933
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you for contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1934
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
firstname=aaa   not store in redis。
looks like bytebuddy proxy has problem。
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1935
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
public CacheKey toCacheKey(Object key) {
    ByteBuf encoded = object.encodeMapKey(key);
    try {
        return toCacheKey(encoded);
    } finally {
        encoded.release();
    }
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1936
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
IndexOutOfBoundsException arise when there are no elements in group
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1937
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redlock采用多个redis实例，避免了主从复制导致的锁丢失问题。
但是好像没有考虑到单台redis实例解锁失败的问题把？
如果单台redis实例解锁成功的概率是0.9，那么有N台实例去解锁，那么成功率肯定会降低的，不知道我的理解对不对？
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1938
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
After upgraded to 3.10 from 3.9, it has trouble in reading data of SetCache, a NullPointerException was raised.

java.io.IOException: java.lang.NullPointerException
at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:247)
at org.redisson.codec.FstCodec$1.decode(FstCodec.java:90)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:364)
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:408)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:373)
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:408)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:373)
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:188)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:143)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:367)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1412)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:943)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:141)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:886)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException: null
at org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:357)
at org.nustaq.serialization.FSTObjectInput.readObjectInternal(FSTObjectInput.java:331)
at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:311)
at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:245)

I found these was something different between two formats created by 3.9 and 3.10
3.9

3.10
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1939
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1940
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
你好，看了下redlock实现的源码，发现如果存在下面这种情况是无法解决的：
假设有6个redis节点，client1和client2同时向redis实例获取同一个锁资源，那么可能发生的结果是——client1获得了3把锁，client2获得了3把锁，由于都没有超过半数，那么client1和client2获取锁都失败；
不知道对于这种场景，除了限制节点个数为奇数，还有其他更好的选择么
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1941
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
evict old keys even with acceptable delay
Actual behavior
eviction delay is too big due to bug
Steps to reproduce or test case
use cache with ttl 10min or 1hour.
in EvictionTask#run is delay that starts with 5seconds and is multiplied by 1.5 if no eviction is needed. therefore in first 10 minutes without evicting is many times multiplied and resulted to delay 110 or 165 seconds. that is CORRECT.
But after 10 minutes running evicting is started and this delay remains at this big value and is NOT decreased due to BUG. In production is this delay very big and redis is not fast enough in evicting and available memory is fulfilled. Jedis consumes under 100MB, redisson consumes 1GB(config limit) in short run.
MapCacheEvictionTask#execute contains
return #expiredKeys1 + #expiredKeys2;
which cause that even for keysLimit=100 is returned number 200.
EvictionTask#run contains
 if (size == keysLimit) { delay = Math.max(minDelay, delay/4); }
and this is always false (200 ==100) and therefore there is no option to decrease delay back to low number.
Redis version
4.0.2
Redisson version
3.10.1 and also 3.10.3
Redisson configuration
SingleServer and also on SentinelServer
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1942
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Stack info:
"simpleMessageListenerContainer-3" #117 prio=5 os_prio=0 tid=0x00007fb72d638000 nid=0x3b2f waiting on condition [0x00007fb6018d6000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <0x0000000084bd56a0> (a java.util.concurrent.CountDownLatch$Sync)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
	at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231)
	at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:148)
	at org.redisson.RedissonObject.get(RedissonObject.java:69)
	at org.redisson.RedissonAtomicLong.addAndGet(RedissonAtomicLong.java:43)
	at org.redisson.RedissonAtomicLong.get(RedissonAtomicLong.java:82)

Steps to reproduce or test case
Small probability and we can't reproduce, maybe related to bad network
Redis version
Redis server v=3.2.12
Redisson version
3.3.1
Redisson configuration
cluster default config
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1943
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Shouldn't the constructor of SingleServerConfig be public, as all other BaseConfig subclasses are? I know I can create it using new Config().useSingleServer() but I would prefer to have it public for some Spring custom properties.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1944
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
The DNS resolver should find valid DNS records, I am trying to connect to the redis hosted on azure. I looked at the existing similar issues but looks like this issue still exists.
Actual behavior
Caused by: io.netty.resolver.dns.DnsResolveContext$SearchDomainUnknownHostException: Search domain query failed. Original hostname: 'redis-c.redis.c.windows.net' failed to resolve 'redis-c.redis.c.windows.net.some.com' after 12 queries 
	at io.netty.resolver.dns.DnsResolveContext.finishResolve(DnsResolveContext.java:877) ~[netty-resolver-dns-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.resolver.dns.DnsResolveContext.tryToFinishResolve(DnsResolveContext.java:838) ~[netty-resolver-dns-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.resolver.dns.DnsResolveContext.query(DnsResolveContext.java:333) ~[netty-resolver-dns-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.resolver.dns.DnsResolveContext.onResponse(DnsResolveContext.java:520) ~[netty-resolver-dns-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.resolver.dns.DnsResolveContext.access$400(DnsResolveContext.java:63) ~[netty-resolver-dns-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.resolver.dns.DnsResolveContext$3.operationComplete(DnsResolveContext.java:377) ~[netty-resolver-dns-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:504) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:483) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:103) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.resolver.dns.DnsQueryContext.setSuccess(DnsQueryContext.java:196) ~[netty-resolver-dns-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.resolver.dns.DnsQueryContext.finish(DnsQueryContext.java:188) ~[netty-resolver-dns-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.resolver.dns.DnsNameResolver$DnsResponseHandler.channelRead(DnsNameResolver.java:1149) ~[netty-resolver-dns-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102) ~[netty-codec-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.nio.AbstractNioMessageChannel$NioMessageUnsafe.read(AbstractNioMessageChannel.java:93) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:677) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:612) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:529) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:491) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_181]

Steps to reproduce or test case
Redis version
Redisson version
3.10.3 and netty 4.1.33
Redisson configuration
Spring Boot Redisson example
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1945
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.redisson.api.RedissonClient]: Factory method 'getRedission' threw exception; nested exception is org.redisson.client.RedisConnectionException: At least two sentinels should be defined in Redis configuration! SENTINEL SENTINELS command returns empty result!
at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185)
at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:583)
... 95 common frames omitted
Caused by: org.redisson.client.RedisConnectionException: At least two sentinels should be defined in Redis configuration! SENTINEL SENTINELS command returns empty result!
at org.redisson.connection.SentinelConnectionManager.(SentinelConnectionManager.java:159)
at org.redisson.config.ConfigSupport.createConnectionManager(ConfigSupport.java:231)
at org.redisson.Redisson.(Redisson.java:121)
at org.redisson.Redisson.create(Redisson.java:164)
at com.hikvision.hosp.ham.main.cfg.RedissonConfig.getRedission(RedissonConfig.java:79)
at com.hikvision.hosp.ham.main.cfg.RedissonConfig$$EnhancerBySpringCGLIB$$8aeaf904.CGLIB$getRedission$1()
at com.hikvision.hosp.ham.main.cfg.RedissonConfig$$EnhancerBySpringCGLIB$$8aeaf904$$FastClassBySpringCGLIB$$c419b4b8.invoke()
at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:365)
at com.hikvision.hosp.ham.main.cfg.RedissonConfig$$EnhancerBySpringCGLIB$$8aeaf904.getRedission()
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154)
... 96 common frames omitted
when run this code :
List<Map<String, String>> sentinelSentinels = connection.sync(StringCodec.INSTANCE, RedisCommands.SENTINEL_SENTINELS, cfg.getMasterName());
sentinelSentinels size  is 0
Why?
Redis version
4.0.2
Redisson version
3.10.2
Redisson configuration



config.useSentinelServers()
.setPassword(redisProperties.getPassword())
.setMasterName(sentinel.getMaster())
.addSentinelAddress("redis://10.13.69.153:26379,redis://10.33.43.37:26379")
.setReadMode(ReadMode.MASTER_SLAVE)
.setDnsMonitoringInterval(5000)
.setSubscriptionConnectionMinimumIdleSize(1)
.setSubscriptionConnectionPoolSize(50)
.setTimeout(3000)
.setConnectTimeout(10000)
.setIdleConnectionTimeout(10000);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1946
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
For this code
“RBatch batch = client.createBatch();
Future<Collection> future = batch.getKeys().findKeysByPatternAsync(PATTERN_PREFIX + "*");"
it always return all matching keys?
In case the number of keys is very large , I need to get keys in batches. There seems to be no way out.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1947
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
For example, got a map from redisson:
 Map map = redisson.getMap("mapName");
map.put("name","obama");
redisson.putMap("mapName"); // does this step needed if I want all servers running the same java project get the new inserted element? 

To be clarify, If I run:
Map map = redisson.getMap("mapName");
map.put("name","obama");

on server 1 without redisson.putMap("mapName"), can server 2 get ("name","obama") when it do
Map map = redisson.getMap("mapName");?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1948
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Save a string, the prefix is garbled when it is taken out；
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1949
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Actual behavior
When trying to de-serialize a modified class ( add/remove field ) it fails and it throws an exception.
Expected behavior
When it cannot deserialize an object, it should ignore the cache as if it did not exist and call the method again and cache the new object...
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1950
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
15:35:12.756 [redisson-netty-1-1] ERROR org.redisson.client.handler.CommandDecoder - Unable to decode data. reply: $-1
, channel: [id: 0xf819abf5, L:/10.2.232.212:60019 - R:10.2.145.113/10.2.145.113:6379], command: CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@7078d41d(failure: java.util.concurrent.CancellationException)], command=(EVAL), params=[if (redis.call('exists', KEYS[1]) == 0) then redis.call('hset', KEYS[1], ARGV[2], 1); redis.call('pe..., 1, redisson_sortedset_lock:{testqueue}, 30000, c6d227cd-fb96-4350-b26f-9f47f2bd029c:19], codec=org.redisson.client.codec.LongCodec]
java.util.concurrent.CancellationException
at java.util.concurrent.CompletableFuture.cancel(CompletableFuture.java:2263)
at org.redisson.misc.RedissonPromise.cancel(RedissonPromise.java:239)
at org.redisson.command.CommandAsyncService$13.run(CommandAsyncService.java:941)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:682)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:757)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:485)
at java.lang.Thread.run(Thread.java:745)
15:39:03.936 [redisson-netty-1-6] ERROR org.redisson.client.handler.CommandDecoder - Unable to decode data. reply: :1
, channel: [id: 0x25aa8d2b, L:/10.2.232.212:60596 - R:10.2.145.113/10.2.145.113:6379], command: CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@7e62623(failure: java.util.concurrent.CancellationException)], command=(EVAL), params=[if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then redis.call('pexpire', KEYS[1], ARGV[1]); retu..., 1, redisson_sortedset_lock:{testqueue}, 30000, c6d227cd-fb96-4350-b26f-9f47f2bd029c:19], codec=org.redisson.client.codec.LongCodec]
java.util.concurrent.CancellationException
at java.util.concurrent.CompletableFuture.cancel(CompletableFuture.java:2263)
at org.redisson.misc.RedissonPromise.cancel(RedissonPromise.java:239)
at org.redisson.command.CommandAsyncService$13.run(CommandAsyncService.java:941)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:682)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:757)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:485)
at java.lang.Thread.run(Thread.java:745)
Expected behavior
reconnect to network
Actual behavior
there is a lock  name redisson_sortedset_lock:{testqueue} which dosen't release,it seem's like it can't release lock cause network boke,however it get a lock before network boke.
Steps to reproduce or test case
1.run code blow
public class TestReleaseLock {
public static void main(String[] args) {
Config config = new Config();
    MasterSlaveServersConfig serverConfig = config.useMasterSlaveServers()
            .setTimeout(1000000)
            .setMasterAddress("redis://10.2.145.113:6379")
            .addSlaveAddress("redis://10.2.145.113:6379");

    serverConfig.setTimeout(100);
    serverConfig.setRetryAttempts(3);
    serverConfig.setRetryInterval(1000);
    serverConfig.setPingConnectionInterval(10000);
    serverConfig.setMasterConnectionMinimumIdleSize(5);
    serverConfig.setKeepAlive(true);

    RedissonClient redissonClient = Redisson.create(config);

    ExecutorService pullService = Executors.newFixedThreadPool(1);
    pullService.execute(new Runnable() {
        RPriorityBlockingQueue<String> blockingQueue = redissonClient.getPriorityBlockingQueue("testqueue");

        @Override
        public void run() {
            while (true) {
                try{
                    System.out.println("waiting...");
                    String trunk = blockingQueue.take();
                    Thread.sleep(1000*2);
                    System.out.println(trunk);
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }
    });
}

}
2.disconnect your network
3.wait a few minute,then reconnect your network
Redis version
3.2.3
Redisson version
3.10.1
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1951
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
两个线程只有一个上锁成功,另一个等待超时后上锁失败
Actual behavior
两个线程都尝试加锁,但是都没成功,等待时间超时后都失败了

Steps to reproduce or test case
public static void main(String[] args) {
        new Thread() {
            @Override
            public void run() {
                runInFairLock("test", 5000, new LockCallBack() {
                    @Override
                    public void locked() {
                        System.err.println("1:locked");
                        try {
                            Thread.sleep(1000 * 60 * 60);
                        } catch (InterruptedException e) {
                            e.printStackTrace();
                        }
                    }

                    @Override
                    public void lockFail() {
                        System.err.println("1:lockFail");
                    }
                });
            }
        }.start();

        new Thread() {
            @Override
            public void run() {
                runInFairLock("test", 5000, new LockCallBack() {
                    @Override
                    public void locked() {
                        System.err.println("2:locked");
                    }

                    @Override
                    public void lockFail() {
                        System.err.println("2:lockFail");
                    }
                });
            }
        }.start();
    }

public static void runInFairLock(String name, long waitTime, LockCallBack lockCallBack) {
        RLock lock = redissonClient.getFairLock(name);
        _tryRunInLock(lock, waitTime, 1000L * 60 * 60 * 24, TimeUnit.MILLISECONDS,lockCallBack);
    }

private static void _tryRunInLock(RLock lock, long waitTime, long leaseTime, TimeUnit unit, LockCallBack lockCallBack) {
        boolean res = false;
        try {
            logger.error(Thread.currentThread().getName() + ", " + lock.getName() + ", " + "tryLock");
            res = lock.tryLock(waitTime, leaseTime, TimeUnit.MILLISECONDS);
            if (res) {
                logger.error(Thread.currentThread().getName() + ", " + lock.getName() + ", " + "locked");
                lockCallBack.locked();
            } else {
                logger.error(Thread.currentThread().getName() + ", " + lock.getName() + ", " + "lockFail");
                lockCallBack.lockFail();
            }
        } catch (InterruptedException e) {
            // 只有拥有锁的进程才能解锁，其他进程解锁则会抛出IllegalMonitorStateException错误
            // TODO: 2019-01-18 测试该场景
            logger.error(Thread.currentThread().getName() + ", " + lock.getName() + ", 只有拥有锁的进程才能解锁");
        } finally {
            logger.error(Thread.currentThread().getName() + ", " + lock.getName() + ", lockResult = " + res + ", isLocked=" + lock.isLocked() + ", isHeldByCurrentThread=" + lock.isHeldByCurrentThread());
            if (res) {
                logger.error(Thread.currentThread().getName() + ", " + lock.getName() + ", do unlock");
                lock.unlock();
            } else {
                logger.error(Thread.currentThread().getName() + ", " + lock.getName() + ", undo unlock");
            }
        }
    }

Redis version
redis-3.0.2
Redisson version
3.10.0
Redisson configuration
单机
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1952
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We're using Redisson tomcat session manager 3.10.0, and got exceptions as below:
Expected behavior
Redisson should catch the any exceptions happened during read/write sessions and returned null instead of throwing them to client.
Actual behavior
Exception thrown on page:
org.apache.catalina.loader.StandardClassLoader@307765b4^M
    at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:247)
    at org.redisson.codec.FstCodec$1.decode(FstCodec.java:70)
    at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:330)
    at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:380)
    at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:343)
    at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:130)
    at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:110)
    at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502)
    at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
    at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
    at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
    at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
    at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
    at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
    at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965)
    at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
    at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656)
    at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:591)
    at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:508)
    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470)
    at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909)
    at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    ... 1 more

Caused by: java.lang.RuntimeException: class not found CLASSNAME:com.sun.proxy.$Proxy228 loader:WebappClassLoader^M
context: /sbv5^M
delegate: false^M
repositories:^M
/WEB-INF/classes/^M
----------> Parent Classloader:^M
org.apache.catalina.loader.StandardClassLoader@307765b4^M
    at org.nustaq.serialization.FSTClazzNameRegistry.classForName(FSTClazzNameRegistry.java:235)
    at org.nustaq.serialization.FSTClazzNameRegistry.classForName(FSTClazzNameRegistry.java:190)
    at org.nustaq.serialization.FSTClazzNameRegistry.decodeClass(FSTClazzNameRegistry.java:173)
    at org.nustaq.serialization.coders.FSTStreamDecoder.readClass(FSTStreamDecoder.java:478)
    at org.nustaq.serialization.FSTObjectInput.readClass(FSTObjectInput.java:939)
    at org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:347)
    at org.nustaq.serialization.FSTObjectInput.readObjectFields(FSTObjectInput.java:713)
    at org.nustaq.serialization.FSTObjectInput.instantiateAndReadNoSer(FSTObjectInput.java:566)
    at org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:374)
    at org.nustaq.serialization.FSTObjectInput.readObjectInternal(FSTObjectInput.java:331)
    at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:311)
    at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:245)
    ... 36 more

Caused by: java.lang.ClassNotFoundException: com.sun.proxy.$Proxy228
at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1720)
at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1571)
at java.lang.Class.forName0(Native Method)
at java.lang.Class.forName(Class.java:348)
at org.nustaq.serialization.FSTClazzNameRegistry.classForName(FSTClazzNameRegistry.java:197)
... 47 more
Redisson version
3.10.0
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1953
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
no exception in readAllMap
Actual behavior
NullPointerException happened in
Steps to reproduce or test case
run the attached code "RedissonNullException.zip"
Redis version
Redis server v=4.0.8 sha=00000000:0 malloc=jemalloc-4.0.3 bits=64 build=9d70bbb410c08012
Redisson version
3.10.3
Redisson configuration
    Config redissonConfig = new Config();
    redissonConfig.useSingleServer()
        .setTimeout(1000000)
        .setAddress("redis://192.168.1.123:6379")
        .setDatabase(10)
        .setPassword("123")
        .setConnectionPoolSize(10)
        .setConnectionMinimumIdleSize(2);
    redissonConfig.setCodec(new FstCodec());
    redissonConfig.setLockWatchdogTimeout(5000);
    
    RedissonClient client = Redisson.create(redissonConfig);
    
    LocalCachedMapOptions options = LocalCachedMapOptions.defaults()
           .evictionPolicy(EvictionPolicy.NONE)
           .cacheSize(0)
           .reconnectionStrategy(ReconnectionStrategy.NONE)
           .syncStrategy(SyncStrategy.UPDATE)
           .evictionPolicy(EvictionPolicy.WEAK)
           .timeToLive(0)
           .maxIdle(0);

Log file
nullExceptionLog.txt
RedissonNullException.zip
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1954
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
no memory leak
Actual behavior
memory leak
Steps to reproduce or test case
run the attached code
Redis version
Redis server v=4.0.8 sha=00000000:0 malloc=jemalloc-4.0.3 bits=64 build=9d70bbb410c08012
Redisson version
3.10.3
Redisson configuration
    Config redissonConfig = new Config();
    redissonConfig.useSingleServer()
        .setTimeout(1000000)
        .setAddress("redis://192.168.1.123:6379")
        .setDatabase(10)
        .setPassword("123")
        .setConnectionPoolSize(10)
        .setConnectionMinimumIdleSize(2);
    redissonConfig.setCodec(new FstCodec());
    redissonConfig.setLockWatchdogTimeout(5000);

public static final LocalCachedMapOptions options = LocalCachedMapOptions.defaults()
       .evictionPolicy(EvictionPolicy.NONE)
       .cacheSize(0)
       .reconnectionStrategy(ReconnectionStrategy.NONE)
       .syncStrategy(SyncStrategy.UPDATE)
       .evictionPolicy(EvictionPolicy.WEAK)
       .timeToLive(0)
       .maxIdle(0);

RedissonMemoryLeakTest.zip
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1955
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
No errors should be thrown after setting maxmemory-policy :volatile-lru, maxmemory:4MB.
Actual behavior
When I am using two threads to put values through redisson to different database with limited memory(maxmemory-policy :volatile-lru, maxmemory:4MB),  error like org.redisson.client.RedisOutOfMemoryException: command not allowed when used memory > 'maxmemory' sprang up, and the database was flushed by redisson.
But I replaced to use Jedis(2.8.0) to test again, no such exceptions came out, and the database was not flushed by Jedis. The items which exceed 4MB  can be deleted by redis automatically because of volatile-lru policy.
Steps to reproduce or test case

Run commands on redis-cli,  config set maxmemory-policy volatile-lru  config set maxmemory 4mb
Run the code twice(Two threads) using different database with type to 0.

Redis version
3.2.4
Redisson version
3.10.3
Redisson configuration
singleServer, refer to the codes for details.
Codes I run
import org.redisson.Redisson;
import org.redisson.api.RMap;
import org.redisson.api.RedissonClient;
import org.redisson.config.Config;

import java.util.UUID;
import java.util.concurrent.TimeUnit;

import redis.clients.jedis.Jedis;

public class RedisExceptionTest {
    public static void test(int type, int database) {
        int index = 0;
        if (type == 1) {
            Jedis jedis = new Jedis("localhost", 6379);
            jedis.select(database);
            do {
                index++;
                try {
                    jedis.setex("Chemical:" + index, 3 * 60, UUID.randomUUID().toString());
                } catch (Exception e) {
                    e.printStackTrace();
                }
            } while (true);
        } else {
            Config config = new Config();
            config.useSingleServer().setAddress("redis://localhost:6379").setDatabase(database);
            RedissonClient client = Redisson.create(config);
            do {
                index++;
                try {
                    RMap<String, String> rMap = client.getMap("Chemical:" + index);
                    rMap.put(String.valueOf(index), UUID.randomUUID().toString());
                    rMap.expire(3L, TimeUnit.MINUTES);
                } catch (Exception e) {
                    e.printStackTrace();
                }
            } while (true);
        }
    }
    public static void main(String[] args) {
        //First arg 0 means using redisson, Second arg 1 means using database 1.
        //Please run twice of this application by changing different database.
        RedisExceptionTest.test(0, 1);
    }
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1956
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redisson Map Cache Event Notification doesn't work with HPE's NONSTOP OS.
This is because of the endianness.
Below logic is there in MapCacheEventCodec.decode(ByteBuf buf, State state, Decoder<?> decoder) method,
if (isWindows) {
keyLen = buf.readIntLE();
} else {
keyLen = (int) buf.readLongLE();
}
Here, if it is windows, buf.readIntLE() is used, or else buf.readLongLE() is used. But for HPE's NONSTOP OS, buf.readLong() has to be used.
To fix this, two classes has to be modified,


RedissonMapCache - Like how isWindows is being set using "Windows" substring, isNonstop boolean also can be initialized using "NONSTOP" substring
if (isNonstop == null) {
RFuture<Map<String, String>> serverFuture = commandExecutor.readAsync((String)null, StringCodec.INSTANCE, RedisCommands.INFO_SERVER);
serverFuture.syncUninterruptibly();
String os = serverFuture.getNow().get("os");
isNonstop = os.contains("NONSTOP");
}
Also, while initializing MapCacheEventCodec, need to pass isNonstop boolean.
new MapCacheEventCodec(codec, isWindows, isNonstop) - in all the 4 places


MapCacheEventCodec - Need to declare isNonstop boolean and initialize(in constructor) based on the isNonstop boolean that is received from ReidssonMapCache


Also, in the decode method, like how isWindows is being checked, need to check isNonstop and use buf.readLong() if it is NONSTOP as given below.
if (isWindows) {
keyLen = buf.readIntLE();
}else if (isNonstop) {
keyLen = buf.readLong();
} else {
keyLen = (int) buf.readLongLE();
}
Could you please fix this in Redisson code?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1957
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redis version
redis-4.0 Tencent Cloud Cluster (腾讯云集群版)
Redisson version
3.10.0-3.10.3
Redisson configuration
    Config config = new Config();
    config.useSingleServer()
            .setAddress("redis://10.1.1.16:6379")
            .setTimeout(3000)
            .setPassword(password);

1、腾讯云集群版对外只有一个代理IP，没有具体的子节点ip，Redisson无法配置成cluster模式，目前本地只能配置成单机模式，有没有针对腾讯云集群版方面的配置介绍？
2、使用RedissonLock 进行tryLock 或 unLock操作时，经常会出现 org.redisson.client.RedisException: ERR only (P)SUBSCRIBE / (P)UNSUBSCRIBE / PING / QUIT allowed in this context错误。不知道有没有碰到过类似的问题可以借鉴？ (非必现，运行一段时间后会出来)
lock.tryLock场景：
org.redisson.client.RedisException: ERR only (P)SUBSCRIBE / (P)UNSUBSCRIBE / PING / QUIT allowed in this context. channel: [id: 0xaeff9cd8, L:/172.16.0.184:60030 - R:10.1.1.16/10.1.1.16:6379] command: (EVAL), params: [if (redis.call('exists', KEYS[1]) == 0) then redis.call('hset', KEYS[1], ARGV[2], 1); redis.call('pe..., 1, redis_lock:order_center:order:update🔒11031138634123182082, 60000, a1f84934-abba-4bf9-b076-107ef093ebf6:96]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:314)
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:130)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:110)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:648)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:583)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:500)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:462)
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
lock.unlock()场景：
org.redisson.client.RedisException: ERR only (P)SUBSCRIBE / (P)UNSUBSCRIBE / PING / QUIT allowed in this context. channel: [id: 0x12f793e3, L:/172.16.0.184:60042 - R:10.1.1.16/10.1.1.16:6379] command: (EVAL), params: [if (redis.call('exists', KEYS[1]) == 0) then redis.call('publish', KEYS[2], ARGV[1]); return 1; end;..., 2, redis_lock:order_center:order:update🔒11031138634123182082, redisson_lock__channel:{redis_lock:order_center:order:update🔒11031138634123182082}, 0, 60000, a1f84934-abba-4bf9-b076-107ef093ebf6:124]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:314)
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:130)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:110)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502)  ... ...
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1958
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
request.getSession().getSessionContext().getIds();
This method return ids are same  as Redis store。
Actual behavior
When session is created by other tomcat instance, This method return ids are less than Redis store.
Steps to reproduce or test case
Redis version
Redisson version
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1959
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1960
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
类似问题#1754
Expected behavior
队列元素依然存在，并且能够在指定延迟后取到
Actual behavior
队列元素丢失
Steps to reproduce or test case
应该是必现的一个问题。运行大概两三天会出现延时队列元素丢失的问题。
队列创建代码：
private static RBlockingQueue<Long> taskQueue = RedissonHelper.redisson.getBlockingQueue("WX_DELAYED_TASK_QUEUE");
private static RDelayedQueue<Long> delayedTaskQueue = RedissonHelper.redisson.getDelayedQueue(taskQueue);
入队列代码：
delayedTaskQueue.offer(one, delayTime, TimeUnit.MILLISECONDS);
获取元素的代码：
while (true) {
try {
   printQueue("before execute");
   execute(taskQueue.take());
   printQueue("after execute");
   } catch (Exception e) {
   log.error("由任务队列获取任务失败", e);
   }
}
printQueue代码：
public static void printQueue(String hint) {
       log.info("taskTrace start: " + hint);
       delayedTaskQueue.readAll().forEach(one -> log.info(String.format("taskTrace: delayedTaskQueue 内容: %s", one)));
       log.info("taskTrace end: " + hint);
   }
在服务器运行一段时间后发现任务执行失败，查看日志发现delayedTaskQueue中的元素都不见了，日志如下：
15:38:43,424  INFO TaskService:969 - taskTrace start: Thread pool check
15:38:43,425  INFO TaskService:970 - taskTrace: delayedTaskQueue 内容: 1097757933673955328
15:38:43,425  INFO TaskService:970 - taskTrace: delayedTaskQueue 内容: 1097758524814962690
15:38:43,425  INFO TaskService:970 - taskTrace: delayedTaskQueue 内容: 1097458667441139716
15:38:43,425  INFO TaskService:970 - taskTrace: delayedTaskQueue 内容: 1097692298050850818
15:38:43,425  INFO TaskService:970 - taskTrace: delayedTaskQueue 内容: 1098112565378068482
15:38:43,425  INFO TaskService:970 - taskTrace: delayedTaskQueue 内容: 1098113151238463493
15:38:43,426  INFO TaskService:971 - taskTrace remainTimeToLive: -2
15:38:43,426  INFO TaskService:972 - taskTrace end: Thread pool check
15:43:42,450  INFO TaskService:969 - taskTrace start: Thread pool check
15:43:42,451  INFO TaskService:970 - taskTrace: delayedTaskQueue 内容: 1097757933673955328
15:43:42,451  INFO TaskService:970 - taskTrace: delayedTaskQueue 内容: 1097758524814962690
15:43:42,451  INFO TaskService:970 - taskTrace: delayedTaskQueue 内容: 1097458667441139716
15:43:42,451  INFO TaskService:970 - taskTrace: delayedTaskQueue 内容: 1097692298050850818
15:43:42,451  INFO TaskService:970 - taskTrace: delayedTaskQueue 内容: 1098112565378068482
15:43:42,451  INFO TaskService:970 - taskTrace: delayedTaskQueue 内容: 1098113151238463493
15:43:42,452  INFO TaskService:971 - taskTrace remainTimeToLive: -2
15:43:42,452  INFO TaskService:972 - taskTrace end: Thread pool check
15:48:41,483  INFO TaskService:969 - taskTrace start: Thread pool check
15:48:41,483  INFO TaskService:971 - taskTrace remainTimeToLive: -1
15:48:41,483  INFO TaskService:972 - taskTrace end: Thread pool check
15:53:40,507  INFO TaskService:969 - taskTrace start: Thread pool check
15:53:40,507  INFO TaskService:971 - taskTrace remainTimeToLive: -1
15:53:40,507  INFO TaskService:972 - taskTrace end: Thread pool check
15:58:39,533  INFO TaskService:969 - taskTrace start: Thread pool check
15:58:39,534  INFO TaskService:971 - taskTrace remainTimeToLive: -1
15:58:39,534  INFO TaskService:972 - taskTrace end: Thread pool check

这个问题在我这边是必现的。如果需要配合，我这边可以随时复现。谢谢。
Redis version
4.0
Redisson version
3.7.0
Redisson configuration
singleServerConfig:
  #连接空闲超时，单位：毫秒
  idleConnectionTimeout: 10000
  pingTimeout: 1000
  #连接超时，单位：毫秒
  connectTimeout: 10000
  #命令等待超时，单位：毫秒
  timeout: 3000
  #命令失败重试次数
  retryAttempts: 3
  #命令重试发送时间间隔，单位：毫秒
  retryInterval: 1500
  #重新连接时间间隔，单位：毫秒
  reconnectionTimeout: 3000
  #执行失败最大次数
  failedAttempts: 3
  #单个连接最大订阅数量
  subscriptionsPerConnection: 5
  #客户端名称
  clientName: null
  #地址
  address: "redis://test"
  #数据库编号
  database: 0
  #密码
  password: 123456
  #发布和订阅连接的最小空闲连接数
  subscriptionConnectionMinimumIdleSize: 1
  #发布和订阅连接池大小
  subscriptionConnectionPoolSize: 50
  #最小空闲连接数
  connectionMinimumIdleSize: 32
  #连接池大小
  connectionPoolSize: 64
  #是否启用DNS监测
  #dnsMonitoring: false
  #DNS监测时间间隔，单位：毫秒
  #dnsMonitoringInterval: 5000
threads: 0
nettyThreads: 0
codec: !<org.redisson.codec.JsonJacksonCodec> {}
transportMode : "NIO"
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1961
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I wrote the following code:
RMap<String, String> rmap = 
redissonClient.getLocalCachedMap("name",  
      LocalCachedMapOptions
          .defaults()
          .evictionPolicy(LocalCachedMapOptions.EvictionPolicy.LRU)
          .timeToLive(1, TimeUnit.SECONDS)
          .syncStrategy(LocalCachedMapOptions.SyncStrategy.NONE));
rmap.put("1", "test");
Thread.sleep(3000);

And then I expect, that rmap.get("1") will return null, but it returns previously set value.
I tried to debug library code and found the following:

AbstractCacheMap.isValueExpired() returns true
AbstractCacheMap removes value from cache and so get(Object key) returns null
after that RedissonLocalCachedMap/RedissonMap.getAsync() goes to Redis and my value there still exists
so RedissonLocalCachedMap calls cachePut(cacheKey, key, value), and expired value is again in cache
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1962
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1963
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1964
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1965
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
shutdown successfully
Actual behavior
There are errors on Eclipse console ,sort of
[redisson-netty-4-6] ERROR org.redisson.client.handler.CommandsQueue - Exception occured. Channel: [id: 0xd0d91ecc, L:/192.168.0.147:60301 - R:192.168.0.144/192.168.0.144:6379]
java.io.IOException: The remote host forcibly shuts down an existing connection。
at sun.nio.ch.SocketDispatcher.read0(Native Method)
at sun.nio.ch.SocketDispatcher.read(Unknown Source)
at sun.nio.ch.IOUtil.readIntoNativeBuffer(Unknown Source)
at sun.nio.ch.IOUtil.read(Unknown Source)
at sun.nio.ch.SocketChannelImpl.read(Unknown Source)
at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:288)
at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)
at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:677)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:612)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:529)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:491)
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Unknown Source)
19:10:05.060 [redisson-netty-4-8] ERROR org.redisson.client.handler.CommandsQueue - Exception occured. Channel: [id: 0xf56a3ced, L:/192.168.0.147:60316 - R:192.168.0.144/192.168.0.144:6379]
java.io.IOException: The remote host forcibly shuts down an existing connection。
at sun.nio.ch.SocketDispatcher.read0(Native Method)
at sun.nio.ch.SocketDispatcher.read(Unknown Source)
at sun.nio.ch.IOUtil.readIntoNativeBuffer(Unknown Source)
at sun.nio.ch.IOUtil.read(Unknown Source)
at sun.nio.ch.SocketChannelImpl.read(Unknown Source)
at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:288)
at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)
at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:677)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:612)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:529)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:491)
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Unknown Source)
Steps to reproduce or test case
import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import org.redisson.Redisson;
import org.redisson.api.RList;
import org.redisson.api.RedissonClient;
public class ListExamples {
public static void main(String[] args) {
    // connects to 127.0.0.1:6379 by default
    RedissonClient redisson = Redisson.create();
    redisson.shutdown();
}

}
Redis version
redis-64.3.0.503  windows
Redisson version
3.10.1
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1966
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
After a Redis response timeout, Redisson needs to be resilient and back to normal operation after Redis timeout and allow to lock and unlock critical sections again.
Actual behavior
After a Redis response timeout between attempts, Redisson adds the lock to scheduled renew task and never remove them. So, the application enters on a deadlock due to a lock renewed even after unlock.
The task can run on the same thread due to reentrant lock feature, but when the task runs on another thread a deadlock occurs.
Steps to reproduce or test case

Start Redis
Run the test application (https://github.com/hmagarotto/redissonlock) with a simple locked task.
Force a timeout on Redis runnning a client pause command: "CLIENT PAUSE 5000"

Redis version
4.0.10
Redisson version
3.10.3
Redisson configuration
Single server default
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1967
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When we use RMap, we find that memory can't be released, which leads to frequent fullgc in the production environment. Is there a solution or optimization update of relevant modules now?
The version we used was 3.8.2
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1968
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We are currently facing some issues with ElastiCache/Redisson without being able to determine the root cause so far - thus I'm giving it a try here ...
We've set up ElastiCache in cluster-mode (3 Nodes) - and configured Redisson correspondingly.
We are using distributed locks and some RMapCaches. The caches have a max-size (thus LRU-eviction) and TTLs set for both lock as well the cache entries.
During the last few months we ran into a couple of out-of-memory-related outages - that is Redis runs OOM, not the client.
The memory consumption is usually staying constant (limited by the LRU policy and TTL) for weeks but then tanks out of of the blue.  Per "step", the memory consumption does pretty much double. The "step down" in memory takes 1-2 hours before stabilizing on a lower level.
According to our statistics, the number of keys remains constant - less than 100 of which 15 belong to the caches and the rest being TTLed-locks. The number of keys (entries) per cache is also constant - with either well below the size ceiling or the LRU is recognized (=ceiling not exceeded).
I'm wondering whether somebody has seen a similar issue?
With Redisson 3.10, there's a new option to determine the size of an RMap - so we'll use that to investigate further - but I suspect that the size of individual cache entries (which, in theory, could cause this) is not the reason. If we had huge entries, we'd expect to see a recovery after the TTL period, but this is not the case.
Just from gut feeling, it feels as if this is somehow related to a replication - that would at least explain those "steps" to some degree.
Redis version
4.0.10
Redisson version
3.9.0
Redisson configuration
Cluster-mode
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1969
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We are using an AWS ElastiCache Redis 4.0.10 cluster with Redisson 3.10.3 and following a
cache.valueSize(id);
where cache is a RMapCache we can spot the following in our logs:
reply: ReplayingDecoderByteBuf(ridx=2111, widx=3072), command: (HSTRLEN), params: [xxxxx, PooledUnsafeDirectByteBuf(ridx: 0, widx: 16, cap: 256)]: java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Long
T
09 Mar 2019 06:00:31.152aws-beta_JBoss[aws-beta-app-02] at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1436)
09 Mar 2019 06:00:31.152aws-beta_JBoss[aws-beta-app-02] at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1203)
09 Mar 2019 06:00:31.152aws-beta_JBoss[aws-beta-app-02] at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1247)
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502)
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441)
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278)
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408)
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:677)
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:612)
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:529)
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:491)
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at java.lang.Thread.run(Thread.java:748) [:1.8.0_131]
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Long
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at org.redisson.client.protocol.convertor.IntegerReplayConvertor.convert(IntegerReplayConvertor.java:39) [redisson-3.10.3.jar:]
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at org.redisson.client.protocol.convertor.IntegerReplayConvertor.convert(IntegerReplayConvertor.java:23) [redisson-3.10.3.jar:]
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at org.redisson.client.handler.CommandDecoder.handleResult(CommandDecoder.java:434) [redisson-3.10.3.jar:]
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:370) [redisson-3.10.3.jar:]
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:201) [redisson-3.10.3.jar:]
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:143) [redisson-3.10.3.jar:]
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:122) [redisson-3.10.3.jar:]
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502)
09 Mar 2019 06:00:31.153aws-beta_JBoss[aws-beta-app-02] at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)

Actual behavior
Steps to reproduce or test case
Redis version
4.0.10
Redisson version
3.10.3
Redisson configuration
Cluster-Mode
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1970
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
This is a extreme situation, I need get a multilock that contain tens of thousands of locks, It will take several minutes, Is it  possible to impor  MultiLock  trylock performance?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1971
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi all!
We use Redisson with the tomcat-8 integration. Because this is a legacy application with mutable session objects we have to use updateMode=AFTER_REQUEST.
The problem we faces is that this update mode will not be able to sync removed attrbutes to redis and inform other running tomcat instances. This is bad because our other instances of Tomcat ends up using removed attributes.
It's actually easy to spot the bug if one inspect RedissonSession.java#L267-L276:
    protected void removeAttributeInternal(String name, boolean notify) {
        super.removeAttributeInternal(name, notify);
        
        if (updateMode == UpdateMode.DEFAULT && map != null) {
            map.fastRemove(name);
            if (readMode == ReadMode.MEMORY) {
                topic.publish(new AttributeRemoveMessage(redissonManager.getNodeId(), getId(), name));
            }
        }
    }
You can see that removeAttributeInternal only does publish the removed attribute if updateMode=DEFAULT. This would be fine if Redisson somehow stored which attribute names which was removed so that they also was synced in the store function triggered by  the UpdateValve.
    public void store(HttpSession session) throws IOException {
        if (session == null) {
            return;
        }
        
        if (updateMode == UpdateMode.AFTER_REQUEST) {
            RedissonSession sess = (RedissonSession) super.findSession(session.getId());
            if (sess != null) {
                sess.save();
            }
        }
    }
The problem is that store will only save the current attributes (see RedissonSession.java#L278-L303) on the session, and not the removed attributes. Handling removed attributes will require that Redisson  keeps control of both the added and the removed attributes within one request cycle (the same attribute may be added and removed multiple times).
How can this be fixed?
Solution 1: relax AFTER_REQUEST
I would argue that you actually want all session attributes to be synced as soon as possible. But in the rare scenario where you operate on mutable session data you would do an extra force-update after the request completes.
The proposal would be to replace AFTER_REQUEST mode with FORCE_UPDATE_AFTER_REQUEST. Then all addAttrbiute & removeAttribute should be synced as soon as possible, the same way you get with the DEFUALT mode today. But in addition you will get all attributes synced after the request completes. This would be easy to implement as it will only require removal of the if-guard inside the removeAttributeInternal function.
It could also be beneficial if one is able to specify a white-list of attributes known to be immutable.
Solution 2: Redission keeps track of removed attributes
In this solution Redisson needs to keep track a map of removed attributes during a request cycle and make sure to remove these attributes from redis and notify all other tomcat instances. This will be more complex to implement correctly than solution 1.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1972
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
and how i configuration it ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1973
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1974
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
在同一个进程中维护大量的RLocalCachedMap会不会存在问题。如果会，该怎么处理。
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1975
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We are on version 3.7.2 and only using RMap, RScoredSet and are facing the same issue in production where netty threads used by redisson consumed 12GB of total 16GB of allocated heap space in one application and 8GB out of 16 GB on another application . One observation i have made is that netty threads had created around 275,000 thread local maps with each consuming around a fixed amount of heap. It all seems to be related with weblogic context aware classloader because it is shared by all the netty threads.
Since the heap dump is quite large I will be attching the screenshots.
@mrniko setting  -Dio.netty.allocator.useCacheForAllThreads=false had no effects
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1976
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
When an exception is thrown upon the AUTH command the exception contains the actual password as a param. This happens because LogHelper.toString called by RedisConnection.async nowadays accepts a "Object..." all the time, and LogHelper redacts the password only when a single object of the type CommandData is passed.
Actual behavior
Caused by: org.redisson.client.RedisTimeoutException: Command execution timeout for command: (AUTH), command params: [our actual password], Redis client: [addr=rediss://server:6379]
at org.redisson.client.RedisConnection$2.run(RedisConnection.java:214)
at io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38)
at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:127)
... 6 common frames omitted
Steps to reproduce or test case
Redis version
Redisson version
3.10.4
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1977
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am using RMapCache to handle my distributed collections.
When adding to the map, i use:
	map.put("DTO1", dto, 20, TimeUnit.SECONDS);

So the key should expire after 20 seconds. This works, if the process is not terminated before the expiration timestamp. However, if the process dies for any reason, the key never expires.
By observing this behavior, I have concluded that is the Java process that makes the Key expire. I would like Redisson to use Redis EXPIRE behavior for keys, so that the Java process is not responsible for expiring the key.
This way, i will know for sure that the key will expire after the given time, even if for any reason the java process dies.
Is this possible to do with Redisson?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1978
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1979
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1980
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1981
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1982
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1983
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1984
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1985
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1986
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1987
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1988
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1989
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1990
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1991
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1992
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1993
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1994
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1995
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1996
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1997
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1998
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/1999
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2000
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2001
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2002
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2003
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2004
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2005
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2006
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2007
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2008
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2009
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2010
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2011
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2012
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2013
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2014
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2015
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2016
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2017
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2018
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2019
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2020
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2021
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2022
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2023
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2024
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2025
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2026
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2027
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2028
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2029
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2030
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2031
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2032
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2033
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2034
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2035
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2036
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2037
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2038
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2039
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2040
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2041
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2042
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2043
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2044
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2045
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2046
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2047
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2048
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2049
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2050
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2051
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2052
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2053
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2054
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2055
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2056
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2057
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2058
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2059
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2060
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2061
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2062
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2063
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2064
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2065
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2066
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2067
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2068
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2069
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2070
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2071
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2072
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2073
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2074
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2075
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2076
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2077
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2078
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2079
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2080
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2081
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2082
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2083
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2084
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2085
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2086
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2087
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2088
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2089
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2090
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2091
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2092
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2093
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2094
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2095
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2096
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2097
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2098
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2099
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2100
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2101
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2102
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2103
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2104
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2105
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2106
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case
in our test env, we set log level debug, and there's some output for redisson, I found redisson always use one thread to do clusterChangeCheck, no matter how many times I relaunch.

I read source code, and I found default nettyThread is 32, why does redisson just use second thread?
Redis version
3.2.11
Redisson version
3.10.2
Redisson configuration
we only set cluster nodes and password.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2107
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
TypedJsonJacksonCodec should decode messages within stream to specific types.
Actual behavior
JSON is decoded to LinkedHashMap rather than to specific type.
Steps to reproduce or test case
RStream<String, Message> stream = redissonClient.getStream("stream", new TypedJsonJacksonCodec(String.class, Message.class));
Map<StreamMessageId, Map<String, Message>> messageMap = stream.readGroup("group", "consumer");

messageMap.forEach((key, value) -> {
    value.forEach((k, v) -> {
        log.info("Class: {}", v.getClass()); // prints LinkedHashMap
        v.getValue(); // ClassCastException
    });
});

Redis version
5.0
Redisson version
3.10.7
Redisson configuration
Config redisConfig = new Config();
redisConfig.useSingleServer().setAddress(url);
RedissonReactiveClient redissonClient = Redisson.create(redisConfig);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2108
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior  删除所有指定前缀的key
Actual behavior  报错误日志
Steps to reproduce or test case 执行完 deleteByPatternAsync，debug至下一行代码处，此时查看redis桌面管理工具，多次reload要删除的key，发现没有被删除，断点通过，报出错误日志
Redis version  3.2.9
Redisson version  3.10.0
Redisson configuration  config.useSingleServer().setAddress("redis://" +redisProperties.getHost() + ":" + redisProperties.getPort()); config.setEventLoopGroup(new NioEventLoopGroup());
[2019-05-15 10:48:08 ERROR] [nioEventLoopGroup-2-8] [CommandDecoder.java:134] - Unable to decode data. reply: *2
$4
6672
0
, channel: [id: 0x9e3649f8, L:/172.23.193.131:53309 - R:192.168.240.121/192.168.240.121:8379], command: CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@ef9691d(failure: java.util.concurrent.CancellationException)], command=(SCAN), params=[0, MATCH, gift:goodsList:215:, COUNT, 100], codec=org.redisson.client.codec.StringCodec]
java.util.concurrent.CancellationException: null
at java.util.concurrent.CompletableFuture.cancel(CompletableFuture.java:2263)
at org.redisson.misc.RedissonPromise.cancel(RedissonPromise.java:239)
at org.redisson.command.CommandAsyncService$13.run(CommandAsyncService.java:887)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:682)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:757)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:485)
at java.lang.Thread.run(Thread.java:748)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2109
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Redis server response timeout (3000 ms) occured after 3 retry attempts. Command: (DEL), params: [quick_pay_api_agent_password_count_16600000001], channel: [id: 0xea739d38, L:/192.168.0.137:61678 - R:192.168.1.38/192.168.1.38:6379] org.redisson.client.RedisResponseTimeoutException: Redis server response timeout (3000 ms) occured after 3 retry attempts. Command: (DEL), params: [quick_pay_api_agent_password_count_16600000001], channel: [id: 0xea739d38, L:/192.168.0.137:61678 - R:192.168.1.38/192.168.1.38:6379] at org.redisson.command.CommandAsyncService$8.run(CommandAsyncService.java:935) at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:682) at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:757) at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:485) at java.lang.Thread.run(Thread.java:745)
Actual behavior
Steps to reproduce or test case
Redis version
4.0.3
Redisson version
3.10.7
Redisson configuration
<bean id="stringCodec" class="org.redisson.client.codec.StringCodec"/> <redisson:client id="sentinelRedisClient" codec-ref="stringCodec" > <redisson:sentinel-servers master-name="${redisson.master_name}"  database="0" retry-attempts="3" retry-interval="1500" password="${redisson.pwd}" connect-timeout="60000" master-connection-pool-size="100" master-connection-minimum-idle-size="10"> <redisson:sentinel-address value="${redisson.node1}" /> <redisson:sentinel-address value="${redisson.node2}" /> <redisson:sentinel-address value="${redisson.node3}" /> </redisson:sentinel-servers> </redisson:client>
我的需求
1、数据连接池里面，会拥有最小链接数量
2、如果所有链接都断了，链接池数量为0
3、如果连接池数量为0，在用户再次用到RedissonClient，会去重新获取链接，retry-attempts 就应该生效。
现在是 error
redisson 会开启一个线程，维持redis心跳， redis 如果掉线 1500 ms 重试 3次，再获取不到链接的话。RedissonClient就不能用了。
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2110
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Hi,
I am using "AFTER_REQUEST" update mode in Redisson Session Manager configuration to ensure that mutable session attributes are in sync with the session stored in Redis
But it fails with this exception :
Caused by: java.lang.RuntimeException: Class org.apache.catalina.session.StandardSessionFacade does not implement Serializable or externalizable
This is my configuration:
<ResourceLink name="bean/redisson"
              global="bean/redisson"
	  type="org.redisson.api.RedissonClient" />

 <Manager className="org.redisson.tomcat.JndiRedissonSessionManager"
     readMode="REDIS"
     updateMode="AFTER_REQUEST"
     jndiName="bean/redisson" />

Please advise what is wrong ?
Actual behavior
Steps to reproduce or test case
Redis version
Redisson version
I am running Tomcat 8.0.14 version and Redisson Tomcat jar - redisson-tomcat-8-3.10.6.jar
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2111
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
config

org.redisson.client.RedisResponseTimeoutException: Redis server response timeout (3000 ms) occured after 3 retry attempts. Command: (EVAL), params: [if (redis.call('exists', KEYS[1]) == 0) then redis.call('hset', KEYS[1], ARGV[2], 1); redis.call('pe..., 1, CAMPAIGN_LOCK_ee3aa6b4-b89f-469e-bf16-83c100ad7262, 300000, bf26bdb9-3584-4cbd-9fc5-dfbed4b2cc52:148], channel: [id: 0x4e899fa3, L:/10.233.80.88:52776 - R:B2B-prd-PPM-redis-0.redis.cache.chinacloudapi.cn/42.159.102.154:6380]
当出现一次这个问题后，后面所有获取锁的代码都会出现这个问题
并且 使用jedis不会出现这个问题
部分服务在重启后，立刻恢复可用。
部分服务在没有重启的情况下，2小时后又重新恢复可用了。
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
Redisson version
3.10.6
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2112
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No deletion after removing the last N；
RScoredSortedSet set = redissonClient.getScoredSortedSet(RedisLogin.PASSING.getName());
list=set.pollLast(10);
Which api？
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2113
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
georadius GEO  73.9064 18.5453 10 km STOREDIST userResultSet


userResultSet key points to a sortedSet which is sorted by distance.
Actual behavior
Redisson currently only supports the STORE option
georadius GEO  73.9064 18.5453 10 km STORE userResultSet

This creates a sortedSet using the hash value.
Steps to reproduce or test case
Redis version
Redisson version
3.10.4
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2114
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
将maven依赖修改为：
 <dependency> <groupId>org.redisson</groupId> <artifactId>redisson-spring-boot-starter</artifactId> <exclusions> <exclusion> <artifactId>redisson-spring-data-21</artifactId> <groupId>org.redisson</groupId> </exclusion> </exclusions> <version>3.10.6</version> </dependency> <!--  解决redisson  AbstractMethodError错误  --> <dependency> <groupId>org.redisson</groupId> <!-- for Spring Data Redis v.2.0.x --> <artifactId>redisson-spring-data-20</artifactId> <version>3.10.6</version> </dependency>
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2115
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Redisson in single server mode should reconnect after the connection is unavailable for some time.
Actual behavior
Redisson fails to re-establish a connection to the Redis server.
Steps to reproduce or test case
Hard to reproduce.
Redis version
4.0.1
Redisson version
3.5.0
Redisson configuration
       Config config = new Config(); config.useSingleServer() .setAddress(serverAddress.toString()) .setRetryAttempts(retryAttempts) .setRetryInterval(retryInterval);
At some point, when Redis is needed, an error is reported when trying to
java.util.concurrent.CompletionException: org.redisson.client.RedisConnectionException: MasterConnectionPool no available Redis entries.  Disconnected hosts: [localhost/127.0.0.1:6378] at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292) at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308) at java.util.concurrent.CompletableFuture.biRelay(CompletableFuture.java:1284) at java.util.concurrent.CompletableFuture$BiRelay.tryFire(CompletableFuture.java:1270) at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474) at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1977) at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:97) at org.redisson.command.CommandAsyncService.checkAttemptFuture(CommandAsyncService.java:804) at org.redisson.command.CommandAsyncService.access$300(CommandAsyncService.java:79) at org.redisson.command.CommandAsyncService$9.operationComplete(CommandAsyncService.java:609) at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507) at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481) at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420) at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122) at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:98) at org.redisson.command.CommandAsyncService$7.run(CommandAsyncService.java:539) at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:663) at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:738) at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:466) at java.lang.Thread.run(Thread.java:748) Caused by: org.redisson.client.RedisConnectionException: MasterConnectionPool no available Redis entries.  Disconnected hosts: [localhost/127.0.0.1:6378] at org.redisson.connection.pool.ConnectionPool.get(ConnectionPool.java:196) at org.redisson.connection.pool.MasterConnectionPool.get(MasterConnectionPool.java:31) at org.redisson.connection.MasterSlaveEntry.connectionWriteOp(MasterSlaveEntry.java:409) at org.redisson.connection.MasterSlaveConnectionManager.connectionWriteOp(MasterSlaveConnectionManager.java:708) at org.redisson.command.CommandAsyncService.async(CommandAsyncService.java:502) at org.redisson.command.CommandAsyncService$7.run(CommandAsyncService.java:551) ... 4 common frames omitted
Debug logs when the connection is unavailable, and redisson is trying to reconnect:
2019-05-16 13:01:06,518 DEBUG 2920 [ool-41-thread-1] o.r.client.handler.ConnectionWatchdog    : reconnecting RedisConnection@1311315531 [redisClient=[addr=localhost/127.0.0.1:6378], channel=[id: 0x0e9a8682, L:0.0.0.0/0.0.0.0:64139]] to localhost/127.0.0.1:6378  2019-05-16 13:01:06,519 DEBUG 2920 [isson-netty-1-6] o.r.client.handler.ConnectionWatchdog    : RedisConnection@1311315531 [redisClient=[addr=localhost/127.0.0.1:6378], channel=[id: 0x0e9a8682, L:0.0.0.0/0.0.0.0:64139]] connected to localhost/127.0.0.1:6378, command: null 2019-05-16 13:01:06,695 DEBUG 2920 [ool-54-thread-1] o.r.client.handler.ConnectionWatchdog    : reconnecting RedisConnection@1621118964 [redisClient=[addr=localhost/127.0.0.1:6378], channel=[id: 0x312d8beb, L:0.0.0.0/0.0.0.0:64141]] to localhost/127.0.0.1:6378  2019-05-16 13:01:06,695 DEBUG 2920 [isson-netty-5-3] o.r.client.handler.ConnectionWatchdog    : RedisConnection@1621118964 [redisClient=[addr=localhost/127.0.0.1:6378], channel=[id: 0x312d8beb, L:0.0.0.0/0.0.0.0:64141]] connected to localhost/127.0.0.1:6378, command: null 2019-05-16 13:01:06,845 DEBUG 2920 [ool-54-thread-1] o.r.client.handler.ConnectionWatchdog    : reconnecting RedisConnection@452093370 [redisClient=[addr=localhost/127.0.0.1:6378], channel=[id: 0x5168a7f1, L:0.0.0.0/0.0.0.0:64143]] to localhost/127.0.0.1:6378  2019-05-16 13:01:06,845 DEBUG 2920 [isson-netty-5-4] o.r.client.handler.ConnectionWatchdog    : RedisConnection@452093370 [redisClient=[addr=localhost/127.0.0.1:6378], channel=[id: 0x5168a7f1, L:0.0.0.0/0.0.0.0:64143]] connected to localhost/127.0.0.1:6378, command: null
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2116
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I want to get the lock's owner name when i lock fail.So I can know who prevent me to get lcok.
Can i get it?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2117
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Async API for org.redisson.api.RMap#entrySet(java.lang.String, int)
Actual behavior
There is only sync API available.
Steps to reproduce or test case
Redis version
Redisson version
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2118
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
SentinelServersConfig,MasterSlaveServersConfig,ClusterServersConfig,ReplicatedServersConfig all has a public constructor except SingleServerConfig, it makes SingleServerConfig hard to extends. Why not defined SingleServerConfig consistent with a public constructor?
Redisson version 3.10.7
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2119
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
您好，有个问题咨询下，背景是这样的，公司最近在对网络进行大面积调整，现在出现这样的情况，redis域名 redis.xxxx.com 之前绑定在ip A下，网络调整后，切换到IP B，如果应用不重启的话，redissClient无法使用redis.xxxx.com无法自动切换连接到 IP B，异常信息依然是连接IP A。请问下现在redisson 断线重连机制是什么样的？重连时如何刷新InetSocketAddress？
Expected behavior
redis域名绑定ip变更后，能正常链接到切换后的新ip
Actual behavior
redis域名变更后连接能切换到新ip redis
Steps to reproduce or test case
测试通过修改hosts文件，将映射
redis.xxxx.com   ip a
#redis.xxxx.com   ip b
切换后测试redissonClient连接是否正常
Redis version
redis 4.0.10
Redisson version
redisson 3.10.6
Redisson configuration
cache:
redis:
address: redis://redis.xxxxxx.com:6379
password: xxxx
# 默认缓存有效期：30天
expire-time: 30
pool-config:
min-idle: 10
pool-size: 32
connect-timeout: 15000
max-wait-timeout: 10000
retry-attempts: 3
retry-interval: 1000
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2120
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am getting a memory leak when I try to connect to Redis using SentinelServer and the server is unavailable.
I create a separated thread trying to connect in a loop and the memory consumption increase over time. My RedissonWrapper code:
`
@component
public class RedissonWrapper {
private  ExecutorService executor;
private  AtomicReference<RedissonClient> redissonClientSupplier;
private final NioEventLoopGroup nioEventLoopGroup;

@Autowired
public RedissonWrapper(RedisConfig redisConfig) {
    nioEventLoopGroup = new NioEventLoopGroup();
    ThreadFactory schedulerThreadFactory = new ThreadFactoryBuilder().setNameFormat("REDISSON_WRAPPER-%d").build();
    executor = Executors.newSingleThreadExecutor(schedulerThreadFactory);


    executor.submit(() -> {
        redissonClientSupplier = new AtomicReference<>(null);
        RedissonClient redissonClient = null;

        while (redissonClient == null) {
            try {
                redissonClient = createRedissonClient(redisConfig);
                if (redissonClient != null) {
                    log.info("Redisson Client successfully created");
                    this.redissonClientSupplier.set(redissonClient);
                    executor.shutdown();
                }
            } catch (Exception e) {
                log.error("Error while creating Redis Client with messagee: '{}'. Trying again in 5 seconds...",
                        e.getMessage());
                log.error("Error while creating Redis Client ", e);
                System.gc();
                try {
                    Thread.sleep(5000);
                } catch (InterruptedException e1) {
                    e1.printStackTrace();
                }
            }
        }

    });
}


public RedissonClient getRedissonClient() {
    return redissonClientSupplier.get();
}

public boolean isRedisUp() {
    RedissonClient redissonClient = getRedissonClient();
    if (redissonClient == null) {
        return false;
    }
    try {
        for (Node node : redissonClient.getNodesGroup().getNodes()) {
            if (node.ping()) {
                return true;
            }
        }
    } catch (Exception e) {
        log.warn("Exception caught when trying to ping the nodes: {}", e.getMessage());
    }
    return false;
}

private RedissonClient createRedissonClient(RedisConfig redisConfig) {
    Config config = new Config();
    config.setEventLoopGroup(nioEventLoopGroup);
    config.setReferenceEnabled(false);
    if (redisConfig.isSentinelEnabled()) {
        SentinelServersConfig sentinelServersConfig = config.useSentinelServers();
        sentinelServersConfig
                .setDatabase(redisConfig.getDatabase())
                .setPassword(redisConfig.getPassword())
                .setMasterName(redisConfig.getMasterName());
        redisConfig.getNodes().forEach(sentinelServersConfig::addSentinelAddress);
    } else {
        config.useSingleServer()
                .setAddress(redisConfig.getNodes().get(0));
    }
    return Redisson.create(config);
}

}`
Simulating the error:
1 - Turn Off the REDIS SERVER
2 - Execute the code (Spring Boot)
LOG: https://anonfile.com/a7Q6ubs8nb/log_demo_redis_txt
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2121
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am fairly new to Redisson and had a few questions I would like clarified. I read through the documentation, but the description of config settings weren't very helpful to me.


For every RedissonClient, a connection pool is created with a set min idle size and max size. How is each connection exactly used? Does each operation use a connection? Are ops batched into one request and sent through the connection?


When we set the threads parameter (setThreads), what are these threads used for? Connecting to redis? Deserializing?


When we set the nettyThreads parameter, what are these threads used for?


What is relationship between nettyThreads, threads, and connectionPool? What are important things to keep in mind while tuning these parameters?


Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2122
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2123
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The following is an excerpt from the documentation regarding pattern topics:
// subscribe to all topics by `topic1.*` pattern
RPatternTopic topic1 = redisson.getPatternTopic("topic1.*");
int listenerId = topic1.addListener(Message.class, new PatternMessageListener<Message>() {
    @Override
    public void onMessage(String pattern, String channel, Message msg) {
         Assert.fail();
    }
});

The pattern string looks like a regexp even though it is a glob string, which confounded us.
Please clarify the documentation, both in the code example - for instance by replacing "topic1.*" with something like "topic.x*" - and the documentation for RedissonClient.getPatternTopic()
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2124
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
My understanding is that the counter in AsyncSemaphore should decrement by 1 when a new connection is added to the pool however by calling releaseConnection(entry) in the runnable,  the counter is added by 1, which means after minimal idle size of connections are created, the counter will be the same as it was before the pool is initialized.
Please help me understand this, as I think more than max pool size of connections would be allowed to exist in the pool, since counter is not decremented after the pool's initialization.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2125
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
With ~800qps from 2 RedissonClients, we do not expect to see ~2qps of error rate with the following error: RedisTimeoutException: Unable to send batch after 3 retry attempts. Ideally, we should see no errors, or few errors as this isn't high load.
Actual behavior
We observe around 2qps errors (RedisTimeoutException: Unable to send batch after 3 retry attempts) that increase in a "step" up fashion. See image:

This graph is the traffic sent to redis in the same timespan:

As a side note: we are running 2 kubernetes pods, each with one RedissonClient that cumulatively are making requests/seeing the errors from the graphs above. The interesting thing to note is that for about 9hours after we start the pods (creating a new client in each) and send them traffic, they perform fine for around ~9hours and then the errors begin. We hypothesize that there is some issue in how the connections are managed.
Steps to reproduce or test case

Create 2 RedissonClient instances
Send between 400-850qps of traffic (variable) for around a day, where traffic includes batch ADD and PUT commands.
Observe failures.

Redis version
4.0.1
Redisson version
3.10.7
Redisson configuration
Cluster mode
Read mode: Master (we do not have slave nodes)
Master connection pool size: 64
Master connection pool minimum idle size: 0
Slave connection pool size: 0
Slave connection pool minimum idle size: 0
Subscription connection pool size: 0 (we do not use pubsub capabilities of redis)
Subscription connection pool minimum idle size: 0
Connect timeout: 500ms
Timeout: 500ms
Retry attempts: 3
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2126
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redisson-spring-data
RedissonReactiveSubscription
private final AtomicReference<Flux<Message<ByteBuffer, ByteBuffer>>> flux = new AtomicReference<>();
the document of AtomicReference  is Creates a new AtomicReference with null initial value.
@Override
public Flux<Message<ByteBuffer, ByteBuffer>> receive() {
    if (flux.get() == null) {
        return flux.get();
    }
}

this well always return null
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2127
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
首先赞一下作者的耐心，关于RedissonRedLock的实现我的疑问：RedissonRedLock据称是实现了http://ifeve.com/redis-lock/#respond 这篇文章提出的RedLock算法，按照这个算法的意图，加锁操作应该分散在不同的master节点以承受节点宕掉的风险。而RedissonRedLock使用自己提前实例化的RLock，通过联锁的方式实现 ，用户用字符串创建的RLock的key保存在哪个master具有随机性，多个RLock有较大概率保存在同一个master节点，这样有可能一个master节点宕掉就会导致key的丢失数量过半。因此这样设计是否没有达到RedLock算法的意图？
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2128
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
2-May-2019 06:36:26.528 SEVERE [localhost-startStop-1] org.apache.tomcat.util.digester.Digester.startElement Begin event threw exception
java.lang.ClassNotFoundException: org.redisson.tomcat.RedissonSessionManager
at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
at org.apache.tomcat.util.digester.ObjectCreateRule.begin(ObjectCreateRule.java:116)
at org.apache.tomcat.util.digester.Digester.startElement(Digester.java:1253)
at com.sun.org.apache.xerces.internal.parsers.AbstractSAXParser.startElement(AbstractSAXParser.java:509)
at com.sun.org.apache.xerces.internal.parsers.AbstractXMLDocumentParser.emptyElement(AbstractXMLDocumentParser.java:182)
at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanStartElement(XMLDocumentFragmentScannerImpl.java:1339)
at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2784)
at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:602)
at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:505)
at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:842)
at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:771)
at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)
at com.sun.org.apache.xerces.internal.parsers.AbstractSAXParser.parse(AbstractSAXParser.java:1213)
at com.sun.org.apache.xerces.internal.jaxp.SAXParserImpl$JAXPSAXParser.parse(SAXParserImpl.java:643)
at org.apache.tomcat.util.digester.Digester.parse(Digester.java:1521)
at org.apache.catalina.startup.ContextConfig.processContextConfig(ContextConfig.java:527)
at org.apache.catalina.startup.ContextConfig.contextConfig(ContextConfig.java:465)
at org.apache.catalina.startup.ContextConfig.init(ContextConfig.java:728)
at org.apache.catalina.startup.ContextConfig.lifecycleEvent(ContextConfig.java:310)
at org.apache.catalina.util.LifecycleBase.fireLifecycleEvent(LifecycleBase.java:94)
at org.apache.catalina.util.LifecycleBase.setStateInternal(LifecycleBase.java:395)
at org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:108)
at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:140)
at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:754)
at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:730)
at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:734)
at org.apache.catalina.startup.HostConfig.deployDirectory(HostConfig.java:1140)
at org.apache.catalina.startup.HostConfig$DeployDirectory.run(HostConfig.java:1875)
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:748)
22-May-2019 06:36:26.529 SEVERE [localhost-startStop-1] org.apache.catalina.startup.ContextConfig.processContextConfig Parse error in context.xml for []
org.xml.sax.SAXParseException; systemId: file:/usr/share/tomcat8/conf/context.xml; lineNumber: 28; columnNumber: 77; Error at (28, 77) : org.redisson.tomcat.RedissonSessionManager
at org.apache.tomcat.util.digester.Digester.createSAXException(Digester.java:1971)
at org.apache.tomcat.util.digester.Digester.createSAXException(Digester.java:2003)
at org.apache.tomcat.util.digester.Digester.startElement(Digester.java:1256)
at com.sun.org.apache.xerces.internal.parsers.AbstractSAXParser.startElement(AbstractSAXParser.java:509)
at com.sun.org.apache.xerces.internal.parsers.AbstractXMLDocumentParser.emptyElement(AbstractXMLDocumentParser.java:182)
at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanStartElement(XMLDocumentFragmentScannerImpl.java:1339)
at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2784)
at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:602)
at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:505)
at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:842)
at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:771)
at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)
at com.sun.org.apache.xerces.internal.parsers.AbstractSAXParser.parse(AbstractSAXParser.java:1213)
at com.sun.org.apache.xerces.internal.jaxp.SAXParserImpl$JAXPSAXParser.parse(SAXParserImpl.java:643)
at org.apache.tomcat.util.digester.Digester.parse(Digester.java:1521)
at org.apache.catalina.startup.ContextConfig.processContextConfig(ContextConfig.java:527)
at org.apache.catalina.startup.ContextConfig.contextConfig(ContextConfig.java:465)
at org.apache.catalina.startup.ContextConfig.init(ContextConfig.java:728)
at org.apache.catalina.startup.ContextConfig.lifecycleEvent(ContextConfig.java:310)
at org.apache.catalina.util.LifecycleBase.fireLifecycleEvent(LifecycleBase.java:94)
at org.apache.catalina.util.LifecycleBase.setStateInternal(LifecycleBase.java:395)
at org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:108)
at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:140)
at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:754)
at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:730)
at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:734)
at org.apache.catalina.startup.HostConfig.deployDirectory(HostConfig.java:1140)
at org.apache.catalina.startup.HostConfig$DeployDirectory.run(HostConfig.java:1875)
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassNotFoundException: org.redisson.tomcat.RedissonSessionManager
at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
at org.apache.tomcat.util.digester.ObjectCreateRule.begin(ObjectCreateRule.java:116)
at org.apache.tomcat.util.digester.Digester.startElement(Digester.java:1253)
... 30 more
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
Redisson version
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2129
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi friends,
sorry if my topic is duplicated. I've looked for my question but haven't found any answer yet.
my question :  is RMapCache's onCreate event fired as a multi thread function?
for example: if I have multiple clients that produce data endlessly, is it possible to get produced data concurrently with onCreate event? or it's fired consecutively?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2130
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have a Spring-boot app with Redisson and actuator.
All system components are up and running: my app, Redis cluster, etc.
The health-check API is being called at "/health" (backed by actuator).
Please note that running the "CLUSTER NODES" command on the cluster (either with one node or several nodes) completes successfully:
ec2e193e101e02518ac64c9ff1ad4f7bcfc20f03 172.31.150.67:7001 slave ee9fcd350dff2ec8ee3044638e5bd2ffd00497ed 0 1558604295100 1 connected
ee9fcd350dff2ec8ee3044638e5bd2ffd00497ed 172.31.150.67:7000 myself,master - 0 0 0 connected 0-16383
Expected behavior
"status": "UP" is expected
Actual behavior
"status": "DOWN" is received.
The following detailed message appears:
redis": {
"status": "DOWN",
"connectionFactory": {
"status": "DOWN",
"error": "org.springframework.data.redis.ClusterStateFailureException: Could not retrieve cluster information. CLUSTER NODES returned with error."
},
"redisConnectionFactory": {
"status": "UP",
"cluster_size": 1,
"slots_up": 16384,
"slots_fail": 0
}
}
Steps to reproduce or test case
Setup a redis cluster with one or more nodes.
Redis version
3.0.7
Redisson version
Happens on both 2.2.12 and 3.10.6
Redisson configuration
{
"clusterServersConfig":{
"idleConnectionTimeout":10000,
"connectTimeout":1000,
"timeout":1000,
"retryAttempts":3,
"retryInterval":1000,
"failedSlaveReconnectionInterval":3000,
"failedSlaveCheckInterval":60000,
"password":null,
"subscriptionsPerConnection":5,
"clientName":null,
"loadBalancer":{
"class":"org.redisson.connection.balancer.RoundRobinLoadBalancer"
},
"subscriptionConnectionMinimumIdleSize":1,
"subscriptionConnectionPoolSize":25,
"slaveConnectionMinimumIdleSize":5,
"slaveConnectionPoolSize":100,
"masterConnectionMinimumIdleSize":5,
"masterConnectionPoolSize":100,
"readMode":"SLAVE",
"subscriptionMode":"SLAVE",
"nodeAddresses":[
"//10.222.222.55:7000",
"//10.222.222.55:7001",
"//10.222.222.54:7000",
"//10.222.222.54:7001",
"//10.222.222.53:7000",
"//10.222.222.53:7001"
],
"scanInterval":1000,
"pingConnectionInterval":1,
"keepAlive": false,
"tcpNoDelay": false
},
"threads":16,
"nettyThreads":32,
"codec":{
"class":"org.redisson.codec.FstCodec"
},
"transportMode":"NIO"
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2131
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
分布式执行服务（Executor Service）是如何执行的？
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2132
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
All the timeout kv will disappear automaticlly.
Actual behavior
Some permanent kv still alive, and whose ttl are -1.
Steps to reproduce or test case
Using Tomcat Session Manager normally
Redis version
2.2
Redisson version
Newest version
Redisson configuration
{
"singleServerConfig": {
"password": "******",
"address": "redis://192.168.56.101:6379",
"database": 8,
"subscriptionsPerConnection": 3,
"subscriptionConnectionMinimumIdleSize": 3,
"subscriptionConnectionPoolSize": 3,
"connectionMinimumIdleSize": 3,
"connectionPoolSize": 3,
}
}
Details
First of all, after using Tomcat Session Manager for a long time, I found many kv in Redis and their ttl are all -1.

Then I cleared Redis and did a simple test, first I put config content to tomcat in context.xml, then open a page but not did login action. I found a ttl=-1 kv.

And second I did login with user name and password, I found another kv, but the ttl is session timeout second and was reducing automaticlly.

After a while (longer then timeout config value), it disappered. But another kv (ttl=-1) was still alive.

In my expected case, all the kv will disappered automaticlly. That is to say, after a long long time and if nobody do login action, the Redis server will be empty.
Do anybody has some advise for this issue?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2133
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Development environment ,it run ok ,i use it well。
development-right-log
[INFO] 29 16:11:13 [main] - Redisson 3.10.7
[INFO] 29 16:11:13 [main] - redis://127.0.0.1:6379 is the master
[WARN] 29 16:11:13 [main] - ReadMode = SLAVE, but slave nodes are not found! Please specify all nodes in replicated mode.
[INFO] 29 16:11:13 [redisson-netty-4-7] - 32 connections initialized for 127.0.0.1/127.0.0.1:6379
[INFO] 29 16:11:13 [redisson-netty-4-5] - 1 connections initialized for 127.0.0.1/127.0.0.1:6379
[INFO] 29 16:11:13 [redisson-netty-4-9] - 32 connections initialized for 127.0.0.1/127.0.0.1:6379
[INFO] 29 16:11:13 [redisson-netty-4-11] - 1 connections initialized for 127.0.0.1/127.0.0.1:6379
[INFO] 29 16:11:14 [main] - Redisson 3.10.7
[INFO] 29 16:11:14 [main] - redis://127.0.0.1:6379 is the master
[WARN] 29 16:11:14 [main] - ReadMode = SLAVE, but slave nodes are not found! Please specify all nodes in replicated mode.
[INFO] 29 16:11:14 [redisson-netty-6-18] - 1 connections initialized for 127.0.0.1/127.0.0.1:6379
[INFO] 29 16:11:14 [redisson-netty-6-6] - 32 connections initialized for 127.0.0.1/127.0.0.1:6379
[INFO] 29 16:11:14 [redisson-netty-6-10] - 32 connections initialized for 127.0.0.1/127.0.0.1:6379
[INFO] 29 16:11:14 [redisson-netty-6-11] - 1 connections initialized for 127.0.0.1/127.0.0.1:6379
development-redis-version
    Redis 2.8.2101 (00000000/0) 64 bit

development-redisson-version:

org.redisson
redisson
3.10.7

development-redisson-conf:
@bean
public RedissonClient redisson() throws IOException {
Config config = new Config();
config.useReplicatedServers()
.setScanInterval(2000) // 主节点变化扫描间隔时间
.addNodeAddress("redis://127.0.0.1:6379")
.setPassword("123456");
return Redisson.create(config);
}
Actual behavior
   in my Production Environment it didnt work ,and throw those Exception.

Production-error-log
Redisson 3.10.7
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'roomUtil': Unsatisfied dependency expressed through field 'redisson'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'redisson' defined in com.App: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.redisson.api.RedissonClient]: Factory method 'redisson' threw exception; nested exception is java.lang.NullPointerException: Name is null
at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:584)
at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90)
at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:370)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1336)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:572)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495)
at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317)
at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)
at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:759)
at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867)
at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:548)
at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:140)
at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:754)
at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:386)
at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
at com.App.main(App.java:53)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48)
at org.springframework.boot.loader.Launcher.launch(Launcher.java:87)
at org.springframework.boot.loader.Launcher.launch(Launcher.java:50)
at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:51)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'redisson' defined in com.App: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.redisson.api.RedissonClient]: Factory method 'redisson' threw exception; nested exception is java.lang.NullPointerException: Name is null
at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:591)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1246)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1096)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495)
at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317)
at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)
at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:251)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1135)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1062)
at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:581)
... 25 more
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.redisson.api.RedissonClient]: Factory method 'redisson' threw exception; nested exception is java.lang.NullPointerException: Name is null
at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185)
at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:583)
... 37 more
Caused by: java.lang.NullPointerException: Name is null
at java.lang.Enum.valueOf(Enum.java:236)
at org.redisson.connection.ReplicatedConnectionManager$Role.valueOf(ReplicatedConnectionManager.java:60)
at org.redisson.connection.ReplicatedConnectionManager.(ReplicatedConnectionManager.java:79)
at org.redisson.config.ConfigSupport.createConnectionManager(ConfigSupport.java:238)
at org.redisson.Redisson.(Redisson.java:119)
at org.redisson.Redisson.create(Redisson.java:159)
at com.App.redisson(App.java:146)
at com.App$$EnhancerBySpringCGLIB$$e3868ddc.CGLIB$redisson$3()
at com.App$$EnhancerBySpringCGLIB$$e3868ddc$$FastClassBySpringCGLIB$$1f9713c.invoke()
at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:365)
at com.App$$EnhancerBySpringCGLIB$$e3868ddc.redisson()
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154)
... 38 more
Production-redis-version
Redis 4.0 (Alibaba Cloud Cluster Edition)
Production-redisson-version:

org.redisson
redisson
3.10.7

Production-redisson-conf:
@bean
public RedissonClient redisson() throws IOException {
Config config = new Config();
config.useReplicatedServers()
.setScanInterval(2000) // 主节点变化扫描间隔时间
.addNodeAddress("redis://127.0.0.1:6379")
.setPassword("123456");
return Redisson.create(config);
}
Steps to reproduce or test case
public class App{
public static void main(String[] args) {
SpringApplication.run(App.Class，args)
}
}
Redis version
development-redis-version
Redis 2.8.2101 (00000000/0) 64 bit
Production-redis-version
Redis 4.0 (Alibaba Cloud Cluster Edition)
Redisson version
     <dependency>
        <groupId>org.redisson</groupId>
        <artifactId>redisson</artifactId>
        <version>3.10.7</version>
    </dependency>

Redisson configuration
@Bean
public RedissonClient redisson() throws IOException {
			Config config = new Config();
    config.useReplicatedServers()
            .setScanInterval(2000) // 主节点变化扫描间隔时间
            .addNodeAddress("redis://127.0.0.1:6379")
            .setPassword("123456");
			return Redisson.create(config);
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2134
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
哨兵模式下测试: 1主2从3哨兵。
当随机重启一台节点后，redisson出现了不停的警告:
2019-05-29 16:48:11.893  WARN 18938 --- [ueue-netty-1-24] o.r.c.SentinelConnectionManager          : Skipped slave up 192.168.1.91:6381 for master redis://192.168.1.91:6380 differs from current redis://192.168.1.91:6382
2019-05-29 16:48:11.907  WARN 18938 --- [ueue-netty-1-14] o.r.c.SentinelConnectionManager          : Skipped slave up 192.168.1.91:6381 for master redis://192.168.1.91:6380 differs from current redis://192.168.1.91:6382
2019-05-29 16:48:12.898  WARN 18938 --- [ueue-netty-1-22] o.r.c.SentinelConnectionManager          : Skipped slave up 192.168.1.91:6381 for master redis://192.168.1.91:6380 differs from current redis://192.168.1.91:6382
2019-05-29 16:48:12.908  WARN 18938 --- [ueue-netty-1-24] o.r.c.SentinelConnectionManager          : Skipped slave up 192.168.1.91:6381 for master redis://192.168.1.91:6380 differs from current redis://192.168.1.91:6382
2019-05-29 16:48:13.900  WARN 18938 --- [ueue-netty-1-22] o.r.c.SentinelConnectionManager          : Skipped slave up 192.168.1.91:6381 for master redis://192.168.1.91:6380 differs from current redis://192.168.1.91:6382
2019-05-29 16:48:13.915  WARN 18938 --- [queue-netty-1-2] o.r.c.SentinelConnectionManager          : Skipped slave up 192.168.1.91:6381 for master redis://192.168.1.91:6380 differs from current redis://192.168.1.91:6382

大概5分钟后恢复。
Redis version
5.0.4
Redisson version
3.10.6
Redisson configuration
{
"connectTimeout":10000,
"database":1,
"dnsMonitoringInterval":1000,
"failedSlaveCheckInterval":5000,
"failedSlaveReconnectionInterval":3000,
"idleConnectionTimeout":10000,
"keepAlive":true,
"loadBalancer":{},
"masterConnectionMinimumIdleSize":32,
"masterConnectionPoolSize":1024,
"masterName":"mymaster",
"pingConnectionInterval":1000,
"pingTimeout":1000,
"readMode":"SLAVE",
"retryAttempts":3,
"retryInterval":1500,
"scanInterval":1000,
"sentinelAddresses":[
"redis://192.168.1.91:26380",
"redis://192.168.1.91:26381",
"redis://192.168.1.91:26382"
],
"slaveConnectionMinimumIdleSize":32,
"slaveConnectionPoolSize":1024,
"slaveSubscriptionConnectionMinimumIdleSize":1,
"slaveSubscriptionConnectionPoolSize":50,
"sslEnableEndpointIdentification":true,
"sslProvider":"JDK",
"subscriptionConnectionMinimumIdleSize":1,
"subscriptionConnectionPoolSize":50,
"subscriptionMode":"MASTER",
"subscriptionsPerConnection":5,
"tcpNoDelay":false,
"timeout":10000
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2135
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
Redisson version
3.11.1-SNAPSHOT
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2136
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
No ClassNotFoundException to occur
Actual behavior
ClassNotFoundException occur during object deserialization
Steps to reproduce or test case
Redis version
Redisson version
3.11.1-SNAPSHOT
Redisson configuration
    <ResourceLink name="session/redisson"
                  global="session/redisson"
		          type="org.redisson.api.RedissonClient" />
				  
    <Manager className="org.redisson.tomcat.JndiRedissonSessionManager"
         readMode="REDIS"
		 updateMode="DEFAULT"
         jndiName="session/redisson" />
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2137
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for your contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2138
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2139
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
As I'm following through the code, the method setupMasterEntry is executed in a single-threaded context, so what is the idea of the RFuture? The caller of this method is essentially "blocked" on this method until it's done. Am I understanding this right? If the caller expects a Future to be returned immediately, all the heavy-lifting work has to be done by a different thread, which is the basic idea of the Future/Promise model.
Please correct me.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2140
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
JVM1:
lock = redissonClient.getRedLock(
                  redissonClient.getReadWriteLock("name").readLock(), 
                  some_other_lock_1)

Then call lock.tryLock() first, return true.
JVM2:
lock = redissonClient.getRedLock(
                  redissonClient.getReadWriteLock("name").writeLock(), 
                  some_other_lock_2)

Then call lock.tryLock() after the previous call has been made, now it should return false because there is a readLock under the same name.
Actual behavior
JVM1:
lock = redissonClient.getRedLock(
                  redissonClient.getReadWriteLock("name").readLock(), 
                  some_other_lock_1)

Then call lock.tryLock() first return true as expected.
JVM2:
lock = redissonClient.getRedLock(
                  redissonClient.getReadWriteLock("name").writeLock(), 
                  some_other_lock_2)

Then call lock.tryLock() after the previous one, now it return true i.e. have both write lock and read lock on the same ReadWriteLock.
Steps to reproduce or test case
As described above.
In case if this is useful information, if replace getRedLock with getMultiLock it actually works. Also if having only one JVM it also works.
Redis version
Redis server v=3.2.0 sha=00000000:0 malloc=jemalloc-4.0.3 bits=64 build=8d88dc6cfd069418
Redisson version
        <dependency>
            <groupId>org.redisson</groupId>
            <artifactId>redisson</artifactId>
            <version>3.11.0</version>
        </dependency>

java version "1.8.0_191"
Java(TM) SE Runtime Environment (build 1.8.0_191-b12)
Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode)

Redisson configuration
One redis standalone instance.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2141
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
startup
Actual behavior
get error
Caused by: java.lang.IllegalStateException: Default configuration hasn't been specified! at org.redisson.jcache.JCacheManager.createCache(JCacheManager.java:118) at org.springframework.boot.autoconfigure.cache.JCacheCacheConfiguration.jCacheCacheManager(JCacheCacheConfiguration.java:101) at org.springframework.boot.autoconfigure.cache.JCacheCacheConfiguration$$EnhancerBySpringCGLIB$$a6ce7558.CGLIB$jCacheCacheManager$1(<generated>) at org.springframework.boot.autoconfigure.cache.JCacheCacheConfiguration$$EnhancerBySpringCGLIB$$a6ce7558$$FastClassBySpringCGLIB$$3ebd8bcd.invoke(<generated>) at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228) at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358) at org.springframework.boot.autoconfigure.cache.JCacheCacheConfiguration$$EnhancerBySpringCGLIB$$a6ce7558.jCacheCacheManager(<generated>) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
Steps to reproduce or test case

use redisson with springboot
use spring.cache.chach-name=default in application.properties

Redis version
server :2.6.9
Redisson version
3.7.5
Redisson configuration
Config config = new Config(); config.setTransportMode(TransportMode.NIO); config.useSingleServer().setAddress("redis://"+this.redisProperties.getHost()+":"+this.redisProperties.getPort()); config.useSingleServer().setPassword(this.redisProperties.getPassword()); config.useSingleServer().setTimeout(this.redisProperties.getTimeout());
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2142
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
SUCCESS
Actual behavior
Redisson is shutdown
Steps to reproduce or test case
    @Autowired
    private RedissonDistributedLocker distributedLocker;

    @Test
    public void lockTest() {

        String lockKey = "test";

        for (int i = 0; i < 50; i++) {
            Thread t = new Thread(new Runnable() {
                @Override
                public void run() {
                    try {
                        System.err.println("=============线程开启============" + Thread.currentThread().getName());
                        distributedLocker.lock(lockKey, 10L); //直接加锁，获取不到锁则一直等待获取锁
                        Thread.sleep(100); //获得锁之后可以进行相应的处理
                        System.err.println("======获得锁后进行相应的操作======" + Thread.currentThread().getName());
                        distributedLocker.unlock(lockKey);  //解锁
                        System.err.println("=============================" + Thread.currentThread().getName());

                        //尝试获取锁，等待5秒，自己获得锁后一直不解锁则10秒后自动解锁
//                        boolean isGetLock = distributedLocker.tryLock(lockKey, TimeUnit.SECONDS, 1L, 10L);
//                        if (isGetLock) {
//                            Thread.sleep(5000); //获得锁之后可以进行相应的处理
//                            System.err.println("======获得锁后进行相应的操作======" + Thread.currentThread().getName());
//                            distributedLocker.unlock(lockKey);
//                            System.err.println("=============================" + Thread.currentThread().getName());
//                        }
                    } catch (Exception e) {
                        e.printStackTrace();
                    }
                }
            });
            t.start();
        }
    }


Redis version
5.0.4
Redisson version
3.10.7
Redisson configuration
# Redisson配置。支持单机，主从，哨兵，集群等模式
# 此为单机模式
singleServerConfig:
  idleConnectionTimeout: 10000
  connectTimeout: 10000
  timeout: 3000
  retryAttempts: 3
  retryInterval: 1500
  password: foo
  subscriptionsPerConnection: 5
  clientName: null
  address: "redis://192.168.3.53:6379"
  subscriptionConnectionMinimumIdleSize: 1
  subscriptionConnectionPoolSize: 50
  connectionMinimumIdleSize: 32
  connectionPoolSize: 64
  database: 0
  dnsMonitoringInterval: 5000
threads: 16
nettyThreads: 32
codec:
  class: "org.redisson.codec.JsonJacksonCodec"
transportMode: "NIO"
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2143
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
4.0.6
Redisson version
3.11.0
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2144
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RedissonReadLock.class#tryLockInnerAsync
redis.call('pexpire', KEYS[1], ARGV[1]); 

If thread1 set expire 5000ms ,and then thread2 set expire 1000ms, then thread2 shutdown.
In this case,thread1 will lose its lock.
I think we can change code like this
local remainTime = redis.call('pttl', KEYS[1])
redis.call('pexpire', KEYS[1], math.max(remainTime,ARGV[1])); 

And the rwlock_timeout key will be not required.
Am I right? Where is the problem?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2145
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We have a testing redis cluster environment with only 1 master and 1 slave. When using redisson client with RedissonBinaryStream to write byte array to redis server, we encountered the exception logged below.
Expected behavior
Successfully write and read from Redis Cluster using RedissonBinaryStream implementation
Actual behavior
Seeing exception:
Exception in thread "main" org.redisson.client.RedisException: CROSSSLOT Keys in request don't hash to the same slot. channel: [id: 0x6264422d, L:/<hide ip>:61627 - R:/<hide ip>:6379] command: CommandData [promise=org.redisson.misc.RedissonPromise@5ebfe264[Not completed], command=(EVAL), params=[local parts = redis.call('get', KEYS[2]); local lastPartName = KEYS[1];if parts ~= false then lastPa..., 2, stream-test, stream-test:parts], codec=org.redisson.client.codec.ByteArrayCodec@16e94982]
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:267)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:127)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:628)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:563)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)

Steps to reproduce or test case
Redis version
3.2.8
Redisson version
3.4.1
Redisson configuration
 String redisClusterEntryEndpoint = bcConfig.getEndpoint();
        Config config = new Config();
        config.useClusterServers().addNodeAddress(redisClusterEntryEndpoint);
        return Redisson.create(config);

OutputStream os = redissonClient.getBinaryStream(key).getOutputStream();
os.write(bytes);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2146
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redisson fails to connect to slave node.
Expected behavior
successful connection.
Actual behavior

Can't add slave: rediss://[ip]:[port]",mhash="6ff2ffa1",exc="org.redisson.client.RedisConnectionException: Unable to connect to Redis server: [ip1]/[ip2]:[port]
at org.redisson.connection.pool.ConnectionPool$1.lambda$run$0(ConnectionPool.java:160)
at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:183)
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511)
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:485)
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424)
at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:121)
at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:96)
at org.redisson.connection.pool.ConnectionPool.promiseFailure(ConnectionPool.java:330)
at org.redisson.connection.pool.ConnectionPool.lambda$createConnection$1(ConnectionPool.java:296)
at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:183)
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511)
at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:504)
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:483)
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424)
at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:121)
at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:96)
at org.redisson.client.RedisClient$2$2.run(RedisClient.java:245)
at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:462)
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException: null
at io.netty.channel.nio.AbstractNioChannel.doClose()(Unknown Source)

Steps to reproduce or test case
Redis version
3.2.7
Redisson version
3.10.7
Redisson configuration

{
"clusterServersConfig" : {
"idleConnectionTimeout" : 10000,
"pingTimeout" : 1000,
"connectTimeout" : 10000,
"timeout" : 3000,
"retryAttempts" : 3,
"retryInterval" : 3500,
"password" : "1",
"subscriptionsPerConnection" : 15,
"sslEnableEndpointIdentification" : true,
"sslProvider" : "JDK",
"pingConnectionInterval" : 0,
"keepAlive" : false,
"tcpNoDelay" : false,
"loadBalancer" : {
"class" : "org.redisson.connection.balancer.RoundRobinLoadBalancer"
},
"slaveConnectionMinimumIdleSize" : 10,
"slaveConnectionPoolSize" : 35,
"failedSlaveReconnectionInterval" : 3000,
"failedSlaveCheckInterval" : 60000,
"masterConnectionMinimumIdleSize" : 10,
"masterConnectionPoolSize" : 35,
"readMode" : "MASTER",
"subscriptionMode" : "MASTER",
"subscriptionConnectionMinimumIdleSize" : 1,
"subscriptionConnectionPoolSize" : 30,
"dnsMonitoringInterval" : 5000,
"natMap" : { },
"nodeAddresses" : [ "rediss://[ip]:[port]" ],
"scanInterval" : 10000,
"slaveSubscriptionConnectionPoolSize" : 30,
"slaveSubscriptionConnectionMinimumIdleSize" : 1
},
"threads" : 0,
"nettyThreads" : 0,
"codec" : {
"class" : "org.redisson.codec.JsonJacksonCodec"
},
"referenceEnabled" : true,
"transportMode" : "NIO",
"lockWatchdogTimeout" : 30000,
"keepPubSubOrder" : true,
"decodeInExecutor" : false,
"useScriptCache" : false,
"minCleanUpDelay" : 5,
"maxCleanUpDelay" : 1800,
"addressResolverGroupFactory" : {
"class" : "org.redisson.connection.RoundRobinDnsAddressResolverGroupFactory"
}
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2147
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Spring bean created successfully
Actual behavior
Caused by: java.lang.NullPointerException: null
    at org.redisson.liveobject.core.RedissonObjectBuilder.fillCodecMethods(RedissonObjectBuilder.java:192)
    at org.redisson.liveobject.core.RedissonObjectBuilder.<init>(RedissonObjectBuilder.java:108)
    at org.redisson.command.CommandAsyncService.enableRedissonReferenceSupport(CommandAsyncService.java:155)
    at org.redisson.command.CommandAsyncService.enableRedissonReferenceSupport(CommandAsyncService.java:124)
    at org.redisson.Redisson.enableRedissonReferenceSupport(Redisson.java:701)
    at org.redisson.Redisson.create(Redisson.java:166)
    at com.canva.embed.server.RpcLauncherConfiguration.embedRedisClient(RpcLauncherConfiguration.java:192)
    at com.canva.embed.server.RpcLauncherConfiguration$$EnhancerBySpringCGLIB$$7265447b.CGLIB$embedRedisClient$5(<generated>)
    at com.canva.embed.server.RpcLauncherConfiguration$$EnhancerBySpringCGLIB$$7265447b$$FastClassBySpringCGLIB$$851420f7.invoke(<generated>)
    at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:244)
    at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:363)
    at com.canva.embed.server.RpcLauncherConfiguration$$EnhancerBySpringCGLIB$$7265447b.embedRedisClient(<generated>)
    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.base/java.lang.reflect.Method.invoke(Method.java:564)
    at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154)

Steps to reproduce or test case
We have several spring beans that initialise in prallel
Redis version
?
Redisson version
3.10.1
Redisson configuration
@Bean
  RedissonClient embedRedisClient( //
      @Value("${embed.cache.nodes}") String nodes, //
      @Value("${embed.cache.connections}") int connections, //
      @Value("${embed.cache.command.retry.attempts}") int retryAttempts, //
      @Value("${embed.cache.command.retry.interval.ms}") int retryInterval, //
      @Value("${embed.cache.command.server.timeout.ms}") int timeout
  ) {
    String[] splitNodes = nodes.split("\\s*,\\s*");
    Preconditions.checkArgument(splitNodes.length > 0);

    int maxConnections = connections * 2;

    Config config = new Config();
    if (splitNodes.length == 1) {
      config.useSingleServer()
          .setAddress(splitNodes[0])
          .setConnectionPoolSize(connections)
          .setRetryAttempts(retryAttempts)
          .setRetryInterval(retryInterval)
          .setTimeout(timeout);
    } else {
      config.useReplicatedServers() //
          .addNodeAddress(splitNodes)
          .setMasterConnectionMinimumIdleSize(connections)
          .setMasterConnectionPoolSize(maxConnections)
          .setSlaveConnectionMinimumIdleSize(connections)
          .setSlaveConnectionPoolSize(maxConnections)
          .setRetryAttempts(retryAttempts)
          .setRetryInterval(retryInterval)
          .setTimeout(timeout);
    }
    return Redisson.create(config);
  }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2148
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
在执行大量的 异步操作时,速度很慢,而且大量报错。nettyThreads和'connection pool'也不能无限增加吧.  而且报错都集中在线程 eventloop-thread-1
org.redisson.client.RedisTimeoutException: Unable to get connection! Try to increase 'nettyThreads' and 'connection pool' settings or set decodeInExecutor = true and increase 'threads' settingNode source: NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=value:50:queue:0, freeConnectionsAmount=32, freeConnectionsCounter=value:32:queue:1, freezed=false, freezeReason=null, client=[addr=redis://127.0.0.1:6379], nodeType=MASTER, firstFail=0]]], command: (HGET), params: [test-map, PooledUnsafeDirectByteBuf(ridx: 0, widx: 6, cap: 256)] after 3 retry attempts
	at org.redisson.command.CommandAsyncService$6.run(CommandAsyncService.java:703)
	at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:682)
	at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:757)
	at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:485)
	at java.lang.Thread.run(Thread.java:748)

Steps to reproduce or test case
    public static RedissonClient newRedissonClient() {
        Config config = new Config();
        config.useSingleServer()
                .setAddress(System.getProperty("redis.host", "redis://127.0.0.1:6379"))
                .setDatabase(0)
                .setTimeout(10000)
                .setConnectionPoolSize(1024)
                .setConnectTimeout(10000);
        config.setThreads(32);
        config.setNettyThreads(32);

        return Redisson.create(config);
    }


    @SneakyThrows
    public static void main(String[] args) {
        RedissonClient client = newRedissonClient();

        RMap<String, Object> map = client.getMap("test-map");
        map.put("key1", "value1");
        map.put("key2", "value2");
        map.put("key3", "value3");
        CountDownLatch latch = new CountDownLatch(100000);
        for (int i = 0; i < 100000; i++) {
            int fi = i;
            map.getAsync("key1")
                    .whenComplete((val, err) -> {
                        System.out.println(val + " => " + fi+" =>"+Thread.currentThread().getName());

                        if(null!=err){
                            err.printStackTrace();
                        }
                        latch.countDown();

                    });
        }
        latch.await();
        client.shutdown();
    }
Redis version
5.0.4
Redisson version
3.10.6
Redisson configuration
 Config config = new Config();
        config.useSingleServer()
                .setAddress(System.getProperty("redis.host", "redis://127.0.0.1:6379"))
                .setDatabase(0)
                .setTimeout(10000)
                .setConnectionPoolSize(1024)
                .setConnectTimeout(10000);
        config.setThreads(32);
        config.setNettyThreads(32);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2149
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
here is my code:
     public @interface RateLimiter {
               int limit() default 5;//放行数量,5个
              int timeout() default 1;//限流时间间隔，默认1秒
              String rateKey() default "";//限流器，自定义key
            String timeUnit() default "SECONDS";//限流器，默认限流时间单位
     }        

==========================================================
@ApiOperation(value = "测试格式化显示", notes = "测试格式化显示", httpMethod = "GET")
@RequestMapping(value = "/formatCode", method = RequestMethod.GET)
@ratelimiter(limit = 1,timeUnit=“SECONDS”,timeout =5,rateKey="formatCode")
public String formatCode(HttpServletRequest req) {
System.err.println("formatJson");
return "format_code";
}
public static boolean tryAcquire(RedissonClient redisClient,
String rateKey,long permits,long
timeout,String timeUnit) {
RRateLimiter rateLimiter = redisClient.getRateLimiter(rateKey);
//初始化,最大流速 = 每1秒钟产生10个令牌
rateLimiter.trySetRate(RateType.OVERALL, permits, timeout,
RateIntervalUnit.SECONDS);//1秒permits个token
return rateLimiter.tryAcquire(1,0, TimeUnit.SECONDS);//间隔一秒，尝试一次
}
public class RateLimiterInterceptor extends HandlerInterceptorAdapter {
private Logger logger = LoggerFactory.getLogger(RateLimiterInterceptor.class);

@Autowired
    private RedissonClient redisClient;

@Override
public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler)  {
		if(handler instanceof HandlerMethod){
			 HandlerMethod handlerMethod = (HandlerMethod) handler;
	         Method method = handlerMethod.getMethod();
	         RateLimiter rateLimiter = method.getAnnotation(RateLimiter.class);
	         if (rateLimiter != null) {
	             int limit = ObjectUtils.isEmpty(rateLimiter.limit())?RedisRateLimiter.REDISSON_RATE_LIMITER_PERMITS:rateLimiter.limit();
	             long timeout = ObjectUtils.isEmpty(rateLimiter.timeout())?RedisRateLimiter.REDISSON_RATE_LIMITER_TIMEOUT:rateLimiter.timeout();
	             String rateKey=StringUtils.isEmpty(rateLimiter.rateKey())?request.getRequestURI():rateLimiter.rateKey();//key为空判断
	             rateKey=RedisRateLimiter.REDISSON_RATE_LIMITER_KEY+rateKey;
	             String timeUnit=ObjectUtils.isEmpty(rateLimiter.timeUnit())?RedisRateLimiter.REDISSON_RATE_LIMITER_TIMEUNIT:rateLimiter.timeUnit();
	             Boolean isAllow=RedisRateLimiter.tryAcquire(redisClient, rateKey, limit, timeout, timeUnit);
	             if(!isAllow){
	            	 logger.warn("很抱歉，服务器繁忙，请稍后重试!");
	            	 throw new RRException("服务器繁忙，请稍后重试!", HttpStatus.SERVICE_UNAVAILABLE.value());
	             }
	         }
		}
		return true;
	}

}
when frequent calls  formatCode,this config rateLimiter.tryAcquire(1,0, TimeUnit.SECONDS);
does not work normly above the version 3.7.2,here is the doc
current version:3.7.2
/**
* Acquires the given number of permits only if all are available
* within the given waiting time.
*
* Acquires the given number of permits, if all are available and returns immediately,
* with the value {@code true}, reducing the number of available permits by one.
*
* If no permit is available then the current thread becomes
* disabled for thread scheduling purposes and lies dormant until
* the specified waiting time elapses.
*
* If a permits is acquired then the value {@code true} is returned.
*
* If the specified waiting time elapses then the value {@code false}
* is returned.  If the time is less than or equal to zero, the method
* will not wait at all.
*
* @param permits amount
* @param timeout the maximum time to wait for a permit
* @param unit the time unit of the {@code timeout} argument
* @return {@code true} if a permit was acquired and {@code false}
*         if the waiting time elapsed before a permit was acquired
*/
boolean tryAcquire(long permits, long timeout, TimeUnit unit);
All code can see  (https://gitee.com/bootstrap2table/boot_master/tree/feature/boot-simple),
need help to fixed this bug,thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2150
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redisson version 3.10.7
Linked with https://bugs.java.com/bugdatabase/view_bug.do?bug_id=6587184
Problem is in RedisClient.java,  line 172:
        byte[] addr = NetUtil.createByteArrayFromIpAddressString(uri.getHost());
uri.getHost() is returning null, so validation of address inside netty is throwing NPE when it tries to get length of the string that is null.
I'm providing the stack trace:
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.redisson.api.RedissonClient]: Factory method 'redissonClient' threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:622)
	... 42 more
Caused by: java.lang.NullPointerException
	at io.netty.util.NetUtil.isValidIpV4Address(NetUtil.java:648)
	at io.netty.util.NetUtil.createByteArrayFromIpAddressString(NetUtil.java:368)
	at org.redisson.client.RedisClient.resolveAddr(RedisClient.java:172)
	at org.redisson.connection.MasterSlaveEntry.setupMasterEntry(MasterSlaveEntry.java:123)
	at org.redisson.connection.MasterSlaveEntry.setupMasterEntry(MasterSlaveEntry.java:118)
	at org.redisson.connection.MasterSlaveConnectionManager.initSingleEntry(MasterSlaveConnectionManager.java:345)
	at org.redisson.connection.MasterSlaveConnectionManager.<init>(MasterSlaveConnectionManager.java:163)
	at org.redisson.connection.SingleConnectionManager.<init>(SingleConnectionManager.java:34)
	at org.redisson.config.ConfigSupport.createConnectionManager(ConfigSupport.java:229)
	at org.redisson.Redisson.<init>(Redisson.java:119)
	at org.redisson.Redisson.create(Redisson.java:159)
	at net.icpweb.messaging.broker.configuration.MessagingAutoConfiguration.redissonClient(MessagingAutoConfiguration.java:114)
	at net.icpweb.messaging.broker.configuration.MessagingAutoConfiguration$$EnhancerBySpringCGLIB$$30111eb4.CGLIB$redissonClient$1(<generated>)
	at net.icpweb.messaging.broker.configuration.MessagingAutoConfiguration$$EnhancerBySpringCGLIB$$30111eb4$$FastClassBySpringCGLIB$$ba41b375.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:244)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:363)
	at net.icpweb.messaging.broker.configuration.MessagingAutoConfiguration$$EnhancerBySpringCGLIB$$30111eb4.redissonClient(<generated>)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154)
	... 43 more


Configuration is YAML based:
singleServerConfig:
  idleConnectionTimeout: 10000
  pingTimeout: 1000
  connectTimeout: 10000
  timeout: 3000
  retryAttempts: 3
  retryInterval: 1500
  subscriptionsPerConnection: 5
  sslEnableEndpointIdentification: true
  sslProvider: "JDK"
  pingConnectionInterval: 0
  keepAlive: false
  tcpNoDelay: false
  address: "redis_test:3809"
  subscriptionConnectionMinimumIdleSize: 1
  subscriptionConnectionPoolSize: 50
  connectionMinimumIdleSize: 32
  connectionPoolSize: 64
  database: 0
  dnsMonitoringInterval: 5000
threads: 16
nettyThreads: 32
referenceEnabled: true
transportMode: "NIO"
lockWatchdogTimeout: 30000
keepPubSubOrder: true
decodeInExecutor: false
useScriptCache: false
minCleanUpDelay: 5
maxCleanUpDelay: 1800
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2151
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
it seems RRemoteService.getFreeWorkers api code issue?
from the document RRemoteService.getFreeWorkers, I get the follow description
int getFreeWorkers(Class<?> remoteInterface)
Returns free workers amount available for tasks
code:
      RedissonClient client = Redisson.create(config);
      RRemoteService rpc = client.getRemoteService();
      System.out.println(rpc.getFreeWorkers())
      System.out.println(rpc.getFreeWorkers())

print:
100
0

Then I find the source code
RedissonRemoteService.java
Expected behavior
    @Override
    public int getFreeWorkers(Class<?> remoteInterface) {
        Entry entry = remoteMap.get(remoteInterface);
        if (entry == null) {
            return 0;
        }
        return entry.getCounter().get();
    }
Actual behavior
    @Override
    public int getFreeWorkers(Class<?> remoteInterface) {
        Entry entry = remoteMap.remove(remoteInterface);
        if (entry == null) {
            return 0;
        }
        return entry.getCounter().get();
    }
are you kidding me？
why remove? it should be get
Entry entry = remoteMap.remove(remoteInterface);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2152
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2153
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
What I want to do is depending on PRINCIPAL_NAME_INDEX_NAME in redis to control the Spring Security's maximum session management through SpringSessionBackedSessionRegistry class.
The first look at RedissonSessionRepository.save() confused me that it is an empty method which says "session changes are stored in real-time". In comparison, the standard RedisOperationsSessionRepository.save() of spring-session-data-redis has codes to create PRINCIPAL_NAME_INDEX_NAME. In fact, these codes are in RedisOperationsSessionRepository$RedisSession.saveDelta().
Expected behavior
The PRINCIPAL_NAME_INDEX_NAME key is created with Spring Security's principal information
Actual behavior
The PRINCIPAL_NAME_INDEX_NAME key is not created
Steps to reproduce or test case
Using Spring Boot 2.1.3/Spring Security 5.1.4/Spring Session 2.1.4, during which the Spring Session java configuration is:
@EnableRedissonHttpSession(keyPrefix = "xxx:")
public class SessionConfig {
    @Bean
    public static ConfigureRedisAction configureRedisAction() {
        return ConfigureRedisAction.NO_OP;
    }
}
Redis version
5.0.0 on AWS Elasticache
Redisson version
3.11.0
Redisson configuration
clusterServersConfig:
   retryAttempts: 6
   retryInterval: 20000
   readMode: "MASTER_SLAVE"
   nodeAddresses:
   - "redis://xxx.xxxxxx.clustercfg.apne1.cache.amazonaws.com:6379"
   scanInterval: 5000
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2154
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
09-Jun-2019 14:13:21.573 WARNING [main] org.apache.catalina.startup.Catalina.load Permissions incorrect, read permission is not allowed on the file.
09-Jun-2019 14:13:21.573 SEVERE [main] org.apache.catalina.startup.Catalina.start Cannot start server. Server instance is not configured.
OpenJDK 64-Bit Server VM warning: ignoring option MaxPermSize=64m; support was removed in 8.0
09-Jun-2019 14:14:06.084 WARNING [main] org.apache.catalina.startup.Catalina.load Unable to load server configuration from [/usr/share/tomcat8/conf/server.xml]
After deploying the following error encounters Please help us to resolve.
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
Redisson version
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2155
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Please retain changes related to bug fix only. Use master branch and not 3.0.0
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2156
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2157
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
I'm getting a timeout when I try to read some keys from an RMapCache.  This also seems to trigger a catastrophic out of memory error in the application
Setup:
	RMapCache<String, ChartSettings> chartSettingsMap
		=client.getMapCache("chart_settings_v493" kryoCodec);
	System.out.println(chartSettingsMap.get("203658_71497") != null);

This should generally print true/false, and it works most of the time.   But about 1 key out of 500 or so, this throws a timeout error.
Actual behavior
In debug mode, I'm getting the following information, with a hard error.  If I do this on production, with this key, the server will fail within about 30 minutes.
[DEBUG] 2019-06-10 11:21:13.988 [pool-2-thread-1] CommandAsyncService - connection released for command (EVAL) and params [local value = redis.call('hget', KEYS[1], ARGV[2]); if value == false then return nil; end; local t,..., 5, chart_settings_v493, redisson__timeout__set:{chart_settings_v493}, redisson__idle__set:{chart_settings_v493}, redisson__map_cache__last_access__set:{chart_settings_v493}, {chart_settings_v493}:redisson_options, 1560190864239, PooledUnsafeDirectByteBuf(ridx: 0, widx: 13, cap: 256)] from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=9, freeSubscribeConnectionsCounter=value:499:queue:0, freeConnectionsAmount=32, freeConnectionsCounter=value:640:queue:0, freezed=false, freezeReason=null, client=[addr=redis://redisURL:6379], nodeType=MASTER, firstFail=0]]] using connection RedisConnection@317440608 [redisClient=[addr=redis://redisURL:6379], channel=[id: 0x5f92a270, L:/redisURL:51719 - R:redisURL/redisURL:6379], command=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@16f27bad(failure: java.util.concurrent.CancellationException)], command=(EVAL), params=[local value = redis.call('hget', KEYS[1], ARGV[2]); if value == false then return nil; end; local t,..., 5, chart_settings_v493, redisson__timeout__set:{chart_settings_v493}, redisson__idle__set:{chart_settings_v493}, redisson__map_cache__last_access__set:{chart_settings_v493}, {chart_settings_v493}:redisson_options, 1560190864239, PooledUnsafeDirectByteBuf(ridx: 0, widx: 13, cap: 256)], codec=org.redisson.codec.KryoCodec]]
[DEBUG] 2019-06-10 11:21:13.988 [pool-2-thread-1] CommandAsyncService - attempt 3 for command (EVAL) and params [local value = redis.call('hget', KEYS[1], ARGV[2]); if value == false then return nil; end; local t,..., 5, chart_settings_v493, redisson__timeout__set:{chart_settings_v493}, redisson__idle__set:{chart_settings_v493}, redisson__map_cache__last_access__set:{chart_settings_v493}, {chart_settings_v493}:redisson_options, 1560190864239, PooledUnsafeDirectByteBuf(ridx: 0, widx: 13, cap: 256)]
[DEBUG] 2019-06-10 11:21:13.989 [pool-2-thread-1] CommandAsyncService - acquired connection for command (EVAL) and params [local value = redis.call('hget', KEYS[1], ARGV[2]); if value == false then return nil; end; local t,..., 5, chart_settings_v493, redisson__timeout__set:{chart_settings_v493}, redisson__idle__set:{chart_settings_v493}, redisson__map_cache__last_access__set:{chart_settings_v493}, {chart_settings_v493}:redisson_options, 1560190864239, PooledUnsafeDirectByteBuf(ridx: 0, widx: 13, cap: 256)] from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=9, freeSubscribeConnectionsCounter=value:499:queue:0, freeConnectionsAmount=31, freeConnectionsCounter=value:639:queue:0, freezed=false, freezeReason=null, client=[addr=redis://redisURL:6379], nodeType=MASTER, firstFail=0]]] using node redisURL/redisURL:6379... RedisConnection@937932367 [redisClient=[addr=redis://redisURL:6379], channel=[id: 0xeddb5e30, L:/redisURL:51687 - R:redisURL/redisURL:6379], command=null]
[DEBUG] 2019-06-10 11:21:14.331 [redisson-netty-2-28] ClusterConnectionManager - slot 13278 for chart_settings_v493
[DEBUG] 2019-06-10 11:21:14.331 [redisson-netty-2-28] CommandAsyncService - acquired connection for command (EVAL) and params [if redis.call('setnx', KEYS[6], ARGV[4]) == 0 then return -1;end;redis.call('expire', KEYS[6], ARGV[..., 6, chart_settings_v493, redisson__timeout__set:{chart_settings_v493}, redisson__idle__set:{chart_settings_v493}, redisson_map_cache_expired:{chart_settings_v493}, redisson__map_cache__last_access__set:{chart_settings_v493}, redisson__execute_task_once_latch:{chart_settings_v493}, 1560190874331, 100, ...] from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=9, freeSubscribeConnectionsCounter=value:499:queue:0, freeConnectionsAmount=30, freeConnectionsCounter=value:638:queue:0, freezed=false, freezeReason=null, client=[addr=redis://redisURL:6379], nodeType=MASTER, firstFail=0]]] using node redisURL/redisURL:6379... RedisConnection@1194676392 [redisClient=[addr=redis://redisURL:6379], channel=[id: 0xf5e2e193, L:/redisURL:51695 - R:redisURL/redisURL:6379], command=null]
[DEBUG] 2019-06-10 11:21:14.436 [redisson-netty-2-9] CommandAsyncService - connection released for command (EVAL) and params [if redis.call('setnx', KEYS[6], ARGV[4]) == 0 then return -1;end;redis.call('expire', KEYS[6], ARGV[..., 6, chart_settings_v493, redisson__timeout__set:{chart_settings_v493}, redisson__idle__set:{chart_settings_v493}, redisson_map_cache_expired:{chart_settings_v493}, redisson__map_cache__last_access__set:{chart_settings_v493}, redisson__execute_task_once_latch:{chart_settings_v493}, 1560190874331, 100, ...] from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=9, freeSubscribeConnectionsCounter=value:499:queue:0, freeConnectionsAmount=31, freeConnectionsCounter=value:639:queue:0, freezed=false, freezeReason=null, client=[addr=redis://redisURL:6379], nodeType=MASTER, firstFail=0]]] using connection RedisConnection@1194676392 [redisClient=[addr=redis://redisURL:6379], channel=[id: 0xf5e2e193, L:/redisURL:51695 - R:redisURL/redisURL:6379], command=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@4deb5c36(success: 0)], command=(EVAL), params=[if redis.call('setnx', KEYS[6], ARGV[4]) == 0 then return -1;end;redis.call('expire', KEYS[6], ARGV[..., 6, chart_settings_v493, redisson__timeout__set:{chart_settings_v493}, redisson__idle__set:{chart_settings_v493}, redisson_map_cache_expired:{chart_settings_v493}, redisson__map_cache__last_access__set:{chart_settings_v493}, redisson__execute_task_once_latch:{chart_settings_v493}, 1560190874331, 100, ...], codec=org.redisson.client.codec.LongCodec]]
[DEBUG] 2019-06-10 11:21:14.436 [redisson-netty-2-9] MapCacheEvictionTask - 0 elements evicted. Object name: chart_settings_v493
[DEBUG] 2019-06-10 11:21:15.921 [redisson-netty-2-30] DnsQueryContext - [id: 0x5d625e3a] WRITE: [9457: /redisURL:53], DefaultDnsQuestion(redisDNSEntry. IN A)
[DEBUG] 2019-06-10 11:21:15.922 [redisson-netty-2-30] DnsQueryContext - [id: 0x5d625e3a] WRITE: [53085: /redisURL:53], DefaultDnsQuestion(redisDNSEntry. IN AAAA)
[DEBUG] 2019-06-10 11:21:15.926 [redisson-netty-2-30] DnsNameResolver - [id: 0x5d625e3a] RECEIVED: [53085: /redisURL:53], DatagramDnsResponse(from: /redisURL:53, to: /0:0:0:0:0:0:0:0:60483, 53085, QUERY(0), NoError(0), RD RA)
DefaultDnsQuestion(redisDNSEntry. IN AAAA)
DefaultDnsRawRecord(use1.cache.amazonaws.com. 274 IN SOA 69B)
DefaultDnsRawRecord(OPT flags:0 udp:4000 0B)
[DEBUG] 2019-06-10 11:21:15.946 [redisson-netty-2-30] DnsNameResolver - [id: 0x5d625e3a] RECEIVED: [9457: /redisURL:53], DatagramDnsResponse(from: /redisURL:53, to: /0:0:0:0:0:0:0:0:60483, 9457, QUERY(0), NoError(0), RD RA)
DefaultDnsQuestion(redisDNSEntry. IN A)
DefaultDnsRawRecord(redisDNSEntry. 15 IN A 4B)
DefaultDnsRawRecord(redisDNSEntry. 15 IN A 4B)
DefaultDnsRawRecord(redisDNSEntry. 15 IN A 4B)
DefaultDnsRawRecord(OPT flags:0 udp:4000 0B)
[DEBUG] 2019-06-10 11:21:16.016 [redisson-netty-2-5] ClusterConnectionManager - cluster nodes state got from redisURL/redisURL:6379:
30502c66324cedca9bfab2be72c50d6adc77abc3 10.99.41.203:6379@1122 slave 29500303a7c5f9d4dbfe6fff2f007df6fd050285 0 1560190875000 1 connected
e4dad2ac204e4bc5e9ca85827ae50d5b340f11c4 redisURL:6379@1122 slave 29500303a7c5f9d4dbfe6fff2f007df6fd050285 0 1560190875505 1 connected
29500303a7c5f9d4dbfe6fff2f007df6fd050285 redisURL:6379@1122 myself,master - 0 1560190873000 1 connected 0-16383
[DEBUG] 2019-06-10 11:21:17.088 [pool-2-thread-1] CommandAsyncService - connection released for command (EVAL) and params [local value = redis.call('hget', KEYS[1], ARGV[2]); if value == false then return nil; end; local t,..., 5, chart_settings_v493, redisson__timeout__set:{chart_settings_v493}, redisson__idle__set:{chart_settings_v493}, redisson__map_cache__last_access__set:{chart_settings_v493}, {chart_settings_v493}:redisson_options, 1560190864239, PooledUnsafeDirectByteBuf(ridx: 0, widx: 13, cap: 256)] from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=9, freeSubscribeConnectionsCounter=value:499:queue:0, freeConnectionsAmount=32, freeConnectionsCounter=value:640:queue:0, freezed=false, freezeReason=null, client=[addr=redis://redisURL:6379], nodeType=MASTER, firstFail=0]]] using connection RedisConnection@937932367 [redisClient=[addr=redis://redisURL:6379], channel=[id: 0xeddb5e30, L:/redisURL:51687 - R:redisURL/redisURL:6379], command=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@6e811051(failure: org.redisson.client.RedisResponseTimeoutException: Redis server response timeout (3000 ms) occured after 3 retry attempts. Command: (EVAL), params: [local value = redis.call('hget', KEYS[1], ARGV[2]); if value == false then return nil; end; local t,..., 5, chart_settings_v493, redisson__timeout__set:{chart_settings_v493}, redisson__idle__set:{chart_settings_v493}, redisson__map_cache__last_access__set:{chart_settings_v493}, {chart_settings_v493}:redisson_options, 1560190864239, PooledUnsafeDirectByteBuf(ridx: 0, widx: 13, cap: 256)], channel: [id: 0xeddb5e30, L:/redisURL:51687 - R:redisURL/redisURL:6379])], command=(EVAL), params=[local value = redis.call('hget', KEYS[1], ARGV[2]); if value == false then return nil; end; local t,..., 5, chart_settings_v493, redisson__timeout__set:{chart_settings_v493}, redisson__idle__set:{chart_settings_v493}, redisson__map_cache__last_access__set:{chart_settings_v493}, {chart_settings_v493}:redisson_options, 1560190864239, PooledUnsafeDirectByteBuf(ridx: 0, widx: 13, cap: 256)], codec=org.redisson.codec.KryoCodec]]
Redis server response timeout (3000 ms) occured after 3 retry attempts. Command: (EVAL), params: [local value = redis.call('hget', KEYS[1], ARGV[2]); if value == false then return nil; end; local t,..., 5, chart_settings_v493, redisson__timeout__set:{chart_settings_v493}, redisson__idle__set:{chart_settings_v493}, redisson__map_cache__last_access__set:{chart_settings_v493}, {chart_settings_v493}:redisson_options, 1560190864239, PooledUnsafeDirectByteBuf(ridx: 0, widx: 13, cap: 256)], channel: [id: 0xeddb5e30, L:/redisURL:51687 - R:redisURL/redisURL:6379]
org.redisson.client.RedisResponseTimeoutException: Redis server response timeout (3000 ms) occured after 3 retry attempts. Command: (EVAL), params: [local value = redis.call('hget', KEYS[1], ARGV[2]); if value == false then return nil; end; local t,..., 5, chart_settings_v493, redisson__timeout__set:{chart_settings_v493}, redisson__idle__set:{chart_settings_v493}, redisson__map_cache__last_access__set:{chart_settings_v493}, {chart_settings_v493}:redisson_options, 1560190864239, PooledUnsafeDirectByteBuf(ridx: 0, widx: 13, cap: 256)], channel: [id: 0xeddb5e30, L:/redisURL:51687 - R:redisURL/redisURL:6379]
at org.redisson.command.CommandAsyncService$8.run(CommandAsyncService.java:935)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:682)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:757)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:485)
at java.lang.Thread.run(Thread.java:748)
Steps to reproduce or test case
Unknown
Redis version - 5.0.4 on AWS as a cluster
Redisson version - 3.10.7
Redisson configuration
public static RedissonClient createRedissonClient(Properties o) {
	Config config = new Config()
			.setAddressResolverGroupFactory(new DnsAddressResolverGroupFactory());
	config.useClusterServers()
		.addNodeAddress(o.getProperty("testRedisURL"))
		.setSubscriptionConnectionMinimumIdleSize(10)
		.setSubscriptionConnectionPoolSize(500)
		.setSlaveConnectionMinimumIdleSize(10)
		.setSlaveConnectionPoolSize(640)
		.setMasterConnectionMinimumIdleSize(32)
		.setMasterConnectionPoolSize(640)
		.setRetryAttempts(3);
	RedissonClient client = Redisson.create(config);
	return client;
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2158
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for your contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2159
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
问题
@参考教程
第三方框架整合
单机配置
redisson 整合 Spring Session 报错,一直提示RedisTimeoutException:null
netty线程尝试开大32,64
连接超时开启到30000
都不行
不整合spring session没有问题
依赖版本
springboot 2.1.5RELEASE
spring-session-core  2.1.2.RELEASE
redisson-spring-boot-starter 3.11.0RELEASE
报错信息
` Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2019-06-11 11:48:13.566 ERROR 2284 --- [           main] o.s.boot.SpringApplication               : Application run failed
org.springframework.context.ApplicationContextException: Unable to start web server; nested exception is org.springframework.boot.web.server.WebServerException: Unable to start embedded Tomcat
at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:157) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:543) ~[spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) [spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) [spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) [spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) [spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) [spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
at com.wokeoo.test.TestApplication.main(TestApplication.java:26) [classes/:na]
Caused by: org.springframework.boot.web.server.WebServerException: Unable to start embedded Tomcat
at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize(TomcatWebServer.java:125) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.(TomcatWebServer.java:86) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getTomcatWebServer(TomcatServletWebServerFactory.java:427) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getWebServer(TomcatServletWebServerFactory.java:180) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.createWebServer(ServletWebServerApplicationContext.java:181) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:154) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
... 8 common frames omitted
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'sessionRepositoryFilterRegistration' defined in class path resource [org/springframework/boot/autoconfigure/session/SessionRepositoryFilterConfiguration.class]: Unsatisfied dependency expressed through method 'sessionRepositoryFilterRegistration' parameter 1; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'springSessionRepositoryFilter' defined in class path resource [org/redisson/spring/session/config/RedissonHttpSessionConfiguration.class]: Unsatisfied dependency expressed through method 'springSessionRepositoryFilter' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sessionRepository' defined in class path resource [org/redisson/spring/session/config/RedissonHttpSessionConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.redisson.spring.session.RedissonSessionRepository]: Factory method 'sessionRepository' threw exception; nested exception is org.redisson.client.RedisTimeoutException
at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:769) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:509) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1321) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1160) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:204) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.boot.web.servlet.ServletContextInitializerBeans.getOrderedBeansOfType(ServletContextInitializerBeans.java:235) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
at org.springframework.boot.web.servlet.ServletContextInitializerBeans.getOrderedBeansOfType(ServletContextInitializerBeans.java:226) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
at org.springframework.boot.web.servlet.ServletContextInitializerBeans.addServletContextInitializerBeans(ServletContextInitializerBeans.java:101) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
at org.springframework.boot.web.servlet.ServletContextInitializerBeans.(ServletContextInitializerBeans.java:88) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.getServletContextInitializerBeans(ServletWebServerApplicationContext.java:261) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.selfInitialize(ServletWebServerApplicationContext.java:234) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
at org.springframework.boot.web.embedded.tomcat.TomcatStarter.onStartup(TomcatStarter.java:54) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5139) ~[tomcat-embed-core-9.0.19.jar:9.0.19]
at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) ~[tomcat-embed-core-9.0.19.jar:9.0.19]
at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1377) ~[tomcat-embed-core-9.0.19.jar:9.0.19]
at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1367) ~[tomcat-embed-core-9.0.19.jar:9.0.19]
at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266) ~[na:1.8.0_144]
at java.util.concurrent.FutureTask.run(FutureTask.java) ~[na:1.8.0_144]
at org.apache.tomcat.util.threads.InlineExecutorService.execute(InlineExecutorService.java:75) ~[tomcat-embed-core-9.0.19.jar:9.0.19]
at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:134) ~[na:1.8.0_144]
at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:902) ~[tomcat-embed-core-9.0.19.jar:9.0.19]
at org.apache.catalina.core.StandardHost.startInternal(StandardHost.java:831) ~[tomcat-embed-core-9.0.19.jar:9.0.19]
at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) ~[tomcat-embed-core-9.0.19.jar:9.0.19]
at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1377) ~[tomcat-embed-core-9.0.19.jar:9.0.19]
at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1367) ~[tomcat-embed-core-9.0.19.jar:9.0.19]
at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266) ~[na:1.8.0_144]
at java.util.concurrent.FutureTask.run(FutureTask.java) ~[na:1.8.0_144]
at org.apache.tomcat.util.threads.InlineExecutorService.execute(InlineExecutorService.java:75) ~[tomcat-embed-core-9.0.19.jar:9.0.19]
at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:134) ~[na:1.8.0_144]
at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:902) ~[tomcat-embed-core-9.0.19.jar:9.0.19]
at org.apache.catalina.core.StandardEngine.startInternal(StandardEngine.java:262) ~[tomcat-embed-core-9.0.19.jar:9.0.19]
at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) ~[tomcat-embed-core-9.0.19.jar:9.0.19]
at org.apache.catalina.core.StandardService.startInternal(StandardService.java:423) ~[tomcat-embed-core-9.0.19.jar:9.0.19]
at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) ~[tomcat-embed-core-9.0.19.jar:9.0.19]
at org.apache.catalina.core.StandardServer.startInternal(StandardServer.java:932) ~[tomcat-embed-core-9.0.19.jar:9.0.19]
at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) ~[tomcat-embed-core-9.0.19.jar:9.0.19]
at org.apache.catalina.startup.Tomcat.start(Tomcat.java:455) ~[tomcat-embed-core-9.0.19.jar:9.0.19]
at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize(TomcatWebServer.java:106) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
... 13 common frames omitted
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'springSessionRepositoryFilter' defined in class path resource [org/redisson/spring/session/config/RedissonHttpSessionConfiguration.class]: Unsatisfied dependency expressed through method 'springSessionRepositoryFilter' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sessionRepository' defined in class path resource [org/redisson/spring/session/config/RedissonHttpSessionConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.redisson.spring.session.RedissonSessionRepository]: Factory method 'sessionRepository' threw exception; nested exception is org.redisson.client.RedisTimeoutException
at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:769) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:509) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1321) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1160) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:277) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1248) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1168) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:857) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:760) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
... 55 common frames omitted
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sessionRepository' defined in class path resource [org/redisson/spring/session/config/RedissonHttpSessionConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.redisson.spring.session.RedissonSessionRepository]: Factory method 'sessionRepository' threw exception; nested exception is org.redisson.client.RedisTimeoutException
at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:627) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:607) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1321) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1160) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:277) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1248) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1168) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:857) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:760) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
... 69 common frames omitted
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.redisson.spring.session.RedissonSessionRepository]: Factory method 'sessionRepository' threw exception; nested exception is org.redisson.client.RedisTimeoutException
at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:622) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
... 83 common frames omitted
Caused by: org.redisson.client.RedisTimeoutException: null
at org.redisson.pubsub.PublishSubscribeService$3.run(PublishSubscribeService.java:235) ~[redisson-3.11.0.jar:na]
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:682) ~[netty-common-4.1.36.Final.jar:4.1.36.Final]
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:757) ~[netty-common-4.1.36.Final.jar:4.1.36.Final]
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:485) ~[netty-common-4.1.36.Final.jar:4.1.36.Final]
at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_144] `
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2160
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2161
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for your contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2162
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
Redisson version
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2163
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2164
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am thinking of the possibility of separating out the Reddison client from Tomcat container. Is there any way to do that? or do I always have to use RedissonSessionManager with Tomcat? I am using AWS Elasticache Redis. Thanks.
Redisson version - 3.10
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2165
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Reads to be disctibuted across primary + replica servers for ReadMode.Master_Slave and ReadMode.Slave
Actual behavior
All the reads are going to primary server
Steps to reproduce or test case
We are using Aws elasticCache redis instance ( 1 primary 1 replica )
I have tried both useReplicated and useMaterSlave configs below
config.useReplicatedServers()
// use "rediss://" for SSL connection
.setScanInterval(50)
.addNodeAddress("redis://serverIp")
.addNodeAddress("redis://serverIp")
.setReadMode(ReadMode.SLAVE);
config.useMasterSlaveServers()
// use "rediss://" for SSL connection
.setMasterAddress("redis://primaryIp")
.addSlaveAddress("redis://replicaIp")
.setReadMode(ReadMode.SLAVE);
Also note I have tried both read modes ReadMode.SLAVE and ReadMode.MASTER_SLAVE
Redis version
tried on two redis version same result
4.10
5.0.0
Redisson version
3.9.0
Redisson configuration
config.useReplicatedServers()
// use "rediss://" for SSL connection
.setScanInterval(50)
.addNodeAddress("redis://serverIp")
.addNodeAddress("redis://serverIp")
.setReadMode(ReadMode.SLAVE);
config.useMasterSlaveServers()
// use "rediss://" for SSL connection
.setMasterAddress("redis://primaryIp")
.addSlaveAddress("redis://replicaIp")
.setReadMode(ReadMode.SLAVE);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2166
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Why bloom filter bit size limit Integer.MAX_VALUE*2？not Integer.MAX_VALUE or other value ？
@mrniko can you tell me the reason？
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2167
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In method private void changeMaster(URI address, ClientConnectionsEntry oldMaster, RFuture<RedisClient> future), parameter oldMaster is assigned masterEntry, however on complete of the future of setupMasterEntry, masterEntry is already assigned a new value which means oldMaster changes as well. How can this oldMaster get ahold of the "old master" as the code intends? After hours of reading the code my brain is slow, so I must be wrong. Please help me understand this.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2168
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2169
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Here's how I use it：
DragonBoatActivityVo dragonBoatActivityVo = this.dragonBoatService.getActivity();
Integer statusCode = 100;
if (dragonBoatActivityVo.getStatus()==1){
RLock rLock = redissonClient.getLock(openid);
try {
rLock.lock();
statusCode = this.dragonBoatService.addShareDrawNum(openid,sOpenid);
}catch (Exception e){
e.printStackTrace();
}finally {
rLock.unlock();
}
}
But there are still high concurrency issues
Two of the same information is generated
Request to solve
thank
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2170
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Actual behavior
org.redisson.client.RedisResponseTimeoutException: Redis server response timeout (3000 ms) occured after 3 retry attempts. Command: (EVAL), params: [local s = redis.call('hgetall', KEYS[1]); local result = {}; local maxSize = tonumber(redis.call('hg..., 5, onlineUserCache, redisson__timeout__set:{onlineUserCache}, redisson__idle__set:{onlineUserCache}, redisson__map_cache__last_access__set:{onlineUserCache}, {onlineUserCache}:redisson_options, 1560498015304], channel: [id: 0xa205d196, ...............
at org.redisson.command.CommandAsyncService$13.run(CommandAsyncService.java:960)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:682)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:757)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:485)
at java.lang.Thread.run(Thread.java:748)
question:
when i get allvalue of a key, occured RedisResponseTimeoutException,why? the numbers of the values is 10000 or more .
Steps to reproduce or test case
###Redis version
3.2.11
Redisson version
2.15.2
Redisson configuration
redisson:sentinel-address
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2171
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2172
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RedissonRedLock lock = new RedissonRedLock(lock1, lock2, lock3);
boolean res = lock.tryLock(-1, 10, TimeUnit.SECONDS);
if waitTime == -1  and leaseTime != -1，multiple threads get the lock at the same time
Thank you
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2173
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@mrniko ^
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2174
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2175
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Redisson throws RedisTimeoutException after timeout has exceeded.
Actual behavior
There is a race condition where Redisson may throw RedisTimeoutException after retryInterval has exceeded but before timeout has exceeded (in a nutshell when there are bursts of commands, commands will timeout even if timeout hasn't passed if retry interval is set to 0).
line 765 in CommandAsyncService seems suspect as it uses retry interval for the initial timeout value..
     Timeout timeout = connectionManager.newTimeout(retryTimerTask, connectionManager.getConfig().getRetryInterval(), TimeUnit.MILLISECONDS);
org.redisson.client.RedisTimeoutException: Unable to send command! Try to increase 'nettyThreads' and/or connection pool size settings Node source: NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=value:50:queue:0, freeConnectionsAmount=31, freeConnectionsCounter=value:63:queue:0, freezed=false, freezeReason=null, client=[addr=redis://127.0.0.1:6379], nodeType=MASTER, firstFail=0]]], connection: RedisConnection@1164990041 [redisClient=[addr=redis://127.0.0.1:6379], channel=[id: 0xfe590eb3, L:/127.0.0.1:61299 - R:127.0.0.1/127.0.0.1:6379], command=null], current command in queue: null, command: (EVAL), params: [local insertable = false; local value = redis.call('hget', KEYS[1], ARGV[5]); local t, val;if value ..., 8, HibernateCache.Product, redisson__timeout__set:{HibernateCache.Product}, redisson__idle__set:{HibernateCache.Product}, redisson_map_cache_created:{HibernateCache.Product}, redisson_map_cache_updated:{HibernateCache.Product}, redisson__map_cache__last_access__set:{HibernateCache.Product}, redisson_map_cache_removed:{HibernateCache.Product}, {HibernateCache.Product}:redisson_options, ...] after 0 retry attempts
Steps to reproduce or test case
On faster machines you may need to create some artificial load then run the reproducer..
stress --cpu 8 --timeout 120

import org.redisson.Redisson;
import org.redisson.api.RMap;
import org.redisson.api.RedissonClient;
import org.redisson.client.RedisException;
import org.redisson.codec.SnappyCodec;
import org.redisson.config.Config;
import org.redisson.config.SingleServerConfig;
import org.redisson.config.TransportMode;

import java.io.Serializable;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ForkJoinPool;

/**
 * @author Johno Crawford (johno@sulake.com)
 */
public class BurstMain {

    private static final ForkJoinPool forkJoinPool = new ForkJoinPool(16);

    public static void main(String[] args) {
        final Config config = new Config();
        final SingleServerConfig singleServerConfig = config.useSingleServer();
        singleServerConfig.setDatabase(3);
        singleServerConfig.setTimeout(1000);
        singleServerConfig.setRetryAttempts(0);
        singleServerConfig.setRetryInterval(0);
        //singleServerConfig.setConnectionPoolSize(8);
        //singleServerConfig.setConnectionMinimumIdleSize(8);
        singleServerConfig.setRetryInterval(0);
        singleServerConfig.setTcpNoDelay(true);
        singleServerConfig.setKeepAlive(true);
        singleServerConfig.setAddress("redis://127.0.0.1:6379");
        config.setCodec(new SnappyCodec());
        config.setTransportMode(TransportMode.NIO);
        config.setReferenceEnabled(false);

        final RedissonClient redissonClient = Redisson.create(config);

        for (int i = 0; i < 16; i++) {
            createWorker(redissonClient, i);
        }

        redissonClient.shutdown();
    }

    private static void createWorker(RedissonClient redissonClient, int id) {
        CompletableFuture<Void> cf = new CompletableFuture<>();
        CompletableFuture.runAsync(() -> {
            final RMap<String, Room> rMap = redissonClient.getMap("mymap" + id );
            rMap.clear();

            try {
                for (int i = 0; i < 100000; i++) {
                    rMap.put("huuhaa_" + i, new Room(i, "huuhaa", 12));
                    rMap.get("huuhaa_" + i);
                    rMap.get("huuhaa_" + i);
                }
                cf.complete(null);
            } catch (RedisException e) {
                cf.completeExceptionally(e);
            }
        }, forkJoinPool);
        cf.join();
    }

    private static class Room implements Serializable {

        private static final long serialVersionUID = 1L;

        private int id;
        private String name;
        private int score;

        public Room() {
        }

        public Room(int id, String name, int score) {
            this.id = id;
            this.name = name;
            this.score = score;
        }
    }
}
Redis version
redis-5.0.5-1.fc30.x86_64 / 4.0.9
Redisson version
3.10.7
Redisson configuration
n/a
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2176
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi everybody
I'm trying to configure hibernate (5.4.3 final) with redisson (3.11.0). I use RedissonRegionFactory by default but i want that expiration.time_to_live be 10 seconds.
How should the correct configuration be?
hibernate.cache.redisson.RedissonRegionFactory.expiration.time_to_live = 10000 ???
Thanks in advanced.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2177
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
We noticed recently there are a lot of org.nustaq.serialization.FSTConfiguration instances around in our jvm service(with redisson 3.6 installed and FstCodec enabled).But according to the comment in the javadoc, construction of org.nustaq.serialization.FSTConfiguration is very expensive, which should be cached and reused.
After some digging in redisson's code, I get some clue, it may be caused by the implementation type of org.redisson.command.CommandAsyncService#CODECS . By design, codec construction should be limited, mostly old ones from the ConcurrentHashMap stored in the ReferenceCacheMap should get returned. But since CODECS is a weak reference cache map, the ConcurrentHashMap is possible to get removed by GC. And since there is only one possible strong reference to the ConcurrentHashMap, which is a local variable in org.redisson.command.CommandAsyncService#getCodec,  the possibility of CODECS getting cleared during a GC event is very large.
the declaration and usage of org.redisson.command.CommandAsyncService#CODECS  is included in the following snippet.

    private static final Map<ClassLoader, Map<Codec, Codec>> CODECS = ReferenceCacheMap.weak(0, 0);

    protected Codec getCodec(Codec codec) {
        if (codec == null) {
            return codec;
        }

        for (Class<?> clazz : BaseCodec.SKIPPED_CODECS) {
            if (clazz.isAssignableFrom(codec.getClass())) {
                return codec;
            }
        }

        Codec codecToUse = codec;
        ClassLoader threadClassLoader = Thread.currentThread().getContextClassLoader();
        if (threadClassLoader != null) {
            Map<Codec, Codec> map = CODECS.get(threadClassLoader); // this is the only possible strong reference to the ConcurrentHashMap stored in CODECS
            if (map == null) {
                synchronized (CODECS) {
                    map = CODECS.get(threadClassLoader);
                    if (map == null) {
                        map = new ConcurrentHashMap<Codec, Codec>();
                        CODECS.put(threadClassLoader, map);
                    }
                }
            }
            codecToUse = map.get(codec);
            if (codecToUse == null) {
                try {
                    codecToUse = codec.getClass().getConstructor(ClassLoader.class, codec.getClass()).newInstance(threadClassLoader, codec);
                } catch (NoSuchMethodException e) {
                    codecToUse = codec;
                    // skip
                } catch (Exception e) {
                    throw new IllegalStateException(e);
                }
                map.put(codec, codecToUse);
            }
        }
        return codecToUse;
    }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2178
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
UpdateValve valve should be installed only once for tomcat pipeline but if there are multiple web application each one will instantiate a new RedissonSessionManager and each startInternal() will install it's own copy of the UpdateValve, more over the UpdateValve  have back reference to RedissonSessionManager, so remove this reference in order to have only one UpdateValve installed for the tomcat pipeline and allow proper RedissonSessionManager garbage collection.
When we have Redisson client set in JNDI which is shared between web applications we need to remove MessageListener from the topic when web application is deinstalled during stopInternal method of RedissonSessionManager
Actual behavior
Each web app will create it's own RedissonSessionManager instance which will result in multiple UpdateValve instances installed into tomcat pipeline
MessageListener is not removed from redisson topic which will cause web application class loader memory leak as MessageListener have reference to codecToUse which in turn have reference to application class loader
Steps to reproduce or test case
Redis version
Redisson version
3.11.1-SNAPSHOT
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2179
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Are you sure pipeline is a singleton object?
The getEngine().getPipeline() will get Engine pipeline that is shared between web apps

If we use getEngine().getPipeline() then the valves will be like this:
[org.redisson.tomcat.UpdateValve[Catalina], org.apache.catalina.core.StandardEngineValve[Catalina]]
If we do not check if the valve is added into getEngine().getPipeline() other instances of the valve per web app will be added into the same pipeline (having as many UpdateValve as we have web apps)
if we use getContext().getPipeline() the valves are like this:
[org.apache.catalina.authenticator.BasicAuthenticator[/XXXWEBAPP], org.redisson.tomcat.UpdateValve[/XXXWEBAPP], org.apache.catalina.core.StandardContextValve[/XXXWEBAPP]]
as you could see the getContext().getPipeline() is per web app pipeline but the UpdateValve is added in the middle of the pipeline valves instead as the first valve like in case of getEngine().getPipeline() - so we want redisson valve to be the wrapper valve so it is not like other valves could be added before the redisson session manager valve
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2180
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Please delete this issue, needs more work before filing. I cant delete myself.
see #2181
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2181
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behaviour
None, or fewer Exceptions (just during failover period)
Actual behaviour
After a master re-election (and not otherwise) a constant percentage (about 1%) of the requests fail with this exception until the Redisson client is re-initialised manually with a pod bounce.
org.redisson.client.RedisTimeoutException: Subscribe timeout: (60000ms). Increase 'subscriptionsPerConnection' and/or 'subscriptionConnectionPoolSize' parameters. at org.redisson.command.CommandAsyncService.syncSubscription(CommandAsyncService.java:167) ~[redisson-3.10.7.jar!/:na] at org.redisson.RedissonLock.lock(RedissonLock.java:183) ~[redisson-3.10.7.jar!/:na] at org.redisson.RedissonLock.lock(RedissonLock.java:157) ~[redisson-3.10.7.jar!/:na] at com.ajw.quondam.redis.RedisConnector.removeKey(RedisConnector.java:53) ~[classes!/:1.0-SNAPSHOT]
Steps to reproduce or test case
I'm running 3 redis (master, slave, slave) alongside 3 sentinels.
 I'm running a constant load of requests through a redisson client which can run indefinitely without any issue. 
When I introduce a chaos script to trigger a failure of the master and thus a master re-election I start to see the errors, yet only for a very small percentage of the requests (but that percentage remains constant indefinitely until a manual restart of the redisson client happens)
Each request acquires and releases an RLock with a chance of collision with another request being 1 in 100.
If I lower the collision probability to be 1 in 10000 this problem almost completely disappears to the point where I lose only perhaps a single request, during the failover period (which is the expected behaviour for the higher collision case also)
Redis version
redis_version:4.0.11
Redisson version
3.10.7
Redisson configuration
.setSubscriptionsPerConnection(20) 
.setSubscriptionConnectionPoolSize(200) 
.setRetryAttempts(15) 
.setRetryInterval(3000) 
.setSubscriptionConnectionMinimumIdleSize(50) 
.setSlaveConnectionPoolSize(200)
 .setMasterConnectionPoolSize(200)
 .setTimeout(15000)
.setNettyThreads(128)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2182
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
期待tryLock返回成功
Actual behavior
实际每次加锁都会返回false
Steps to reproduce or test case
每次加锁都会失败
Redis version
Redisson version
3.8到3.11都尝试了
Redisson configuration
singleServerConfig:
idleConnectionTimeout: 10000
pingTimeout: 1000
connectTimeout: 10000
timeout: 3000
retryAttempts: 3
retryInterval: 1500
reconnectionTimeout: 3000
failedAttempts: 3
password: null
subscriptionsPerConnection: 5
clientName: null
address: "redis://127.0.0.1:6379"
subscriptionConnectionMinimumIdleSize: 1
subscriptionConnectionPoolSize: 50
connectionMinimumIdleSize: 32
connectionPoolSize: 64
database: 0
dnsMonitoring: false
dnsMonitoringInterval: 5000
threads: 10
nettyThreads: 10
codec: !<org.redisson.codec.JsonJacksonCodec> {}
transportMode :NIO
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2183
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
1.大部分的教程里写的都是：
General usage：

@transactional
try{
①请求加锁（lock）
②执行业务逻辑（business logic)
}catch(Exception e){
//处理异常(handle exception)
}finally {
③解锁(unlock)
}

写了一个小例子测试，打印的日志如下：
Write a small sample test and print the following log:

当前线程：：154 加锁成功（Current thread:: 154 locks successfully）
Creating a new SqlSession
Registering transaction synchronization for SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@5a98c21a]
JDBC Connection [com.mysql.jdbc.JDBC4Connection@1f7b84c6] will be managed by Spring
==>  Preparing: select * from test_me where id = 1
==> Parameters:
<==    Columns: id, total, thread
<==        Row: 1, 233, null
<==      Total: 1
Releasing transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@5a98c21a]
当前线程：：154 初始值>>>233 最新值>>>234
Fetched SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@5a98c21a] from current transaction
==>  Preparing: update test_me set total = ? where id = 1
Time：16 ms - ID：com.you.order.mapper.TestMeMapper.get
Execute SQL：
select
*
from
test_me
where
id = 1
==> Parameters: 234(Integer)
<==    Updates: 1
Releasing transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@5a98c21a]
Time：29 ms - ID：com.you.order.mapper.TestMeMapper.update
Execute SQL：
update
test_me
set
total = ?
where
id = 1
当前线程：：154 解锁（Current thread::154 unlock）
Transaction synchronization committing SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@5a98c21a]
Transaction synchronization deregistering SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@5a98c21a]
Transaction synchronization closing SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@5a98c21a]

》从上面可以看出来事务的提交是发生在解锁操作之后，这样是不是就存在一种可能性，在事务还没有提交完成以前，其他线程由于该线程已经解锁而发生并发问题？？？
（类似于@transaction和synchronized的并发问题）
As can be seen from the above, transaction committing occurs after the unlocking operation. Is there a possibility that other threads will have concurrent problems because the thread has been unlocked before the transaction has been submitted?
(Similar to @transaction and synchronized concurrency issues)
2.我用jmeter做了测试，却发现好像没有在解锁和提交事务之间发生并发问题，个人疑惑，希望大佬解解惑，谢谢😀
I tested it with JMeter and found no concurrency problems between unlocking and committing transactions.If you know, please let me know. Thank you.😀
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2184
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
addListEx 这个操作不是原子的 所以高并发下会出现问题，并没有实现ex的原子性操作
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2185
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Currently there is no way to tell when a jar file has been build - This feature request is to add Build-Time manifest entry so that we could tell when it was build/rebuild as often if release version is not changed (e.g. providing patches via rebuild of the master code) once the modified version of the jar file is created we can't tell if it contains the fixes or not by simply having a file inside the jar to tell us when it has been build. Also some of the jars that are created do not have the default implementation entries and/or specification entries
Expected behavior
Each jar to have default implementation/specification entries and have a build time - optionally if we have git branch / commit into MANIFEST.MF would be beneficial as well
Actual behavior
Steps to reproduce or test case
Redis version
Redisson version
Redisson configuration
3.11.1-SNAPSHOT
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2186
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
If we want to serialize object with codec other than SerializationCodec as the values are not Serializable for example and if the web app xml have the distributable tag when we try to set attribute into the session that is not Serializable an exception will be thrown that the object is not serializable
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
Redisson version
3.11.1-SNAPSHOT
Redisson configuration
Redisson codec other than SerializationCodec and web application that have web.xml tag distributable
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2187
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RedissonSession setAttribute do not check if the value is null before removing the attribute name from removedAttributes collection
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
Redisson version
3.11.1-SNAPSHOT
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2188
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@mrniko
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2189
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2190
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2191
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2192
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2193
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2194
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2195
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2196
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2197
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2198
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2199
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2200
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2201
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2202
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2203
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2204
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2205
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2206
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2207
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2208
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2209
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2210
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2211
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2212
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2213
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2214
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2215
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2216
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2217
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2218
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2219
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2220
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2221
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2222
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2223
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2224
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2225
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2226
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2227
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2228
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2229
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2230
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2231
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2232
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2233
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2234
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2235
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2236
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2237
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2238
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2239
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2240
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2241
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2242
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2243
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2244
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2245
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2246
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2247
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2248
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2249
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2250
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2251
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2252
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2253
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2254
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2255
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2256
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2257
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2258
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2259
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2260
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2261
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2262
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2263
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2264
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2265
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2266
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2267
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2268
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2269
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2270
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2271
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2272
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2273
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2274
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2275
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2276
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2277
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2278
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2279
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2280
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2281
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2282
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2283
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2284
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2285
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2286
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2287
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2288
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2289
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2290
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2291
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2292
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2293
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2294
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2295
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2296
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2297
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2298
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2299
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2300
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2301
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2302
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2303
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2304
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2305
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2306
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2307
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2308
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
When submitting task with taskRetryInterval option set, the task should run on the next available Redisson executor node when the original executor node was killed.
Actual behavior
The task is not retried on the next available worker. Also when the worker node is started again it will run duplicate task on all the available worker nodes.
Steps to reproduce or test case
Submit JobA and then start 2 instance of the Worker lets say Worker1 and Worker2. When Worker1 is running JobA kill that worker, now the Worker2 should try to run the JobA after the taskRetryInterval, but it does not. Now start Worker1 again, Redisson will duplicate the task run on both Worker1 and Worker2.
public class Schedule {

	public static void main(String[] args) {
		RedissonClient client = Redisson.create();
                ExecutorOptions option = ExecutorOptions.defaults();
                option.taskRetryInterval(3000, TimeUnit.MILLISECONDS);
		RScheduledExecutorService executorService = client.getExecutorService("JobA",option);
                // submit JobA
		RExecutorFuture<?> future = executorService
                .submit(new JobA());
	}

}


JobA:
public class JobA implements Runnable {

	@Override
	public void run() {
                System.out.println("JOB A started!!!!!!!!!!");
		try {
			Thread.sleep(10000);
		} catch (InterruptedException e) {
			e.printStackTrace();
		}
		System.out.println("JOB A finished!!!!!!!!!!");
	}

}

Worker:
public class Worker{
	public static void main(String[] args) {
		Config config = new Config();
		config.useSingleServer().setAddress("redis://127.0.0.1:6379");
		RedissonNodeConfig nodeConfig = new RedissonNodeConfig(config);
		nodeConfig.getExecutorServiceWorkers().put("JobA", 1);
		RedissonNode node = RedissonNode.create(nodeConfig);
		node.start();
	}

}

Redis version
Redis 3.0.503
Redisson version
3.9.1
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2309
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
长时间运行，不会导致内存泄露
Actual behavior
长时间运行，导致内存泄露
Steps to reproduce or test case
1.从spring官网上生成spring boot的demo项目。
2.在pom.xml中增加对redisson的依赖。
<dependency>
	<groupId>org.redisson</groupId>
	<artifactId>redisson</artifactId>
	<version>3.11.3</version>
</dependency>
3.debug方式启动spring boot。
4.通过断点观察

可以看到redisson所依赖的netty里，这个数组的的大小会不断增大，最终导致oom。
Redis version
redis_version:5.0.4
redis_git_sha1:00000000
redis_git_dirty:0
redis_build_id:913214bd6b0ee4ea
redis_mode:cluster
os:Linux 3.10.0-957.1.3.el7.x86_64 x86_64
arch_bits:64
multiplexing_api:epoll
atomicvar_api:atomic-builtin
Redisson version
3.11.3
Redisson configuration
我是在spring boot里通过代码的方式配置的。
@SpringBootApplication
public class Test3Application {

    public static void main(String[] args) {
        SpringApplication.run(Test3Application.class, args);
    }

    @Bean
    public RedissonClient getRedisson() {
        Config config = new Config();
        config.useClusterServers()
                .setScanInterval(2000) // cluster state scan interval in milliseconds
                .addNodeAddress("redis://10.193.xxx.xxx:8303");
        RedissonClient redisson = Redisson.create(config);
        return redisson;
    }

}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2310
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Get saved session
Actual behavior
Errror on get saved session
[http-nio-8080-exec-3] org.redisson.tomcat.RedissonSessionManager.findSession Session 220E103487E92F790688E64E864CE089 can't be found 09/09/19 17:31:22 ERROR hamburgsud.schedule.report.sign.in.controller.SignInController:44 Unable to sign in. java.lang.IllegalArgumentException: The user cannot be null.
Steps to reproduce or test case
Tomcat configuration Steps
Redis version
lastest
Redisson version
3-11-2
Redisson configuration
singleServerConfig:
idleConnectionTimeout: 10000
connectTimeout: 10000
timeout: 3000
retryAttempts: 3
retryInterval: 1500
password: null
subscriptionsPerConnection: 5
clientName: null
address: "redis://10.121.224.137:7000"
subscriptionConnectionMinimumIdleSize: 1
subscriptionConnectionPoolSize: 50
connectionMinimumIdleSize: 24
connectionPoolSize: 64
database: 0
dnsMonitoringInterval: 5000
threads: 16
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2311
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redisson and redis are used ONLY as cache by spring @Cacheable(value="xy", key="ab") annotations.  TTL is set to 10min. no manual access or manual redisson commands are written in code.
Expected behavior
after catch RedisOutOfMemoryException redisson evicts old keys to make more space, because redis cannot handle outOfMemory due to redisson creates key "xy" that represents whole cache name and ttl is not set for this key. Value of this key is "map" that contains cache our keys "ab" and cached values. There exists also other redis key with prefix redisson__timeout__set:{xy} that holds TTL.
Actual behavior
after RedisOutOfMemoryException there is inconsistency that stored records are alive and is returned from cache after 5 days even we have TTL only 10min. Maybe because redisson first put value to xy cache and next put TTL value to redisson__timeout__set:{xy} cache. if write to redisson__timeout__set:{xy} caused OOM exception then record in xy cache will stay alive forever.
Steps to reproduce or test case
set redis max memory to low value and store bigger data to cache.
Redis version
v5.0.4
Redisson version
v3.10.7
Redisson configuration
private static final int CONNECTION_POOL_SIZE = 256;
private static final int SUBSCRIPTION_CONNECTION_MINIMUM_IDLE_SIZE = 2;
private static final int SUBSCRIPTION_POOL_SIZE = 100;
private static final int SUBSCRIPTIONS_PER_CONNECTION_SIZE = 20;
private static final int RETRY_INTERVAL = 100;
private static final int RETRY_ATTEMPTS = 1;
config.useMasterSlaveServers()
.setMasterAddress(halCacheProperties.getRedisMaster())
.addSlaveAddress(halCacheProperties.getRedisSlaves())
.setRetryInterval(RETRY_INTERVAL)
.setRetryAttempts(RETRY_ATTEMPTS)
.setReadMode(ReadMode.MASTER_SLAVE)
.setMasterConnectionPoolSize(CONNECTION_POOL_SIZE)
.setSlaveConnectionPoolSize(CONNECTION_POOL_SIZE)
.setSubscriptionConnectionMinimumIdleSize(SUBSCRIPTION_CONNECTION_MINIMUM_IDLE_SIZE)
.setSubscriptionConnectionPoolSize(SUBSCRIPTION_POOL_SIZE)
.setSubscriptionsPerConnection(SUBSCRIPTIONS_PER_CONNECTION_SIZE);
config.setCodec(new SerializationCodec());   //codec, to fix concurrency problem with fstCodec
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2312
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redis server response timeout (1000 ms) occured for command: (EVAL) with params: [if (redis.call('exists', KEYS[1]) == 0) then redis.call('hset', KEYS[1], ARGV[2], 1); redis.call('pexpire', KEYS[1], ARGV[1]); return nil; end; if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then redis.call('hincrby', KEYS[1], ARGV[2], 1); redis.call('pexpire', KEYS[1], ARGV[1]); return nil; end; return redis.call('pttl', KEYS[1]);, 1, _dtlocks/OrderVerificProcessor_WelfareVerific#O20190825000042, 600000, 30f2dd72-90c5-4863-b712-aff5fd06c828:351]
redisson.2.2.13
when occouring this problem,the redis has not much qps
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2313
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In https://github.com/redisson/redisson/wiki/6.-Distributed-objects#612-ratelimiter, the example is:
// 5 permits per 2 seconds
limiter.trySetRate(RateType.OVERALL, 1, 2, RateIntervalUnit.SECONDS);

Should it be the following?
limiter.trySetRate(RateType.OVERALL, 5, 2, RateIntervalUnit.SECONDS);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2314
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am using Redisson's Tomcat9 session manager going against Azure Redis Cache
with readMode=MEMORY and updateMode=DEFAULT .
This is mainly for session failover in case a server fails. Sessions are sticky, and so during normal operation, all session reads should be local within Tomcat.
Occasionally all of our Tomcat instances experience Netty timeout errors and requests to Redis fail.  This causes a complete failure of the application, as sessions are unavailable. This failure seems unnecessary, since the session data is available in local Tomcat memory and is not dependent on Redis (except in the case of failover)
Is there any way to get Redisson session manager to circuit break if calls to Redis fail or time out, and fall back to using session data from local memory ? The exception is below. Any help would be appreciated. Thanks!
Sep 05, 2019 1:09:58 AM org.redisson.tomcat.RedissonSessionManager findSession
SEVERE: Can't read session object by id: 36D02EC9371A380BBA8A8A6C7BAC6C37
org.redisson.client.RedisTimeoutException: Unable to send command! Try to increase 'nettyThreads' and/or connection pool size settings Node source: NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=0, freeSubscribeConnectionsCounter=value:49:queue:0, freeConnectionsAmount=9, freeConnectionsCounter=value:63:queue:0, freezed=false, freezeReason=null, client=[addr=rediss://sessions-redis.redis.cache.windows.net:6380], nodeType=MASTER, firstFail=0]]], connection: RedisConnection@310983480 [redisClient=[addr=rediss://sessions-redis.redis.cache.windows.net:6380], channel=[id: 0x51576dba, L:/10.23.152.48:49800 - R:sessions-redis.redis.cache.windows.net/137.116.35.20:6380], currentCommand=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@3f0a0e71(failure: java.util.concurrent.CancellationException)], command=(PUBLISH), params=[p-bs:redisson:tomcat_session_updates:/auth, PooledUnsafeDirectByteBuf(freed)], codec=org.redisson.client.codec.StringCodec]], command: (HMGET), params: [p-bs:redisson:tomcat_session:36D02EC9371A380BBA8A8A6C7BAC6C37, PooledUnsafeDirectByteBuf(ridx: 0, widx: 24, cap: 256), PooledUnsafeDirectByteBuf(ridx: 0, widx: 13, cap: 256), PooledUnsafeDirectByteBuf(ridx: 0, widx: 24, cap: 256), PooledUnsafeDirectByteBuf(ridx: 0, widx: 27, cap: 256), PooledUnsafeDirectByteBuf(ridx: 0, widx: 15, cap: 256), PooledUnsafeDirectByteBuf(ridx: 0, widx: 20, cap: 256)] after 3 retry attempts
at org.redisson.command.CommandAsyncService$6.run(CommandAsyncService.java:714)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:682)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:757)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:485)
at java.lang.Thread.run(Thread.java:748)
Expected behavior
Redisson Session Manager should fail gracefully and fall back to local memory if Redis calls fail, and Tomcat requests should succeed
Actual behavior
All Tomcat requests that use the http session data fail
Steps to reproduce or test case
Issue is intermittent, but occurs when calls to Netty time out
Redis version
Azure Cache for Redis
Redisson version
3.11.0
Redisson configuration
singleServerConfig:
idleConnectionTimeout: 10000
connectTimeout: 10000
timeout: 3000
retryAttempts: 3
retryInterval: 1500
subscriptionsPerConnection: 5
clientName: null
subscriptionConnectionMinimumIdleSize: 1
subscriptionConnectionPoolSize: 50
connectionMinimumIdleSize: 10
connectionPoolSize: 64
database: 0
dnsMonitoringInterval: 35000
threads: 16
nettyThreads: 32
codec: !<org.redisson.codec.FstCodec> {}
transportMode: "NIO"
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2315
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2316
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello,
We are running in to DNS resolution failures sometimes.
`DatagramDnsResponse(from: /10.0.0.2:53, to: /0:0:0:0:0:0:0:0:53018, 52723, QUERY(0), NoError(0), RD RA)
DefaultDnsQuestion(useast101-rd01-0001.j2b5o9.0001.use1.cache.amazonaws.com. IN A)
DefaultDnsRawRecord(useast101-rd01-0001.j2b5o9.0001.use1.cache.amazonaws.com. 15 IN A 4B)
DefaultDnsRawRecord(OPT flags:0 udp:4096 0B)
2019-09-11 06:50:21,154-0700 [toe=00p4dqty02gn9h] [redisson-netty-2-24] DEBUG - [id: 0x9099eb92] WRITE: [58273: /10.0.0.2:53], DefaultDnsQuestion(useast101-rd01-0002.j2b5o9.0001.use1.cache.amazonaws.com. IN A)
2019-09-11 06:50:21,155-0700 [toe=00p4dqty02gn9h] [redisson-netty-2-24] DEBUG - [id: 0x9099eb92] WRITE: [31257: /10.0.0.2:53], DefaultDnsQuestion(useast101-rd01-0002.j2b5o9.0001.use1.cache.amazonaws.com. IN AAAA)
2019-09-11 06:50:21,155-0700 [toe=00p4dqty02gn9h] [redisson-netty-2-24] DEBUG - [id: 0x9099eb92] WRITE: [54664: /10.0.0.2:53], DefaultDnsQuestion(useast101-rd01-0001.j2b5o9.0001.use1.cache.amazonaws.com. IN A)
2019-09-11 06:50:22,881-0700 [toe=00p4dqty02gn9h] [redisson-netty-2-24] DEBUG - [id: 0x9099eb92] WRITE: [32392: /10.0.0.2:53], DefaultDnsQuestion(useast101-rd01-0001.j2b5o9.0001.use1.cache.amazonaws.com. IN AAAA)
2019-09-11 06:50:40,212-0700 [toe=00p4dqty02gn9h] [redisson-netty-2-35] ERROR - Command execution timeout for command: (INFO REPLICATION), params: [], Redis client: [addr=redis://useast101-rd01-0001.j2b5o9.0001.use1.cache.amazonaws.com:6379] org.redisson.client.RedisTimeoutException: Command execution timeout for command: (INFO REPLICATION), params: [], Redis client: [addr=redis://useast101-rd01-0001.j2b5o9.0001.use1.cache.amazonaws.com:6379]
at org.redisson.client.RedisConnection$1.run(RedisConnection.java:209) [redisson-3.10.7.jar:?]
at io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:127) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:405) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500) [netty-transport-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:906) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at java.lang.Thread.run(Thread.java:748) [?:1.8.0_181]
2019-09-11 06:50:37,598-0700 [toe=00p4dqty02gn9h] [redisson-netty-2-24] ERROR - Unable to resolve useast101-rd01-0002.j2b5o9.0001.use1.cache.amazonaws.com io.netty.resolver.dns.DnsResolveContext$SearchDomainUnknownHostException: Search domain query failed. Original hostname: 'useast101-rd01-0002.j2b5o9.0001.use1.cache.amazonaws.com' failed to resolve 'useast101-rd01-0002.j2b5o9.0001.use1.cache.amazonaws.com' after 2 queries
at io.netty.resolver.dns.DnsResolveContext.finishResolve(DnsResolveContext.java:877) [netty-resolver-dns-4.1.34.Final.jar:4.1.34.Final]
at io.netty.resolver.dns.DnsResolveContext.tryToFinishResolve(DnsResolveContext.java:838) [netty-resolver-dns-4.1.34.Final.jar:4.1.34.Final]
at io.netty.resolver.dns.DnsResolveContext.query(DnsResolveContext.java:333) [netty-resolver-dns-4.1.34.Final.jar:4.1.34.Final]
at io.netty.resolver.dns.DnsResolveContext.access$600(DnsResolveContext.java:63) [netty-resolver-dns-4.1.34.Final.jar:4.1.34.Final]
at io.netty.resolver.dns.DnsResolveContext$3.operationComplete(DnsResolveContext.java:382) [netty-resolver-dns-4.1.34.Final.jar:4.1.34.Final]
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:502) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:495) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:474) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:415) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:540) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:533) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:114) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.resolver.dns.DnsQueryContext.setFailure(DnsQueryContext.java:220) [netty-resolver-dns-4.1.34.Final.jar:4.1.34.Final]
at io.netty.resolver.dns.DnsQueryContext.access$300(DnsQueryContext.java:43) [netty-resolver-dns-4.1.34.Final.jar:4.1.34.Final]
at io.netty.resolver.dns.DnsQueryContext$4.run(DnsQueryContext.java:170) [netty-resolver-dns-4.1.34.Final.jar:4.1.34.Final]
at io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:127) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:405) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500) [netty-transport-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:906) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at java.lang.Thread.run(Thread.java:748) [?:1.8.0_181]
Caused by: io.netty.resolver.dns.DnsNameResolverTimeoutException: [/10.0.0.2:53] query timed out after 5000 milliseconds (no stack trace available)
2019-09-11 06:51:13,388-0700 [toe=00p4dqty02gn9h] [redisson-netty-2-24] ERROR - Unable to resolve useast101-rd01-0001.j2b5o9.0001.use1.cache.amazonaws.com io.netty.resolver.dns.DnsResolveContext$SearchDomainUnknownHostException: Search domain query failed. Original hostname: 'useast101-rd01-0001.j2b5o9.0001.use1.cache.amazonaws.com' failed to resolve 'useast101-rd01-0001.j2b5o9.0001.use1.cache.amazonaws.com' after 2 queries
at io.netty.resolver.dns.DnsResolveContext.finishResolve(DnsResolveContext.java:877) [netty-resolver-dns-4.1.34.Final.jar:4.1.34.Final]
at io.netty.resolver.dns.DnsResolveContext.tryToFinishResolve(DnsResolveContext.java:838) [netty-resolver-dns-4.1.34.Final.jar:4.1.34.Final]
at io.netty.resolver.dns.DnsResolveContext.query(DnsResolveContext.java:333) [netty-resolver-dns-4.1.34.Final.jar:4.1.34.Final]
at io.netty.resolver.dns.DnsResolveContext.access$600(DnsResolveContext.java:63) [netty-resolver-dns-4.1.34.Final.jar:4.1.34.Final]
at io.netty.resolver.dns.DnsResolveContext$3.operationComplete(DnsResolveContext.java:382) [netty-resolver-dns-4.1.34.Final.jar:4.1.34.Final]
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:502) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:495) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:474) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:415) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:540) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:533) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:114) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.resolver.dns.DnsQueryContext.setFailure(DnsQueryContext.java:220) [netty-resolver-dns-4.1.34.Final.jar:4.1.34.Final]
at io.netty.resolver.dns.DnsQueryContext.access$300(DnsQueryContext.java:43) [netty-resolver-dns-4.1.34.Final.jar:4.1.34.Final]
at io.netty.resolver.dns.DnsQueryContext$4.run(DnsQueryContext.java:170) [netty-resolver-dns-4.1.34.Final.jar:4.1.34.Final]
at io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:127) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:405) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500) [netty-transport-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:906) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-common-4.1.35.Final.jar:4.1.35.Final]
at java.lang.Thread.run(Thread.java:748) [?:1.8.0_181]
Caused by: io.netty.resolver.dns.DnsNameResolverTimeoutException: [/10.0.0.2:53] query timed out after 5000 milliseconds (no stack trace available)`
The redisson configuration details are as below
Redisson Version : 3.10.7
Redis Server : Elasticache
Redisson Configuration
Server Mode: Replication
Threads: 32
Netty Threads : 64
decodeInExecutor:false
timeout : 10 seconds
pingInterval : 60 seconds
Can you please look in to this. This is happening intermittently(nearly 50% of times)
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
Redisson version
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2317
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redis version
V 2.2 Provided by PCF.
Redisson version
3.9.0
Redisson configuration
	Config config = new Config();
	String url = String.format("%s%s%s%s", "redis://", 127.0.0.1, COLON, 6379);
	config.useSingleServer().setAddress(url).setPassword(password);
	return Redisson.create(config);

The exception I see is:
Caused by: org.redisson.client.RedisException: ERR unknown command EVAL, with args beginning with: local value =
  redis.call('hget', KEYS[1], ARGV[2]); if value == false then return
  nil; end;
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2318
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello,
I've tried running tasks Runnable/Callable that have autowired dependencies from SpringBoot and I get serialization errors on scheduling tasks or null pointer exceptions when tasks are about to execute.
I've crawled through documentation very carefully and I've even noticed there is some invalid documentation examples.
Please check out in your documentation Section 9. , 9.4.3. Distributed scheduled executor service. Scheduling a task with Spring beans.
Example code is invalid and it doesn't work.
To summarize:
Is there a way to create Callable/Runnable tasks that have SpringBoot beans as dependencies autowired - Important: that they dont have to implement Serializable interface.
Thank you.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2319
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Multithread concurrency can be unlocked successfully
Actual behavior
Multithread concurrency with only one thread successfully unlocked

Are there any problems with the script here?
When a thread finds the corresponding key, it deletes the whole key. Is it impossible for other threads to find it?
Steps to reproduce or test case

Redis version
spring-boot-starter-data-redis 2.1.7.RELEASE
Redisson version
3.6.5
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2320
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Code
public void addRoutePath(String rxpkData, Rxpk rxpk, RouteMap routeMap, int seconds) {
    RxpkPathContext lockContext = new RxpkPathContext();
    lockContext.setRxpk(rxpk);
    lockContext.setRouteMap(routeMap);
    String name = ROUTE_KEY.replace("{rxpkData}", rxpkData);
    RSet<String> set = redisson.getSet(name);
    set.add(JSONObject.toJSONString(lockContext));
    set.expire(seconds, TimeUnit.SECONDS);
}

public List<RxpkPathContext> getRoutePaths(String rxpkData) {
    String name = ROUTE_KEY.replace("{rxpkData}", rxpkData);
    return redisson.<String>getSet(name).readAll().stream()
        .map(path -> JSONObject.parseObject(path, RxpkPathContext.class))
        .collect(Collectors.toList());;
}
Redisson configuration
public RedissonClient redisson() {
    Config config = new Config();
    config.setNettyThreads(32)
        .setCodec(new JsonJacksonCodec())
        .useSingleServer()
        .setConnectionMinimumIdleSize(16)
        .setConnectionPoolSize(64)
        .setAddress(address)
        .setPassword(password);
    return Redisson.create(config);
}
Exception
2019-09-12 17:31:22.729 ERROR --- [] o.r.client.handler.CommandDecoder        : Unable to decode data. channel: [id: 0x7a8d9c11, L:/11.193.49.163:44086 - R:r-uf6c6b15f63a9214.redis.rds.aliyuncs.com/100.118.18.139:6379], reply: ReplayingDecoderByteBuf(ridx=850, widx=9495), command: (SMEMBERS), params: [lora_route_ea7b6661]
com.fasterxml.jackson.databind.exc.InvalidTypeIdException: Missing type id when trying to resolve subtype of [simple type, class java.lang.Object]: missing typeid property '@class'
 at [Source: (io.netty.buffer.ByteBufInputStream); line: 1, column: 837]
  at com.fasterxml.jackson.databind.exc.InvalidTypeIdException.from(InvalidTypeIdException.java:43)
  at com.fasterxml.jackson.databind.DeserializationContext.missingTypeIdException(DeserializationContext.java:1645)
  at com.fasterxml.jackson.databind.DeserializationContext.handleMissingTypeId(DeserializationContext.java:1218)
  at com.fasterxml.jackson.databind.jsontype.impl.TypeDeserializerBase._handleMissingTypeId(TypeDeserializerBase.java:300)
  at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedUsingDefaultImpl(AsPropertyTypeDeserializer.java:164)
  at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:105)
  at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromAny(AsPropertyTypeDeserializer.java:193)
  at com.fasterxml.jackson.databind.deser.std.UntypedObjectDeserializer$Vanilla.deserializeWithType(UntypedObjectDeserializer.java:712)
  at com.fasterxml.jackson.databind.deser.impl.TypeWrappedDeserializer.deserialize(TypeWrappedDeserializer.java:68)
  at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4013)
  at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3070)
  at org.redisson.codec.JsonJacksonCodec$2.decode(JsonJacksonCodec.java:95)
  at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:384)
  at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:428)
  at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:393)
  at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:215)
  at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:153)
  at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:122)
  at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502)
  at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
  at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
  at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
  at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
  at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
  at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
  at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
  at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
  at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
  at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
  at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
  at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
  at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:677)
  at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:612)
  at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:529)
  at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:491)
  at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
  at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
  at java.lang.Thread.run(Thread.java:766)
2019-09-12 17:31:22.730 WARN  --- [] io.netty.channel.DefaultChannelPipeline  : An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
io.netty.handler.codec.DecoderException: com.fasterxml.jackson.databind.exc.InvalidTypeIdException: Missing type id when trying to resolve subtype of [simple type, class java.lang.Object]: missing type id property '@class'
 at [Source: (io.netty.buffer.ByteBufInputStream); line: 1, column: 837]
  at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:421)
  at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
  at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
  at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
  at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
  at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
  at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
  at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
  at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
  at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
  at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
  at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
  at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:677)
  at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:612)
  at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:529)
  at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:491)
  at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
  at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
  at java.lang.Thread.run(Thread.java:766)
Caused by: com.fasterxml.jackson.databind.exc.InvalidTypeIdException: Missing type id when trying to resolve subtype of [simple type, class java.lang.Object]: missing type id property '@class'
 at [Source: (io.netty.buffer.ByteBufInputStream); line: 1, column: 837]
  at com.fasterxml.jackson.databind.exc.InvalidTypeIdException.from(InvalidTypeIdException.java:43)
  at com.fasterxml.jackson.databind.DeserializationContext.missingTypeIdException(DeserializationContext.java:1645)
  at com.fasterxml.jackson.databind.DeserializationContext.handleMissingTypeId(DeserializationContext.java:1218)
  at com.fasterxml.jackson.databind.jsontype.impl.TypeDeserializerBase._handleMissingTypeId(TypeDeserializerBase.java:300)
  at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedUsingDefaultImpl(AsPropertyTypeDeserializer.java:164)
  at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:105)
  at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromAny(AsPropertyTypeDeserializer.java:193)
  at com.fasterxml.jackson.databind.deser.std.UntypedObjectDeserializer$Vanilla.deserializeWithType(UntypedObjectDeserializer.java:712)
  at com.fasterxml.jackson.databind.deser.impl.TypeWrappedDeserializer.deserialize(TypeWrappedDeserializer.java:68)
  at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4013)
  at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3070)
  at org.redisson.codec.JsonJacksonCodec$2.decode(JsonJacksonCodec.java:95)
  at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:384)
  at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:428)
  at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:393)
  at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:215)
  at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:153)
  at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:122)
  at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502)
  at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
  ... 28 common frames omitted
org.redisson.client.RedisException: Unexpected exception while processing command
  at org.redisson.command.CommandAsyncService.convertException(CommandAsyncService.java:354)
  at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:158)
  at org.redisson.RedissonObject.get(RedissonObject.java:94)
  at org.redisson.RedissonSet.readAll(RedissonSet.java:140)
  at com.aliyun.iotx.loraserver.major.dal.CacheServiceImpl.getRoutePaths(CacheServiceImpl.java:134)
  at java.lang.Thread.run(Thread.java:766)
Caused by: com.fasterxml.jackson.databind.exc.InvalidTypeIdException: Missing type id when trying to resolve subtype of [simple type, class java.lang.Object]: missing type id property '@class'
 at [Source: (io.netty.buffer.ByteBufInputStream); line: 1, column: 837]
  at com.fasterxml.jackson.databind.exc.InvalidTypeIdException.from(InvalidTypeIdException.java:43)
  at com.fasterxml.jackson.databind.DeserializationContext.missingTypeIdException(DeserializationContext.java:1645)
  at com.fasterxml.jackson.databind.DeserializationContext.handleMissingTypeId(DeserializationContext.java:1218)
  at com.fasterxml.jackson.databind.jsontype.impl.TypeDeserializerBase._handleMissingTypeId(TypeDeserializerBase.java:300)
  at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedUsingDefaultImpl(AsPropertyTypeDeserializer.java:164)
  at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:105)
  at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromAny(AsPropertyTypeDeserializer.java:193)
  at com.fasterxml.jackson.databind.deser.std.UntypedObjectDeserializer$Vanilla.deserializeWithType(UntypedObjectDeserializer.java:712)
  at com.fasterxml.jackson.databind.deser.impl.TypeWrappedDeserializer.deserialize(TypeWrappedDeserializer.java:68)
  at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4013)
  at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3070)
  at org.redisson.codec.JsonJacksonCodec$2.decode(JsonJacksonCodec.java:95)
  at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:384)
  at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:428)
  at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:393)
  at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:215)
  at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:153)
  at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:122)
  at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502)
  at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
  at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
  at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
  at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
  at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
  at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
  at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
  at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
  at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
  at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
  at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
  at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
  at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:677)
  at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:612)
  at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:529)
  at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:491)
  at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
  at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
  ... 1 common frames omitted
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2321
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Redisson add all sentinels
Actual behavior
Add only the first one, ignoring the other two.
[main] INFO org.redisson.connection.SentinelConnectionManager - master: redis://172.31.30.1:6379 added
[main] INFO org.redisson.connection.SentinelConnectionManager - slave: redis://172.31.41.2:6379 added
[redisson-netty-2-12] INFO org.redisson.connection.SentinelConnectionManager - sentinel: redis://172.31.30.1:26379 added
[redisson-netty-2-20] INFO org.redisson.connection.pool.PubSubConnectionPool - 1 connections initialized for 172.31.41.2/172.31.41.2:6379
[redisson-netty-2-27] INFO org.redisson.connection.pool.SlaveConnectionPool - 24 connections initialized for 172.31.41.2/172.31.41.2:6379
[redisson-netty-2-32] INFO org.redisson.connection.pool.MasterConnectionPool - 24 connections initialized for 172.31.30.1/172.31.30.1:6379

When the added sentinel and the master fail, even if fail over happens normally with the other 2 sentinels, redisson dont reconnect.
Steps to reproduce or test case
Configure de redisson with Tomcat 9
Redis version
5.0.5
Redisson version
3.11.1
Redisson configuration
{
   "sentinelServersConfig":{
      "idleConnectionTimeout":10000,
      "connectTimeout":10000,
      "timeout":3000,
      "retryAttempts":3,
      "retryInterval":1500,
      "failedSlaveReconnectionInterval":3000,
      "failedSlaveCheckInterval":60000,
      "password":null,
      "subscriptionsPerConnection":5,
      "clientName":null,
      "loadBalancer":{
         "class":"org.redisson.connection.balancer.RoundRobinLoadBalancer"
      },
      "subscriptionConnectionMinimumIdleSize":1,
      "subscriptionConnectionPoolSize":50,
      "slaveConnectionMinimumIdleSize":24,
      "slaveConnectionPoolSize":64,
      "masterConnectionMinimumIdleSize":24,
      "masterConnectionPoolSize":64,
      "readMode":"SLAVE",
      "subscriptionMode":"SLAVE",
      "sentinelAddresses":[
         "redis://172.31.30.1:26379",
         "redis://172.31.41.2:26379",
         "redis://172.31.4.2:26379"
      ],
      "masterName":"mymaster",
      "database":0
   },
   "threads":16,
   "nettyThreads":32,
   "codec":{
      "class":"org.redisson.codec.FstCodec"
   },
   "transportMode":"NIO"
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2322
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
RRateLimiter does not have a setRate/setRateAsync method.
It only has trySetRate/trySetRateAsync methods, so once a rate-limiter's config is persisted to Redis, it cannot be overwritten.
Actual behavior
Invoking RRateLimiter.trySetRate twice with different rate-limiter configuration values does not overwrite, since it uses HSETNX instead of HSET operation.
Steps to reproduce or test case
RRateLimiter rateLimiter = redisson.getRateLimiter("myRateLimiter");
boolean success;
success = rateLimiter.trySetRate(RateType.OVERALL, 1, 1, RateIntervalUnit.SECONDS);
System.out.println(success); // "true"
success = rateLimiter.trySetRate(RateType.OVERALL, 2, 2, RateIntervalUnit.SECONDS);
System.out.println(success); // "false"

There is no way to overwrite the existing "myRateLimiter" with a different rate, besides modifying the rate limiter name
Redis version
4.0.11
Redisson version
3.11.2
Redisson configuration
N/A
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2323
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@mrniko I am aware you have proposed some workarounds in #2322, but I am curious what the opposition to this change is.  Would you be willing to elaborate further on why this change is not acceptable?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2324
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2325
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I use a semaphore in a complex system with 300 permits while the background workflow has 1000 concurrent requests. It takes about 7ms for processing after permit acquired.
For unfair semaphore, the delay for acquiring the permit is less than 1ms while delay for fair semaphore is more than 30ms.
I understand unfair semaphore may have a slightly better performance. But why it differs so much?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2326
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
<dependency> <groupId>org.springframework.data</groupId> <artifactId>spring-data-redis</artifactId> </dependency> <dependency> <groupId>org.redisson</groupId> <artifactId>redisson-spring-data-18</artifactId> <version>3.11.3</version> <exclusions> <exclusion> <groupId>net.bytebuddy</groupId> <artifactId>byte-buddy</artifactId> </exclusion> </exclusions> </dependency> <dependency> <groupId>net.bytebuddy</groupId> <artifactId>byte-buddy</artifactId> <version>1.8.17</version> </dependency>
org.redisson.spring.session.RedissonSessionRepository

Actual behavior

Steps to reproduce or test case
Redis version
4.0.1
Redisson version
3.11.3
Redisson configuration
 <contenxt:property-placeholder location="classpath*:application.properties"/> <bean id="stringCodec" class="org.redisson.client.codec.StringCodec"/> <redisson:client id="sentinelRedisClient" codec-ref="stringCodec" > <redisson:sentinel-servers master-name="${redisson.master_name}"  database="0" password="${redisson.pwd}" connect-timeout="60000" master-connection-pool-size="30" master-connection-minimum-idle-size="10"> <redisson:sentinel-address value="${redisson.node1}" /> <redisson:sentinel-address value="${redisson.node2}" /> <redisson:sentinel-address value="${redisson.node3}" /> </redisson:sentinel-servers> </redisson:client>
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2327
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2328
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
2019-09-19 08:58:14.374 o.r.c.ClusterConnectionManager redisson-netty-2-7 [INFO] 16384 slots added to redis://10.1.135.28:6379
2019-09-19 08:58:14.374 o.r.c.ClusterConnectionManager redisson-netty-2-7 [INFO] 16384 slots removed from redis://10.1.135.28:6379
2019-09-19 08:58:14.374 o.r.c.ClusterConnectionManager redisson-netty-2-7 [INFO] 10944 slots added to redis://10.1.135.70:6379
2019-09-19 08:58:14.374 o.r.c.ClusterConnectionManager redisson-netty-2-7 [INFO] 10944 slots removed from redis://10.1.135.70:6379
2019-09-19 08:58:14.374 o.r.c.ClusterConnectionManager redisson-netty-2-7 [INFO] 5504 slots added to redis://10.1.135.127:6379
2019-09-19 08:58:14.374 o.r.c.ClusterConnectionManager redisson-netty-2-7 [INFO] 5504 slots removed from redis://10.1.135.127:6379
2019-09-19 08:58:14.375 o.r.c.ClusterConnectionManager redisson-netty-2-7 [INFO] 24576 slots found to add
2019-09-19 08:58:19.387 o.r.c.ClusterConnectionManager redisson-netty-2-30 [INFO] 16384 slots added to redis://10.1.135.28:6379
2019-09-19 08:58:19.388 o.r.c.ClusterConnectionManager redisson-netty-2-30 [INFO] 16384 slots removed from redis://10.1.135.28:6379
2019-09-19 08:58:19.388 o.r.c.ClusterConnectionManager redisson-netty-2-30 [INFO] 10944 slots added to redis://10.1.135.70:6379
2019-09-19 08:58:19.388 o.r.c.ClusterConnectionManager redisson-netty-2-30 [INFO] 10944 slots removed from redis://10.1.135.70:6379
2019-09-19 08:58:19.388 o.r.c.ClusterConnectionManager redisson-netty-2-30 [INFO] 5504 slots added to redis://10.1.135.127:6379
2019-09-19 08:58:19.388 o.r.c.ClusterConnectionManager redisson-netty-2-30 [INFO] 5504 slots removed from redis://10.1.135.127:6379
2019-09-19 08:58:19.389 o.r.c.ClusterConnectionManager redisson-netty-2-30 [INFO] 24576 slots found to add
2019-09-19 08:58:24.402 o.r.c.ClusterConnectionManager redisson-netty-2-17 [INFO] 16384 slots added to redis://10.1.135.28:6379
2019-09-19 08:58:24.402 o.r.c.ClusterConnectionManager redisson-netty-2-17 [INFO] 16384 slots removed from redis://10.1.135.28:6379
2019-09-19 08:58:24.403 o.r.c.ClusterConnectionManager redisson-netty-2-17 [INFO] 10944 slots added to redis://10.1.135.70:6379
2019-09-19 08:58:24.403 o.r.c.ClusterConnectionManager redisson-netty-2-17 [INFO] 10944 slots removed from redis://10.1.135.70:6379
2019-09-19 08:58:24.403 o.r.c.ClusterConnectionManager redisson-netty-2-17 [INFO] 5504 slots added to redis://10.1.135.127:6379
2019-09-19 08:58:24.403 o.r.c.ClusterConnectionManager redisson-netty-2-17 [INFO] 5504 slots removed from redis://10.1.135.127:6379
2019-09-19 08:58:24.404 o.r.c.ClusterConnectionManager redisson-netty-2-17 [INFO] 24576 slots found to add
2019-09-19 08:58:29.416 o.r.c.ClusterConnectionManager redisson-netty-2-5 [INFO] 16384 slots added to redis://10.1.135.28:6379
2019-09-19 08:58:29.416 o.r.c.ClusterConnectionManager redisson-netty-2-5 [INFO] 16384 slots removed from redis://10.1.135.28:6379
2019-09-19 08:58:29.417 o.r.c.ClusterConnectionManager redisson-netty-2-5 [INFO] 10944 slots added to redis://10.1.135.70:6379
2019-09-19 08:58:29.417 o.r.c.ClusterConnectionManager redisson-netty-2-5 [INFO] 10944 slots removed from redis://10.1.135.70:6379
2019-09-19 08:58:29.417 o.r.c.ClusterConnectionManager redisson-netty-2-5 [INFO] 5504 slots added to redis://10.1.135.127:6379
2019-09-19 08:58:29.417 o.r.c.ClusterConnectionManager redisson-netty-2-5 [INFO] 5504 slots removed from redis://10.1.135.127:6379
2019-09-19 08:58:29.418 o.r.c.ClusterConnectionManager redisson-netty-2-5 [INFO] 20480 slots found to add
2019-09-19 08:58:34.430 o.r.c.ClusterConnectionManager redisson-netty-2-17 [INFO] 16384 slots added to redis://10.1.135.28:6379
2019-09-19 08:58:34.431 o.r.c.ClusterConnectionManager redisson-netty-2-17 [INFO] 16384 slots removed from redis://10.1.135.28:6379
2019-09-19 08:58:34.431 o.r.c.ClusterConnectionManager redisson-netty-2-17 [INFO] 10944 slots added to redis://10.1.135.70:6379
2019-09-19 08:58:34.431 o.r.c.ClusterConnectionManager redisson-netty-2-17 [INFO] 10944 slots removed from redis://10.1.135.70:6379
2019-09-19 08:58:34.432 o.r.c.ClusterConnectionManager redisson-netty-2-17 [INFO] 5504 slots added to redis://10.1.135.127:6379
2019-09-19 08:58:34.432 o.r.c.ClusterConnectionManager redisson-netty-2-17 [INFO] 5504 slots removed from redis://10.1.135.127:6379
2019-09-19 08:58:34.433 o.r.c.ClusterConnectionManager redisson-netty-2-17 [INFO] 16384 slots found to add
2019-09-19 08:58:39.446 o.r.c.ClusterConnectionManager redisson-netty-2-17 [INFO] 16384 slots added to redis://10.1.135.28:6379
2019-09-19 08:58:39.446 o.r.c.ClusterConnectionManager redisson-netty-2-17 [INFO] 16384 slots removed from redis://10.1.135.28:6379
2019-09-19 08:58:39.447 o.r.c.ClusterConnectionManager redisson-netty-2-17 [INFO] 10944 slots added to redis://10.1.135.70:6379
2019-09-19 08:58:39.447 o.r.c.ClusterConnectionManager redisson-netty-2-17 [INFO] 10944 slots removed from redis://10.1.135.70:6379
2019-09-19 08:58:39.447 o.r.c.ClusterConnectionManager redisson-netty-2-17 [INFO] 5504 slots added to redis://10.1.135.127:6379
2019-09-19 08:58:39.447 o.r.c.ClusterConnectionManager redisson-netty-2-17 [INFO] 5504 slots removed from redis://10.1.135.127:6379
2019-09-19 08:58:39.448 o.r.c.ClusterConnectionManager redisson-netty-2-17 [INFO] 16384 slots found to add
Steps to reproduce or test case
Redis version
3.2.10
Redisson version
3.11.2
Redisson configuration
Config config = new Config();
config.useClusterServers().setTimeout(timeout);
for(String host : hosts.split(",")) {
    config.useClusterServers().addNodeAddress("redis://" + host);
}

this.redisson = Redisson.create(config);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2329
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2330
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi  ,
I am using following code :
Config config = new Config();
config.useSingleServer().setAddress("redis://127.0.0.1:6379");
client = Redisson.create(config);
RMapCache<String,String >map = client.getMapCache("TestMap1");
RFuture result =mapCache.putAsync("5","6");
I can get the same value back using redisson , But when i see all values using redis-cli , i see following:
:~$ redis-cli -h 127.0.0.1 -p 6379
127.0.0.1:6379> hgetall  TestMap1

"\xf7\x01"
"\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\xfc\x03abc"
"\x00\x01\x1eorg.redisson.RedissonReference\xfc(org.redisson.client.codec.ByteArrayCodec\xfc\x011\xfc\x1eorg.redisson.api.RBinaryStream\x00"
"\x00\x00\x00\x00\x00\x00\x00\x00\x06\x00\x00\x00\x00\x00\x00\x00\xfb$\x03abc"

How could i avoid this serialization or encoding of data so that i can access the data using some other redisson client ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2331
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Session xxxxxxxxxxxxxx can't be found
Expected behavior
get session from redission
Actual behavior
Sep 20, 2019 2:31:33 PM org.redisson.tomcat.RedissonSessionManager findSession INFO: Session 2905FF64FAF76CCF89DC2FF4CDE7BFB9 can't be found Sep 20, 2019 2:31:33 PM org.redisson.tomcat.RedissonSessionManager findSession INFO: Session 2905FF64FAF76CCF89DC2FF4CDE7BFB9 can't be found Sep 20, 2019 2:31:33 PM org.redisson.tomcat.RedissonSessionManager findSession INFO: Session 2905FF64FAF76CCF89DC2FF4CDE7BFB9 can't be found Sep 20, 2019 2:31:33 PM org.redisson.tomcat.RedissonSessionManager findSession INFO: Session 2905FF64FAF76CCF89DC2FF4CDE7BFB9 can't be found {"valid":false,"currentSessionId":"0F7CC0D1A51C285102F4BD3A68B7F858","sessionIdFromCookie":"2905FF64FAF76CCF89DC2FF4CDE7BFB9","fromCookie":true,"url":"http://xxx.xxx.xxx/back/"} {"valid":true,"currentSessionId":"0F7CC0D1A51C285102F4BD3A68B7F858","sessionIdFromCookie":"0F7CC0D1A51C285102F4BD3A68B7F858","fromCookie":true,"url":"http://xxx.xxx.xxx/goh5.min.css"}
But i found key 'redission:tomcat_session:2905FF64FAF76CCF89DC2FF4CDE7BFB9' in redis client
Steps to reproduce or test case
1、restart tomcat
2、access other tomcat
Redis version
3.0.5
Redisson version
2.15.2
Redisson configuration
{ "singleServerConfig":{ "idleConnectionTimeout":10000, "pingTimeout":1000, "connectTimeout":10000, "timeout":3000, "retryAttempts":3, "retryInterval":1500, "password":"exam", "subscriptionsPerConnection":5, "clientName":"cloud-search-session", "address": "redis://10.31.145.19:6380", "subscriptionConnectionMinimumIdleSize":1, "subscriptionConnectionPoolSize":50, "connectionMinimumIdleSize":10, "connectionPoolSize":64, "database":8, "dnsMonitoringInterval":5000, "keepAlive":true, "pingConnectionInterval":60000 }, "threads":0, "nettyThreads":0, "codec":{ "class":"org.redisson.codec.JsonJacksonCodec" }, "transportMode":"NIO" }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2332
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Dear all,
I tried to test with redisson lib but I saw lack of basic example.
In redis I set String value, for example SET testkey testvalue.
How can I use redisson to get  the String value of testkey?
Here are my code:
public static void main(String[] args) {
Config config = new Config();
// use single Redis server
config.useSingleServer().setAddress("redis://IP:6379");
RedissonClient redisson = Redisson.create(config);
	// perform operations
	RBucket<String> bucket = redisson.getBucket("testkey");
	System.out.println("Value of testkey: " + bucket.get());
    
	//shutdown 
	redisson.shutdown();
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2333
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
The redisson should reconnect and query without exceptions, after the slave restarted.
Actual behavior
After the slave node restarted successfully, the server using redisson v2.13.1 printed logs like ClusterConnectionManager.java:245 | - slaves: [redis://x.x.x.x:x] added for slot ranges:[[x-x]] , and I took it as redisson had reconnected to the slave node. However, when the server queried data in this node, there were expections:
org.redisson.client.RedisConnectionException: RedisConnection@xxxx [redisClient=[addr=redis://x.x.x.x:x], channel=[id: xxxx, L:x.x.x.x/x.x.x.x:xxxx]] is not active!
	at org.redisson.connection.pool.ConnectionPool.promiseFailure(ConnectionPool.java:323)
	at org.redisson.connection.pool.ConnectionPool.connectTo(ConnectionPool.java:253)
	at org.redisson.connection.pool.ConnectionPool.access$300(ConnectionPool.java:53)
	at org.redisson.connection.pool.ConnectionPool$3.run(ConnectionPool.java:214)
	at org.redisson.pubsub.AsyncSemaphore.acquire(AsyncSemaphore.java:142)
	at org.redisson.pubsub.AsyncSemaphore.acquire(AsyncSemaphore.java:125)
	at org.redisson.connection.ClientConnectionsEntry.acquireConnection(ClientConnectionsEntry.java:134)
	at org.redisson.connection.pool.ConnectionPool.acquireConnection(ConnectionPool.java:161)
	at org.redisson.connection.pool.ConnectionPool.acquireConnection(ConnectionPool.java:224)
	at org.redisson.connection.pool.ConnectionPool.get(ConnectionPool.java:172)
	at org.redisson.connection.pool.SlaveConnectionPool.get(SlaveConnectionPool.java:30)
	at org.redisson.connection.balancer.LoadBalancerManager.nextConnection(LoadBalancerManager.java:244)
	at org.redisson.connection.MasterSlaveEntry.connectionReadOp(MasterSlaveEntry.java:457)
	at org.redisson.connection.MasterSlaveConnectionManager.connectionReadOp(MasterSlaveConnectionManager.java:576)
	at org.redisson.command.CommandAsyncService.getConnection(CommandAsyncService.java:679)
	at org.redisson.command.CommandAsyncService.async(CommandAsyncService.java:536)
	at org.redisson.command.CommandAsyncService$8.run(CommandAsyncService.java:625)
	at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:670)
	at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:745)
	at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:473)
	at java.lang.Thread.run(Thread.java:748)

By contrast, the servers using redisson v3.7.3 recovered as expected.
Steps to reproduce or test case
The redis cluster are composed of 3 masters with 3 slaves.
I did cluster failover on the slave, after the master and slave switched successfully, i did shutdown and restarted the server. After the operations, the redisson threw exceptions when queried the restarted redis node, and could not recovered automatically in half an hour.
Redis version
3.2.9
Redisson version
Exception version：2.13.1
Right version：3.7.3
Redisson configuration
We are using recommend parameters in redisson wiki, here are 2 key parameters：
{
  "clusterServerConfig": {
    "idleConnectionTimeout": 10000,
    ...,
    "readMode": "SLAVE",
    ...
  }
}

Other problems
After master-slave switch and restart slave node, I found all redisson(v2.13.1 and v3.7.3) connections increased significantly(almost twice as normal connections), and config timeout set xxx was useless. When i restarted the servers, the redisson connections were back to normal. So is there a reason that redisson do no release idle connections for a long time?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2334
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In RedissionSessionManager.findSession()
source code：
RedissonSession session = (RedissonSession) createEmptySession();
session.setId(id);
session.setManager(this);
session.load(attrs);

Session.setId() will sync data to redis, but before session.setId() , the isValid is not initialized. Maybe execute session.load(atttr) before session.setId() can fix this BUG.

RedissonSession session = (RedissonSession) createEmptySession();
session.load(attrs);
session.setId(id);
session.setManager(this);

Expected behavior
Session is valid
Actual behavior
Session is invalid
Steps to reproduce or test case
1、access tomcat A, createSession
2、access tomcat B, findSession
Redis version
ignore
Redisson version
ignore
Redisson configuration
ignore
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2335
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Call RSet.getSize() returns set size of N, and a subsequent call to RSet.iterator(batchSize) allows you to iterate through all N items.
Actual behavior
Call RSet.getSize() returns set size of N, and a subsequent call to RSet.iterator(batchSize) returns an iterator that has no items to iterate through.  Without (first) getting the size, the iterator will iterate through the set of N elements.  For some reason, getting the size (first) makes the set appear to be empty, and there seems to be no method to "reset" to the head of the set, if this is, indeed, what is happening.  Another detail that may also be notable is that, each time I restart my application, RSet.size() returns the expected size, so the data is not being removed with a call to get the cardinality of the set.
Steps to reproduce or test case
Get a set by calling RSet testSet = RedissonClient.getSet("testSet");
Add items to the set with testSet.addAll(Arrays.asList("1", "2", "3", "4", "5"));
Get the set size with int testSetSize = RSet.size();
The size of testSetSize == 5.
Get an iterator with testSet.iterator(5);
Attempt to iterate over the set, but there will be no items to iterate over.
Redis version
4.0.8
Redisson version
3.11.3
Redisson configuration
Config config = new Config();
config.setCodec(new KryoCodec)
.useMasterSlaveServers()
.setMasterAddress("redis://192.168.0.2")
.addSlaveAddress("redis://192.168.0.3")
.addSlaveAddress("redis://192.168.0.4")
.setReadMode(ReadMode.MASTER_SLAVE)
.setDatabase(1)
.setTimeout(FIVE_MINUTES)
return Redisson.create(config);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2336
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In my Kubernetes setup, REDIS pods get created as following..
`
crdb-crdb-redisio-sentinel-0                    1/1     Running                 0          39d    12.18.1.222   samt-worker-02   
crdb-crdb-redisio-sentinel-1                    1/1     Running                 0          54d    12.18.1.147   samt-worker-03   
crdb-crdb-redisio-sentinel-2                    1/1     Running                 0          39d    12.18.1.191   samt-worker-01   
crdb-crdb-redisio-server-0                      3/3     Running                 0          54d    12.18.1.156   samt-worker-03   
crdb-crdb-redisio-server-1                      3/3     Running                 0          39d    12.18.1.187   samt-worker-01   
crdb-crdb-redisio-server-2                      3/3     Running                 0          39d    12.18.1.215
samt-worker-02   
`
So 1 master and few slaves
Output of "kubectl get svc" is like:
`
crdb-crdb-redisio                      ClusterIP   10.254.111.38            6379/TCP                                                                                    54d    app=crdb-crdb-redisio,crdb-dbtype=redisio,csf-component=crdb,csf-subcomponent=redisio,heritage=Tiller,redisio_role=master,release=crdb,type=server
crdb-crdb-redisio-readonly             ClusterIP   10.254.211.116           6379/TCP                                                                                    54d    app=crdb-crdb-redisio,crdb-dbtype=redisio,csf-component=crdb,csf-subcomponent=redisio,heritage=Tiller,redisio_role=slave,release=crdb,type=server
`
Expected behavior
I want to connect to both master-slave via Raddison client
Actual behavior
I'm not sure how though because there are like following ways!
config.useClusterServers().
config.useSingleServer().
config.useMasterSlaveServers()
Steps to reproduce or test case
Redis version
not sure
Redisson version
3.3.0
Redisson configuration
This is what i am confused with
Could you please provide a sample code on how best to connect to Redis with master slave configuration?
master could become slave and vice versa so how dynamically Raddision would take care of this switch?
IPs of service needs to be configured or IPs of pods?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2337
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redisson session key is keeps increasing rapidly, now there are 300,000 key in redis, but HttpSessionListener can't get any sessionCreated even.
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
4
Redisson version
2.15.2
Redisson configuration
ignore
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2338
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I found that redisson-lock can not run well on aliyun-redis which cluster by proxy like code or twemproxy. Does anyone occour this problem?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2339
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
You can use it via Redisson.createBatch method. It accumulates all invoked commands in one batch command.
Originally posted by @mrniko in #263 (comment)
How can we exactly do that?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2340
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
需要整合zipkin做链路跟踪，发现Redisson没有提供对应的扩展点
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2341
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Here is an example https://github.com/redisson/redisson/wiki/10.-additional-features#103-execution-batches-of-commands
Originally posted by @mrniko in #2339 (comment)
I tried using RedissonClient.createBatch(), its returning null. Whereas,      RBucket getBucket(String name) is working fine.
Can't figure out the issue behind this. I am extending RedissonClient and initialised its constructor.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2342
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2343
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
While trying to track down an issue we had with AWS Elasticache redis + Redisson and a botched failover, this question came up -- "What is the difference between config.useReplicatedServers() and config.useMasterSlaveServers()?
The documentation suggests that ReplicatedServers is the right choice for Elasticache but doesn't go into more details. Thoughts?
Thanks
Tony
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2344
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
我现在的业务是数据入库成功后更新redis，之前mysql事务是没开启的。我的想法是mysql事务和redis事务都开启，当db入库成功后存redis缓存，否则一起回滚。
刚才试了下，貌似RedissonTransactionManager无法和DataSourceTransactionManager共存，不知大家有没有解决方案
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2345
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@component
public class RedisMessageListenerConfig {
@Bean
RedisMessageListenerContainer container(RedisConnectionFactory connectionFactory,
                                        @Autowired @Qualifier("cacheHandlerAdapter") MessageListenerAdapter cacheHandlerAdapter,
                                        @Autowired @Qualifier("cacheHandlerAdapter1") MessageListenerAdapter cacheHandlerAdapter1) {
    RedisMessageListenerContainer container = new RedisMessageListenerContainer();
    container.setConnectionFactory(connectionFactory);
    container.addMessageListener(cacheHandlerAdapter, topic());
    container.addMessageListener(cacheHandlerAdapter1, topic1());

    return container;
}

@Bean
MessageListenerAdapter cacheHandlerAdapter(CachePurgeHandler cachePurgeHandler) {
    return new MessageListenerAdapter(cachePurgeHandler);
}

@Bean
MessageListenerAdapter cacheHandlerAdapter1(CachePurgeHandler1 cachePurgeHandler1) {
    return new MessageListenerAdapter(cachePurgeHandler1);
}

@Bean
ChannelTopic topic() {
    return new ChannelTopic("CACHE_PURGE");
}

@Bean
ChannelTopic topic1() {
    return new ChannelTopic("messageQueue");
}

}
Expected behavior
the listener execute multi times as the topics` size
Actual behavior
execute one time
Steps to reproduce or test case
redis-cli> PUBLISH messageQueue "{"id": 4, "name": "xxoo"}"
Redis version
newest version
Redisson version
3.11.4
Redisson configuration
redis-spring-boot
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2346
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2347
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
While looking through the server logs of our application running on Microsoft Azure, I came across the UnknownHostException below. It seems to occur on average once or twice a day.
<04:58:48> [ERROR] [DNSMonitor] Unable to resolve app.redis.cache.windows.net
java.net.UnknownHostException: failed to resolve 'app.redis.cache.windows.net'
	at io.netty.resolver.dns.DnsResolveContext.finishResolve(DnsResolveContext.java:925) [netty-resolver-dns-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.resolver.dns.DnsResolveContext.tryToFinishResolve(DnsResolveContext.java:884) [netty-resolver-dns-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.resolver.dns.DnsResolveContext.query(DnsResolveContext.java:356) [netty-resolver-dns-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.resolver.dns.DnsResolveContext.access$600(DnsResolveContext.java:64) [netty-resolver-dns-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.resolver.dns.DnsResolveContext$2.operationComplete(DnsResolveContext.java:405) [netty-resolver-dns-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:570) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:549) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:608) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.resolver.dns.DnsQueryContext.setFailure(DnsQueryContext.java:228) [netty-resolver-dns-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.resolver.dns.DnsQueryContext.access$300(DnsQueryContext.java:42) [netty-resolver-dns-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.resolver.dns.DnsQueryContext$4.run(DnsQueryContext.java:177) [netty-resolver-dns-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:134) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:510) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:518) [netty-transport-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1044) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
Caused by: io.netty.resolver.dns.DnsNameResolverTimeoutException: [/127.0.0.11:53] query via UDP timed out after 5000 milliseconds (no stack trace available)

I found this issue which discusses a similar problem, but I am still seeing the error after upgrading to the latest version of Redisson.
Redis version
3.2.7
Redisson version
3.11.4
Redisson configuration
config.useSingleServer()
    .setAddress(PROTOCOL + HOST_PORT)
    .setPassword(PASSWORD)
    .setConnectTimeout(15000)
    .setConnectionMinimumIdleSize(32)
    .setConnectionPoolSize(32)
    .setRetryAttempts(3)
    .setRetryInterval(1500);
Any assistance would be much appreciated.
Thanks.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2348
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2349
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2350
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
For the Redisson executor and scheduled executor service, is there a way to get the count of pending tasks in the queue?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2351
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2352
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2353
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
DC's . in LN and US
Want primaries + slaves in US, just replicas in LN
Want Sentinel HA
Want to hit the primaries+slaves in US when runnng service on US, LN would only be used with reconfigure/failover.

But it looks like the connection pool will try to spread over all slaves?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2354
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When using RedissonTopic，subscribe sucess and when publish message, can subscribe message success. Bug after a few days,publish message success, but cannot subscribe message.
I found some errors in redis log:
[22387] 07 Oct 00:00:30.521 - Reading from client: Connection reset by peer
[22387] 07 Oct 00:00:30.521 - Reading from client: Connection reset by peer
[22387] 07 Oct 00:00:30.521 - Reading from client: Connection reset by peer
[22387] 07 Oct 00:00:30.521 - Reading from client: Connection reset by peer
There no error in my application.
redisson version is 3.10.0
RTopic topic = redissonClient.getTopic(CacheKeyUtil.getMyTopic());
listenerId = topic.addListener(RedisTopicModel.class, (channel, topicModel) -> {
LoggerUtil.info(getClass(), "redis topic listener,channel:{0},msg:{1}", channel, topicModel);
// do something
});
Is connection reset but no reconnect?How can I resolved ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2355
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Calls to RedissonLock.unlock() are expected to finish after the lock has been deleted from Redis.
Actual behavior
We have experienced several threads locked forever waiting inside calls to RedissonLock.unlock() in our production system within a few hours after upgrading to Redisson 3.11.4 from Redisson 3.8.0.
Steps to reproduce or test case
Unfortunately I am unable to reproduce the problem on my own computer. We have however experienced it on several of our production servers within just a few hours after starting our newer version of the application with updated Redisson version. We upgraded from 3.8.0 in order to receive fixes for bug #1966 - Deadlock after Redis timeout, which we also experienced a couple of times. However right after start we have found some (29) exceptions in our logs coming from internal redisson threads:
[redisson-netty-5-24] WARN  io.netty.util.concurrent.DefaultPromise - An exception was thrown by org.redisson.misc.RedissonPromise$$Lambda$50/265319658.operationComplete()
java.lang.NullPointerException: null
	at org.redisson.RedissonLock.cancelExpirationRenewal(RedissonLock.java:330) ~[redisson-3.11.4.jar:3.11.4]
	at org.redisson.RedissonLock.lambda$unlockAsync$3(RedissonLock.java:583) ~[redisson-3.11.4.jar:3.11.4]
	at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:187) ~[redisson-3.11.4.jar:3.11.4]
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577) ~[netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:570) ~[netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:549) ~[netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490) ~[netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615) ~[netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604) ~[netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104) ~[netty-common-4.1.41.Final.jar:4.1.41.Final]
	at org.redisson.misc.RedissonPromise.trySuccess(RedissonPromise.java:82) ~[redisson-3.11.4.jar:3.11.4]
	at org.redisson.command.RedisExecutor.handleReference(RedisExecutor.java:505) ~[redisson-3.11.4.jar:3.11.4]
	at org.redisson.command.RedisExecutor.handleSuccess(RedisExecutor.java:498) ~[redisson-3.11.4.jar:3.11.4]
	at org.redisson.command.RedisExecutor.handleResult(RedisExecutor.java:483) ~[redisson-3.11.4.jar:3.11.4]
	at org.redisson.command.RedisExecutor.checkAttemptPromise(RedisExecutor.java:469) ~[redisson-3.11.4.jar:3.11.4]
	at org.redisson.command.RedisExecutor.lambda$execute$3(RedisExecutor.java:187) ~[redisson-3.11.4.jar:3.11.4]
	at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:187) ~[redisson-3.11.4.jar:3.11.4]
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:570) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:549) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at org.redisson.misc.RedissonPromise.trySuccess(RedissonPromise.java:82) [redisson-3.11.4.jar:3.11.4]
	at org.redisson.client.handler.CommandDecoder.completeResponse(CommandDecoder.java:454) [redisson-3.11.4.jar:3.11.4]
	at org.redisson.client.handler.CommandDecoder.handleResult(CommandDecoder.java:449) [redisson-3.11.4.jar:3.11.4]
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:372) [redisson-3.11.4.jar:3.11.4]
	at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:209) [redisson-3.11.4.jar:3.11.4]
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:147) [redisson-3.11.4.jar:3.11.4]
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:117) [redisson-3.11.4.jar:3.11.4]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:505) [netty-codec-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) [netty-codec-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:283) [netty-codec-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374) [netty-transport-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360) [netty-transport-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352) [netty-transport-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1422) [netty-transport-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374) [netty-transport-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360) [netty-transport-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:931) [netty-transport-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) [netty-transport-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:700) [netty-transport-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:635) [netty-transport-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:552) [netty-transport-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:514) [netty-transport-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1044) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-common-4.1.41.Final.jar:4.1.41.Final]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_151]

After that we were investigating issues with blocked threads by analyzing thread dumps. All stuck threads had exactly the same stack trace as below:
 rabbitmq-thread-1awaiting notification on [ 0x00000005e298c400 ] , holding [ 0x00000005cad3ebd0 ]
at java.lang.Object.wait(Native Method)
at java.lang.Object.wait(Object.java:502)
at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:252)
at org.redisson.misc.RedissonPromise.await(RedissonPromise.java:110)
at org.redisson.misc.RedissonPromise.await(RedissonPromise.java:35)
at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:132)
at org.redisson.RedissonObject.get(RedissonObject.java:90)
at org.redisson.RedissonLock.unlock(RedissonLock.java:453)
at ... (our code goes below)

After examining the source code of RedissonLock.java we have found that the NullPointerException occurs probably due to missing timeout object inside task:
329:        if (threadId == null || task.hasNoThreads()) {
330:            task.getTimeout().cancel();
331:            EXPIRATION_RENEWAL_MAP.remove(getEntryName());
332:        }
I'm not sure if it would solve the root cause why task.getTimeout() returns null, but calls to cancelExpirationRenewal method should not fail with an exception, otherwise, e.g. in RedissonLock.unlockAsync method the future will never receive a result (or a failure):
    @Override
    public RFuture<Void> unlockAsync(long threadId) {
        RPromise<Void> result = new RedissonPromise<Void>();
        RFuture<Boolean> future = unlockInnerAsync(threadId);

        future.onComplete((opStatus, e) -> {
            if (e != null) {
                cancelExpirationRenewal(threadId);
                result.tryFailure(e);
                return;
            }

            if (opStatus == null) {
                IllegalMonitorStateException cause = new IllegalMonitorStateException("attempt to unlock lock, not locked by current thread by node id: "
                        + id + " thread-id: " + threadId);
                result.tryFailure(cause);
                return;
            }
            
            cancelExpirationRenewal(threadId);
            result.trySuccess(null);
        });

        return result;
    }
Please add null check for timeout inside the ExpirationEntry object.
We had to return to 3.8.0 version because of this problem. I think it is quire severe.
Redis version
4.0.2
Redisson version
3.11.4
Redisson configuration
Default configuration with sentinel servers.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2356
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
Redisson version
3.11.0
Redisson configuration
AtomicDouble这个方法去计算浮点是不精确的是不是考虑BigDecimal借鉴一下？
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2357
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am getting following exception sometimes in my tomcat app which uses redisson client to connect to AWS Redis. it says java.lang.ClassNotFoundException: com.sun.proxy.$Proxy222 but I have all the jar files in the classpath. Could someone shed some light on this. Thanks
org.redisson.client.RedisException: Unexpected exception while processing command
	org.redisson.command.CommandAsyncService.convertException(CommandAsyncService.java:403)
	org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:200)
	org.redisson.RedissonObject.get(RedissonObject.java:87)
	org.redisson.RedissonMap.readAllMap(RedissonMap.java:528)
	org.redisson.tomcat.RedissonSessionManager.findSession(RedissonSessionManager.java:149)
	org.apache.catalina.connector.Request.doGetSession(Request.java:2913)
	org.apache.catalina.connector.Request.getSession(Request.java:2310)
	org.apache.catalina.connector.RequestFacade.getSession(RequestFacade.java:897)
	javax.servlet.http.HttpServletRequestWrapper.getSession(HttpServletRequestWrapper.java:229)
	javax.servlet.http.HttpServletRequestWrapper.getSession(HttpServletRequestWrapper.java:229)
	javax.servlet.http.HttpServletRequestWrapper.getSession(HttpServletRequestWrapper.java:229)
	org.apache.struts2.dispatcher.SessionMap.<init>(SessionMap.java:62)
	org.apache.struts2.dispatcher.Dispatcher.createContextMap(Dispatcher.java:645)
	org.apache.struts2.dispatcher.ng.PrepareOperations.createActionContext(PrepareOperations.java:82)
	org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter.doFilter(StrutsPrepareAndExecuteFilter.java:89)
	com.org.tester.web.filters.TesterSecurityWrapperFilter.doFilter(testerSecurityWrapperFilter.java:51)
	com.org.tester.web.filters.CSRFFilter.doFilter(CSRFFilter.java:59)
	org.apache.logging.log4j.web.Log4jServletFilter.doFilter(Log4jServletFilter.java:64)
	com.org.tester.web.filters.ServiceBoundryInitFilter.doFilter(ServiceBoundryInitFilter.java:109)
	com.org.tester.web.filters.TesterSecurityWrapperFilter.doFilter(testerSecurityWrapperFilter.java:51)
	com.org.tester.web.filters.CSRFFilter.doFilter(CSRFFilter.java:59)
	org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	org.apache.logging.log4j.web.Log4jServletFilter.doFilter(Log4jServletFilter.java:71)
root cause

java.io.IOException: java.lang.RuntimeException: class not found CLASSNAME:com.sun.proxy.$Proxy222 loader:WebappClassLoader
  context: /orgv5
  delegate: false
  repositories:
    /WEB-INF/classes/
----------> Parent Classloader:
java.net.URLClassLoader@5e8f9e2d

	org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:247)
	org.redisson.codec.FstCodec$1.decode(FstCodec.java:70)
	org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:330)
	org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:380)
	org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:343)
	org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:130)
	org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:110)
	io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502)
	io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
	io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965)
	io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656)
	io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:591)
	io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:508)
	io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470)
	io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909)
	io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	java.lang.Thread.run(Thread.java:748)
root cause

java.lang.RuntimeException: class not found CLASSNAME:com.sun.proxy.$Proxy222 loader:WebappClassLoader
  context: /orgv5
  delegate: false
  repositories:
    /WEB-INF/classes/
----------> Parent Classloader:
java.net.URLClassLoader@5e8f9e2d

	org.nustaq.serialization.FSTClazzNameRegistry.classForName(FSTClazzNameRegistry.java:235)
	org.nustaq.serialization.FSTClazzNameRegistry.classForName(FSTClazzNameRegistry.java:190)
	org.nustaq.serialization.FSTClazzNameRegistry.decodeClass(FSTClazzNameRegistry.java:173)
	org.nustaq.serialization.coders.FSTStreamDecoder.readClass(FSTStreamDecoder.java:478)
	org.nustaq.serialization.FSTObjectInput.readClass(FSTObjectInput.java:939)
	org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:347)
	org.nustaq.serialization.FSTObjectInput.readObjectFields(FSTObjectInput.java:713)
	org.nustaq.serialization.FSTObjectInput.instantiateAndReadNoSer(FSTObjectInput.java:566)
	org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:374)
	org.nustaq.serialization.FSTObjectInput.readObjectFields(FSTObjectInput.java:713)
	org.nustaq.serialization.FSTObjectInput.readObjectCompatibleRecursive(FSTObjectInput.java:635)
	org.nustaq.serialization.FSTObjectInput.readObjectCompatible(FSTObjectInput.java:574)
	org.nustaq.serialization.FSTObjectInput.instantiateAndReadNoSer(FSTObjectInput.java:559)
	org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:374)
	org.nustaq.serialization.FSTObjectInput.readObjectFields(FSTObjectInput.java:713)
	org.nustaq.serialization.FSTObjectInput.instantiateAndReadNoSer(FSTObjectInput.java:566)
	org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:374)
	org.nustaq.serialization.FSTObjectInput.readObjectInternal(FSTObjectInput.java:331)
	org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:311)
	org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:245)
	org.redisson.codec.FstCodec$1.decode(FstCodec.java:70)
	org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:330)
	org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:380)
	org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:343)
	org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:130)
	org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:110)
	io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502)
	io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
	io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965)
	io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656)
	io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:591)
	io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:508)
	io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470)
	io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909)
	io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	java.lang.Thread.run(Thread.java:748)
root cause

java.lang.ClassNotFoundException: com.sun.proxy.$Proxy222
	org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1720)
	org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1571)
	java.lang.Class.forName0(Native Method)
	java.lang.Class.forName(Class.java:348)
	org.nustaq.serialization.FSTClazzNameRegistry.classForName(FSTClazzNameRegistry.java:197)
	org.nustaq.serialization.FSTClazzNameRegistry.classForName(FSTClazzNameRegistry.java:190)
	org.nustaq.serialization.FSTClazzNameRegistry.decodeClass(FSTClazzNameRegistry.java:173)
	org.nustaq.serialization.coders.FSTStreamDecoder.readClass(FSTStreamDecoder.java:478)
	org.nustaq.serialization.FSTObjectInput.readClass(FSTObjectInput.java:939)
	org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:347)
	org.nustaq.serialization.FSTObjectInput.readObjectFields(FSTObjectInput.java:713)
	org.nustaq.serialization.FSTObjectInput.instantiateAndReadNoSer(FSTObjectInput.java:566)
	org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:374)
	org.nustaq.serialization.FSTObjectInput.readObjectFields(FSTObjectInput.java:713)
	org.nustaq.serialization.FSTObjectInput.readObjectCompatibleRecursive(FSTObjectInput.java:635)
	org.nustaq.serialization.FSTObjectInput.readObjectCompatible(FSTObjectInput.java:574)
	org.nustaq.serialization.FSTObjectInput.instantiateAndReadNoSer(FSTObjectInput.java:559)
	org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:374)
	org.nustaq.serialization.FSTObjectInput.readObjectFields(FSTObjectInput.java:713)
	org.nustaq.serialization.FSTObjectInput.instantiateAndReadNoSer(FSTObjectInput.java:566)
	org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:374)
	org.nustaq.serialization.FSTObjectInput.readObjectInternal(FSTObjectInput.java:331)
	org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:311)
	org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:245)
	org.redisson.codec.FstCodec$1.decode(FstCodec.java:70)
	org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:330)
	org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:380)
	org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:343)
	org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:130)
	org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:110)
	io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502)
	io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
	io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965)
	io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656)
	io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:591)
	io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:508)
	io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470)
	io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909)
	io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	java.lang.Thread.run(Thread.java:748)
note The full stack trace of the root cause is available in the Apache Tomcat logs.```
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2358
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redisson version is 2.15.2，In a concurrent environment, the number of maps continues to grow, with 4000,000 pieces of data. When replaced by redisTemplate, only 100,000 pieces of data are run at the same time and remain unchanged. All data is set to an hour timeout
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2359
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2360
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have the next example https://github.com/kaa-ghub/redisson-sheduler.
Expected behavior
I assume there should be an API with which I could find out if there are running tasks for a given executor manager.
RScheduledExecutorService executor = redissonClient.getExecutorService("defaultExecutor");
Map<?> tasks = executor.getTasks();

Actual behavior
Each time when start the application, a new task is added and the running jobs are duplicated.
Steps to reproduce or test case
Run a example two or more times.
Redis version
5.0.3
Redisson version
3.11.2
Redisson configuration
https://github.com/kaa-ghub/redisson-sheduler/blob/master/config/application.yml
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2361
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
can use a different codec rather than the codec defined in config to encode and decode the object.
Actual behavior
it works when encoding, but doesn't work when decoding
Steps to reproduce or test case
        RBuckets buckets = client.getBuckets(StringCodec.INSTANCE);
        Map<String, String> items = buckets.get("buckets:A", "buckets:B", "buckets:C");

        items.put("buckets:A", "XYZ");
        items.put("buckets:B", "OPM");
        items.put("buckets:C", "123");

        buckets.set(items);
        items = buckets.get("buckets:A", "buckets:B", "buckets:C");
        Assert.assertEquals(3, items.size());
        Assert.assertEquals("XYZ", items.get("buckets:A")); // this line will be fail. because the value of this key is a byte array.
the issue should be in the CommandAsyncService.executeBatchedAsync function. when the Redis is not in cluster mode, the parameter codec is useless.
    private <T, R> RFuture<R> executeBatchedAsync(boolean readOnly, Codec codec, RedisCommand<T> command, SlotCallback<T, R> callback, String... keys) {
        if (!this.connectionManager.isClusterMode()) {
            return readOnly ? this.readAsync((String)null, command, keys) : this.writeAsync((String)null, command, keys); 
        } else {
            Map<MasterSlaveEntry, List<String>> range2key = new HashMap();
            String[] var7 = keys;
            int var8 = keys.length;

            ...
Redis version
5
Redisson version
3.11.4
Redisson configuration
        config = new Config();
        config.setCodec(ByteArrayCodec.INSTANCE)
              .useMasterSlaveServers()
              .setMasterAddress("redis://xxx.aws.com:6379")
              .addSlaveAddress("redis://xxx.aws.com:6379")
              .setConnectTimeout(5000)
              .setTimeout(2000)
              .setClientName("Tester")
              .setRetryInterval(500);


        client = Redisson.create(config);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2362
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
不会存在非常多的RedisConnection，堆内存、cpu正常
Actual behavior
存在非常多的RedisConnection，新生代，年老代都接近100%，cpu达到300%
Steps to reproduce or test case
Redis version
4.0.8
Redisson version
3.10.1
Redisson configuration
Config config = new Config();
config.setNettyThreads(0).setThreads(0).setCodec(new JsonJacksonCodec()).setReferenceEnabled(true);
config.useSingleServer()
.setAddress("redis://"+"ip".concat(":").concat(String.valueOf(port)))
.setDatabase(1)
.setPassword("password")
.setIdleConnectionTimeout(10000)
.setPingConnectionInterval(30000)
.setPingTimeout(1000)
.setConnectTimeout(10000)
.setTimeout(3000)
.setRetryAttempts(3)
.setRetryInterval(1500)
.setSubscriptionsPerConnection(5)
.setClientName("none")
.setSubscriptionConnectionMinimumIdleSize(1)
.setSubscriptionConnectionPoolSize(50)
.setConnectionPoolSize(64)
.setConnectionMinimumIdleSize(10)
.setDnsMonitoringInterval(5000);
RedissonClient redissonClient = Redisson.create(config);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2363
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
<dependency> <groupId>org.redisson</groupId> <artifactId>redisson-spring-data-18</artifactId> <version>3.11.3</version> <exclusions> <exclusion> <groupId>net.bytebuddy</groupId> <artifactId>byte-buddy</artifactId> </exclusion> </exclusions> </dependency> <dependency> <groupId>net.bytebuddy</groupId> <artifactId>byte-buddy</artifactId> <version>1.8.17</version> </dependency>
Steps to reproduce or test case
2019-10-15 10:15:26.640 | [redisson-netty-2-20] | [ERROR] | org.redisson.connection.SentinelConnectionManager - Can't execute SENTINEL commands on 10.145.0.227/10.145.0.227:26379 org.redisson.client.RedisTimeoutException: Command execution timeout for command: (SENTINEL GET-MASTER-ADDR-BY-NAME), params: [mymaster], Redis client: [addr=redis://10.145.0.227:26379] at org.redisson.client.RedisConnection$1.run(RedisConnection.java:209) at io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38) at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:127) at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163) at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:416) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:515) at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.lang.Thread.run(Thread.java:745) java.lang.OutOfMemoryError: GC overhead limit exceeded at java.lang.Long.toUnsignedString0(Long.java:356) at java.lang.Long.toHexString(Long.java:272) at io.netty.buffer.ByteBufUtil$HexUtil.<clinit>(ByteBufUtil.java:1023) at io.netty.buffer.ByteBufUtil.hexDump(ByteBufUtil.java:139) at io.netty.channel.DefaultChannelId.asShortText(DefaultChannelId.java:210) at io.netty.channel.AbstractChannel.toString(AbstractChannel.java:380) at org.slf4j.helpers.MessageFormatter.safeObjectAppend(MessageFormatter.java:299) at org.slf4j.helpers.MessageFormatter.deeplyAppendParameter(MessageFormatter.java:271) at org.slf4j.helpers.MessageFormatter.arrayFormat(MessageFormatter.java:233) at org.slf4j.helpers.MessageFormatter.arrayFormat(MessageFormatter.java:173) at ch.qos.logback.classic.spi.LoggingEvent.getFormattedMessage(LoggingEvent.java:293) at ch.qos.logback.classic.spi.LoggingEvent.prepareForDeferredProcessing(LoggingEvent.java:206) at ch.qos.logback.core.OutputStreamAppender.subAppend(OutputStreamAppender.java:205) at ch.qos.logback.core.OutputStreamAppender.append(OutputStreamAppender.java:100) at ch.qos.logback.core.UnsynchronizedAppenderBase.doAppend(UnsynchronizedAppenderBase.java:84) at ch.qos.logback.core.spi.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:51) at ch.qos.logback.classic.Logger.appendLoopOnAppenders(Logger.java:270) at ch.qos.logback.classic.Logger.callAppenders(Logger.java:257) at ch.qos.logback.classic.Logger.buildLoggingEventAndAppend(Logger.java:421) at ch.qos.logback.classic.Logger.filterAndLog_2(Logger.java:414) at ch.qos.logback.classic.Logger.warn(Logger.java:700) at org.redisson.client.handler.CommandDecoder.completeResponse(CommandDecoder.java:461) at org.redisson.client.handler.CommandDecoder.handleResult(CommandDecoder.java:455) at org.redisson.client.handler.CommandDecoder.decodeResult(CommandDecoder.java:444) at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:438) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:393) at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:215) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:153) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:122) at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:505) at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:283) 2019-10-15 10:15:26.646 | [redisson-netty-2-15] | [WARN ] | org.redisson.client.handler.CommandDecoder - response has been skipped due to timeout! channel: [FAILED toString()], command: (SENTINEL SENTINELS), params: [mymaster] SLF4J: Failed toString() invocation on an object of type [io.netty.channel.socket.nio.NioSocketChannel] Reported exception: java.lang.NoClassDefFoundError: Could not initialize class io.netty.buffer.ByteBufUtil$HexUtil at io.netty.buffer.ByteBufUtil.hexDump(ByteBufUtil.java:139) at io.netty.channel.DefaultChannelId.asShortText(DefaultChannelId.java:210) at io.netty.channel.AbstractChannel.toString(AbstractChannel.java:380) at org.slf4j.helpers.MessageFormatter.safeObjectAppend(MessageFormatter.java:299) at org.slf4j.helpers.MessageFormatter.deeplyAppendParameter(MessageFormatter.java:271) at org.slf4j.helpers.MessageFormatter.arrayFormat(MessageFormatter.java:233) at org.slf4j.helpers.MessageFormatter.arrayFormat(MessageFormatter.java:173) at ch.qos.logback.classic.spi.LoggingEvent.getFormattedMessage(LoggingEvent.java:293) at ch.qos.logback.classic.spi.LoggingEvent.prepareForDeferredProcessing(LoggingEvent.java:206) at ch.qos.logback.core.OutputStreamAppender.subAppend(OutputStreamAppender.java:205) at ch.qos.logback.core.OutputStreamAppender.append(OutputStreamAppender.java:100) at ch.qos.logback.core.UnsynchronizedAppenderBase.doAppend(UnsynchronizedAppenderBase.java:84) at ch.qos.logback.core.spi.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:51) at ch.qos.logback.classic.Logger.appendLoopOnAppenders(Logger.java:270) at ch.qos.logback.classic.Logger.callAppenders(Logger.java:257) at ch.qos.logback.classic.Logger.buildLoggingEventAndAppend(Logger.java:421) at ch.qos.logback.classic.Logger.filterAndLog_2(Logger.java:414) at ch.qos.logback.classic.Logger.warn(Logger.java:700) at org.redisson.client.handler.CommandDecoder.completeResponse(CommandDecoder.java:461) at org.redisson.client.handler.CommandDecoder.handleResult(CommandDecoder.java:455) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:340) at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:215) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:153) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:122) at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:505) at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:283) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352) at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1421) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:697) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632) at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511) at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.lang.Thread.run(Thread.java:745) 2019-10-15 10:15:31.600 | [redisson-netty-2-15] | [WARN ] | org.redisson.client.handler.CommandDecoder - response has been skipped due to timeout! channel: [FAILED toString()], command: (QUIT), params: [] SLF4J: Failed toString() invocation on an object of type [io.netty.channel.socket.nio.NioSocketChannel] Reported exception: java.lang.NoClassDefFoundError: Could not initialize class io.netty.buffer.ByteBufUtil$HexUtil at io.netty.buffer.ByteBufUtil.hexDump(ByteBufUtil.java:139) at io.netty.channel.DefaultChannelId.asShortText(DefaultChannelId.java:210) at io.netty.channel.AbstractChannel.toString(AbstractChannel.java:380) at org.slf4j.helpers.MessageFormatter.safeObjectAppend(MessageFormatter.java:299) at org.slf4j.helpers.MessageFormatter.deeplyAppendParameter(MessageFormatter.java:271) at org.slf4j.helpers.MessageFormatter.arrayFormat(MessageFormatter.java:233) at org.slf4j.helpers.MessageFormatter.arrayFormat(MessageFormatter.java:173) at ch.qos.logback.classic.spi.LoggingEvent.getFormattedMessage(LoggingEvent.java:293) at ch.qos.logback.classic.spi.LoggingEvent.prepareForDeferredProcessing(LoggingEvent.java:206) at ch.qos.logback.core.OutputStreamAppender.subAppend(OutputStreamAppender.java:205) at ch.qos.logback.core.OutputStreamAppender.append(OutputStreamAppender.java:100) at ch.qos.logback.core.UnsynchronizedAppenderBase.doAppend(UnsynchronizedAppenderBase.java:84) at ch.qos.logback.core.spi.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:51) at ch.qos.logback.classic.Logger.appendLoopOnAppenders(Logger.java:270) at ch.qos.logback.classic.Logger.callAppenders(Logger.java:257) at ch.qos.logback.classic.Logger.buildLoggingEventAndAppend(Logger.java:421) at ch.qos.logback.classic.Logger.filterAndLog_2(Logger.java:414) at ch.qos.logback.classic.Logger.warn(Logger.java:700) at org.redisson.client.handler.CommandDecoder.completeResponse(CommandDecoder.java:461) at org.redisson.client.handler.CommandDecoder.handleResult(CommandDecoder.java:455) at org.redisson.client.handler.CommandDecoder.decodeResult(CommandDecoder.java:444) at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:438) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:393) at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:215) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:153) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:122) at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:505) at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:283) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352) at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1421) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:697) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632) at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511) at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.lang.Thread.run(Thread.java:745) 2019-10-15 10:15:31.602 | [redisson-netty-2-15] | [WARN ] | org.redisson.client.handler.CommandDecoder - response has been skipped due to timeout! channel: [FAILED toString()], command: (SENTINEL GET-MASTER-ADDR-BY-NAME), params: [mymaster] SLF4J: Failed toString() invocation on an object of type [io.netty.channel.socket.nio.NioSocketChannel] Reported exception: java.lang.NoClassDefFoundError: Could not initialize class io.netty.buffer.ByteBufUtil$HexUtil at io.netty.buffer.ByteBufUtil.hexDump(ByteBufUtil.java:139) at io.netty.channel.DefaultChannelId.asShortText(DefaultChannelId.java:210) at io.netty.channel.AbstractChannel.toString(AbstractChannel.java:380) at org.slf4j.helpers.MessageFormatter.safeObjectAppend(MessageFormatter.java:299) at org.slf4j.helpers.MessageFormatter.deeplyAppendParameter(MessageFormatter.java:271) at org.slf4j.helpers.MessageFormatter.arrayFormat(MessageFormatter.java:233) at org.slf4j.helpers.MessageFormatter.arrayFormat(MessageFormatter.java:173) at ch.qos.logback.classic.spi.LoggingEvent.getFormattedMessage(LoggingEvent.java:293) at ch.qos.logback.classic.spi.LoggingEvent.prepareForDeferredProcessing(LoggingEvent.java:206) at ch.qos.logback.core.OutputStreamAppender.subAppend(OutputStreamAppender.java:205) at ch.qos.logback.core.OutputStreamAppender.append(OutputStreamAppender.java:100) at ch.qos.logback.core.UnsynchronizedAppenderBase.doAppend(UnsynchronizedAppenderBase.java:84) at ch.qos.logback.core.spi.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:51) at ch.qos.logback.classic.Logger.appendLoopOnAppenders(Logger.java:270) at ch.qos.logback.classic.Logger.callAppenders(Logger.java:257) at ch.qos.logback.classic.Logger.buildLoggingEventAndAppend(Logger.java:421) at ch.qos.logback.classic.Logger.filterAndLog_2(Logger.java:414) at ch.qos.logback.classic.Logger.warn(Logger.java:700) at org.redisson.client.handler.CommandDecoder.completeResponse(CommandDecoder.java:461) at org.redisson.client.handler.CommandDecoder.handleResult(CommandDecoder.java:455) at org.redisson.client.handler.CommandDecoder.decodeResult(CommandDecoder.java:444) at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:438) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:393) at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:215) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:153) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:122) at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:505) at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:283) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352) at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1421) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:697) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632) at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511) at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.lang.Thread.run(Thread.java:745) 2019-10-15 10:15:31.604 | [redisson-netty-2-15] | [WARN ] | org.redisson.client.handler.CommandDecoder - response has been skipped due to timeout! channel: [FAILED toString()], command: (SENTINEL SLAVES), params: [mymaster] 2019-10-15 10:15:31.606 | [[ACTIVE] ExecuteThread: '4' for queue: 'weblogic.kernel.Default (10.145.0.225:2181)] | [INFO ] | org.apache.zookeeper.ClientCnxn - Socket connection established to 10.145.0.225/10.145.0.225:2181, initiating session SLF4J: Failed toString() invocation on an object of type [io.netty.channel.socket.nio.NioSocketChannel] Reported exception: java.lang.NoClassDefFoundError: Could not initialize class io.netty.buffer.ByteBufUtil$HexUtil at io.netty.buffer.ByteBufUtil.hexDump(ByteBufUtil.java:139) at io.netty.channel.DefaultChannelId.asShortText(DefaultChannelId.java:210) at io.netty.channel.AbstractChannel.toString(AbstractChannel.java:380) at org.slf4j.helpers.MessageFormatter.safeObjectAppend(MessageFormatter.java:299) at org.slf4j.helpers.MessageFormatter.deeplyAppendParameter(MessageFormatter.java:271) at org.slf4j.helpers.MessageFormatter.arrayFormat(MessageFormatter.java:233) at org.slf4j.helpers.MessageFormatter.arrayFormat(MessageFormatter.java:173) at ch.qos.logback.classic.spi.LoggingEvent.getFormattedMessage(LoggingEvent.java:293) at ch.qos.logback.classic.spi.LoggingEvent.prepareForDeferredProcessing(LoggingEvent.java:206) at ch.qos.logback.core.OutputStreamAppender.subAppend(OutputStreamAppender.java:205) at ch.qos.logback.core.OutputStreamAppender.append(OutputStreamAppender.java:100) at ch.qos.logback.core.UnsynchronizedAppenderBase.doAppend(UnsynchronizedAppenderBase.java:84) at ch.qos.logback.core.spi.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:51) at ch.qos.logback.classic.Logger.appendLoopOnAppenders(Logger.java:270) at ch.qos.logback.classic.Logger.callAppenders(Logger.java:257) at ch.qos.logback.classic.Logger.buildLoggingEventAndAppend(Logger.java:421) at ch.qos.logback.classic.Logger.filterAndLog_2(Logger.java:414) at ch.qos.logback.classic.Logger.warn(Logger.java:700) at org.redisson.client.handler.CommandDecoder.completeResponse(CommandDecoder.java:461) at org.redisson.client.handler.CommandDecoder.handleResult(CommandDecoder.java:455) at org.redisson.client.handler.CommandDecoder.decodeResult(CommandDecoder.java:444) at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:438) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:393) at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:215) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:153) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:122) at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:505) at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:283) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352) at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1421) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:697) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632) at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511) at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.lang.Thread.run(Thread.java:745)
Redis version
4.0
Redisson version
3.11.3
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2364
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Trying to remove multiple records through transaction , when executing case after 4,5 successful iteration,  transaction commitAsync doesnt return at all. test generator keeps waiting indefinitely.
around 2k size of testSet
Steps to reproduce or test case
`	try {
		for (String test : testSet) {
			transaction.getSetCache(DETAILS+ test.toString())
					.remove(testId);
		}
        
		tHandle.future = transaction.commitAsync();

	} catch (Exception exp) {
		transaction.rollbackAsync();

	}`

Redis version
5.0.4
Redisson version
3.11.4
Redisson configuration
defaults clustered server, nettyThread 64
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2365
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am using following function code to insert data in redis :
public List<Map<JioNSSFSnssai, HashSet>> getAmfIdForTaiListSnssaiPair(List taiList) {
List<Map<JioNSSFSnssai, HashSet>> resMap = new ArrayList<>();
RBatch batch = redissonClient.createBatch(BatchOptions.defaults());
for(JioNSSFTai tai :taiList) {
batch.getMapCache("mapName").getAsync(tai);
}
    BatchResult<?> res = batch.execute();

    for(int i=0 ;i<res.getResponses().size();i++) {
        Map<JioNSSFSnssai, HashSet<String>>mapData =(Map<JioNSSFSnssai, HashSet<String>>)res.getResponses().get(i);
        resMap.add(mapData);
        
    }
    return resMap;
}

Value is a Map whose key is : JioNSSFSnssai
and Have defined this class as following with over-riding equals and hashcode :
public class JioNSSFSnssai {
@SerializedName("sst")
private Integer sst = null;

@SerializedName("sd")
private String sd = null;

public Integer getSst() {
	return sst;
}

public void setSst(Integer sst) {
	this.sst = sst;
}

public String getSd() {
	return sd;
}

public void setSd(String sd) {
	this.sd = sd;
}

@Override
public String toString() {
	return "JioNSSFSnssai [sst=" + sst + ", sd=" + sd + "]";
}

@Override
public boolean equals(Object o) {
	if (this == o) return true;
	if (o == null || getClass() != o.getClass()) return false;
	JioNSSFSnssai snssai = (JioNSSFSnssai) o;
	return com.google.common.base.Objects.equal(sst, snssai.sst) &&
			com.google.common.base.Objects.equal(sd, snssai.sd);
}

@Override
public int hashCode() {
	int resp=com.google.common.base.Objects.hashCode(sst, sd);
	return resp;
}

}
I see that HashCode of values key(JIONSSFSNSSAI) obtained from redis has changes , not sure whats the reason for it ?
As a result I can't perform operations on the obtained Map since equals and hashcode don't match to the same key.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2366
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2367
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello @mrniko
We are facing an issue when using redisson with Elasticache with replication.
We are writing some 100K key value pairs to a map and then renaming it. Then we immediately attempt to read the same. It fails and redisson reports that the key does not exist.
Note that we have default values of read mode (SLAVE) and scan interval (1000ms) . Can you please suggest if changing to MASTER_SLAVE read mode can help in this. Also are there any configurations on redisson that we can try with.
Thanks,
Yash

Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
Redisson version
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2368
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2369
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
I want to migrate data from an old Redis cluster to a new one programmatically, so I did this :
            legacyRedisClient.getKeys()
                .getKeys()
                .forEach(key -> {
                    LOGGER.info("Redis Migration : Migrating key {}", key);
                    Optional.of(legacyRedisClient.getBucket(key))
                            .filter(RObject::isExists)
                            .map(RBucket::get)
                            .ifPresent(value -> {
                                LOGGER.info("Redis Migration : Storing element with key {}", key);
                                RBucket<Object> bucket = encryptedRedisClient.getBucket(key);
                                bucket.set(value);
                                bucket.expire(48L, DAYS);
                            });
                });

The problem with this, is that I when I do RBucket::get, Redisson try to decode the value with a class that is not necessarily in the classpath (because that was set by an other microservice).
Is there a way to disable decoding in Redisson ? Or a better way to do this ?
Redis version
3.2.6
Redisson version
3.11.2
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2370
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Connects to Redis on AWS
Actual behavior
Netty throws an exception trying to resolve the hostname:
Caused by: io.netty.resolver.dns.DnsResolveContext$SearchDomainUnknownHostException: Search domain query failed. Original hostname: 'ec2-54-234-206-155.compute-1.amazonaws.com]' failed to resolve 'ec2-54-234-206-155.compute-1.amazonaws.com].ec2.internal' after 3 queries

Somehow, there is a ] added to the hostname (ec2-54-234-206-155.compute-1.amazonaws.com]), even though my redisson.json does not contain one.
Steps to reproduce or test case
Click this button to deploy the repro example for free on Heroku:

Then view the logs (you may need to restart the app if you want to view the logs in the browser because it crashes).
Or you may run this sample app with a command like:
$ java -jar webapp-runner.jar --session-store redis --session-store-pool-size 5 target/heroku-redisson-test.war

Redis version
5.0
Redisson version
3.11.4 (appeared in 3.11.01 and possibly earlier but not before 3.10.0)
Redisson configuration
{"singleServerConfig":{"idleConnectionTimeout":10000,"pingTimeout":1000,"connectTimeout":10000,"timeout":5000,"retryAttempts":3,"retryInterval":1500,"password":"pb9e2626905755078bb5c0fa4d482a19e5871b66645aac0c8650794d3c6e742f2","subscriptionsPerConnection":5,"sslEnableEndpointIdentification":true,"sslProvider":"JDK","
pingConnectionInterval":0,"keepAlive":false,"tcpNoDelay":false,"address":"redis://<redacted>:<redacted>@ec2-54-234-206-155.compute-1.amazonaws.com:15319","subscriptionConnectionMinimumIdleSize":1,"subscriptionConnectionPoolSize":50,"connectionMinimumIdleSize":5,"connectionPoolSize":5,"database":0,"dnsMonitoringInterval
":5000},"threads":16,"nettyThreads":32,"codec":{"class":"org.redisson.codec.FstCodec"},"referenceEnabled":true,"transportMode":"NIO","lockWatchdogTimeout":30000,"keepPubSubOrder":true,"decodeInExecutor":false,"useScriptCache":false,"minCleanUpDelay":5,"maxCleanUpDelay":1800,"addressResolverGroupFactory":{"class":"org.redisson.connection.DnsAddressResolverGroupFa
ctory"}}
Other information
Tomcat 8.5.47
The source code for the webapp-runner code that sets up Redisson can be found on Github.
Full error:
SEVERE: The session manager failed to start
org.apache.catalina.LifecycleException: io.netty.resolver.dns.DnsResolveContext$SearchDomainUnknownHostException: Search domain query failed. Original hostname: 'ec2-34-226-17-251.compute-1.amazonaws.com]' failed to resolve 'ec2-34-226-17-251.compute-1.amazonaws.com].ec2.internal' after 3 queries
	at org.redisson.tomcat.RedissonSessionManager.buildClient(RedissonSessionManager.java:354)
	at org.redisson.tomcat.RedissonSessionManager.startInternal(RedissonSessionManager.java:237)
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183)
	at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5182)
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183)
	at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1412)
	at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1402)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: io.netty.resolver.dns.DnsResolveContext$SearchDomainUnknownHostException: Search domain query failed. Original hostname: 'ec2-34-226-17-251.compute-1.amazonaws.com]' failed to resolve 'ec2-34-226-17-251.compute-1.amazonaws.com].ec2.internal' after 3 queries
	at io.netty.resolver.dns.DnsResolveContext.finishResolve(DnsResolveContext.java:925)
	at io.netty.resolver.dns.DnsResolveContext.tryToFinishResolve(DnsResolveContext.java:884)
	at io.netty.resolver.dns.DnsResolveContext.query(DnsResolveContext.java:356)
	at io.netty.resolver.dns.DnsResolveContext.onResponse(DnsResolveContext.java:543)
	at io.netty.resolver.dns.DnsResolveContext.access$400(DnsResolveContext.java:64)
	at io.netty.resolver.dns.DnsResolveContext$2.operationComplete(DnsResolveContext.java:400)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:570)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:549)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)
	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)
	at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)
	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)
	at io.netty.resolver.dns.DnsQueryContext.setSuccess(DnsQueryContext.java:204)
	at io.netty.resolver.dns.DnsQueryContext.finish(DnsQueryContext.java:196)
	at io.netty.resolver.dns.DnsNameResolver$DnsResponseHandler.channelRead(DnsNameResolver.java:1320)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1422)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:931)
	at io.netty.channel.nio.AbstractNioMessageChannel$NioMessageUnsafe.read(AbstractNioMessageChannel.java:93)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:700)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:635)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:552)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:514)
	at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1044)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2371
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Amazon ElastiCache Redis cluster mode, Redis version:  3.2.4
Redisson version: 3.11.x Community version.
Java version: Oracle 1.8
App: Spring boot 1.5.22 with spring-data-redis 1.8.23
Hi,
When I deploy my app to Amazon dev server, after about 24 to 28 hours, I got the following log:
2019-10-20 03:50:26.532  INFO 10880 --- [redisson-netty-2-5] o.r.c.ClusterConnectionManager           : 16384 slots added to redis://10.5.3.207:6379 --- MDC: {, , , , }
2019-10-20 03:50:26.532  INFO 10880 --- [redisson-netty-2-5] o.r.c.ClusterConnectionManager           : 16384 slots removed from redis://10.5.3.207:6379 --- MDC: {, , , , }
2019-10-20 03:50:26.533  INFO 10880 --- [redisson-netty-2-5] o.r.c.ClusterConnectionManager           : 18432 slots found to add --- MDC: {, , , , }
2019-10-20 03:50:31.543  INFO 10880 --- [redisson-netty-2-5] o.r.c.ClusterConnectionManager           : 16384 slots added to redis://10.5.3.207:6379 --- MDC: {, , , , }
2019-10-20 03:50:31.543  INFO 10880 --- [redisson-netty-2-5] o.r.c.ClusterConnectionManager           : 16384 slots removed from redis://10.5.3.207:6379 --- MDC: {, , , , }
2019-10-20 03:50:31.547  INFO 10880 --- [redisson-netty-2-5] o.r.c.ClusterConnectionManager           : 28672 slots found to add --- MDC: {, , , , }
2019-10-20 03:50:36.557  INFO 10880 --- [redisson-netty-2-5] o.r.c.ClusterConnectionManager           : 16384 slots added to redis://10.5.3.207:6379 --- MDC: {, , , , }
2019-10-20 03:50:36.557  INFO 10880 --- [redisson-netty-2-5] o.r.c.ClusterConnectionManager           : 16384 slots removed from redis://10.5.3.207:6379 --- MDC: {, , , , }
2019-10-20 03:50:36.558  INFO 10880 --- [redisson-netty-2-5] o.r.c.ClusterConnectionManager           : 28672 slots found to add --- MDC: {, , , , }
2019-10-20 03:50:41.575  INFO 10880 --- [redisson-netty-2-5] o.r.c.ClusterConnectionManager           : 16384 slots added to redis://10.5.3.207:6379 --- MDC: {, , , , }
2019-10-20 03:50:41.576  INFO 10880 --- [redisson-netty-2-5] o.r.c.ClusterConnectionManager           : 16384 slots removed from redis://10.5.3.207:6379 --- MDC: {, , , , }
2019-10-20 03:50:41.581  INFO 10880 --- [redisson-netty-2-5] o.r.c.ClusterConnectionManager           : 28672 slots found to add --- MDC: {, , , , }
And my app sometimes throws exception when it gets data from redis.
I have such issue in redisson 3.11.0.to 3.11.4
If I switch back to redisson 3.10.7, then it is ok. Please help to fix it. Thank you very much.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2372
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Session object is stored in Redis
Actual behavior
Getting the following error trying to enable session replication via Redisson:
21-Oct-2019 14:15:42.488 SEVERE [http-nio2-8086-exec-9] org.apache.coyote.http11.Http11Processor.service Error processing request
java.lang.ClassCastException: org.apache.catalina.session.StandardManager cannot be cast to org.redisson.tomcat.RedissonSessionManager
at org.redisson.tomcat.UpdateValve.invoke(UpdateValve.java:55)
at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:798)
at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:806)
at org.apache.tomcat.util.net.Nio2Endpoint$SocketProcessor.doRun(Nio2Endpoint.java:1735)
at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
at org.apache.tomcat.util.net.AbstractEndpoint.processSocket(AbstractEndpoint.java:1069)
at org.apache.tomcat.util.net.Nio2Endpoint$Nio2SocketWrapper$3.completed(Nio2Endpoint.java:575)
at org.apache.tomcat.util.net.Nio2Endpoint$Nio2SocketWrapper$3.completed(Nio2Endpoint.java:553)
at sun.nio.ch.Invoker.invokeUnchecked(Invoker.java:126)
at sun.nio.ch.Invoker$2.run(Invoker.java:218)
at sun.nio.ch.AsynchronousChannelGroupImpl$1.run(AsynchronousChannelGroupImpl.java:112)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
at java.lang.Thread.run(Thread.java:748)
Steps to reproduce or test case
Tomcat Version 8.0.14
Redis version
Redisson version
redisson-tomcat-8-3.11.5
Redisson configuration
singleServerConfig:
address: "redis://${REDIS_HOST}:${REDIS_PORT}"
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2373
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: no further information: /
at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:353)
at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2374
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
集合比对，求差集
Actual behavior
Caused by: java.io.IOException: java.lang.NullPointerException
at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:247)
at org.redisson.codec.FstCodec$1.decode(FstCodec.java:164)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:364)
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:408)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:373)
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:199)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:139)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:114)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
Steps to reproduce or test case
public Set sdiffSet(String setSourceKey, String setDestKey) {
RSet sourceSet = redissonClient.getSet(setSourceKey);
	return sourceSet.readDiff(setDestKey);
}

Redis version
3.10.5
Redisson version
Redisson configuration
redis.pool.lock.waitTime=30000
redis.pool.lock.leaseTime=10000
redis.pool.cache.hostPrefix=redis://
redis.pool.cache.servers=redis1:7000,redis2:7000,redis3:7000,redis1:7001,redis2:7001,redis3:7001
redis.pool.cache.password=xxxxxx
redis.pool.cache.lockWatchTime=20
redis.pool.cache.cluserMaxAttempts=20
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2375
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
redis里的key显示为 limit:api:test=123
Actual behavior
redis里的key显示为： limit:api:limit:api:test=123
Steps to reproduce or test case
public static String wrap(String key){
return "limit:api": + key
}
bucket = redisson.getBucket(wrap(“test”), codec)
bucket.set(“123”);
Redis version
3.2.9
Redisson version

			org.redisson
			redisson-spring-boot-starter
			${redisson-spring-boot-starter.version.version}
			
				
					org.redisson
					redisson-spring-data-21
				
				
					spring-boot-actuator-autoconfigure
					org.springframework.boot
				
			
		
		
			org.redisson
			redisson-spring-data-20
			${redisson-spring-boot-starter.version.version}
		
### Redisson configuration
clusterServersConfig:
idleConnectionTimeout: 10000
pingTimeout: 1000
connectTimeout: 10000
timeout: 3000
retryAttempts: 3
retryInterval: 1500
reconnectionTimeout: 3000
failedAttempts: 3
subscriptionsPerConnection: 5
clientName: null
slaveSubscriptionConnectionMinimumIdleSize: 1
slaveSubscriptionConnectionPoolSize: 50
slaveConnectionMinimumIdleSize: 32
slaveConnectionPoolSize: 64
masterConnectionMinimumIdleSize: 32
masterConnectionPoolSize: 64
readMode: "SLAVE"
nodeAddresses:
- "redis://risk-redis1:7000"
- "redis://risk-redis1:7001"
- "redis://risk-redis2:7002"
- "redis://risk-redis2:7003"
- "redis://risk-redis3:7004"
- "redis://risk-redis3:7005"
scanInterval: 1000
threads: 0
nettyThreads: 0
codec: !<org.redisson.codec.JsonJacksonCodec> {}
transportMode: NIO
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2376
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
why session is null？
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2377
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi there,
I am using redisson and just imagined a possible behavior on scaled environments.
I have a Redisson Map like that:
public abstract class BaseAuthMapEntry implements MyDataSerializable {

    /**
     * The website for the session
     */
    private BaseWebsite website;

    ...

    public BaseWebsite getWebsite() {
        return website;
    }

    public void setWebsite(BaseWebsite website) {
        this.website = website;
    }

    @Override
    public ObjectNode toJson() {
        ObjectNode node = mapper.createObjectNode();
        node.put("website_id", website.getId().toString());

        return node;
    }

    @Override
    public void fromJson(ObjectNode json) {
        verifyString(json, "website_id");
        website = BaseWebsite.getById(json.get("website_id").asText());
    }
}
Where MyDataSerializable is my custom serializer for redisson.
Where BaseWebsite is a bean stored in database
Imagine I have two instances which have in memory this map entry.
Now one of them update the BaseWebsite's object and then do a "map.fastput(id, object);"
Since the website_id didn't change, when the other instance will do "map.get(id);", will the map entry be refetched and the website's object reloaded or not?
Thanks,
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2378
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
When I add a @Column on an @Entity, I want Redisson to invalidate the cache, so to do this I manually change the region property in the @Cache annotation.
Is there a better way to do this ?
Actual behavior
When I add a @Column on an @Entity with @Cache, I got an exception when Redisson try to fetch the entity in Redis.
Redisson version
3.11.2
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2379
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior

在VIP切换后，服务正常运行，可以进行Redisson在Redis上的读写
或在多次尝试失败后丢弃该TCP连接，进行TCP断线重连

Actual behavior

超时

Steps to reproduce or test case

搭建两Redis单点服务器
服务器配置VIP，提供统一出口
Redisson通过VIP访问Redis
正常读写
VIP切换
超时

Redis version

4.0.6

Redisson version

3.11.5

Redisson configuration

Class: SingleServerConfig
Address: redis://192.168.1.30:6379
其中Address为VIP

Consider

是否支持VIP模式，或是否支持TCP断线重连？
若无该模式，如使用useCustomServers()方式是否能解决该问题？

Error Log
org.redisson.client.RedisResponseTimeoutException: Redis server response timeout (3000 ms) occured after 3 retry attempts. Command: (EVAL), params: [local v = redis.call('hget', KEYS[1], ARGV[1]); redis.call('hset', KEYS[1], ARGV[1], ARGV[2]); retur..., 1, test-map, PooledUnsafeDirectByteBuf(ridx: 0, widx: 6, cap: 256), PooledUnsafeDirectByteBuf(ridx: 0, widx: 5, cap: 256)], channel: [id: 0xf04f767c, L:/10.237.147.15:54352 - R:192.168.1.30/192.168.1.30:6379]
	at org.redisson.command.RedisExecutor$3.run(RedisExecutor.java:338) ~[redisson-3.11.5.jar:3.11.5]
	at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:680) ~[netty-common-4.1.42.Final.jar:4.1.42.Final]
	at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:755) ~[netty-common-4.1.42.Final.jar:4.1.42.Final]
	at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:483) ~[netty-common-4.1.42.Final.jar:4.1.42.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.42.Final.jar:4.1.42.Final]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_172]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2380
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@Bean
 public org.springframework.cache.CacheManager redisClient() {
   var client = getRedisClient();
   var cacheManager = new RedissonSpringCacheManager(client);
   CacheConfig defaultConfig = new CacheConfig(60 * 60 * 1000, 0);
   Map<String, CacheConfig> map = new HashMap<>();
   // 下面四个缓存name设置超时时间后， 他们的JsonJacksonCodec编码器就不work了
   map.put(CacheKey.SMS_HAS_INITIALIZED_CONFIG, defaultConfig);
   map.put(CacheKey.SMS_STATE_CACHE_PREFIX, defaultConfig);
   map.put(CacheKey.SMS_SIGNATURE_CACHE_PREFIX, defaultConfig);
   map.put(CacheKey.SYSTEM_TYPE_KEY, defaultConfig);
   cacheManager.setConfig(map);
   cacheManager.setCodec(JsonJacksonCodec.INSTANCE);
   return cacheManager;
 }

redission version: 3.10.5
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2381
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
That it will work at all
Actual behavior
ava.lang.ClassCastException: class org.redisson.misc.CompositeIterable cannot be cast to class io.reactivex.Flowable (org.redisson.misc.CompositeIterable and io.reactivex.Flowable are in unnamed module of loader 'app')
Steps to reproduce or test case
redissonRxClient.getList("ListTest").iterator().doOnNext(o -> logger.info(o)).subscribe();
Redis version
5.0.6
Redisson version

	org.redisson
	redisson
	3.11.5


	io.reactivex.rxjava2
	rxjava
	2.2.13

Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2382
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I was wondering would it be possible for someone to review my PR? Really appreciate it.
Thank you
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2383
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
few Timeout Exceptions
Actual behavior
A lot of timeout exceptions and Can't add slave exceptions
Steps to reproduce or test case
intermittent
Redis version
Azure Redis Cache with 5 shards
4.0.14, 3.2.7
Redisson version
3.11.4
Redisson configuration
Default clustered config with the following overrides:
REDIS_ENABLED | true
REDIS_KEEP_ALIVE | true
REDIS_THREADS | 512
REDIS_NETTY_THREADS | 1024
REDIS_MASTER_CONNECTION_MINIMUM_IDLE_SIZE | 5
REDIS_MASTER_CONNECTION_POOL_SIZE | 10
REDIS_SLAVE_CONNECTION_MINIMUM_IDLE_SIZE | 5
REDIS_SLAVE_CONNECTION_POOL_SIZE | 10
REDIS_TIMEOUT | 1000
REDIS_RETRY_INTERVAL | 500
REDIS_TCP_NO_DELAY | true
I see following exceptions in the log:
`
exception: { [-]
class: org.redisson.client.RedisConnectionException
thrownfrom: unknown
}
level: ERROR
logger_name: org.redisson.cluster.ClusterConnectionManager
message: Can't add slave: rediss://:15002
process: 6523
stack_trace: org.redisson.client.RedisTimeoutException: Command execution timeout for command: (READONLY), params: [], Redis client: [addr=rediss://:15002]
at org.redisson.client.RedisConnection.lambda$async$1(RedisConnection.java:207)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:680)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:755)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:483)
... 2 common frames omitted
Wrapped by: org.redisson.client.RedisConnectionException: Unable to connect to Redis server: /:15002
at org.redisson.connection.pool.ConnectionPool$1.lambda$run$0(ConnectionPool.java:160)
at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:183)
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)
at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)
at io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:608)
at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)
at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:96)
at org.redisson.connection.pool.ConnectionPool.promiseFailure(ConnectionPool.java:330)
at org.redisson.connection.pool.ConnectionPool.lambda$createConnection$1(ConnectionPool.java:296)
at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:183)
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)
at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:570)
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:549)
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)
at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)
at io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:608)
at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)
at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:96)
at org.redisson.client.RedisClient$2$1.run(RedisClient.java:240)
at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:510)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:518)
at i.n.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1044)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
stack_trace: org.redisson.client.RedisTimeoutException: Unable to get connection! Try to increase 'nettyThreads' and/or connection pool size settingsNode source: NodeSource [slot=15393, addr=redis://:15007, redisClient=null, redirect=MOVED, entry=null], command: (PSETEX), params: [some key, 3600000, PooledUnsafeDirectByteBuf(ridx: 0, widx: 457, cap: 512)] after 0 retry attempts
at org.redisson.command.RedisExecutor$2.run(RedisExecutor.java:209)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:680)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:755)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:483)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
level: ERROR
logger_name: org.redisson.cluster.ClusterConnectionManager
message: Can't add master: rediss://:15007 for slot ranges: [[15019-15564], [12288-13652], [4096-5461]]
process: 6574
thread_name: redisson-netty-2-718
timestamp: 2019-10-29 22:32:15.592
`
My logs are flooded with these exceptions and when I login to Azure portal, I see the CPU metric for Redis spiked to 100%. Any help is appreciated.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2384
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redisson的各种数据结构实现还是很精致的，例如Rlock由key，hash还有channel组合而成，RSemaphore由一个key和channel组成。
但是我发现有个疑问，就是假设我用订单id作为key，使用RSemaphore或者RLock，那么就会产生很多不会过期的key，但是这个订单实际上已经处理完了，不会再用到这些key，那么这些key是否只能通过redis自己的LRU过期呢，有没有什么更好的办法？
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2385
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
Redisson version
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2386
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
test RScheduledExecutorService as demo:
`
public static void main(String[] args) {
Config config = new Config();
config.useClusterServers()
.addNodeAddress("127.0.0.1:7001", "127.0.0.1:7002", "127.0.0.1:7003");
RedissonClient redisson = Redisson.create(config);

RedissonNodeConfig nodeConfig = new RedissonNodeConfig(config);
nodeConfig.setExecutorServiceWorkers(Collections.singletonMap("myExecutor", 10));
RedissonNode node = RedissonNode.create(nodeConfig);
node.start();

RExecutorService e = redisson.getExecutorService("myExecutor");
e.execute(new RunnableTask());
e.submit(new CallableTask());
e.schedule(new RunnableTask(), CronSchedule.of("0/10 * * * * ?"));
e.shutdown();
node.shutdown();

}
`
and run 2 JVM
Expected: every 10 second only one thread run in one of two JVM
Actual behavior
has one run thread in both JVM in evety 10 second
shutdown one JVM ,has two run thread in the other JVM.
is that mean: one JVM schedule task , multiple JVM run as woker？
Steps to reproduce or test case
Redis version
3.2.4
Redisson version
3.11.5
Redisson configuration
as demo.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2387
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
org.redisson.client.RedisTimeoutException: Redis server response timeout (3000 ms) occured for command: (EVAL) with params: [if (redis.call('exists', KEYS[1]) == 0) then redis.call('hset', KEYS[1], ARGV[2], 1); redis.call('pe..., 1, redPacket:delivery_reward:userId:1185439964859547664:refSeqId:1189793440456589337:1, 10000, ebe570ad-6760-482a-a0e2-4d46f394963d:474] channel: [id: 0x67e3c291, L:/10.40.4.23:37930 - R:172.16.3.80/172.16.3.80:17001] at org.redisson.command.CommandAsyncService$11.run(CommandAsyncService.java:711) at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:668) at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:743) at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:471) at java.lang.Thread.run(Thread.java:748)
Redis version 5.0.4
Redisson version 3.11.4
Redisson configuration：`
    ClusterServersConfig clusterServersConfig = config.useClusterServers();
    clusterServersConfig.setScanInterval(2000);
    List<String> nodes = Arrays.asList(StringUtils.split(redisProp.getClusterNodes(), ','));
    for (String node : nodes) {
        clusterServersConfig.addNodeAddress("redis://" + node);
    }
    clusterServersConfig.setPingConnectionInterval(60);
    //设置对于master节点的连接池中连接数最大为500
    clusterServersConfig.setMasterConnectionPoolSize(1000);
    //设置对于slave节点的连接池中连接数最大为500
    clusterServersConfig.setSlaveConnectionPoolSize(1000);
    //如果当前连接池里的连接数量超过了最小空闲连接数，而同时有连接空闲时间超过了该数值，那么这些连接将会自动被关闭，并从连接池里去掉。时间单位是毫秒。
    clusterServersConfig.setIdleConnectionTimeout(10000);
    //同任何节点建立连接时的等待超时。时间单位是毫秒。
    clusterServersConfig.setConnectTimeout(30000);
    //等待节点回复命令的时间。该时间从命令发送成功时开始计时。
    clusterServersConfig.setTimeout(3000);
    //当与某个节点的连接断开时，等待与其重新建立连接的时间间隔。时间单位是毫秒。
    clusterServersConfig.setIdleConnectionTimeout(3000);
    clusterServersConfig.setPassword(redisProp.getPassword());
    return Redisson.create(config);`
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2388
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Store write-behind queue in Redis
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2389
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@test
public void testDestroy()
{
RMapCache mapCache = null;
        mapCache = redissonClient.getMapCache("testDestroy");
       // assertTrue(mapCache.trySetMaxSize(5));

        for(int i=0;i<10;i++){
            mapCache.put("abc"+i, i,1, TimeUnit.DAYS);
        }
        assertEquals(5,mapCache.size());

        for(int i=0;i<5;i++){
            assertNull("Expected "+"abc"+i+" to be evicted",mapCache.get("abc"+i));
        }
        mapCache.destroy();
        Object test = mapCache.get("abc9");
        assertEquals(null,test);

    
}

Expected behavior
after mapCache.destroy() any lookup on mapCache should return null.
Actual behavior
mapCache is not destroyed. It is still returning old values.
Steps to reproduce or test case
Redis version
Redisson version
3.11.3
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2390
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
每次通过获取一个 集合例如Map，之后Map.get(key)，这一句很慢，因为get 有闭锁 await 每次都要在10ms 左右。
Actual behavior
怎么能让我的 get 快一些，只是涉及并发读取而已
Steps to reproduce or test case
Redis version
Redisson version
3.11.3
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2391
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2392
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
If I were to set the EvictionPolicy and TimeToLive in the LocalCachedMapOptions when creating a new RLocalCachedMap, does this actually do anything?
Will each entry added to the map get this TTL set to it?  If so, would I be able to configure the redis server to expire entries whose TTL has past?
It is my understanding that the LocalCachedMap does not actually support eviction unless you are using Redisson Pro.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2393
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redisson is using non-blocking I/O. so i think not need many connection.
But not exists detail setting connection pool guide in document.
If in many traffic, Will performance increase as connection pools increase?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2394
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
is it possible to configure multiple codecs ?
we are trying to use redisson for tomcat session replication .
not all our session attributes are serializable, so we cannot use codec which relies on java serialization
i was wondering if we can specify in redisson.yaml list of codecs:
something like that:
codec: !<org.redisson.codec.JsonJacksonCodec> {}, org.redisson.codec.FstCodec  ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2395
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
To have it implemented
Actual behavior
Steps to reproduce or test case
Redis version
5.06
Redisson version
3.11.5
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2396
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
No Exception must be thrown
Actual behavior
2019-11-06 17:22:50:476*[ERROR]scheduled-task-pool-2o.s.s.s.TaskUtils$LoggingErrorHandlerhandleErrorUnexpected error occurred in scheduled task.
java.lang.NumberFormatException: null
at java.math.BigDecimal.(BigDecimal.java:497)
at java.math.BigDecimal.(BigDecimal.java:383)
at java.math.BigDecimal.(BigDecimal.java:809)
at java.math.BigDecimal.valueOf(BigDecimal.java:1277)
at org.redisson.spring.data.connection.RedissonConnection.value(RedissonConnection.java:1089)
at org.redisson.spring.data.connection.RedissonConnection.zRangeByScore(RedissonConnection.java:1370)
at org.redisson.spring.data.connection.RedissonConnection.zRangeByScore(RedissonConnection.java:1098)
at org.springframework.data.redis.core.DefaultZSetOperations.lambda$rangeByScore$10(DefaultZSetOperations.java:197)
at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:225)
at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:185)
at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:96)
at org.springframework.data.redis.core.DefaultZSetOperations.rangeByScore(DefaultZSetOperations.java:197)
Steps to reproduce or test case
Try using RedissonConnectionFactory with RedisTemplate and call the method template.opsForZSet().rangeByScore(id, min, max); with min value as Double.NEGATIVE_INFINITY
Redis version
4.0.9
Redisson version
3.11.5
Redisson configuration
Default Configuration on localhost
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2397
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
The map entry listener should only call once When invoke RMapCache#put method.
I found that if use single server, there will be no problem. But when configured in cluster mode, the listener will call twice.
Actual behavior
The map entry listener call twice.
Steps to reproduce or test case

Clone the reidsson source code.
Execute unit test RedissonMapCacheTest#testCreatedListener
Before step2 , should create redisson server instance with cluster mode.

Redis version
4.0.14
Redisson version
The latest version
Redisson configuration
Config config = new Config();
config.useClusterServers()
.addNodeAddress("redis://xxxx", "redis://xxxx", "redis://xxxx");
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2398
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
counter variable in AsyncSemaphore is not volatile variable.
but getCounter() method is public, and not synchronized.
getCounter() method is possible access by many thread. (not in now. but may be possible in the future.)
so add volatile keyword to counter variable.
Redisson version
redisson-3.11.5 (latest)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2399
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
When any node of a Redis Cluster has configure "cluster-slave-no-failover yes" which is enable after Redis 4.0，the result of "cluster nodes" command will contains a "nofailover" flag like this
xxxxx xxx:6379@16379 slave,nofailover xxxx 0 1573107298000 3 connected
ClusterNodesDecoder should ignore this flag and do nothing.
Actual behavior
ClusterNodesDecoder throw an exception
java.lang.IllegalArgumentException: No enum constant org.redisson.cluster.Cluster.ClusterNodeInfo.Flag.NOFAILOVER
Steps to reproduce or test case

set the config "cluster-slave-no-failover yes" to one slave instance of a Redis Cluster
start a RedissonClient connecting to that Redis Cluster

Redis version
4.0.10
Redisson version
The latest version
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2400
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2401
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2402
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2403
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2404
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2405
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2406
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2407
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2408
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2409
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2410
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2411
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2412
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2413
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2414
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2415
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2416
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2417
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2418
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2419
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2420
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2421
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2422
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2423
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2424
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2425
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2426
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2427
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2428
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2429
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2430
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2431
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2432
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2433
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2434
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2435
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2436
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2437
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2438
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2439
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2440
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2441
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2442
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2443
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2444
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2445
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2446
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2447
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2448
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2449
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2450
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2451
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2452
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2453
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2454
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2455
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2456
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2457
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2458
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2459
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2460
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2461
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2462
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2463
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2464
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2465
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2466
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2467
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2468
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2469
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2470
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2471
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2472
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2473
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2474
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2475
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2476
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2477
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2478
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2479
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2480
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2481
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2482
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2483
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2484
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2485
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2486
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2487
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2488
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2489
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2490
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2491
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2492
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2493
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2494
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2495
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2496
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2497
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2498
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2499
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2500
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2501
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2502
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2503
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2504
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2505
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2506
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2507
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2508
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2509
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2510
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2511
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2512
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2513
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2514
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2515
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2516
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2517
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2518
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2519
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2520
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2521
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2522
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2523
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2524
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2525
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2526
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2527
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2528
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2529
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2530
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2531
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2532
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2533
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2534
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2535
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
We are using Redisson with AWS elasticache redisson cluster. Redisson client throws exception from some of the hosts. Only way to recover is to reboot the EC2 instances/restart the application. Slaves are reachable from the EC2.
Actual behavior
Redisson client fails with the following exception eventhough slaves are reachable from EC2.
Caused by: org.redisson.client.RedisConnectionException: SlaveConnectionPool no available Redis entries.  Disconnected hosts: [10.0.129.98/10.0.129.98:6379]
at org.redisson.connection.pool.ConnectionPool.get(ConnectionPool.java:219) ~[Redisson-3.11.x.jar:?]
at org.redisson.connection.pool.SlaveConnectionPool.get(SlaveConnectionPool.java:30) ~[Redisson-3.11.x.jar:?]
at org.redisson.connection.balancer.LoadBalancerManager.nextConnection(LoadBalancerManager.java:248) ~[Redisson-3.11.x.jar:?]
at org.redisson.connection.MasterSlaveEntry.connectionReadOp(MasterSlaveEntry.java:464) ~[Redisson-3.11.x.jar:?]
at org.redisson.connection.MasterSlaveConnectionManager.connectionReadOp(MasterSlaveConnectionManager.java:607) ~[Redisson-3.11.x.jar:?]
at org.redisson.command.RedisExecutor.getConnection(RedisExecutor.java:645) ~[Redisson-3.11.x.jar:?]
at org.redisson.command.RedisExecutor.execute(RedisExecutor.java:116) ~[Redisson-3.11.x.jar:?]
at org.redisson.command.RedisExecutor$2.run(RedisExecutor.java:245) ~[Redisson-3.11.x.jar:?]
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:663) ~[netty-common-4.1.21.Final.jar:?]
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:738) ~[netty-common-4.1.21.Final.jar:?]
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:466) ~[netty-common-4.1.21.Final.jar:?]
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.21.Final.jar:?]
Steps to reproduce or test case
Exception happens very randomly in production.
Redis version
5.0.6
Redisson version
3.11.6
Redisson configuration
config.setNettyThreads(256)
.useClusterServers()
.addNodeAddress(redisUrl)
.setTimeout(200)
.setRetryInterval(50)
.setMasterConnectionPoolSize(128)
.setMasterConnectionMinimumIdleSize(32)
.setSlaveConnectionPoolSize(128)
.setSlaveConnectionMinimumIdleSize(32)
.setPingConnectionInterval(5000)
.setKeepAlive(true);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2536
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When I try to upgrade redisson from 3.8.2 to the version after 3.11.2. The following code breaks.
public class Demo {
	
	private SingleServerConfig singleServerConfig;
	
	public void test() throws URISyntaxException {
		
		singleServerConfig.setSslKeystore(new URI("test"));
		
	}
}

The code should pass, but it throws an error:
Demo.java:[15,51] incompatible types: java.net.URI cannot be converted to java.net.URL
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2537
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RRateLimiter don't allow query the remain permits for now . so i can not get the permits . i think add a method like :
int remain()


may be well .
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2538
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
我用spring中的@Cacheable时，从数据库中取出来准备序列化存到redis中的数据是Byte类型，但是再从redis中查出来返回的却是Integer，这个是需要修改redisson的数据序列化方式吗？我试了一下包装类Short、Byte都会变成Integer，Character会变成String，Float会变成Double。
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2539
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Might be connected to #2120, but I wasn't too sure about that, so I decided to create a new issue instead.
Expected behavior
No memory leak?
Actual behavior
SentinelConnectionManager is leaking memory because it stores too many connections to the sentinels in the nodeConnections map.
We are using a singleton Redisson instance for connecting to our replicated Redis instance (3 nodes, 3 sentinels). After running for some days, we are experiencing high GC times and OOM errors. Upon investigating the heap dump, we noticed that the SentinelConnectionManager stores nearly 50,000 connection to the same 3 sentinels in its nodeConnections map. However, the sentinels map itself only contains the expected 3 entries.

I tried analyzing and reproducing the leak myself, but I wasn't too successful since I am not familiar with your code. Would be great if you could have a look what could cause such a behavior :)
Unfortunately can't provide the heap dump since it might contain sensitive data.
Steps to reproduce or test case
N/A
Redis version
4.0.2
Redisson version
3.11.3
Redisson configuration
config.useSentinelServers().setMasterName("mymaster")
    .addSentinelAddress(redisSentinelAddress)
    .setPassword("")
    .setReadMode(ReadMode.MASTER)
    .setSubscriptionMode(SubscriptionMode.MASTER)
    .setMasterConnectionPoolSize(64)
    .setRetryInterval(2000)
    .setRetryAttempts(3)
    .setConnectTimeout(1000)
    .setTimeout(5000);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2540
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@mrniko Can you please take a look at the checks. I can't figure out why the linter is failing.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2541
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
服务在运行时,打印的错误日志,在工程中只用到了下面代码,但不确定是不是在执行下面的代码报出来的error日志
...
RLock rLock = redissonClient.getLock(LOCK);
...
rLock.tryLock(1, 3, TimeUnit.SECONDS);
...
rLock.unlock();
error日志如下:
[2020-01-09 10:39:45 ERROR] [nioEventLoopGroup-2-9] [CommandDecoder.java:316] - Error message from Redis: ERR handle request, command 'SUBSCRIBE' is not allowed channel: [id: 0x67a5ab14, L:/serverIp: serverPort - R:redis-serverIp/redis-serverIp:redis-serverPort]
[2020-01-09 10:39:46 ERROR] [nioEventLoopGroup-2-9] [CommandDecoder.java:316] - Error message from Redis: ERR handle request, command 'UNSUBSCRIBE' is not allowed channel: [id: 0x67a5ab14, L:/serverIp: serverPort - R:redis-serverIp/redis-serverIp:redis-serverPort]
Redis version
3.2.11
Redisson version
3.10.0
Redisson configuration
@bean
public RedissonClient redissonClient() {
Config config = new Config();
config.useSingleServer().setAddress("redis://" + redis-serverIp + ":" + redis-serverPort);
config.setEventLoopGroup(new NioEventLoopGroup());
config.setCodec(JsonJacksonCodec.INSTANCE);
return Redisson.create(config);
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2542
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Does the Redisson（BLPOP） support multily key？
Just like BLPOP key [key …]，When multiple key parameters are given, check each list in order of parameter key, and the first non empty list header element will pop up
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2543
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
trylock and unlock success
Actual behavior
RLock unlock always throw an exception what like 'not lock by current thread'
Steps to reproduce or test case
According to the stack information, the underlying asynchronous unlocking may cause the unlocking to throw an exception.This phenomenon can be reproduced 100%.
Redis version
4.0.14
Redisson version
3.11.x-3.12.0
Redisson configuration
standalone mode
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2544
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RLock
lock.isHeldByCurrentThread() verification  before unlocking
but sometimes exception
org.redisson.client.RedisException: Unexpected exception while processing command
at org.redisson.command.CommandAsyncService.convertException(CommandAsyncService.java:400)
at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:204)
at org.redisson.RedissonObject.get(RedissonObject.java:94)
at org.redisson.RedissonLock.isHeldByThread(RedissonLock.java:521)
at org.redisson.RedissonLock.isHeldByCurrentThread(RedissonLock.java:515)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2545
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We are interested in running Sentinel behind a L4 proxy terminating TLS.  This sentinel will report a master at IP:master_port.  This master is behind a second L4 proxy terminating TLS on a port we plan to infer from the reported master_port.   Ideally, Redisson would offer Sentinel + Master over TLS, with the ability to configure a port mapping function to take master_port and translate it to the L4 proxy port terminating TLS in front of the master.   As an aside, our model does not require us to translate either the sentinel or master IP, but the Lettuce example below fully allows that.
Here is the equivalent Lettuce 5.2.2 (due out 2/11/2020) code:
package com.example;

import io.lettuce.core.RedisClient;
import io.lettuce.core.api.StatefulRedisConnection;
import io.lettuce.core.api.sync.RedisCommands;
import io.lettuce.core.internal.HostAndPort;
import io.lettuce.core.resource.ClientResources;
import io.lettuce.core.resource.DnsResolvers;
import io.lettuce.core.resource.MappingSocketAddressResolver;
import org.junit.Test;

public class TestApp {

    @Test
    public void testLettuceSentinel() {
        final MappingSocketAddressResolver portMapper = MappingSocketAddressResolver.create(DnsResolvers.UNRESOLVED,
                                                                                            hostAndPort -> {
                                                                                                int port = hostAndPort.port;
                                                                                                switch (port) {
                                                                                                    case 6380:
                                                                                                        port = port + 1;  
                                                                                                        break;
                                                                                                }
                                                                                                System.out.printf("mapping: %s to %s:%d\n", hostAndPort.toString(), hostAndPort.hostText, port);
                                                                                                return HostAndPort.of(hostAndPort.hostText, port);
                                                                                            });

        final ClientResources clientResources = ClientResources.builder().socketAddressResolver(portMapper).build();

        final RedisClient redisClient = RedisClient.create(clientResources, "rediss-sentinel://192.168.99.1:26381/0#mymaster");

        try (final StatefulRedisConnection<String, String> connection = redisClient.connect()) {
            System.out.println("connected");

            final RedisCommands<String, String> redisCommands = connection.sync();
            redisCommands.clientSetname("blah");

            final String result = redisCommands.set("foo", "bar");
            System.out.printf("set foo result=%s\n", result);

            final String foo = redisCommands.get("foo");
            System.out.printf("get foo=%s\n", foo);
        }
        redisClient.shutdown();
    }
}

Describe alternatives you've considered
Many.  Including putting the sentinel / master cluster behind an F5 load balancer terminating TLS and let the F5 choose the master.  Clients program to the F5 over plain Redis API over TLS.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2546
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
java.lang.IllegalMonitorStateException: attempt to unlock lock, not locked by current thread by node id: 6e3d30b7-83b1-433a-9335-5e8b9916d3ac thread-id: 731
at org.redisson.RedissonLock.lambda$unlockAsync$3(RedissonLock.java:580)
at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:187)
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)
at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:570)
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:549)
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)
at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)
at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)
at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)
at org.redisson.misc.RedissonPromise.trySuccess(RedissonPromise.java:82)
at org.redisson.command.RedisExecutor.handleReference(RedisExecutor.java:483)
at org.redisson.command.RedisExecutor.handleSuccess(RedisExecutor.java:476)
at org.redisson.command.RedisExecutor.handleResult(RedisExecutor.java:461)
at org.redisson.command.RedisExecutor.checkAttemptPromise(RedisExecutor.java:447)
at org.redisson.command.RedisExecutor.lambda$execute$3(RedisExecutor.java:169)
at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:187)
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)
at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:570)
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:549)
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)
at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)
at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)
at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)
at org.redisson.misc.RedissonPromise.trySuccess(RedissonPromise.java:82)
at org.redisson.client.handler.CommandDecoder.completeResponse(CommandDecoder.java:444)
at org.redisson.client.handler.CommandDecoder.handleResult(CommandDecoder.java:439)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:370)
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:196)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:134)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:104)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:493)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:271)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:377)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:355)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:377)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2547
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
in my app, sometimes there are some dead locks in redis
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2548
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redisson version: 3.12.0
When using ipv6, we get the following error:
java.lang.IllegalArgumentException: java.net.MalformedURLException: Invalid host: [[22be:ffee:0:f101::328]
at org.redisson.misc.RedisURI.(RedisURI.java:54)
at org.redisson.connection.SentinelConnectionManager.convert(SentinelConnectionManager.java:595)
at org.redisson.connection.SentinelConnectionManager.(SentinelConnectionManager.java:167)
at org.redisson.config.ConfigSupport.createConnectionManager(ConfigSupport.java:197)
at org.redisson.Redisson.(Redisson.java:120)
at org.redisson.Redisson.create(Redisson.java:160)
...
Caused by: java.net.MalformedURLException: Invalid host: [[22be:ffee:0:f101::328]
at java.net.URL.(URL.java:627)
at java.net.URL.(URL.java:490)
at java.net.URL.(URL.java:439)
at org.redisson.misc.RedisURI.(RedisURI.java:49)
... 82 common frames omitted
Caused by: java.lang.IllegalArgumentException: Invalid host: [[22be:ffee:0:f101::328]
at java.net.URLStreamHandler.parseURL(URLStreamHandler.java:195)
at java.net.URL.(URL.java:622)
... 85 common frames omitted
It seems that in org.redisson.connection.SentinelConnectionManager#createAddress, the square bracket is added to the address; then in new RedisURI(), the square bracket was added AGAIN.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2549
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
**We use redis distributed delay queues for queuing data for future process and connecting to redis using node from each shard in cluster. Around 10% of the data is lost due to these errors.
Redis client version -3.9.1
We see RedisConnectionException and RedisResponseTimeoutException**
org.redisson.client.RedisConnectionException:
SlaveConnectionPool no available Redis entries.  Disconnected hosts: [1.2.4.3/1.1.1.1:6379]
at org.redisson.connection.pool.ConnectionPool.get(ConnectionPool.java:217)
at org.redisson.connection.pool.SlaveConnectionPool.get(SlaveConnectionPool.java:30)
at org.redisson.connection.balancer.LoadBalancerManager.nextConnection(LoadBalancerManager.java:244)
at org.redisson.connection.MasterSlaveEntry.connectionReadOp(MasterSlaveEntry.java:471)
at org.redisson.connection.MasterSlaveConnectionManager.connectionReadOp(MasterSlaveConnectionManager.java:580)
at org.redisson.command.CommandAsyncService.getConnection(CommandAsyncService.java:814)
at org.redisson.command.CommandAsyncService.async(CommandAsyncService.java:671)
at org.redisson.command.CommandAsyncService$10.run(CommandAsyncService.java:760)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:682)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:757)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:485)
at java.lang.Thread.run(Thread.java:748)
RedisResponseTimeoutException: Redis server response timeout (3000 ms) occurred for command:".
Here is the complete error.
org.redisson.client.RedisResponseTimeoutException: Redis server response timeout (3000 ms) occured for command: (EVAL) with params: [local result = {}; local items = redis.call('lrange', KEYS[1], 0, -1); for i, v in ipairs(items) do ..., 1, redisson_delay_queue:{delayEventQueue-e-prod}] channel: [id: 0x0f2e4a10, L:/ - R:]
at org.redisson.command.CommandAsyncService$13.run(CommandAsyncService.java:882)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:682)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:757)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:485)
at java.lang.Thread.run(Thread.java:748)
Redis configuration is below.  We have configured single node from each shard, what is the recommended approach for node configuration, cluster endpoint or nodes from each shard?
{
"clusterServersConfig": {
"idleConnectionTimeout": 10000,
"pingTimeout": 1000,
"connectTimeout": 10000,
"timeout": 3000,
"retryAttempts": 3,
"retryInterval": 1500,
"reconnectionTimeout": 3000,
"failedAttempts": 3,
"password": null,
"subscriptionsPerConnection": 5,
"clientName": "realTimeEventScheduler",
"loadBalancer": {
"class": "org.redisson.connection.balancer.RoundRobinLoadBalancer"
},
"slaveSubscriptionConnectionMinimumIdleSize": 1,
"slaveSubscriptionConnectionPoolSize": 50,
"slaveConnectionMinimumIdleSize": 10,
"slaveConnectionPoolSize": 64,
"masterConnectionMinimumIdleSize": 10,
"masterConnectionPoolSize": 64,
"readMode": "SLAVE",
"nodeAddresses": [
"redis://node:6379",
"redis://node:6379",
"redis://node:6379",
"redis://node:6379"
],
"scanInterval": 1000
},
"threads": 0,
"nettyThreads": 0,
"codec": null,
"useLinuxNativeEpoll": false
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2550
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello
I have a bug in redisson
i have many server who need to be connected on redis
when the first one start all work fine it is connected
but when the second one start the server freeze and there is no error log
it freeze when i call Redisson.create(config)
it's the same program than the first server so i don't understand why it don't work
someone as any idea ?
EDIT!
the only error i've found is this summon when i try to login to the server, it will crash and restart and print me this:
Current Thread: Server thread [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 	PID: 17 | Suspended: false | Native: false | State: WAITING [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 	Stack: [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		sun.misc.Unsafe.park(Native Method) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		java.util.concurrent.CompletableFuture$Signaller.block(CompletableFuture.java:1707) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3323) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		java.util.concurrent.CompletableFuture.waitingGet(CompletableFuture.java:1742) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		java.util.concurrent.CompletableFuture.join(CompletableFuture.java:1947) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		org.redisson.misc.RedissonPromise.syncUninterruptibly(RedissonPromise.java:172) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		org.redisson.misc.RedissonPromise.syncUninterruptibly(RedissonPromise.java:39) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		org.redisson.connection.MasterSlaveConnectionManager.initEntry(MasterSlaveConnectionManager.java:286) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		org.redisson.connection.MasterSlaveConnectionManager.init(MasterSlaveConnectionManager.java:246) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		org.redisson.connection.MasterSlaveConnectionManager.<init>(MasterSlaveConnectionManager.java:164) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		org.redisson.connection.SingleConnectionManager.<init>(SingleConnectionManager.java:49) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		org.redisson.config.ConfigSupport.createConnectionManager(ConfigSupport.java:231) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		org.redisson.Redisson.<init>(Redisson.java:115) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		org.redisson.Redisson.create(Redisson.java:154) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		fr.akame.core.database.redis.RedisAccess.initRedisson(RedisAccess.java:45) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		fr.akame.core.database.redis.RedisAccess.<init>(RedisAccess.java:23) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		fr.akame.core.database.redis.RedisAccess.init(RedisAccess.java:28) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		fr.akame.core.Main$1.run(Main.java:54) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		org.bukkit.craftbukkit.v1_8_R3.scheduler.CraftTask.run(CraftTask.java:59) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		org.bukkit.craftbukkit.v1_8_R3.scheduler.CraftScheduler.mainThreadHeartbeat(CraftScheduler.java:352) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		net.minecraft.server.v1_8_R3.MinecraftServer.B(MinecraftServer.java:783) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		net.minecraft.server.v1_8_R3.DedicatedServer.B(DedicatedServer.java:378) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		net.minecraft.server.v1_8_R3.MinecraftServer.A(MinecraftServer.java:713) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		net.minecraft.server.v1_8_R3.MinecraftServer.run(MinecraftServer.java:616) [14:01:05] [PaperSpigot Watchdog Thread/ERROR]: 		java.lang.Thread.run(Thread.java:748)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2551
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redis: 5.0.12
Redisson: 3.12.0
The following code snippet will successfully create and lock RLock and will throw RedisException unlocking the lock.
   RLock lock = client.getLock("lock-test");
   lock.lock();
   lock.unlock();

org.redisson.client.RedisException: ERR Error running script (call to f_3ffe249c16dee540ac8ab32e39bd408626b9aff7): @user_script:1: ERR hash value is not an integer . channel: [id: 0x7c579845, L:/my-ip:port - R:host/my-ip:port] command: (EVAL), params: [if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then return nil;end; local counter = redis.call('h..., 2, lock-test, redisson_lock__channel:{lock-test}, 0, 30000, 62ad3063-9ff4-4a24-bfe1-bd08254b2968:1]

	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:351)
	at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:199)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:139)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:114)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502)
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:677)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:612)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:529)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:491)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2552
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I tried Master Slave configuration for redission-mybatis. I want to set 'master' only for writer and 'slave' for read only. But when is set master slave configuration i can see master is also used for reading purpose.
Can i set configuration in which 'master' work only as writer not reader?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2553
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
delay queue still work
Actual behavior
delay queue doesn't work
Steps to reproduce or test case
Redis version
3.2.12
Redisson version
3.12.0
Configration:
slaveConnectionMinimumIdleSize: 8
slaveConnectionPoolSize: 50
masterConnectionMinimumIdleSize: 8
masterConnectionPoolSize: 50
throw follow exception continuous, but the the APP host acctualy has ony 7 connection
Unable to acquire connection! Increase connection pool size and/or retryInterval settings Node source: NodeSource [slot=11834, addr=redis://10.10.14.61:6382, redisClient=null, redirect=MOVED, entry=null], command: (EVAL), params: [local expiredValues = redis.call('zrangebyscore', KEYS[2], 0, ARGV[1], 'limit', 0, ARGV[2]); if #exp..., 3, transfer_ttl_queue, redisson_delay_queue_timeout:{transfer_ttl_queue}, redisson_delay_queue:{transfer_ttl_queue}, 1579602478857, 100] after 0 retry attempts
org.redisson.client.RedisTimeoutException: Unable to acquire connection! Increase connection pool size and/or retryInterval settings Node source: NodeSource [slot=11834, addr=redis://10.10.14.61:6382, redisClient=null, redirect=MOVED, entry=null], command: (EVAL), params: [local expiredValues = redis.call('zrangebyscore', KEYS[2], 0, ARGV[1], 'limit', 0, ARGV[2]); if #exp..., 3, transfer_ttl_queue, redisson_delay_queue_timeout:{transfer_ttl_queue}, redisson_delay_queue:{transfer_ttl_queue}, 1579602478857, 100] after 0 retry attempts
thanks.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2554
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Our application uses UUIDs for keys and stores them in a RMapCache<String, Boolean>. Clearing 3MB of expired keys currently takes about 10 minutes though even a trivial service load can generate 5-7MB/min. Is there a way to increase the frequency of the eviction task, or increase the batch size of objects that are expired ?
Currently using a default configuration, connecting to a 3-node Redis cluster in Sentinel mode.
Dependencies:
redisson:redisson-spring-boot-starter:3.11.1
org.springframework.boot:spring-boot-starter-parent:2.1.2.RELEASE
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2555
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is your feature request related to a problem? Please describe.
I have about 100,000 redis object should be persist into Redis.
And they are of several data types. each data type will associate with others.
In other word, they form a cycle.
If I use RCascadeType.PERSIST, the program will stuck. Because it is gone into an infinite loop.
Describe the solution you'd like

regisiter rlo class method should record all the classes that user need to persist
add a new method to calculate the class's adjacencyArrays.
persist vertex classes
construct relationships according to adjacencyArrays.

Describe alternatives you've considered
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2556
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The code is as follows, the lock cannot be automatically deleted, the lock will continue to live

`
/**
 * redis testlock
 */
@GetMapping("/testLock")
public void testLock() {
  new Thread(() -> executeRedis()).start();
  log.error("====================控制器结束==================================="+this);
}



public void executeRedis(){
    final ExecutorService executor = Executors.newSingleThreadExecutor();
    FutureTask<Integer> future = new FutureTask(new RedisCallable(new Date()));
    executor.submit(future);
    try {
        int result = future.get(3, TimeUnit.SECONDS);
        log.error("=================,Thread Finish，Result：{}",JSON.toJSONString(result));
    } catch (Exception e) {
        log.error("=================,Thread Error：{}",e.getMessage(),e);
    }finally {
        future.cancel(true);
        executor.shutdownNow();
    }
}


@Data
@AllArgsConstructor
class RedisCallable implements Callable<Integer> {
    private Date date ;
    @Override
    public Integer call(){
        return redisLock(date);
    }
}



//-----------------------------------------------------------------------------------------------------------------

public int redisLock(Date startTimeStamp) {
    boolean isLock = false;
    RLock lock = redisService.getRedisLock("AAAAAAAAAAAAAAAAAAAA-LOCK");
    try {
        isLock = lock.tryLock(0, TimeUnit.SECONDS);
        if (isLock ) {
            log.error("=================,获取锁成功,开始执行....");
            while( (System.currentTimeMillis()-startTimeStamp.getTime())/1000 <=10 ){
               // log.error("Execute.......{}" , (System.currentTimeMillis()-startTimeStamp.getTime())/1000  );
            }
            log.error("=================线程10s，结束");
           return 1;
        }
    } catch (InterruptedException e) {
        log.error("redisLock-ERROR:{}",e.getMessage(),e);
    } finally {
        unlock(isLock,lock);
    }
    return 0;
}


public void sleep(int sleep,TimeUnit timeUnit){
    try {
        timeUnit.sleep(sleep);
    } catch (InterruptedException e) {
        e.printStackTrace();
    }
}



public void unlock(boolean isLock,RLock lock){
    //sleep(1,TimeUnit.MILLISECONDS);  //此段注释则不会自动删除锁,此段打开则可删除
    if (isLock && lock.isHeldByCurrentThread()){
        lock.unlock();
    }
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2557
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have a redisson lock implementation in my code like:
Distributed lock implementation:
@Autowired
public DistributedLockerImpl(RedissonClient redissonClient) {
this.redissonClient = redissonClient;
}
@Override
public RLock lock(String lockKey, long leaseTime) {
	RLock rlock = redissonClient.getFairLock(lockKey);
	rlock.lock(leaseTime, TimeUnit.SECONDS);
	return rlock;
	
}

@Override
public void unlock(String lockKey) {
	RLock rlock = redissonClient.getFairLock(lockKey);
	rlock.unlock();
}

@Override
public void unlock(RLock rlock) {
	rlock.unlock();
}

And client code is:
RLock lock = distributedLocker.lock(lockKey, 10);
try{
//logic code
}
finally {
distributedLocker.unlock(lock);
logger.info("Removed lock for id {}", lockKey);
}
SonarQube complains not having the lock unlocked in the same path as lock. Is there any solution for this? Or can we not have this implementation for redisson locks? It does always execute the unlock but relies on the client to do so.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2558
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Working with replicaof server.
Returning data when using RedisDesktopManager. But when I tried to create client following exception occurs with RedissonPromise
01-23 19:52:03.408 20281-20281/com.example.uhf E/AndroidRuntime: FATAL EXCEPTION: main Process: com.example.uhf, PID: 20281 java.lang.NoClassDefFoundError: org.redisson.misc.RedissonPromise at org.redisson.connection.MasterSlaveConnectionManager.shutdown(MasterSlaveConnectionManager.java:663) at org.redisson.connection.MasterSlaveConnectionManager.shutdown(MasterSlaveConnectionManager.java:643) at org.redisson.connection.MasterSlaveConnectionManager.stopThreads(MasterSlaveConnectionManager.java:727) at org.redisson.connection.MasterSlaveConnectionManager.initSingleEntry(MasterSlaveConnectionManager.java:363) at org.redisson.connection.MasterSlaveConnectionManager.<init>(MasterSlaveConnectionManager.java:167) at org.redisson.config.ConfigSupport.createConnectionManager(ConfigSupport.java:191) at org.redisson.Redisson.<init>(Redisson.java:120) at org.redisson.Redisson.create(Redisson.java:160) 
I am using
 implementation 'org.redisson:redisson:3.12.6'
using config
config.useMasterSlaveServers() .setMasterAddress("redis://<master ip> <master port>") .setReadMode(ReadMode.SLAVE) .addSlaveAddress("redis://<replica ip> <replica port>"); config.setCodec(JsonJacksonCodec.INSTANCE);
same exception occurs using config.useSingleServer()
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2559
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
There was almost no load on the system and it has almost no activity with only one idle connection  (we keep two connections in reserve - connectionMinimumIdleSize: 2) and the freeConnectionsCounter=63  (out of  connectionPoolSize: 64).
How come we received the “Command still hasn't been written into connection” error message? It seems like something was preventing Redisson from sending commands to Redis, resulting in a timeout exception...
org.redisson.client.RedisTimeoutException: Command still hasn't been written into connection! Increase nettyThreads and/or retryInterval settings Node source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=0, freeSubscribeConnectionsCounter=value:49:queue:0, freeConnectionsAmount=1, freeConnectionsCounter=value:63:queue:0, freezed=false, freezeReason=null, client=[addr=rediss://example8872.redis.cache.windows.net:6380], nodeType=MASTER, firstFail=0]]], connection: RedisConnection@491802721 [redisClient=[addr=rediss:// example8872.redis.cache.windows.net:6380], channel=[id: 0xdfc88972, L:/10.23.209.100:55594 - R: example8872.redis.cache.windows.net/52.111.71.236:6380], currentCommand=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@52cca638(failure: java.util.concurrent.CancellationException)], command=(HMSET), params=[p-bb:redisson:tomcat_session:EFE72C79B569DA602D9867772D1BA0D3, PooledUnsafeDirectByteBuf(freed), PooledUnsafeDirectByteBuf(freed), PooledUnsafeDirectByteBuf(freed), PooledUnsafeDirectByteBuf(freed), PooledUnsafeDirectByteBuf(freed), PooledUnsafeDirectByteBuf(freed), PooledUnsafeDirectByteBuf(freed), PooledUnsafeDirectByteBuf(freed), PooledUnsafeDirectByteBuf(freed), ...], codec=org.redisson.codec.CompositeCodec@2ae5abfe]], command: (HGETALL), params: [p-bb:redisson:tomcat_session:EFE72C79B969DA602D9865372D1BA0D3] after 5 retry attempts
at org.redisson.command.RedisExecutor$2.run(RedisExecutor.java:202) ~[redisson-all.jar:3.11.6]
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:680) ~[netty-common-4.1.32.Final.jar:3.11.6]
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:755) ~[netty-common-4.1.32.Final.jar:3.11.6]
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:483) ~[netty-common-4.1.32.Final.jar:3.11.6
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.32.Final.jar:3.11.6]
at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]

singleServerConfig:
idleConnectionTimeout: 30000
connectTimeout: 30000
timeout: 5000
retryAttempts: 5
retryInterval: 5000
subscriptionsPerConnection: 5
clientName: null
subscriptionConnectionMinimumIdleSize: 1
subscriptionConnectionPoolSize: 50
connectionMinimumIdleSize: 2
connectionPoolSize: 64
database: 0
dnsMonitoringInterval: 10000
threads: 32
nettyThreads: 64
codec: !<org.redisson.codec.FstCodec> {}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2560
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello there.
I try to use Redisson for schedule tasks in my Spring Boot application. And I have the next issue: after application restart with graceful shutdown - Redison scheduled executor service is in shutdown state, and all my tasks are rejected with exception
java.util.concurrent.RejectedExecutionException: Task rejected. ExecutorService is in shutdown state
Here is my code:
I use Distributed scheduled executor service like a bean
@Configuration
public class RedissonScheduledExecutorConfig {

    private static final String EXECUTOR_SERVICE_NAME = "rScheduledExecutor";

    @Bean
    public RScheduledExecutorService rScheduledExecutorService(
            final RedissonClient redissonClient,
            final BeanFactory beanFactory
    ) {
        final WorkerOptions workerOptions = WorkerOptions.defaults().workers(1).beanFactory(beanFactory);
        final ExecutorOptions executorOptions = ExecutorOptions.defaults()
                .taskRetryInterval(0, TimeUnit.SECONDS);
        final RScheduledExecutorService executorService = redissonClient
                .getExecutorService(EXECUTOR_SERVICE_NAME, executorOptions);
        executorService.registerWorkers(workerOptions);
        return executorService;
    }

}

Send the task to executor:
@RestController
@RequiredArgsConstructor
public final class TestController {

    private final RScheduledExecutorService rScheduledExecutorService;

    @GetMapping("/test")
    public String test() {
        final RScheduledFuture<?> rScheduledFuture = this.rScheduledExecutorService.schedule(
                new RunnableTask(),
                60,
                TimeUnit.SECONDS
        );
    }

}

Task implementation:
public final class RunnableTask implements Runnable, Serializable {

    private static final long serialVersionUID = 1L;

    @Autowired
    private transient MyService myService;

    @Override
    public void run() {
        this.myService.sendEmail();
    }

}

I use spring boot version - 2.1.7.RELEASE, and redisson-spring-boot-starter with version 3.11.5
Thank you for any help!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2561
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RedissonReactiveZSetCommands.zCount behaves incorrectly if one of range bounds is unbounded.
if lower bound is unbounded:
actual value: 0
expected value: -inf
if upper bound is unbounded:
actual value: -1
expected value: +inf
btw this is how RedissonReactiveZSetCommands.zRangeByScore implemented.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2562
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
we set TTL into CacheConfig when the cache is initially created. Is there a way to change that AFTER creation?
we are caching an api endpoint and would like to return stale objects even after expiry.
one way to achieve this is to check the downstream api and if not responding then extend ttl to use the existing stale object.

@bean("xxCacheManager")
CacheManager getCM(RedissonClient redissonClient) {
CacheConfig cacheConf = new CacheConfig();
cacheConf.setTTL(...);
Map<String, CacheConfig> configs = new HashMap<String, CacheConfig>() {{ put("xxCacheManager", cacheConf); }};
return new RedissonSpringCacheManager(redissonClient,configs);
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2563
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for your contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2564
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello guys,
I've setup Redission, Redission-Hibernate and Spring Data Cache to work with Spring Boot.
Pom definition:
	<properties>
		<redisson-spring-boot-starter.version>3.11.6</redisson-spring-boot-starter.version>
	</properties>

		<dependency>
			<groupId>org.hibernate</groupId>
			<artifactId>hibernate-core</artifactId>
		</dependency>

		<!-- redisson configuration begin -->
		<!-- For more information refer to documentation: https://github.com/redisson/redisson/tree/master/redisson-spring-boot-starter#spring-boot-starter -->
		<dependency>
			<!-- for Spring Data Redis v.2.1.x -->
			<groupId>org.redisson</groupId>
			<artifactId>redisson-spring-data-21</artifactId>
			<version>${redisson-spring-boot-starter.version}</version>
		</dependency>
		<dependency>
			<groupId>org.redisson</groupId>
			<artifactId>redisson-spring-boot-starter</artifactId>
			<version>${redisson-spring-boot-starter.version}</version>
		</dependency>
		<dependency>
			<groupId>org.redisson</groupId>
			<artifactId>redisson-hibernate-53</artifactId>
			<version>${redisson-spring-boot-starter.version}</version>
		</dependency>
		<!-- redisson configuration end -->


When I start the application I'm getting the following warning:
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/XXX/.m2/repository/de/ruedigermoeller/fst/2.57/fst-2.57.jar) to field java.lang.String.value
WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release


When I start the application through eclipse application lunch, everything works fine. But when I create my application jar (mvn package), and run it by prompt command and issue a request for a cached resource, I'm getting the following error:
ERROR 2020-01-27 16:46:41,393 [redisson-netty-5-11] org.redisson.client.handler.CommandDecoder:decodeCommand(212): Unable to decode data. channel: [id: 0x2137d2ce, L:/127.0.0.1:22780 - R:localhost/127.0.0.1:9000], reply: ReplayingDecoderByteBuf(ridx=122, widx=122), command: (EVAL), params: [local value = redis.call('hget', KEYS[1], ARGV[2]); if value == false then return nil; end; local t,..., 5, Location, redisson__timeout__set:{Location}, redisson__idle__set:{Location}, redisson__map_cache__last_access__set:{Location}, {Location}:redisson_options, 1580150801152, PooledUnsafeDirectByteBuf(ridx: 0, widx: 470, cap: 512)]
java.io.IOException: java.lang.RuntimeException: class not found CLASSNAME:org.hibernate.cache.spi.support.AbstractReadWriteAccess$SoftLockImpl loader:jdk.internal.loader.ClassLoaders$AppClassLoader@c387f44
        at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:247) ~[fst-2.57.jar!/:?]
        at org.redisson.codec.FstCodec$1.decode(FstCodec.java:250) ~[redisson-3.11.6.jar!/:3.11.6]
        at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:378) ~[redisson-3.11.6.jar!/:3.11.6]
        at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:209) [redisson-3.11.6.jar!/:3.11.6]
        at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:147) [redisson-3.11.6.jar!/:3.11.6]
        at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:117) [redisson-3.11.6.jar!/:3.11.6]
        at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:498) [netty-codec-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) [netty-codec-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276) [netty-codec-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:377) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:355) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:377) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) [netty-common-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [netty-common-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-common-4.1.45.Final.jar!/:4.1.45.Final]
        at java.lang.Thread.run(Thread.java:835) [?:?]
Caused by: java.lang.RuntimeException: class not found CLASSNAME:org.hibernate.cache.spi.support.AbstractReadWriteAccess$SoftLockImpl loader:jdk.internal.loader.ClassLoaders$AppClassLoader@c387f44
        at org.nustaq.serialization.FSTClazzNameRegistry.classForName(FSTClazzNameRegistry.java:235) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTClazzNameRegistry.classForName(FSTClazzNameRegistry.java:190) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTClazzNameRegistry.decodeClass(FSTClazzNameRegistry.java:173) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.coders.FSTStreamDecoder.readClass(FSTStreamDecoder.java:478) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTObjectInput.readClass(FSTObjectInput.java:939) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:347) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTObjectInput.readObjectInternal(FSTObjectInput.java:331) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:311) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:245) ~[fst-2.57.jar!/:?]
        ... 24 more
Caused by: java.lang.ClassNotFoundException: org.hibernate.cache.spi.support.AbstractReadWriteAccess$SoftLockImpl
        at jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:583) ~[?:?]
        at jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178) ~[?:?]
        at java.lang.ClassLoader.loadClass(ClassLoader.java:521) ~[?:?]
        at java.lang.Class.forName0(Native Method) ~[?:?]
        at java.lang.Class.forName(Class.java:415) ~[?:?]
        at org.nustaq.serialization.FSTClazzNameRegistry.classForName(FSTClazzNameRegistry.java:197) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTClazzNameRegistry.classForName(FSTClazzNameRegistry.java:190) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTClazzNameRegistry.decodeClass(FSTClazzNameRegistry.java:173) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.coders.FSTStreamDecoder.readClass(FSTStreamDecoder.java:478) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTObjectInput.readClass(FSTObjectInput.java:939) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:347) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTObjectInput.readObjectInternal(FSTObjectInput.java:331) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:311) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:245) ~[fst-2.57.jar!/:?]
        ... 24 more
WARN  2020-01-27 16:46:41,401 [redisson-netty-5-11] io.netty.channel.DefaultChannelPipeline:onUnhandledInboundException(1152): An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
io.netty.handler.codec.DecoderException: java.io.IOException: java.lang.RuntimeException: class not found CLASSNAME:org.hibernate.cache.spi.support.AbstractReadWriteAccess$SoftLockImpl loader:jdk.internal.loader.ClassLoaders$AppClassLoader@c387f44
        at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:421) ~[netty-codec-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276) ~[netty-codec-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:377) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:355) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:377) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) [netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) [netty-common-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [netty-common-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-common-4.1.45.Final.jar!/:4.1.45.Final]
        at java.lang.Thread.run(Thread.java:835) [?:?]
Caused by: java.io.IOException: java.lang.RuntimeException: class not found CLASSNAME:org.hibernate.cache.spi.support.AbstractReadWriteAccess$SoftLockImpl loader:jdk.internal.loader.ClassLoaders$AppClassLoader@c387f44
        at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:247) ~[fst-2.57.jar!/:?]
        at org.redisson.codec.FstCodec$1.decode(FstCodec.java:250) ~[redisson-3.11.6.jar!/:3.11.6]
        at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:378) ~[redisson-3.11.6.jar!/:3.11.6]
        at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:209) ~[redisson-3.11.6.jar!/:3.11.6]
        at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:147) ~[redisson-3.11.6.jar!/:3.11.6]
        at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:117) ~[redisson-3.11.6.jar!/:3.11.6]
        at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:498) ~[netty-codec-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) ~[netty-codec-4.1.45.Final.jar!/:4.1.45.Final]
        ... 17 more
Caused by: java.lang.RuntimeException: class not found CLASSNAME:org.hibernate.cache.spi.support.AbstractReadWriteAccess$SoftLockImpl loader:jdk.internal.loader.ClassLoaders$AppClassLoader@c387f44
        at org.nustaq.serialization.FSTClazzNameRegistry.classForName(FSTClazzNameRegistry.java:235) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTClazzNameRegistry.classForName(FSTClazzNameRegistry.java:190) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTClazzNameRegistry.decodeClass(FSTClazzNameRegistry.java:173) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.coders.FSTStreamDecoder.readClass(FSTStreamDecoder.java:478) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTObjectInput.readClass(FSTObjectInput.java:939) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:347) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTObjectInput.readObjectInternal(FSTObjectInput.java:331) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:311) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:245) ~[fst-2.57.jar!/:?]
        at org.redisson.codec.FstCodec$1.decode(FstCodec.java:250) ~[redisson-3.11.6.jar!/:3.11.6]
        at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:378) ~[redisson-3.11.6.jar!/:3.11.6]
        at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:209) ~[redisson-3.11.6.jar!/:3.11.6]
        at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:147) ~[redisson-3.11.6.jar!/:3.11.6]
        at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:117) ~[redisson-3.11.6.jar!/:3.11.6]
        at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:498) ~[netty-codec-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) ~[netty-codec-4.1.45.Final.jar!/:4.1.45.Final]
        ... 17 more
Caused by: java.lang.ClassNotFoundException: org.hibernate.cache.spi.support.AbstractReadWriteAccess$SoftLockImpl
        at jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:583) ~[?:?]
        at jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178) ~[?:?]
        at java.lang.ClassLoader.loadClass(ClassLoader.java:521) ~[?:?]
        at java.lang.Class.forName0(Native Method) ~[?:?]
        at java.lang.Class.forName(Class.java:415) ~[?:?]
        at org.nustaq.serialization.FSTClazzNameRegistry.classForName(FSTClazzNameRegistry.java:197) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTClazzNameRegistry.classForName(FSTClazzNameRegistry.java:190) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTClazzNameRegistry.decodeClass(FSTClazzNameRegistry.java:173) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.coders.FSTStreamDecoder.readClass(FSTStreamDecoder.java:478) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTObjectInput.readClass(FSTObjectInput.java:939) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:347) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTObjectInput.readObjectInternal(FSTObjectInput.java:331) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:311) ~[fst-2.57.jar!/:?]
        at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:245) ~[fst-2.57.jar!/:?]
        at org.redisson.codec.FstCodec$1.decode(FstCodec.java:250) ~[redisson-3.11.6.jar!/:3.11.6]
        at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:378) ~[redisson-3.11.6.jar!/:3.11.6]
        at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:209) ~[redisson-3.11.6.jar!/:3.11.6]
        at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:147) ~[redisson-3.11.6.jar!/:3.11.6]
        at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:117) ~[redisson-3.11.6.jar!/:3.11.6]
        at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:498) ~[netty-codec-4.1.45.Final.jar!/:4.1.45.Final]
        at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) ~[netty-codec-4.1.45.Final.jar!/:4.1.45.Final]
        ... 17 more

I have checked the dependencies inside the jar and I could find a nested dependency in the lib folder "./BOOT-INF/lib/hibernate-core-5.4.10.Final.jar".
I found the issue 2430, but in my case, all dependencies belongs to the same module.
What I'm missing?
Thanks in advance, Alan
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2565
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Probably this is a RLEC bug - RENAME shouldn't throw such errors since it executed behind cluster proxy. Did you contact their support?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2566
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Unable to unlock when thread isInterrupted,Please,RUN it First!!!!!!

`
/**
 * redis testlock
 */
@GetMapping("/testLock")
public void testLock() {
  new Thread(() -> executeRedis()).start();
  log.error("====================控制器结束==================================="+this);
}



public void executeRedis(){
    final ExecutorService executor = Executors.newSingleThreadExecutor();
    FutureTask<Integer> future = new FutureTask(new RedisCallable(new Date()));
    executor.submit(future);
    try {
        int result = future.get(3, TimeUnit.SECONDS);
        log.error("=================,Thread Finish，Result：{}",JSON.toJSONString(result));
    } catch (Exception e) {
        log.error("=================,Thread Error：{}",e.getMessage(),e);
    }finally {
        future.cancel(true);
        executor.shutdownNow();
    }
}


@Data
@AllArgsConstructor
class RedisCallable implements Callable<Integer> {
    private Date date ;
    @Override
    public Integer call(){
        return redisLock(date);
    }
}



//-----------------------------------------------------------------------------------------------------------------

public int redisLock(Date startTimeStamp) {
    boolean isLock = false;
    RLock lock = redisService.getRedisLock("AAAAAAAAAAAAAAAAAAAA-LOCK");
    try {
        isLock = lock.tryLock(0, TimeUnit.SECONDS);
        if (isLock ) {
            log.error("=================,获取锁成功,开始执行....");
            while( (System.currentTimeMillis()-startTimeStamp.getTime())/1000 <=10 ){
               // log.error("Execute.......{}" , (System.currentTimeMillis()-startTimeStamp.getTime())/1000  );
            }
            log.error("=================线程10s，结束");
           return 1;
        }
    } catch (InterruptedException e) {
        log.error("redisLock-ERROR:{}",e.getMessage(),e);
    } finally {
        unlock(isLock,lock);
    }
    return 0;
}


public void sleep(int sleep,TimeUnit timeUnit){
    try {
        timeUnit.sleep(sleep);
    } catch (InterruptedException e) {
        e.printStackTrace();
    }
}



public void unlock(boolean isLock,RLock lock){
    //sleep(1,TimeUnit.MILLISECONDS);  //此段注释则不会自动删除锁,此段打开则可删除
    if (isLock && lock.isHeldByCurrentThread()){
        lock.unlock();
    }
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2567
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
When using Redisson with JCache with custom Redisson config, this custom config should be taken into account
From documentation:
MutableConfiguration<String, String> jcacheConfig = new MutableConfiguration<>();

Config redissonCfg = ...
Configuration<String, String> config = RedissonConfiguration.fromConfig(redissonCfg, jcacheConfig);

CacheManager manager = Caching.getCachingProvider().getCacheManager();
Cache<String, String> cache = manager.createCache("namedCache", config);

Actual behavior
When executing Caching.getCachingProvider(), underneath config from default json config is used:
From JCachingProvider.java:
public CacheManager getCacheManager(URI uri, ClassLoader classLoader, Properties properties) {
		...
        Config config = this.loadConfig(uri);
        Redisson redisson = null;
        if (config != null) {
          redisson = (Redisson)Redisson.create(config);
		}
		...

Steps to reproduce or test case
Create a simple project with an empty redisson-jache.json(or without the file at all).
Create a cache as explained in the documentation: 14.4 JCache API (JSR-107) implementation -> 3. Using Redisson's config object:
Redisson version
3.11.2
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2568
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We have performed an analysis on how map and cache performs with 50 KB and 1 MB data . As part of it, we observed map performs well compared to cache and also as data size increases the performance is degrading.
But this states better performance with 6 bytes of data even though with open source redisson.
Are there any configuration parameters which will help us to get better performance? If any, please provide the details of those parameters.
Here are the benchmark performance numbers we got for 10000 entries :
**Time in milliseconds.

The redis configuration file, redisson configuration file and the sample program with which the performance numbers are taken are attached below.
redis_conf.txt
clusterServersConfig.txt
TestBenchmarkPerf.txt
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2569
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Reading Redis stream containing message without any field-value pairs should return successfully.
Actual behavior
IndexOutOfBoundsException is thrown:
2020-02-03 11:48:09.875 ERROR 10296 --- [redisson-netty-2-2] o.r.client.handler.CommandDecoder        : Unable to decode data. channel: [id: 0x7991be45, L:/10.x.x.x:40496 - R:xxxx.euc1.cache.amazonaws.com/10.x.x.x:6379], reply: ReplayingDecoderByteBuf(ridx=57, widx=336), command: (XREADGROUP), params: [GROUP, group, consumer, COUNT, 10, BLOCK, 1000, STREAMS, mystream, 0]
java.lang.IndexOutOfBoundsException: Index 0 out of bounds for length 0
	at java.base/jdk.internal.util.Preconditions.outOfBounds(Preconditions.java:64)
	at java.base/jdk.internal.util.Preconditions.outOfBoundsCheckIndex(Preconditions.java:70)
	at java.base/jdk.internal.util.Preconditions.checkIndex(Preconditions.java:248)
	at java.base/java.util.Objects.checkIndex(Objects.java:372)
	at java.base/java.util.ArrayList.get(ArrayList.java:458)
	at org.redisson.client.protocol.decoder.StreamObjectMapReplayDecoder.decode(StreamObjectMapReplayDecoder.java:45)
	at org.redisson.client.protocol.decoder.StreamObjectMapReplayDecoder.decode(StreamObjectMapReplayDecoder.java:31)
	at org.redisson.client.protocol.decoder.ListMultiDecoder2.decode(ListMultiDecoder2.java:46)
	at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:431)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:387)
	at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:422)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:387)
	at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:422)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:387)
	at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:422)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:387)
	at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:422)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:387)
	at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:209)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:147)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:117)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:503)
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:281)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1478)
	at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1227)
	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1274)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:503)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:442)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:281)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1422)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:931)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:700)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:635)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:552)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:514)
	at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:835)

Steps to reproduce or test case
Redis message contents:
*2
$15
1580730488492-0
*-1

Redis version
5.0.4
Redisson version
3.11.6
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2570
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
i am trying to create semaphore using below method from RMap interface.
RSemaphore getSemaphore(K key);
What is the default permits associated with this semaphore ?  i wanted to use Semaphore as an alternate to RLock , so i need a default max permit of 1. I see trySetPermits() method in RSemaphore class.. But is there a way to set default number of permits while creating Semaphore object without having to call trySetPermits() method.
Without a provision to set a default number of permits, how would we achieve the scenario where multiple threads are trying to create a semaphore with same key ? Developer is forced to ensure that everytime a semaphore object is created for a given key,  trySetPermits() method need to be called exactly once in the entire lifecycle of application. Is my understanding right ? what happens in below scenario assuming events happen in same sequence as listed
thread 1 calls rmap.getsemaphore(key1);
thread 1 calls trySetPermits(1); // number of availble permits is 1
thread 1 calls acquire();  // number of available permits to 0
thread 2 calls rmap.getsemaphore(key1);
thread 2 calls trySetPermits(1); // Will this call sets the available permits to 1 again ? What would happen here?
thread 2 calls acquire() // ideally thread 2 should not acquire permit.  What would happen here?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2571
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2572
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2573
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for the contribution, but all logic should be in the same persist method.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2574
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Recently I used redisson 3.11.6 to r/w online redis on our server serivce, however, after it runs few days correctly something bad happens. Yep, it is awful OOM. I dumped server memory file and found that the biggest object is ReferenceCacheMap from redission (see on the pic of jprofiler).. I am really confused about why this object increased all the time and can't be released by GC, I will post some pics, hope anyone can help me to fix this. Thanks a lot.


My config file like this:
{
"masterSlaveServersConfig":{
"idleConnectionTimeout":10000,
"pingTimeout":1000,
"connectTimeout":10000,
"timeout":3000,
"retryAttempts":3,
"retryInterval":1500,
"reconnectionTimeout":3000,
"failedAttempts":3,
"password":"xxxxxxxxxxx",
"subscriptionsPerConnection":5,
"clientName":null,
"loadBalancer":{
"class":"org.redisson.connection.balancer.RoundRobinLoadBalancer"
},
"slaveSubscriptionConnectionMinimumIdleSize":1,
"slaveSubscriptionConnectionPoolSize":50,
"slaveConnectionMinimumIdleSize":100,
"slaveConnectionPoolSize":200,
"masterConnectionMinimumIdleSize":32,
"masterConnectionPoolSize":64,
"readMode":"SLAVE",
"slaveAddresses":[
"redis://xxxxxxxxxx"
],
"masterAddress": "redis://xxxxxxx",
"database":0
},
"threads":0,
"nettyThreads":0,
"codec":{
"class":"org.redisson.codec.JsonJacksonCodec"
},
"transportMode":"NIO"
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2575
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
The pub/sub channels that are created while trying to acquire a lock with RedissonLock should be unsubscribed when no longer needed.
Actual behavior
Some pub/sub channels are still present (meaning that the client did not unsubscribe) even after some locks are no longer used (either they expired or were unlocked). These channels are never cleaned up (still present after 24h since created). The only workaround to get rid of these is to restart the client.
This was observed because it caused a connection leak. When calling RedissonLock to obtain new locks this returned the error : Subscribe timeout: (7500ms). Increase 'subscriptionsPerConnection' and/or 'subscriptionConnectionPoolSize' parameters. We have increased the limits in order to have a workaround for this bug
Steps to reproduce or test case

use RedissonLock.java implementation with method lockInterruptibly(long leaseTime, TimeUnit unit) to obtain multiple locks simultaneously.
use lower limits for  subscription-connection-pool-size and  subscriptions-per-connection to increase the probability to see the bug
wait until this error shows up Subscribe timeout: (7500ms). Increase 'subscriptionsPerConnection' and/or 'subscriptionConnectionPoolSize' parameters.
connect to Redis server and fetch all lock keys and all pub-sub channels.
if number of pub-sub channels > active locks , then the bug was reproduced
if number of pub-sub channels does not decrease at all long after locks are being created, this means that subscriptions have leaked, active long after these are no longer used in RedissonLock implementation

Redis version
5.0.5
Redisson version
3.11.6
Redisson configuration
    <redisson:client id="redissonClient">
        <redisson:single-server
            address="${redis.url}"
            idle-connection-timeout="10000"
            ping-timeout="1000"
            connect-timeout="10000"
            timeout="5000"
            connection-pool-size="32"
            connection-minimum-idle-size="12"
            subscription-connection-pool-size="64"
            subscriptions-per-connection="25"
        />
    </redisson:client>
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2576
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is there a way to know if a map with given name is created at redis end. As per understanding, org.redisson.api.RedissonClient.getMap(java.lang.String name) always gives new RedissonMap and only creates interacts with redis when one does any map operations like get/put.
Which means Using org.redisson.api.RedissonClient.getMap(java.lang.String name) will not send any request to redis ?
So how can i know that if a map with given name already exists at redis end using any of the redisson apis?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2577
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2578
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Test case for this feature is here.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2579
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
code:
redissonClient.getBucket("test123456").set("http://q57u6k1j6.bkt.clouddn.com/7c1da11a-c920-47ac-9b15-a83b3d2daaca");
I want to set "http://q57u6k1j6.bkt.clouddn.com/7c1da11a-c920-47ac-9b15-a83b3d2daaca" into redis server,but I find that this data become "    Ehttp://q57u6k1j6.bkt.clouddn.com/7c1da11a-c920-47ac-9b15-a83b3d2daaca",when I check redis server with tool——Redis Desktop Manager.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2580
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is your feature request related to a problem? Please describe.
We works with a lot of priority queue associated with Comparator (method trySetComparator). Result : Redisson create object in database like {akey}:redisson_sortedset_comparator, but never remove them.
Describe the solution you'd like
Could you add a parameter to set a TTL on theses objects? perhaps in method trySetComparator?
Describe alternatives you've considered
We have to delete these keys regularly, by hand
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2581
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
few questions on RPermitExpirableSemaphore


what is the probability that permit id generated by  acquire() method returns same permit id for different or same key ? In otherwords is there a possiblity of collision of permit Ids in any scenario when acquiring the permit via this interface ?


What happens to the permit when redisson node on which the permit was taken has crashed after permit ? Does the permit expire ? Does the LockWatchDogTimeout come into play here as well ?


How does LockWatchDog Scheduler works ? Is this a single daemon thread or is there a TimerTask triggered for every lock request ? I am looking to understand implementation details of LockWatchDog . can we get a reference to the java class in Redisson Source code that is responsible for prolonging the expiry of keys
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2582
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
No exceptions
Actual behavior
Error messages from CommandPubSubDecoder with messages saying:

Unable to decode data in separate thread: null
Unable to decode data. channel: [id: 0xdf76efe4, L:/100.112.155.17:45107 - R:master.xxx.cache.amazonaws.com/xxx.xxx.xxx.xxx:6379], reply: PooledUnsafeDirectByteBuf(ridx: 170, widx: 170, cap: 170)

Steps to reproduce or test case
Use @EnableRedissonWebSession or tryLockAsync (or potentially anything that uses pubsub). Then configure redisson to decode in executor via isDecodeInExecutor. Under decent load it easily throws these exceptions.
Redis version
5.0.5
Redisson version
3.11.6
Redisson configuration
(Done pragmatically but be equivalent to this:
singleServerConfig:
  idleConnectionTimeout: 30000
  pingTimeout: 1000
  connectTimeout: 1000
  timeout: 1000
  retryAttempts: 3
  retryInterval: 1000
  password: null
  address: null
  subscriptionsPerConnection: 5
  clientName: MyService123
  connectionMinimumIdleSize: 16
  connectionPoolSize: 32
  database: 0
  keepAlive: true
  dnsMonitoringInterval: 60000
  isDecodeInExecutor: true
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2583
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I've recently used spring-data redis and planning to move to redisson without spring.
How do I migrate this snippet of codes to redisson without flushing / reinserting my previous data.
`@RedisHash("client")
public class Client implements Serializable {
@Id
@Indexed
private String id;
@Indexed
private String computerName;
@Indexed
private String ipAddress;

}`
PagingAndSortingRepository.findAll()
I tried using RSet but it throws an NPE
 RSet<Client> rSet = client.getSet("client"); rSet.forEach(c -> { System.out.println(c.toString()); });
Unable to decode data. channel: [id: 0x5ea156f1, L:/127.0.0.1:62502 - R:localhost/127.0.0.1:6379], reply: ReplayingDecoderByteBuf(ridx=58, widx=58), command: (SSCAN), params: [client, 0, COUNT, 10]
java.io.IOException: java.lang.NullPointerException
at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:247)
at org.redisson.codec.FstCodec$1.decode(FstCodec.java:250)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:368)
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:412)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:377)
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:412)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:377)
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:196)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:134)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:104)
at
`
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2584
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello Nikita,
In our application we are using RLocalCachedMaps to improve performance. In certain cases we want to persist the data locally and not send it to redis. For that we are writing to RLocalCachedMaps with the assumption that it would not seed the same data to redis. But we see in background that writes to RLocalCachedMaps are also sent to redis. We verified this using Monitor command on Redis Server.
Can you please confirm if we have a way to prevent the writes to RLocalCachedMaps from going to redis. In case if there is any other Map that we should use, kindly let us know about that as well.
Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2585
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Does Redisson allows to release the semaphore  (RPermitExpirableSemaphore and RSemaphore) on different redisson client (different jvm) than the one on which permit was acquired ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2586
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi, we have some redisson client timeout issue.
We run a service with 30+ JVM instances. some instances' redisson client will randomly timeout (about 2 - 5 instances) and won't recover, but other instances still works fine.  The failed instances also use Jedis for some legacy feature, and it works fine too. We had to reboot the failed instances so it can recover.
Redis servers are in cluster mode, we recently scaled our cluster from 3 masters, 3 slaves to 9 masters, 9 slaves, and the problem happens more often.
Here's the timeout exception, hope it helps:
org.redisson.client.RedisTimeoutException: Unable to send command!
Node source: NodeSource [slot=null, addr=null, redisClient=null, redirect=null, 
entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=50, freeConnectionsAmount=40, freeConnectionsCounter=64, freezed=false, freezeReason=null, 
client=[addr=redis://10.30.123.42:26457], nodeType=MASTER, firstFail=0]]], 
connection: RedisConnection@742197929 [redisClient=[addr=redis://10.30.93.48:26457], 
channel=[id: 0xb70c2d91, L:/10.30.67.79:45357 - R:10.30.93.48/10.30.93.48:26457]], 
command: (GET), 
command params: [CATEGORY::OUTPUT::3_1] after 3 retry attempts
Redis server version: 3.0.7
Redisson version: 3.10.0
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2587
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Relate to #2043
Expected behavior
When using a fixed connection pool of min=64 and max=64 to every node (masters and slaves) on cluster config. Redisson is able to open a healthy connection pool of 64 to each of the nodes
Actual behavior
Connection never recover
Redis version
4.0.8 and use utils/create-cluster to create local cluster
Redission version
3.11.5
Reproduce step
Redisson configuration
		connectTimeout = 500
		timeout = 100
		masterConnectionMinimumIdleSize = 1 <== just to make it easier to reproduce.
		masterConnectionPoolSize = 1
		slaveConnectionMinimumIdleSize = 1
		slaveConnectionPoolSize = 1
		retryAttempts = 3
		retryInterval = 25
		keepAlive = true
		tcpNoDelay = true
		readMode = MASTER_SLAVE
		pingConnectionInterval = 2000
		nodeAddresses = [
							"redis://127.0.0.1:30001",
							"redis://127.0.0.1:30002",
							"redis://127.0.0.1:30003",
							"redis://127.0.0.1:30004",
							"redis://127.0.0.1:30005",
							"redis://127.0.0.1:30006"
		]
					}

and request controller, each HTTP GET request will fetch 100 keys from Redis cluster in batch mode.
	@GetMapping(path = "/get/{id}", produces = MediaType.APPLICATION_JSON_VALUE)
	public CompletionStage<Map<String, String>> get(@PathVariable("id") int id) {

		Set<String> req = new HashSet<>();
		for (int i = 0; i< 100; i++) {
			req.add("test"+ (id * 100  + i));
		}
		CompletionStage<Map<String, String>> test = myRedisClusterWithPrefix.getAllAsync(req);
		test.thenAccept(mm -> {
			//System.out.println("return "+ mm);
		});
		return test;
	}

stress test 100 concurrency
ab -n 10000  -c 100 http://localhost:8080/rapid-samples-minimal-spring-boot/get/5 
just after running about 20 seconds and stop the stress test tool.
then I call curl http://localhost:8080/rapid-samples-minimal-spring-boot/get/5 again
it will already return an error and never recover.
error log is
17:34:10.813 [DEBUG] r.s.o.r.c.ClusterConnectionManager - slot 3699 for api:rapid:test:test560
17:34:10.813 [DEBUG] r.s.o.r.c.RedisExecutor - connection released for command null and params null from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=value:50:queue:0, freeConnectionsAmount=1, freeConnectionsCounter=value:1:queue:0, freezed=false, freezeReason=null, client=[addr=redis://127.0.0.1:30004], nodeType=MASTER, firstFail=0]]] using connection RedisConnection@9214847 [redisClient=[addr=redis://127.0.0.1:30004], channel=[id: 0x25f4bc57, L:/127.0.0.1:53318 - R:127.0.0.1/127.0.0.1:30004], currentCommand=null]
17:34:10.846 [DEBUG] r.s.o.r.c.RedisExecutor - attempt 1 for command null and params null
17:34:10.846 [DEBUG] r.s.o.r.c.RedisExecutor - attempt 1 for command null and params null
17:34:10.881 [DEBUG] r.s.o.r.c.RedisExecutor - attempt 2 for command null and params null
17:34:10.881 [DEBUG] r.s.o.r.c.RedisExecutor - attempt 2 for command null and params null
17:34:10.916 [DEBUG] r.s.o.r.c.RedisExecutor - attempt 3 for command null and params null
17:34:10.917 [DEBUG] r.s.o.r.c.RedisExecutor - attempt 3 for command null and params null
17:34:10.957 [ERROR] c.r.r.e.h.RapidSpringErrorHandler - Unable to process unhandled exception
rapid.shaded.org.redisson.client.RedisTimeoutException: Unable to acquire connection! Increase connection pool size and/or retryIntervalNode source: NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=value:50:queue:0, freeConnectionsAmount=1, freeConnectionsCounter=value:1:queue:0, freezed=false, freezeReason=null, client=[addr=redis://127.0.0.1:30005], nodeType=MASTER, firstFail=0]]], command: null, params: null after 0 retry attempts
	at rapid.shaded.org.redisson.command.RedisExecutor$2.run(RedisExecutor.java:191)
	at rapid.shaded.io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:680)
	at rapid.shaded.io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:755)
	at rapid.shaded.io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:483)
	at rapid.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)

Connection status, still connected.
~ » lsof -P -p `jps |grep Application |awk '{print $1}'` |grep IPv     |grep 3000                                                         yinchin.chen@P49945
java    14825 yinchin.chen  237u     IPv6 0x3dec6b4ca72da4d1        0t0      TCP localhost:53301->localhost:30001 (ESTABLISHED)
java    14825 yinchin.chen  239u     IPv6 0x3dec6b4ca72dcd11        0t0      TCP localhost:53302->localhost:30006 (ESTABLISHED)
java    14825 yinchin.chen  241u     IPv6 0x3dec6b4ca72db051        0t0      TCP localhost:53303->localhost:30004 (ESTABLISHED)
java    14825 yinchin.chen  243u     IPv6 0x3dec6b4ca72dd2d1        0t0      TCP localhost:53304->localhost:30005 (ESTABLISHED)
java    14825 yinchin.chen  245u     IPv6 0x3dec6b4ca8fb3611        0t0      TCP localhost:53305->localhost:30002 (ESTABLISHED)
java    14825 yinchin.chen  246u     IPv6 0x3dec6b4ca8fb3051        0t0      TCP localhost:53306->localhost:30003 (ESTABLISHED)
java    14825 yinchin.chen  247u     IPv6 0x3dec6b4ca8fb3bd1        0t0      TCP localhost:53309->localhost:30001 (ESTABLISHED)
java    14825 yinchin.chen  248u     IPv6 0x3dec6b4ca8fb4191        0t0      TCP localhost:53311->localhost:30002 (ESTABLISHED)
java    14825 yinchin.chen  249u     IPv6 0x3dec6b4ca8fb4751        0t0      TCP localhost:53307->localhost:30001 (ESTABLISHED)
java    14825 yinchin.chen  250u     IPv6 0x3dec6b4ca8fb2a91        0t0      TCP localhost:53310->localhost:30003 (ESTABLISHED)
java    14825 yinchin.chen  253u     IPv6 0x3dec6b4ca8fb24d1        0t0      TCP localhost:53314->localhost:30005 (ESTABLISHED)
java    14825 yinchin.chen  254u     IPv6 0x3dec6b4ca8fb4d11        0t0      TCP localhost:53315->localhost:30006 (ESTABLISHED)
java    14825 yinchin.chen  255u     IPv6 0x3dec6b4ca8fb1f11        0t0      TCP localhost:53308->localhost:30005 (ESTABLISHED)
java    14825 yinchin.chen  256u     IPv6 0x3dec6b4ca8fb1951        0t0      TCP localhost:53313->localhost:30004 (ESTABLISHED)
java    14825 yinchin.chen  260u     IPv6 0x3dec6b4ca8fb52d1        0t0      TCP localhost:53316->localhost:30006 (ESTABLISHED)
java    14825 yinchin.chen  261u     IPv6 0x3dec6b4ca9512611        0t0      TCP localhost:53312->localhost:30004 (ESTABLISHED)
java    14825 yinchin.chen  277u     IPv6 0x3dec6b4ca9513751        0t0      TCP localhost:53318->localhost:30004 (ESTABLISHED)
java    14825 yinchin.chen  279u     IPv6 0x3dec6b4ca9513d11        0t0      TCP localhost:53319->localhost:30006 (ESTABLISHED)
java    14825 yinchin.chen  380u     IPv6 0x3dec6b4cabc0da91        0t0      TCP localhost:53419->localhost:30005 (ESTABLISHED)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2588
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I'm using a Redis Cluster over JCache API with Redisson 3.12.0.
This is my codec:
Config config = new Config();
config.setCodec( 
   FSTConfiguration.createUnsafeBinaryConfiguration()
                               .setCrossPlatform( false )
                               .setForceSerializable( true ) 
);

And I'm using javax.cache.event.CacheEntryListener the following way:
class MyEventListener implements CacheEntryRemovedListener<SomeCacheKey, SomeCacheValue>, Serializable {
    private static final long serialVersionUID = ...;

    @Override
    public void onRemoved( Iterable<CacheEntryEvent<? extends SomeCacheKey,
            ? extends SomeCacheValue>> events ) {
        ...
    }
}

cache.registerCacheEntryListener( new MutableCacheEntryListenerConfiguration<K, V>(
                    new FactoryBuilder.SingletonFactory<>( new MyEventListener ()) ),
                    new FactoryBuilder.SingletonFactory<>( event -> true ),
                    false,
                    true
);

When the event occurs, it comes to org.redisson.jcache.JCacheEventCodec failing here:
public Object decode(ByteBuf buf, State state) throws IOException {
            List<Object> result = new ArrayList();
            int keyLen;
            if (PlatformDependent.isWindows()) {
                keyLen = buf.readIntLE();
            } else {
                keyLen = (int)buf.readLongLE();
            }

            ByteBuf keyBuf = buf.readSlice(keyLen);

with this:
java.lang.IndexOutOfBoundsException: 
readerIndex(4) + length(1342177280) exceeds writerIndex(175): 
UnpooledSlicedByteBuf(ridx: 4, widx: 175, cap: 175/175, unwrapped: PooledUnsafeDirectByteBuf(ridx: 311, widx: 311, cap: 464))

io.netty.buffer.AbstractByteBuf.checkReadableBytes0(AbstractByteBuf.java:1477)
io.netty.buffer.AbstractByteBuf.checkReadableBytes(AbstractByteBuf.java:1463)
io.netty.buffer.AbstractByteBuf.readSlice(AbstractByteBuf.java:880)
org.redisson.jcache.JCacheEventCodec$1.decode(JCacheEventCodec.java:45)
org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:368)
org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:412)
org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:377)
org.redisson.client.handler.CommandPubSubDecoder.decodeCommand(CommandPubSubDecoder.java:76)
org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:134)
org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:91)
io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:498)
io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:377)
io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363)
io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:355)
io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:377)
io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363)
io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)
io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
java.lang.Thread.run(Thread.java:748)

Changing buf.readIntLE() / buf.readLongLE() to buf.readInt() / buf.readLong() fixes the issue.
Can anyone assist with any explanations?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2589
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
see discourse here: http://tomcat.10.x6.nabble.com/Tomcat-doesn-t-propogate-Security-Credentials-during-session-failover-td5094871.html
So the bug comes down to the fact that Redisson uses StandardSession, which does not serialize the security credential at all. Redisson should either:

Implement/Extend it's own Session object
Intentionally replicate security credentials

Expected behavior
If a failover event occurs, it should go un-noticed to an end user
Actual behavior
The user is logged out during a failover event
Steps to reproduce or test case
So you have two tomcat nodes: A & B, clustered in any fashion (forget I
mentioned redisson) of your choosing; let's say they're clustered using the
built in tcp point-to-point replication. Have 5 people logged into an
application on the first server using standard JavaEE APIs
(HttpServletrequest.login) Now turn off server A. Your load balancer starts
sending traffic to server B. Their sessions will be there, BUT they will be
logged out; one has to call HttpServletRequest.login() again. Upon login,
Tomcat destroys the previous session (as it should), nullifying any benefit
for clustering the application in the first place.
Redisson version
org.redisson:redisson-all:3.12.0
org.redisson:redisson-tomcat-8:3.12.0
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2590
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When using RLock to acquire Lock, Does LockWatchDog releases the lock when the thread that acquired the lock crashes for some reason without unlocking ?


Does Redisson gurantee that taking a permit on semaphore via RPermitExpirableSemaphore/Semaphore is an atomic operation ? Means what happens when Redis or Redisson gets crashed in the process of creating the semaphore object ? Is there any chance that there is some partial state left on the Redis ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2591
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We're using the Redis provided by AWS ElastiCache, Cluster mode and we need to handle some logic once losing connections with Redis, so we implement these 2 methods.
I shutdown the Redis manually in order to test these methods. However, it doesn't work as expected.
onDisconnect() is trigged successfully while onConnect() is also trigged unexpectly. Is there anything wrong inside?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2592
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redisson version: 3.12.1
We have the next situation:
Sometimes we update some of our entities that stored in a session.
After that we get a lot of exceptions in log:
org.redisson.client.RedisException: Unexpected exception while processing command
--
at org.redisson.command.CommandAsyncService.convertException(CommandAsyncService.java:401)
at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:205)
at org.redisson.RedissonObject.get(RedissonObject.java:94)
at org.redisson.RedissonMap.readAllMap(RedissonMap.java:507)
at org.redisson.tomcat.RedissonSession.getAttribute(RedissonSession.java:111)
...
Caused by: java.io.InvalidClassException: com.SomeEntity; local class incompatible: stream classdesc serialVersionUID = 123, local class serialVersionUID = 321

We catch this exception when we trying to get some client session parameters.
And it looks strange because the client already in the authorized zone and have a session, but actually session is invalid, so is it possible to invalidate session on deserialization?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2593
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi! Thanks for your work! I'm pretty new to this client and now trying to understand how it should be configured.
I'm using single node of Redis (5.0.7) with Redisson 3.12.1 and keep getting an error:
org.redisson.client.handler.CommandPubSubDecoder,[redisson-netty-2-26:]  Unable to decode data. channel: [id: 0x21b2c047, L:/127.0.0.1:63365 - R:127.0.0.1/127.0.0.1:6379], reply: ReplayingDecoderByteBuf(ridx=1060, widx=3729)
java.io.IOException: java.lang.RuntimeException: class not found CLASSNAME: loader:ParallelWebappClassLoader

As you can see classname is an empty string. Here is the full stacktrace:
at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:247) ~[fst-2.57.jar:?]
at org.redisson.codec.FstCodec$1.decode(FstCodec.java:250) ~[redisson-3.12.1.jar:3.12.1]
at org.redisson.jcache.JCacheEventCodec$1.decode(JCacheEventCodec.java:51) ~[redisson-3.12.1.jar:3.12.1]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:368) ~[redisson-3.12.1.jar:3.12.1]
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:412) ~[redisson-3.12.1.jar:3.12.1]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:377) ~[redisson-3.12.1.jar:3.12.1]
at org.redisson.client.handler.CommandPubSubDecoder.decodeCommand(CommandPubSubDecoder.java:76) ~[redisson-3.12.1.jar:3.12.1]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:134) ~[redisson-3.12.1.jar:3.12.1]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:91) ~[redisson-3.12.1.jar:3.12.1]
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:498) ~[netty-codec-4.1.45.Final.jar:4.1.45.Final]
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) ~[netty-codec-4.1.45.Final.jar:4.1.45.Final]
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276) ~[netty-codec-4.1.45.Final.jar:4.1.45.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:377) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:355) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:377) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[netty-common-4.1.45.Final.jar:4.1.45.Final]
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.45.Final.jar:4.1.45.Final]
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.45.Final.jar:4.1.45.Final]
at java.lang.Thread.run(Thread.java:748) [?:1.8.0_181]

Looking at the source code of JCacheEventCodec I noticed that it reads length of key differently depending on the platform. I'm running Java on Windows machine while Redis is on Linux. Now I want to figure out is it a bug or am I doing something in a wrong way?
BTW I tried to rebuild Redisson with reading key length as long (as if it was Linux or Mac) and the error disappeared.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2594
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hey, sorry for disburbing, is there a way or an event to listen to Object change (for example when I call RBucket.set(something) ?
If no, what do you advise me to use instead ?
Thanks in advance ! :)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2595
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
Redisson version
3.11.2
Redisson configuration
Sentinel mode
Map EntryExpiredListener is disabled, which is restored after the application is restarted, but will be disabled again soon.
I found that it would work every half hour during the failure, which should be a clue.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2596
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Machines are not evenly distributed, and one server never gets the lock.It's going to last forever
redisson 3.12.2
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2597
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We are having an issue using Redisson with Hibernate 5.3.
It appears the items are getting removed correctly due to the TTL, but their is still a Sorted Set that grows without ever getting pruned.
Any of the "redisson__map_cache__last_access__set:{**}" grow without ever having elements removed.
Current properties:
hibernate.cache.redisson.timestamps.expiration.time_to_live: 10
hibernate.cache.redisson.naturalid.expiration.time_to_live: 10
hibernate.cache.redisson.collection.expiration.time_to_live: 10
hibernate.cache.redisson.entity.expiration.time_to_live: 10
hibernate.cache.redisson.query.expiration.time_to_live: 10
Add sensible max. Otherwise they are unbounded.
hibernate.cache.redisson.timestamps.eviction.max_entries: 10000
hibernate.cache.redisson.naturalid.eviction.max_entries: 10000
hibernate.cache.redisson.collection.eviction.max_entries: 10000
hibernate.cache.redisson.entity.eviction.max_entries: 10000
hibernate.cache.redisson.query.eviction.max_entries: 10000
Also tried adding:
hibernate.cache.redisson.timestamps.expiration.max_idle_time: 0
hibernate.cache.redisson.naturalid.expiration.max_idle_time: 0
hibernate.cache.redisson.collection.expiration.max_idle_time: 0
hibernate.cache.redisson.entity.expiration.max_idle_time: 0
hibernate.cache.redisson.query.expiration.max_idle_time: 0
I've traced the code and I don't see any locations where the redisson__map_cache__last_access__set has any elements removed.
In the MapCacheEvictionTask, it does pass in the key, but it is never used in the LUA.
Let me know if I'm missing something in the config. Thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2598
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is your feature request related to a problem? Please describe.
Yes. One of the dependencies (snakeyaml 1.2.4) has a known vulnerability:
CVE-2017-18640
CVSS v2 Base Score: 5 | Impact Score: 2.9 | Exploitability Score: 10
Vulnerability Summary:
The Alias feature in SnakeYAML allows entity expansion during a load operation, a related issue to CVE-2003-1564.
Describe the solution you'd like
Please update to the latest snakeyaml
Describe alternatives you've considered
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2599
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
This is observed in JDK11 JVM. There should be no warnings, especially those that indicate that code may stop working in a future release.
Actual behavior
Warnings issued. See also (fst 295) Reporting here to make redisson committers aware.
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/.../fst-2.57.jar) to field java.lang.String.value
WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release

Steps to reproduce or test case
Running the app that uses redisson
Redis version
N/A
Redisson version
3.12.2
Redisson configuration
N/A
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2600
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We have some counter stored in RMap (LongCodec) so addAndGet operation is used. Unfortunately, following exception thrown when MapWriteBehindTask is invoked.
2020-02-20 06:06:12.708  WARN 2817 --- [sson-netty-2-13] io.netty.util.concurrent.DefaultPromise  : An exception was thrown by org.redisson.misc.RedissonPromise$$Lambda$652/251788397.operationComplete()

java.lang.IllegalArgumentException: java.io.IOException: java.lang.RuntimeException: Class org.redisson.misc.RedissonPromise does not implement Serializable or externalizable
	at org.redisson.RedissonObject.encode(RedissonObject.java:300)
	at org.redisson.RedissonList.addAsync(RedissonList.java:123)
	at org.redisson.RedissonList.addAsync(RedissonList.java:119)
	at org.redisson.RedissonList.add(RedissonList.java:114)
	at org.redisson.MapWriteBehindTask.addTask(MapWriteBehindTask.java:123)
	at org.redisson.RedissonMap.lambda$mapWriterFuture$5(RedissonMap.java:361)
	at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:187)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:570)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:549)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)
	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)
	at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)
	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)
	at org.redisson.misc.RedissonPromise.trySuccess(RedissonPromise.java:82)
	at org.redisson.command.RedisExecutor.handleReference(RedisExecutor.java:482)
	at org.redisson.command.RedisExecutor.handleSuccess(RedisExecutor.java:475)
	at org.redisson.command.RedisExecutor.handleResult(RedisExecutor.java:460)
	at org.redisson.command.RedisExecutor.checkAttemptPromise(RedisExecutor.java:446)
	at org.redisson.command.RedisExecutor.lambda$execute$3(RedisExecutor.java:164)
	at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:187)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:570)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:549)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)
	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)
	at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)
	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)
	at org.redisson.misc.RedissonPromise.trySuccess(RedissonPromise.java:82)
	at org.redisson.client.handler.CommandDecoder.completeResponse(CommandDecoder.java:444)
	at org.redisson.client.handler.CommandDecoder.handleResult(CommandDecoder.java:439)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:370)
	at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:196)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:134)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:104)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:503)
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:281)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1422)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:931)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:700)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:635)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:552)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:514)
	at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: java.lang.RuntimeException: Class org.redisson.misc.RedissonPromise does not implement Serializable or externalizable
	at org.redisson.codec.FstCodec$2.encode(FstCodec.java:279)
	at org.redisson.RedissonObject.encode(RedissonObject.java:298)
	... 53 common frames omitted
Caused by: java.lang.RuntimeException: Class org.redisson.misc.RedissonPromise does not implement Serializable or externalizable
	at org.nustaq.serialization.FSTClazzInfo.<init>(FSTClazzInfo.java:144)
	at org.nustaq.serialization.FSTClazzInfoRegistry.getCLInfo(FSTClazzInfoRegistry.java:129)
	at org.nustaq.serialization.FSTObjectOutput.getFstClazzInfo(FSTObjectOutput.java:534)
	at org.nustaq.serialization.FSTObjectOutput.writeObjectWithContext(FSTObjectOutput.java:416)
	at org.nustaq.serialization.FSTObjectOutput.writeObjectWithContext(FSTObjectOutput.java:369)
	at org.nustaq.serialization.FSTObjectOutput.writeObjectFields(FSTObjectOutput.java:664)
	at org.nustaq.serialization.FSTObjectOutput.defaultWriteObject(FSTObjectOutput.java:546)
	at org.nustaq.serialization.FSTObjectOutput.writeObjectWithContext(FSTObjectOutput.java:458)
	at org.nustaq.serialization.FSTObjectOutput.writeObjectInternal(FSTObjectOutput.java:327)
	at org.nustaq.serialization.FSTObjectOutput.writeObject(FSTObjectOutput.java:294)
	at org.nustaq.serialization.FSTObjectOutput.writeObject(FSTObjectOutput.java:204)
	at org.redisson.codec.FstCodec$2.encode(FstCodec.java:271)
	... 54 common frames omitted

Steps to reproduce or test case
public class MapAddAndGetTest {

    @Test
    public void testEntrySet() throws InterruptedException, ExecutionException {
        Map<Long, Long> storage = new HashMap<>();
        storage.put(1L, 1L);
        storage.put(2L, 2L);
        storage.put(3L, 3L);
        
        RMap<Long, Long> map = getWriteBehindTestMap("test", storage);

        map.addAndGetAsync(1L, 10L).get();
    }
    
    protected <K, V> MapWriter<K, V> createMapWriter(Map<K, V> map) {
        return new MapWriter<K, V>() {

            @Override
            public void write(Map<K, V> values) {
                map.putAll(values);
                System.out.println("map " + map);
            }

            @Override
            public void delete(Collection<K> keys) {
                for (K key : keys) {
                    map.remove(key);
                }
                System.out.println("delete " + keys + " map " + map);
            }
            
        };
    }
    
    protected <K, V> MapLoader<K, V> createMapLoader(Map<K, V> map) {
        return new MapLoader<K, V>() {
            @Override
            public V load(K key) {
                return map.get(key);
            }

            @Override
            public Iterable<K> loadAllKeys() {
                return map.keySet();
            }
        };
    }
    
    protected <K, V> RMap<K, V> getWriteBehindTestMap(String name, Map<K, V> map) {
        MapOptions<K, V> options = MapOptions.<K, V>defaults()
                                    .writer(createMapWriter(map))
                                    .writeMode(WriteMode.WRITE_BEHIND);
        return redisson.getMap(name, LongCodec.INSTANCE, options);        
    }

}

Redis version
3.2.12
Redisson version
3.12.2
Redisson configuration
codec: !<org.redisson.codec.FstCodec> {}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2601
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
No memory leak
Actual behavior
Memory leak
Steps to reproduce or test case
`public class CNRedisHandleFactory {
public static RedissonClient redisson;
public static BatchOptions options;
public static void main(String[] args) throws InterruptedException {
//        String clusterAddress = "192.168.11.73:7000||192.168.11.73:7001||192.168.11.83:7000||192.168.11.83:7001||192.168.11.93:7000||192.168.11.93:7001||192.168.11.107:7000||192.168.11.107:7001||192.168.11.111:7000||192.168.11.111:7001||192.168.11.121:7000||192.168.11.121:7001||192.168.11.131:7000||192.168.11.131:7001";
String ipAddress = "10.253.0.41:7000||10.253.0.41:7001||10.253.0.87:7000||10.253.0.87:7001||10.253.0.112:7000||10.253.0.112:7001||10.253.0.138:7000||10.253.0.138:7001||10.253.0.142:7000||10.253.0.142:7001||10.253.0.159:7000||10.253.0.159:7001||10.253.0.192:7000||10.253.0.192:7001";
int timeOut = 5000;
    List<String> sp = Arrays.asList(ipAddress.split("\\|\\|"));
    List<String> stringList = sp.stream().map(x->"redis://"+x).collect(Collectors.toList());
    String[] ip=stringList.toArray(new String[stringList.size()]);
    Config config = new Config();
    config.useClusterServers().addNodeAddress(ip)
            .setScanInterval(1000).setReadMode(ReadMode.MASTER_SLAVE)
            .setTimeout(timeOut)
            .setRetryAttempts(0)
            .setMasterConnectionPoolSize(64)
            .setSlaveConnectionPoolSize(64)
            .setMasterConnectionMinimumIdleSize(24)
            .setSlaveConnectionMinimumIdleSize(24)
    ;

    options = BatchOptions.defaults()
            .responseTimeout(timeOut, TimeUnit.MILLISECONDS)
            .retryInterval(1500, TimeUnit.MILLISECONDS)
            .retryAttempts(0);

    redisson = Redisson.create(config);

    int thread = Integer.parseInt(args[0]);
    int sleep = Integer.parseInt(args[1]);
    System.out.println("thread:" + thread + " sleep:" + sleep);

    for (int i = 0; i < thread; i++) {
        new Thread(new Runnable() {
            @Override
            public void run() {
                while (true) {
                    try {
                        Set<String> set = new HashSet();
                        int randomKeyNum = new Random().nextInt(10);
                        for (int loop = 0; loop <= randomKeyNum; ++loop) {
                            set.add(redisson.getKeys().randomKey());
                        }
                        Map<String, byte[]> temp = getByteArrayMap(set.toArray(new String[set.size()]));

                    } catch (Exception e) {
                        e.printStackTrace();
                    }
                    try {
                        Thread.sleep(sleep);
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
            }
        }).start();
    }

    Thread.sleep(1000000000000L);
}

public static Map<String,byte[]> getByteArrayMap(String... keys){
    Map<String, byte[]> res = new HashMap<>();
    RBatch batch = redisson.createBatch(options);
    for (String key : keys) {
        batch.getBucket(key, new ByteArrayCodec()).getAsync();
    }
    List<?> res1 = batch.execute().getResponses();
    for (int i = 0; i < res1.size(); i++) {
        if (res1.get(i) != null) {
            res.put(keys[i], (byte[]) res1.get(i));
        }
    }
    return res;
}

}
`
Redis version
5.0 and cluster with 7 nodes
Redisson version
3.12.2
JDK
1.8.0_91
Redisson configuration
Redisson configuration
		config.useClusterServers().addNodeAddress(ip)
        .setScanInterval(1000).setReadMode(ReadMode.MASTER_SLAVE)
        .setTimeout(timeOut)
        .setRetryAttempts(0)
        .setMasterConnectionPoolSize(64)
        .setSlaveConnectionPoolSize(64)
        .setMasterConnectionMinimumIdleSize(24)
        .setSlaveConnectionMinimumIdleSize(24)
;

options = BatchOptions.defaults()
        .responseTimeout(timeOut, TimeUnit.MILLISECONDS)
        .retryInterval(1500, TimeUnit.MILLISECONDS)
        .retryAttempts(0);

and request controller, 500 threads and each HTTP GET request will fetch 1-10 RandomKeys from Redis cluster in batch mode then sleep 30ms.
JVM PARAMS
JAVA_OPTS="-Xms400M -Xmx400M -XX:MaxDirectMemorySize=1G "
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2602
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi, it would be nice to have the ability to set  name for RedissonCache different from map inside cache.
To have different cache in different services with same names in the one redis instance just changing the name of the map inside the cache.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2603
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2604
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2605
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2606
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2607
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2608
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am trying to optimize an elasticache cluster clustered mode disabled in productive use by downscaling to a smaller instance type. As we all know, AWS will migrate to new nodes with different IP addresses and the client will need to reconnect.  I would like to configure my redisson client to reconnect fast to the master node so we minimize the downtime as much as possible. What are the best practices to reduce downtime and to connect to new master nodes and slaves as fast as possible? Note that I am using ReplicatedServers to connect to the cluster.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2609
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
From what I can tell it does. I don't think this is justified. No one should be using a library - casually or otherwise - without metrics and a basic eventing system.
There's many fine features of this product that I'd be HAPPY with as commercial only, including most of its task scheduling, but metrics is an absolute no-go.
Of course my needs may be different from others, but I ask you to reconsider this. Even providing a basic eventing system that OSS could build metrics from would be great.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2610
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2611
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am waiting for this merge. It would be great if you add a getter for redisson field because there is no way of accessing it if you use JCache.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2612
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2613
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
<dependency>
		<groupId>org.redisson</groupId>
		<artifactId>redisson-spring-boot-starter</artifactId>
		<version>2.15.2</version>
	</dependency>

In a spring boot 1.5.6 application , We have a new job which is running every 30 seconds and try to acquire lock to do something . In recent days the job has tried to acquire one specific lock cause of business , We found from 00:13 on Feb 24  the job can not get the lock but after 15:03 the job can get the lock again . The operation on this lock only in this job .
the code on the lock as below :
    boolean res = lock.tryLock();
    if (res) {
        try {
            ...
        } finally {
            if (lock.isHeldByCurrentThread())
                lock.unlock();
        }
    } else {
        LockUtils.logLockError(lockName, amount, null, "consume balance");
        msg = String.format("acquire merchant account lock (%s)failed", lockName);
    }

Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2614
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2615
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2616
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2617
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2618
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2619
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2620
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2621
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2622
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2623
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2624
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2625
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2626
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2627
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2628
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2629
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2630
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2631
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2632
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2633
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2634
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2635
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2636
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2637
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2638
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2639
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2640
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2641
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2642
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2643
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2644
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2645
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2646
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2647
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2648
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2649
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2650
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2651
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2652
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2653
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2654
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2655
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2656
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2657
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2658
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2659
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2660
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2661
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2662
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2663
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2664
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2665
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2666
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2667
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2668
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2669
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2670
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2671
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2672
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2673
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2674
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2675
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2676
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2677
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2678
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2679
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2680
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2681
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2682
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2683
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2684
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2685
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2686
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2687
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2688
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2689
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2690
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2691
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2692
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2693
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2694
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2695
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2696
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2697
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2698
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2699
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2700
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2701
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2702
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2703
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2704
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2705
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2706
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2707
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2708
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2709
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2710
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2711
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2712
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2713
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2714
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2715
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2716
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2717
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2718
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2719
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2720
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2721
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2722
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2723
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2724
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2725
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2726
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2727
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2728
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2729
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
My question is regarding configuration

subscriptionMode.slave

for redisson pubsub in a redis sentinel environment.
Since redis master node does not seem to replicate topics and subscription to the slaves.
I wanted to know how does redisson track on which slave nodes topics have been created.
Also,  if a subscription is created on slave node, it will not replicate to anywhere (being a slave) for two logical reasons:

Redis does not replicate topic subscriptions to slaves
A slave does not replicate anything to other nodes in Sentinel

I am asking this question, because I am unable to publish messages with this configuration.
I will be happy to be corrected if my assumptions above are wrong.
Redisson verison:- 3.11.5
redis version  5.0.5
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2730
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi all,
I wanna create two delayed queues, whose items can be both transferred to one specific queue. It seems, however, there's no queue name for delayed queues since the function getDelayedQueue only accepts just one argument. So getDelayedQueue(specificDestinationQueue) always returns the same delayed queue, right?
Is there any solutions? Any help would be appreciated.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2731
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Problem of 'java.util.Collections$SetFromMap' already exist in V3.12.4
[redisson-netty-2-8] ERROR org.redisson.client.handler.CommandPubSubDecoder - Unable to decode data. channel: [id: 0x2682e00a, L:/172.20.0.184:58040 - R..........], reply: ReplayingDecoderByteBuf(ridx=271, widx=271)
com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of java.util.Collections$SetFromMap (no Creators, like default construct, exist): no default no-arguments constructor found
at [Source: (io.netty.buffer.ByteBufInputStream); line: 1, column: 100] (through reference chain: org.redisson.tomcat.AttributeRemoveMessage["names"])
at com.fasterxml.jackson.databind.exc.InvalidDefinitionException.from(InvalidDefinitionException.java:67)
at com.fasterxml.jackson.databind.DeserializationContext.reportBadDefinition(DeserializationContext.java:1592)
at com.fasterxml.jackson.databind.DeserializationContext.handleMissingInstantiator(DeserializationContext.java:1058)
at com.fasterxml.jackson.databind.deser.ValueInstantiator.createUsingDefault(ValueInstantiator.java:189)
at com.fasterxml.jackson.databind.deser.std.StdValueInstantiator.createUsingDefault(StdValueInstantiator.java:267)
at com.fasterxml.jackson.databind.deser.std.StringCollectionDeserializer.deserialize(StringCollectionDeserializer.java:172)
at com.fasterxml.jackson.databind.deser.std.StringCollectionDeserializer.deserialize(StringCollectionDeserializer.java:21)
at com.fasterxml.jackson.databind.jsontype.impl.AsArrayTypeDeserializer._deserialize(AsArrayTypeDeserializer.java:120)
at com.fasterxml.jackson.databind.jsontype.impl.AsArrayTypeDeserializer.deserializeTypedFromArray(AsArrayTypeDeserializer.java:53)
at com.fasterxml.jackson.databind.deser.std.StringCollectionDeserializer.deserializeWithType(StringCollectionDeserializer.java:257)
at com.fasterxml.jackson.databind.deser.impl.FieldProperty.deserializeAndSet(FieldProperty.java:147)
at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:288)
at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:189)
at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:161)
at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedForId(AsPropertyTypeDeserializer.java:130)
at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:97)
at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromAny(AsPropertyTypeDeserializer.java:193)
at com.fasterxml.jackson.databind.deser.std.UntypedObjectDeserializer$Vanilla.deserializeWithType(UntypedObjectDeserializer.java:712)
at com.fasterxml.jackson.databind.deser.impl.TypeWrappedDeserializer.deserialize(TypeWrappedDeserializer.java:68)
at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4218)
at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3251)
at org.redisson.codec.JsonJacksonCodec$2.decode(JsonJacksonCodec.java:95)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:368)
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:412)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:377)
at org.redisson.client.handler.CommandPubSubDecoder.decodeCommand(CommandPubSubDecoder.java:71)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:134)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:91)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:498)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
throw exceptions when tomcat just start up
Redis v5.0
Redisson v3.12.4
{
"singleServerConfig":{
"idleConnectionTimeout":10000,
"connectTimeout":10000,
"timeout":3000,
"retryAttempts":3,
"retryInterval":1500,
"password":"xxxxxxx",
"subscriptionsPerConnection":5,
"clientName":null,
"address": "xxxxxxxxx",
"subscriptionConnectionMinimumIdleSize":1,
"subscriptionConnectionPoolSize":5,
"connectionMinimumIdleSize":5,
"connectionPoolSize":15,
"database":1,
"dnsMonitoringInterval":5000
},
"threads":16,
"nettyThreads":16,
"codec":{
"class":"org.redisson.codec.JsonJacksonCodec"
},
"transportMode":"NIO"
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2732
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Seeing the following exception in logs which results in command failure:
org.redisson.client.RedisNodeNotFoundException: Node: NodeSource [slot=15299, addr=redis://10.x.x.239:6379, redisClient=null, redirect=MOVED, entry=null] hasn't been discovered yet
        at express.security.session.store.RedisHashStore.logAsyncError(RedisHashStore.java:141)
        at express.security.session.store.RedisHashStore.lambda$removeAsync$6(RedisHashStore.java:136)
        at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:183)

Redis version
5.0.5
Redisson version
3.10.5
Redisson configuration
{
	"clusterServersConfig": {
		"idleConnectionTimeout": 5000,
		"pingTimeout": 250,
		"connectTimeout": 250,
		"timeout": 250,
		"retryAttempts": 3,
		"retryInterval": 150,
		"failedSlaveReconnectionInterval": 300,
		"failedSlaveCheckInterval": 6000,
		"password": "****",
		"subscriptionsPerConnection": 5,
		"clientName": "abc",
		"loadBalancer": {
			"class": "org.redisson.connection.balancer.RoundRobinLoadBalancer"
		},
		"subscriptionConnectionMinimumIdleSize": 1,
		"subscriptionConnectionPoolSize": 5,
		"slaveConnectionMinimumIdleSize": 5,
		"slaveConnectionPoolSize": 5,
		"masterConnectionMinimumIdleSize": 5,
		"masterConnectionPoolSize": 10,
		"readMode": "MASTER",
		"subscriptionMode": "MASTER",
		"nodeAddresses": [10.x.x.235:6379,10.x.x.236:6379,10.x.x.237:6379,10.x.x.238:6379,10.x.x.239:6379,10.x.x.240:6379,10.x.x.241:6379,10.x.x.242:6379,10.x.x.243:6379,10.x.x.244:6379,10.x.x.245:6379,10.x.x.246:6379,10.x.x.247:6379,10.x.x.248:6379,10.x.x.249:6379],
		"scanInterval": 1000,
		"pingConnectionInterval": 0,
		"keepAlive": false,
		"tcpNoDelay": false
	},
	"threads": 10,
	"nettyThreads": 10
}

Is the above issue resolved by: #2234 ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2733
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
description：
When using Redisson's Bucket function, the type conversion error is reported from time to time
such as ：java.lang.Long cannot be cast to org.redisson.client.protocol.decoder.ListScanResult
Expected behavior
Actual behavior
First error
java.lang.ClassCastException: java.lang.Long cannot be cast to com.xiaoyun.show.cache.CacheObject
at com.xiaoyun.show.cache.ActivityCacheHelper.computeIfAbsentCacheObject(ActivityCacheHelper.java:122)
at com.xiaoyun.show.cache.ActivityCacheHelper.getCacheObject(ActivityCacheHelper.java:103)
at com.xiaoyun.show.interceptors.SecurityWebFilter.doFilter(SecurityWebFilter.java:135)
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)
at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
Second error
java.lang.ClassCastException: java.lang.Long cannot be cast to org.redisson.client.protocol.decoder.ListScanResult
at org.redisson.RedissonKeys$2.iterator(RedissonKeys.java:131)
at org.redisson.RedissonKeys$2.iterator(RedissonKeys.java:126)
at org.redisson.BaseIterator.hasNext(BaseIterator.java:54)
at org.redisson.misc.CompositeIterator.hasNext(CompositeIterator.java:39)
at java.util.Iterator.forEachRemaining(Iterator.java:115)
at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)
at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)
at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545)
at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260)
at java.util.stream.ReferencePipeline.toArray(ReferencePipeline.java:438)
at com.xiaoyun.show.cache.ActivityCacheHelper.getCacheObjects(ActivityCacheHelper.java:153)
Steps to reproduce or test case

The code is called as follows(odd and even will appear)：
ActivityBasic activityBasic = cacheHelper.getCacheObject(ActivityBasic.class, activityId);
Map<String, ActivityCoupon> activityCouponMap = cacheHelper.getCacheObjects(ActivityCoupon.class, activityId);
Redis version
Redis server v=5.0.4
Redisson version
3.12.4
Redisson configuration
String address = "redis://" + getIp() + ":" + getPort();
SingleServerConfig singleServerConfig = config.useSingleServer()
       .setAddress(address)
       .setConnectionPoolSize(getPoolSize())
        .setConnectionMinimumIdleSize(getMinimumIdleSize());
if (!StringUtils.isEmpty(getPassword())) {
    singleServerConfig.setPassword(getPassword());
}
config.setCodec(new FstCodec());
config.setLockWatchdogTimeout(1000 * 30);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2734
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In Redis Cluster, all keys require in same slot with lua, so 'lua eval' is forbiddened in some case or in company，then how to solve this to use Redisson Lock?
Caused by: org.redisson.client.RedisException: ERR unknown command 'EVAL'
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2735
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When different tomcat instance which belong to different App use a same redis instance, but not same DB , it looks the session shared among instances ......The  session id of B98D3CB43DC1DF0B40C47EA71B45AED7 (exception as follows ) is belong to user of app A, but the exception throwed in app B.....Is it a bug??
**org.redisson.tomcat.RedissonSessionManager$2.onMessage Unable to handle topic message
java.lang.IllegalStateException: Unable to find session: B98D3CB43DC1DF0B40C47EA71B45AED7
at org.redisson.tomcat.RedissonSessionManager$2.onMessage(RedissonSessionManager.java:316)
*
Redis version:5.0.1
Redisson version:2.12.4
Redisson configuration
context.xml:


redisson.conf of A:
{
"singleServerConfig":{
"idleConnectionTimeout":10000,
"connectTimeout":10000,
"timeout":3000,
"retryAttempts":3,
"retryInterval":1500,
"password":"pw",
"subscriptionsPerConnection":5,
"clientName":null,
"address": "redis://connectString:6379",
"subscriptionConnectionMinimumIdleSize":1,
"subscriptionConnectionPoolSize":5,
"connectionMinimumIdleSize":5,
"connectionPoolSize":15,
"database":2, ## database : 2
"dnsMonitoringInterval":5000
},
"threads":16,
"nettyThreads":16,
"codec":{
"class":"org.redisson.codec.JsonJacksonCodec"
},
"transportMode":"NIO"
}

redisson.conf of app B:
{
"singleServerConfig":{
"idleConnectionTimeout":10000,
"connectTimeout":10000,
"timeout":3000,
"retryAttempts":3,
"retryInterval":1500,
"password":"pw",
"subscriptionsPerConnection":5,
"clientName":null,
"address": "redis://connectString:6379",
"subscriptionConnectionMinimumIdleSize":1,
"subscriptionConnectionPoolSize":5,
"connectionMinimumIdleSize":5,
"connectionPoolSize":15,
"database":1, ## database : 1
"dnsMonitoringInterval":5000
},
"threads":16,
"nettyThreads":16,
"codec":{
"class":"org.redisson.codec.JsonJacksonCodec"
},
"transportMode":"NIO"
}
Threy use same redis , but different database。 Is it not correct usage of redisson in tomcat  session  manager?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2736
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I was trying to deploy simple webapp using Redisson manager on AWS Elastic Beanstalk. The redis that I have configured, is also from AWS Elasticache.
Context.xml:
<Manager className="org.redisson.tomcat.RedissonSessionManager"
          configPath="${catalina.base}/conf/redisson.yml" readMode="REDIS" updateMode="DEFAULT"/>

redisson.yml:
singleServerConfig:
  idleConnectionTimeout: 10000
  connectTimeout: 10000
  timeout: 3000
  retryAttempts: 3
  retryInterval: 1500
  password: null
  subscriptionsPerConnection: 5
  clientName: null
  address: "redis://{ClusterName}.cache.amazonaws.com:6379"
  subscriptionConnectionMinimumIdleSize: 1
  subscriptionConnectionPoolSize: 50
  connectionMinimumIdleSize: 24
  connectionPoolSize: 64
  database: 0
  dnsMonitoringInterval: 5000
threads: 16
nettyThreads: 32
codec: !<org.redisson.codec.FstCodec> {}
transportMode: "NIO"


I have moved these 2 files to conf folder of Tomcat8, and also the required JARs to lib folder. If I login to box, I can see these files correctly updated in Tomcat directory.
Still when the deployment is complete, if I try to access the application, it does not come up. Even though I am able to see the war getting deployed in Tomcat.
Upon observing the logs, I saw below :
INFO [http-nio-8080-exec-3] org.redisson.tomcat.RedissonSessionManager.findSession Session 729345036D7A8E80685303969D2DA502 can't be found
Am I making any mistake here? Redisson version is : 3.12.4
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2737
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello, I'm current experiencing an issue with a Redis cluster(5.0.7) on Redisson 3.12.0 while testing how our system will handle the outage.
I'm using the springboot+Redisson. The test case will keep writing data to Redis Cluster(https://github.com/Grokzen/docker-redis-cluster).  On system startup, everything looks good and cache keys created in all the shards. However, if I take down the entire cluster and restart it again, I saw a bunch of following exception:
"message":"[RedisException] Failed to set cache for key test_key_85. Node for slot: 13620 hasn't been discovered yet. Check cluster slots coverage using CLUSTER NODES command",
Per the output of "CLUSTER NODES", all the nodes' status is "connected"
47419e46ba8f413e5ffb027de3ff8b97afd62bce 127.0.0.1:7005@17005 slave 5a7405b1b79a541f41d489932a6b0eafdb065cd0 0 1588189646053 6 connected 8d8a5c840aace9863b4ba24bf085961159e85bd3 127.0.0.1:7001@17001 master - 0 1588189646000 2 connected 5461-10922 42454fa187444828c9ade52453126dec125e1a9b 127.0.0.1:7004@17004 slave 6aad6a7709c6f06fee8eee3f4d0e94f7e3d0e056 0 1588189647062 5 connected 5a7405b1b79a541f41d489932a6b0eafdb065cd0 127.0.0.1:7000@17000 myself,master - 0 1588189646000 1 connected 0-5460 6aad6a7709c6f06fee8eee3f4d0e94f7e3d0e056 127.0.0.1:7002@17002 master - 0 1588189646054 3 connected 10923-16383 221d400589bfdba00a9fac7181b4222eaed6e23f 127.0.0.1:7003@17003 slave 8d8a5c840aace9863b4ba24bf085961159e85bd3 0 1588189645045 4 connected
Expected behavior
Redisson successfully reconnects to the cluster after the cluster restarts
Actual behavior
Throw exception every time the slot is in 2nd/3rd shard, which means slot number is larger than 5460.
{"thread":"http-nio-9992-exec-1","level":"ERROR","loggerName":"com.doordash.merchantdataservice.common.cache.RedisCacheWrapper","message":"[RedisException] Failed to set cache for key test_key_140. Node for slot: 6285 hasn't been discovered yet. Check cluster slots coverage using CLUSTER NODES command","endOfBatch":false,"loggerFqcn":"org.apache.logging.slf4j.Log4jLogger","instant":{"epochSecond":1588189837,"nanoOfSecond":770000000},"threadId":161,"threadPriority":5} Set key test_key_140 Set key test_key_141 {"thread":"http-nio-9992-exec-1","level":"ERROR","loggerName":"com.doordash.merchantdataservice.common.cache.RedisCacheWrapper","message":"[RedisException] Failed to set cache for key test_key_142. Node for slot: 14543 hasn't been discovered yet. Check cluster slots coverage using CLUSTER NODES command","endOfBatch":false,"loggerFqcn":"org.apache.logging.slf4j.Log4jLogger","instant":{"epochSecond":1588189844,"nanoOfSecond":170831000},"threadId":161,"threadPriority":5} Set key test_key_142 {"thread":"http-nio-9992-exec-1","level":"ERROR","loggerName":"com.doordash.merchantdataservice.common.cache.RedisCacheWrapper","message":"[RedisException] Failed to set cache for key test_key_143. Node for slot: 10478 hasn't been discovered yet. Check cluster slots coverage using CLUSTER NODES command","endOfBatch":false,"loggerFqcn":"org.apache.logging.slf4j.Log4jLogger","instant":{"epochSecond":1588189849,"nanoOfSecond":570894000},"threadId":161,"threadPriority":5} Set key test_key_143 {"thread":"metrics-statsd-reporter-2-thread-1","level":"ERROR","loggerName":"com.codahale.metrics.ScheduledReporter","message":"Exception thrown from StatsDReporter#report. Exception was suppressed.","thrown":{"commonElementCount":0,"localizedMessage":"bound must be positive","message":"bound must be positive","name":"java.lang.IllegalArgumentException","extendedStackTrace":[{"class":"java.util.concurrent.ThreadLocalRandom","method":"nextInt","file":"ThreadLocalRandom.java","line":310,"exact":false,"location":"?","version":"?"},{"class":"com.doordash.util.metrics.StatsDPool","method":"nextIndex","file":"StatsDPool.java","line":28,"exact":false,"location":"dd-util-0.2.12.jar","version":"?"},{"class":"com.doordash.util.metrics.StatsDPool","method":"get","file":"StatsDPool.java","line":24,"exact":false,"location":"dd-util-0.2.12.jar","version":"?"},{"class":"com.doordash.util.metrics.StatsDReporter","method":"report","file":"StatsDReporter.java","line":230,"exact":false,"location":"dd-util-0.2.12.jar","version":"?"},{"class":"com.codahale.metrics.ScheduledReporter","method":"report","file":"ScheduledReporter.java","line":237,"exact":false,"location":"metrics-core-4.0.3.jar","version":"4.0.3"},{"class":"com.codahale.metrics.ScheduledReporter","method":"lambda$start$0","file":"ScheduledReporter.java","line":177,"exact":true,"location":"metrics-core-4.0.3.jar","version":"4.0.3"},{"class":"java.util.concurrent.Executors$RunnableAdapter","method":"call","file":"Executors.java","line":515,"exact":true,"location":"?","version":"?"},{"class":"java.util.concurrent.FutureTask","method":"runAndReset$$$capture","file":"FutureTask.java","line":305,"exact":true,"location":"?","version":"?"},{"class":"java.util.concurrent.FutureTask","method":"runAndReset","file":"FutureTask.java","line":-1,"exact":true,"location":"?","version":"?"},{"class":"java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask","method":"run","file":"ScheduledThreadPoolExecutor.java","line":305,"exact":true,"location":"?","version":"?"},{"class":"java.util.concurrent.ThreadPoolExecutor","method":"runWorker","file":"ThreadPoolExecutor.java","line":1128,"exact":true,"location":"?","version":"?"},{"class":"java.util.concurrent.ThreadPoolExecutor$Worker","method":"run","file":"ThreadPoolExecutor.java","line":628,"exact":true,"location":"?","version":"?"},{"class":"java.lang.Thread","method":"run","file":"Thread.java","line":835,"exact":true,"location":"?","version":"?"}]},"endOfBatch":false,"loggerFqcn":"org.apache.logging.slf4j.Log4jLogger","instant":{"epochSecond":1588189850,"nanoOfSecond":983894000},"threadId":22,"threadPriority":5} {"thread":"http-nio-9992-exec-1","level":"ERROR","loggerName":"com.doordash.merchantdataservice.common.cache.RedisCacheWrapper","message":"[RedisException] Failed to set cache for key test_key_144. Node for slot: 6153 hasn't been discovered yet. Check cluster slots coverage using CLUSTER NODES command","endOfBatch":false,"loggerFqcn":"org.apache.logging.slf4j.Log4jLogger","instant":{"epochSecond":1588189854,"nanoOfSecond":970959000},"threadId":161,"threadPriority":5} Set key test_key_144
Steps to reproduce or test case
Redis version
5.0.7
Redisson version
3.12.0
Redisson configuration
clusterServersConfig:
idleConnectionTimeout: 30000
pingTimeout: 1000
connectTimeout: 3000
timeout: 1000
retryAttempts: 3
retryInterval: 1000
failedSlaveReconnectionInterval: 3000
failedSlaveCheckInterval: 60000
password: null
nodeAddresses:
- "redis://localhost:7001"
subscriptionsPerConnection: 5
clientName: MyService
loadBalancer: !<org.redisson.connection.balancer.RoundRobinLoadBalancer> {}
subscriptionConnectionMinimumIdleSize: 1
subscriptionConnectionPoolSize: 10
slaveConnectionMinimumIdleSize: 1
slaveConnectionPoolSize: 2
masterConnectionMinimumIdleSize: 3
masterConnectionPoolSize: 4
readMode: "SLAVE"
subscriptionMode: "SLAVE"
scanInterval: 1000
pingConnectionInterval: 3000
keepAlive: true
tcpNoDelay: false
threads: 16
nettyThreads: 32
codec: !<org.redisson.codec.JsonJacksonCodec> {}
transportMode: "NIO"
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2738
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I use https://github.com/Grokzen/docker-redis-cluster as my redis-cluster which crates 3 masters ans 3 slaves. I use the following redisson configurations:
clusterServersConfig: idleConnectionTimeout: 30000 pingTimeout: 1000 connectTimeout: 3000 timeout: 1000 retryAttempts: 3 retryInterval: 1000 failedSlaveReconnectionInterval: 3000 failedSlaveCheckInterval: 60000 password: null nodeAddresses: - "redis://localhost:7001" subscriptionsPerConnection: 5 clientName: MyService loadBalancer: !<org.redisson.connection.balancer.RoundRobinLoadBalancer> {} subscriptionConnectionMinimumIdleSize: 1 subscriptionConnectionPoolSize: 10 slaveConnectionMinimumIdleSize: 1 slaveConnectionPoolSize: 2 masterConnectionMinimumIdleSize: 3 masterConnectionPoolSize: 4 readMode: "SLAVE" subscriptionMode: "SLAVE" scanInterval: 1000 pingConnectionInterval: 3000 keepAlive: true tcpNoDelay: false threads: 16 nettyThreads: 32 codec: !<org.redisson.codec.JsonJacksonCodec> {} transportMode: "NIO" 
On app start up, I use "CLIENT LIST | grep MyService | wc -l" to calculate all the connection numbers on each node and get the following results:
7000 : 29  <-- master, self
7001 : 31   <-- master
7002: 29   <-- master
7003: 27.   <-- salve of 7001
7004: 27.   <-- slave of 7002
7005: 27.   <-- slave of 7000
Could u please help to clarify how Redisson determine the connection numbers? or do we have any document that can describe the internal mechanism?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2739
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
version: 3.12.4
When force failing over the number of connections to the new master are getting doubled. We establish around 6000 connections to redis server across all application servers. We didn't change the default idle connections from 24. After failover we observe 48 idle connection to new master, and it's not coming down till we restart the application servers. Because of this issue we had to change the max connections in redis-server to 20000 from 10000.
Configuration used.
Config config = new Config();
config.setCodec(StringCodec.INSTANCE);

SentinelServersConfig serverConfig = config.useSentinelServers()
	.setMasterName("cb-master")
	.setScanInterval(2000) 
	.setReadMode(ReadMode.MASTER_SLAVE) 
	.setTimeout(20000)
	.setPingConnectionInterval(10000)
	.setCheckSentinelsList(false);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2740
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
clusterServersConfig:
idleConnectionTimeout: 30000
pingTimeout: 1000
subscriptionConnectionMinimumIdleSize: 1
subscriptionConnectionPoolSize: 10
slaveConnectionMinimumIdleSize: 1
slaveConnectionPoolSize: 2
masterConnectionMinimumIdleSize: 3
masterConnectionPoolSize: 4
pingConnectionInterval: 0
keepAlive: true
I use the above settings. The connections is always 2 event the idle time is bigger than 20 seconds.
id=134 addr=172.18.0.1:43642 fd=19 name=MerchantDataService age=1278 idle=1278 flags=r db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=readonly id=135 addr=172.18.0.1:43696 fd=20 name=MerchantDataService age=1278 idle=1278 flags=r db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=readonly
Did I miss something?
Btw, for the connections in master node, it always 4 and no connection is closed after idleConnectionTimeout.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2741
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RLock base on thredId to judge holder, how can i custom rules like base on an income string?
or is there any way to implements ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2742
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
It should support multiple timestamps per value and entry expiration.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2743
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Background
I'm using redis as a lock manager in my application. I set up the AWS elasticache redis server with 1 primary and 2 replicas.
Expected behavior
All Redisson clients can connect to the server
Actual behavior
My application is running on mutiple ec2 instances, there is always some instances(for example 2/10, 5/30) can't connect to elasticache redis server.
Steps to reproduce or test case
When I deploy the application through beanstalk. There is always some instance fail at the healthcheck. When I check the log of those instances. Here is what I found:
7:49:43.767 [redisson-netty-9-2] DEBUG io.netty.buffer.AbstractByteBuf - -Dio.netty.buffer.checkAccessible: true
17:49:43.767 [redisson-netty-9-2] DEBUG io.netty.buffer.AbstractByteBuf - -Dio.netty.buffer.checkBounds: true
17:49:43.767 [redisson-netty-9-2] DEBUG i.n.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@48fb807b
17:49:43.798 [redisson-netty-9-2] WARN  io.netty.util.ReferenceCountUtil - Failed to release a message: DatagramPacket(=> /(ip address), PooledUnsafeDirectByteBuf(freed))
17:49:43.894 [redisson-netty-9-2] DEBUG i.netty.resolver.dns.DnsNameResolver - [id: 0xf7a028f9] RECEIVED: [42375: /172.30.0.2:53], DatagramDnsResponse(from: /172.30.0.2:53, to: /0.0.0.0:46149, 42375, QUERY(0), NoError(0), RD RA)
17:49:43.897 [redisson-netty-9-2] DEBUG i.netty.resolver.dns.DnsQueryContext - [id: 0xf7a028f9] WRITE: [51958: /172.30.0.2:53], DefaultDnsQuestion(redis endpoint). IN A)
17:49:43.904 [redisson-netty-9-2] WARN  io.netty.util.ReferenceCountUtil - Failed to release a message: DatagramPacket(=> /(ip address), PooledUnsafeDirectByteBuf(freed))
17:49:43.915 [redisson-netty-9-2] WARN  io.netty.util.ReferenceCountUtil - Failed to release a message: DatagramDnsResponse(from: /(ip address), to: /0.0.0.0:46149, 42375, QUERY(0), NoError(0), RD RA)
17:49:43.921 [redisson-netty-9-2] DEBUG i.netty.resolver.dns.DnsNameResolver - [id: 0xf7a028f9] RECEIVED: [51958: /172.30.0.2:53], DatagramDnsResponse(from: /(ip address), to: /0.0.0.0:46149, 51958, QUERY(0), NoError(0), RD RA)
17:49:43.965 [redisson-netty-9-2] WARN  io.netty.util.ReferenceCountUtil - Failed to release a message: DatagramDnsResponse(from: /(ip address), to: /0.0.0.0:46149, 51958, QUERY(0), NoError(0), RD RA)
17:49:44.055 [redisson-netty-9-3] DEBUG io.netty.handler.ssl.JdkSslContext - Default protocols (JDK): [TLSv1.2, TLSv1.1, TLSv1]
17:49:44.058 [redisson-netty-9-3] DEBUG io.netty.handler.ssl.JdkSslContext - Default cipher suites (JDK): [TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA, TLS_RSA_WITH_AES_128_GCM_SHA256, TLS_RSA_WITH_AES_128_CBC_SHA, TLS_RSA_WITH_AES_256_CBC_SHA]
17:49:44.227 [redisson-netty-9-3] DEBUG io.netty.handler.ssl.SslHandler - [id: 0xea4a64c3, L:/(ip address) - R:(redis master endpoint)/(ip address):6379] SSLEngine.closeInbound() raised an exception.
17:49:44.230 [redisson-netty-9-3] WARN  io.netty.util.ReferenceCountUtil - Failed to release a message: PooledUnsafeDirectByteBuf(freed)
Caused by: org.redisson.client.RedisConnectionException: Can't connect to servers!
	at org.redisson.connection.ReplicatedConnectionManager.<init>(ReplicatedConnectionManager.java:98) ~[redisson-3.12.5.jar:3.12.5]
	at org.redisson.config.ConfigSupport.createConnectionManager(ConfigSupport.java:206) ~[redisson-3.12.5.jar:3.12.5]
	at org.redisson.Redisson.<init>(Redisson.java:64) ~[redisson-3.12.5.jar:3.12.5]
	at org.redisson.Redisson.create(Redisson.java:104) ~[redisson-3.12.5.jar:3.12.5]


Redis version
5.0.5
Redisson version
3.12.5
Redisson configuration
I use replicated serverConfig and I only pass the one master endpoint in the config.
  // 1. Create config object  
Config config = new Config();  
ReplicatedServersConfig replicatedServersConfig = config.useReplicatedServers();  
  String redisURIFormat = "rediss://%s:%d";  
replicatedServersConfig.addNodeAddress(String.format(redisURIFormat, context.get().getEndpoint(), context.get().getPort()));  
replicatedServersConfig.setPassword(context.get().getAuthToken());  
return Redisson.create(config);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2744
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
connections for Redis cluster
7000: 17
7001: 17
7002: 67
7003: 67
7004: 17
7005: 19

d059d4385143f50065d8af39b5d1802eee23995c 127.0.0.1:7005@17005 myself,master - 0 1588375071000 14 connected 0-5460
f45784901ae916629008f28045d3f6c4c229d7b5 127.0.0.1:7002@17002 master - 0 1588375071000 16 connected 10923-16383
5bffb4061e8258210d5dab911af5028e5e9faa65 127.0.0.1:7001@17001 slave 0db7080759d155fa098516c04e442d40ec348234 0 1588375072926 15 connected
0db7080759d155fa098516c04e442d40ec348234 127.0.0.1:7003@17003 master - 0 1588375071513 15 connected 5461-10922
beebdb6edb0fcff2afbff6b9cb0e354dc489bb93 127.0.0.1:7000@17000 slave d059d4385143f50065d8af39b5d1802eee23995c 0 1588375071000 14 connected
c043ee0879b79ee4ca357237433c24897dc25ce8 127.0.0.1:7004@17004 slave f45784901ae916629008f28045d3f6c4c229d7b5 0 1588375071918 16 connected

For those connections to 7002/7003, I found that all of their idle time is larger than idleConnectionTimeout.   Could you please help to clarify why Redisson doesn't kill those connections?
$redis-cli -c -p 7002 client list | grep MyService 
id=171 addr=172.18.0.1:50020 fd=50 name=MyService age=6264 idle=6264 flags=r db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=readonly
id=172 addr=172.18.0.1:50022 fd=51 name=MyService age=6264 idle=6264 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=client
id=173 addr=172.18.0.1:50024 fd=52 name=MyService age=6264 idle=6264 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=cluster
id=174 addr=172.18.0.1:50026 fd=53 name=MyService age=6264 idle=6264 flags=r db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=readonly
id=175 addr=172.18.0.1:50028 fd=54 name=MyService age=6264 idle=6264 flags=r db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=readonly
id=176 addr=172.18.0.1:50034 fd=10 name=MyService age=6264 idle=6264 flags=r db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=readonly

My setting is as following:
clusterServersConfig:
  idleConnectionTimeout: 30000
  subscriptionConnectionMinimumIdleSize: 1
  subscriptionConnectionPoolSize: 10
  slaveConnectionMinimumIdleSize: 16
  slaveConnectionPoolSize: 64
  masterConnectionMinimumIdleSize: 16
  masterConnectionPoolSize: 64
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2745
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
您好！我使用了masterSlaveServersConfig配置好主从分离环境了！
/**
* 加载redisson配置
* @return
* @throws IOException
*/
@bean(destroyMethod="shutdown")
public RedissonClient redissonClient() throws IOException {
InputStream inputStream = new ClassPathResource(configProperties.getRedisson().getPath()).getInputStream();
return Redisson.create(Config.fromYAML(inputStream));
}
这是加载方式！现在无法确认redisconClien实例化出来的  在走读库的同时是否是走的从库（无感知）
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2746
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We have a prod env which is using Redis cluster in AWS and aws provide a cluster endpoint. Our redisson configuration is cluster mode. But we just use the cluster endpoint in nodeAddress but not a list of cluster nodes:
  nodeAddresses:
    - "redis://my_cluster_endpoing.xxx.clustercfg.usw2.cache.amazonaws.com:6379"

When we upgrade Redis cluster,  ip address of all the nodes are  changed. It seems that Redisson cannot figure out the new ip address. It keeps  reconnecting to the old ip addresses and we have to bounce all the micro services to mitigate this issue.
I found that DNS monitoring is not enabled for cluster mode. Do you have any suggestion do solve/work-around this issue?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2747
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
7000: 115
7001: 79
7002: 110
7003: 55
7004: 63
7005: 70
bfecab1697163710144b8b2d856ec9849644ce19 127.0.0.1:7004@17004 slave 156092ec03d87f4758ead59d381115bc814fb02d 0 1588575861519 5 connected
156092ec03d87f4758ead59d381115bc814fb02d 127.0.0.1:7000@17000 master - 0 1588575863034 1 connected 0-5460
33b499b2eaa6b5b3cce9000a2c69f6377e115f5b 127.0.0.1:7002@17002 master - 0 1588575862021 3 connected 10923-16383
b91203ffc948b641f1d6e72fccee5b89abc063ad 127.0.0.1:7003@17003 slave 33b499b2eaa6b5b3cce9000a2c69f6377e115f5b 0 1588575861519 4 connected
a2b3d429e43d749577366e7890af4b849c7ba11c 127.0.0.1:7005@17005 myself,slave e5c2bd7af1c0929ffa792b4da28b58c143a39671 0 1588575862000 6 connected
e5c2bd7af1c0929ffa792b4da28b58c143a39671 127.0.0.1:7001@17001 master - 0 1588575861013 2 connected 5461-10922

Description : I set slaveConnectionPoolSize/masterConnectionPoolSize to 64.  But node 7000/7002(master) has 115 connections
Question_1: Is this a bug?
Description : I waited for a long time to check if those connections can be killed.  Unfortunately, those connections are always alive. It seems that idleConnectionTimeout doesn't work as expected.
id=193 addr=172.18.0.1:49182 fd=128 name=MyServiceName age=414 idle=366 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=psetex

Question_2 : I'm wondering if there's something wrong with my configuration or it's a bug?
My Configuration is as followed: Cluster mode
  idleConnectionTimeout: 30000
  slaveConnectionMinimumIdleSize: 16
  slaveConnectionPoolSize: 64
  masterConnectionMinimumIdleSize: 16
  masterConnectionPoolSize: 64
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2748
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redisson version: 3.12.4
In production we are seeing intermittent error spikes of background sentinel commands timeout failures like SENTINEL SENTINELS, SENTINEL SLAVES, SENTINEL GET-MASTER-ADDR-BY-NAME. Are these related to available nettyThreads? This is happening only in couple of servers, we have around 100+ servers in production with similar settings. At the same time we didn't see any regular application side used commands' redis timeouts.
org.redisson.client.RedisTimeoutException: Command execution timeout for command: (SENTINEL GET-MASTER-ADDR-BY-NAME)

Can you let me know what could be reason for these intermittent errors?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2749
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Distributed scheduled executor service occur exception：
Caused by: java.lang.IllegalArgumentException: java.io.IOException: java.lang.RuntimeException: Class org.redisson.Redisson does not implement Serializable or externalizable
	at org.redisson.RedissonExecutorService.encode(RedissonExecutorService.java:383)
	at org.redisson.RedissonExecutorService.scheduleAsync(RedissonExecutorService.java:979)
	at org.redisson.RedissonExecutorService.schedule(RedissonExecutorService.java:969)
	at com.xiaoyun.ws.support.ServerPacketSchedule.scheduleSendPackets(ServerPacketSchedule.java:46)
	at com.xiaoyun.ws.support.ServerPacketSchedule.<init>(ServerPacketSchedule.java:35)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:172)
	... 21 common frames omitted
Caused by: java.io.IOException: java.lang.RuntimeException: Class org.redisson.Redisson does not implement Serializable or externalizable
	at org.redisson.codec.FstCodec$2.encode(FstCodec.java:279)
	at org.redisson.RedissonExecutorService.encode(RedissonExecutorService.java:378)
	... 30 common frames omitted
Caused by: java.lang.RuntimeException: Class org.redisson.Redisson does not implement Serializable or externalizable
	at org.nustaq.serialization.FSTClazzInfo.<init>(FSTClazzInfo.java:144)
	at org.nustaq.serialization.FSTClazzInfoRegistry.getCLInfo(FSTClazzInfoRegistry.java:129)
	at org.nustaq.serialization.FSTObjectOutput.getFstClazzInfo(FSTObjectOutput.java:534)
	at org.nustaq.serialization.FSTObjectOutput.writeObjectWithContext(FSTObjectOutput.java:416)
	at org.nustaq.serialization.FSTObjectOutput.writeObjectWithContext(FSTObjectOutput.java:369)
	at org.nustaq.serialization.FSTObjectOutput.writeObjectFields(FSTObjectOutput.java:664)
	at org.nustaq.serialization.FSTObjectOutput.defaultWriteObject(FSTObjectOutput.java:546)
	at org.nustaq.serialization.FSTObjectOutput.writeObjectWithContext(FSTObjectOutput.java:458)
	at org.nustaq.serialization.FSTObjectOutput.writeObjectInternal(FSTObjectOutput.java:327)
	at org.nustaq.serialization.FSTObjectOutput.writeObject(FSTObjectOutput.java:294)
	at org.nustaq.serialization.FSTObjectOutput.writeObject(FSTObjectOutput.java:204)
	at org.redisson.codec.FstCodec$2.encode(FstCodec.java:271)
code as：
 executorService = redisson.getExecutorService("ServerPacketSchedule");
 RunnableTask runnableTask = new RunnableTask(bootstrap, redisson );
 scheduledFuture = executorService.schedule(runnableTask, CronSchedule.of("0/1 * * * * ?"));
 public static class RunnableTask implements Runnable, Serializable {
     private RedissonClient redissonClient;
     private TioWebSocketServerBootstrap bootstrap;
 
     public RunnableTask(TioWebSocketServerBootstrap bootstrap, RedissonClient redissonClient) {
         this.redissonClient = redissonClient;
         this.bootstrap = bootstrap;
     }
     @Override
     public void run() {
         RList<Object> list = redissonClient.getList("live:packet-buffer");
         if (CollectionUtils.isNotEmpty(list)) {
             WsResponse wsResponse = ServerPacket.createBath(list.toArray());
             Tio.sendToAll(bootstrap.getTioConfig(), wsResponse);
             list.clear();
         }
     }
 }
redisson-version：3.12.5
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2750
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
org.redisson.client.RedisNodeNotFoundException: Node for slot: 14296 hasn't been discovered yet. Check cluster slots coverage using CLUSTER NODES command
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2751
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
in UpdateValve,java there is following code (all tomcat valves needs to be checked for such code):
getNext().invoke(request, response);

and getNext() could return null if there are no additional valves to invoke
Expected behavior
No NullPointerException to occur
Actual behavior
NullPointerException would occur in Valves that uses getNext().invoke(...), if getNext() return null.
Steps to reproduce or test case
Redis version
Redisson version
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2752
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We have a Redis cluster in AWS, in which there're 50 master nodes. Each master node has 1 slave node.
One of the nodes looks like:
001-001.usw2.cache.amazonaws.com (master)
001-002.usw2.cache.amazonaws.com (slave)
I use nslookup to check the ip address of these dns records.
master(001-001.usw2.cache.amazonaws.com) has ip : 172.31.33.149
slave(001-002.usw2.cache.amazonaws.com) has ip : 172.31.33.51
Our Redisson client keeps connecting to an unknown ip:  172.31.33.151
Per the result of "cluster nodes", I found that the unknown ip is a failed slave node,
b34bae2fef43d70f75be8162140188e87823012f 172.31.33.151:6379 slave,fail bc8f4f25b680672c389192d076d8f050a0705675 1587800858187 1587800853882 290 connected
bc8f4f25b680672c389192d076d8f050a0705675 172.31.30.149:6379 master - 0 1588725334984 290 connected 10924-10976 11014-11287
d3d42e9140d2aa90237023c1938ce1ad5ee331bd 172.31.33.51:6379 slave bc8f4f25b680672c389192d076d8f050a0705675 0 1588725335480 290 connected

Per the AWS console, I'm sure that dns name of the current slave is 172.31.33.51.
So the ip 151 should be stale and we should not reconnect to that address. The retry attempts throw a timeout exception and make cpu/memory usage high, which lead to memory leak issue.
{"stream":"stdout","time":"2020-05-06T00:44:47.475020436Z","thread":"redisson-netty-8-25","level":"ERROR","loggerName":"org.redisson.cluster.ClusterConnectionManager","message":"Can't add slave: redis://172.31.33.151:6379","thrown":{"commonElementCount":0,"localizedMessage":"Unable to connect to Redis server: 172.31.33.151/172.31.33.151:6379","message":"Unable to connect to Redis server: 172.31.33.151/172.31.33.151:6379","name":"org.redisson.client.RedisConnectionException","cause":{"commonElementCount":6,"localizedMessage":"connection timed out: 172.31.33.151/172.31.33.151:6379","message":"connection timed out: 172.31.33.151/172.31.33.151:6379","name":"io.netty.channel.ConnectTimeoutException","extendedStackTrace":[{"class":"io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1","method":"run","file":"AbstractNioChannel.java","line":267,"exact":false,"location":"netty-transport-4.1.31.Final.jar!/","version":"4.1.31.Final"},{"class":"io.netty.util.concurrent.PromiseTask$RunnableAdapter","method":"call","file":"PromiseTask.java","line":38,"exact":false,"location":"netty-common-4.1.31.Final.jar!/","version":"4.1.31.Final"},{"class":"io.netty.util.concurrent.ScheduledFutureTask","method":"run","file":"ScheduledFutureTask.java","line":127,"exact":false,"location":"netty-common-4.1.31.Final.jar!/","version":"4.1.31.Final"}]},"extendedStackTrace":[{"class":"org.redisson.connection.pool.ConnectionPool$1","method":"lambda$run$0","file":"ConnectionPool.java","line":160,"exact":true,"location":"redisson-3.12.0.jar!/","version":"3.12.0"},{"class":"org.redisson.misc.RedissonPromise","method":"lambda$onComplete$0","file":"RedissonPromise.java","line":183,"exact":true,"location":"redisson-3.12.0.jar!/","version":"3.12.0"},{"class":"io.netty.util.concurrent.DefaultPromise","method":"notifyListener0","file":"DefaultPromise.java","line":511,"exact":true,"location":"netty-common-4.1.31.Final.jar!/","version":"4.1.31.Final"},{"class":"io.netty.util.concurrent.DefaultPromise","method":"notifyListenersNow","file":"DefaultPromise.java","line":485,"exact":true,"location":"netty-common-4.1.31.Final.jar!/","version":"4.1.31.Final"},{"class":"io.netty.util.concurrent.DefaultPromise","method":"notifyListeners","file":"DefaultPromise.java","line":424,"exact":true,"location":"netty-common-4.1.31.Final.jar!/","version":"4.1.31.Final"},{"class":"io.netty.util.concurrent.DefaultPromise","method":"tryFailure","file":"DefaultPromise.java","line":121,"exact":true,"location":"netty-common-4.1.31.Final.jar!/","version":"4.1.31.Final"},{"class":"org.redisson.misc.RedissonPromise","method":"tryFailure","file":"RedissonPromise.java","line":96,"exact":true,"location":"redisson-3.12.0.jar!/","version":"3.12.0"},{"class":"org.redisson.connection.pool.ConnectionPool","method":"promiseFailure","file":"ConnectionPool.java","line":330,"exact":true,"location":"redisson-3.12.0.jar!/","version":"3.12.0"},{"class":"org.redisson.connection.pool.ConnectionPool","method":"lambda$createConnection$1","file":"ConnectionPool.java","line":296,"exact":true,"location":"redisson-3.12.0.jar!/","version":"3.12.0"},{"class":"org.redisson.misc.RedissonPromise","method":"lambda$onComplete$0","file":"RedissonPromise.java","line":183,"exact":true,"location":"redisson-3.12.0.jar!/","version":"3.12.0"},{"class":"io.netty.util.concurrent.DefaultPromise","method":"notifyListener0","file":"DefaultPromise.java","line":511,"exact":true,"location":"netty-common-4.1.31.Final.jar!/","version":"4.1.31.Final"},{"class":"io.netty.util.concurrent.DefaultPromise","method":"notifyListeners0","file":"DefaultPromise.java","line":504,"exact":true,"location":"netty-common-4.1.31.Final.jar!/","version":"4.1.31.Final"},{"class":"io.netty.util.concurrent.DefaultPromise","method":"notifyListenersNow","file":"DefaultPromise.java","line":483,"exact":true,"location":"netty-common-4.1.31.Final.jar!/","version":"4.1.31.Final"},{"class":"io.netty.util.concurrent.DefaultPromise","method":"notifyListeners","file":"DefaultPromise.java","line":424,"exact":true,"location":"netty-common-4.1.31.Final.jar!/","version":"4.1.31.Final"},{"class":"io.netty.util.concurrent.DefaultPromise","method":"tryFailure","file":"DefaultPromise.java","line":121,"exact":true,"location":"netty-common-4.1.31.Final.jar!/","version":"4.1.31.Final"},{"class":"org.redisson.misc.RedissonPromise","method":"tryFailure","file":"RedissonPromise.java","line":96,"exact":true,"location":"redisson-3.12.0.jar!/","version":"3.12.0"},{"class":"org.redisson.client.RedisClient$2$2","method":"run","file":"RedisClient.java","line":249,"exact":true,"location":"redisson-3.12.0.jar!/","version":"3.12.0"},{"class":"io.netty.util.concurrent.AbstractEventExecutor","method":"safeExecute","file":"AbstractEventExecutor.java","line":163,"exact":true,"location":"netty-common-4.1.31.Final.jar!/","version":"4.1.31.Final"},{"class":"io.netty.util.concurrent.SingleThreadEventExecutor","method":"runAllTasks","file":"SingleThreadEventExecutor.java","line":404,"exact":true,"location":"netty-common-4.1.31.Final.jar!/","version":"4.1.31.Final"},{"class":"io.netty.channel.nio.NioEventLoop","method":"run","file":"NioEventLoop.java","line":466,"exact":true,"location":"netty-transport-4.1.31.Final.jar!/","version":"4.1.31.Final"},{"class":"io.netty.util.concurrent.SingleThreadEventExecutor$5","method":"run","file":"SingleThreadEventExecutor.java","line":897,"exact":true,"location":"netty-common-4.1.31.Final.jar!/","version":"4.1.31.Final"},{"class":"io.netty.util.concurrent.FastThreadLocalRunnable","method":"run","file":"FastThreadLocalRunnable.java","line":30,"exact":true,"location":"netty-common-4.1.31.Final.jar!/","version":"4.1.31.Final"},{"class":"java.lang.Thread","method":"run","file":"Thread.java","line":834,"exact":true,"location":"?","version":"?"}]},"endOfBatch":false,"loggerFqcn":"org.apache.logging.slf4j.Log4jLogger","instant":{"epochSecond":1588725887,"nanoOfSecond":474607000},"threadId":156,"threadPriority":5,"meta":{"env":"prod"},"kubernetes":{"pod_name":"merchant-data-service-kafka-consumer-5b75584d77-4c4gm","namespace_name":"merchant-data-service","pod_id":"9c34263d-8f20-11ea-9d66-06e0ee830e70","labels":{"app":"kafka-consumer","managed-by":"Tiller","pod-template-hash":"1631140833","service":"merchant-data-service"},"host":"ip-172-31-225-82.us-west-2.compute.internal","container_name":"kafka-consumer","docker_id":"fb46025e3378900deb8b095ab0b0b011436779227ec18351e721a587cb377808","container_hash":"c3afd6353de439e6101efc9ff908f940664e0dfbaf976499bae061abef11c5d5"}}

Our system do have connection for the master node (ip 172.31.33.149) and the new slave node (ip 172.31.33.51)
Is there any way/configuration to stop Redisson connecting to the stale node?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2753
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I want to use bloom filter by redisson and set expire.
when data is expired, init agin, I need to execute RBloomFilter.add() too many times.
how can I use by pipeline? thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2754
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Exception as below:
[05-06 21:59:06] [ERROR] [http-nio-8889-e] o.a.c.c.C.[.[.[/showservice].[dispatcherServlet]   - Servlet.service() for servlet [dispatcherServlet] in context with path [/showservice] threw exception
org.redisson.client.RedisException: ERR bad lua script for redis cluster, all the keys that the script uses should be passed using the KEYS array, and KEYS should not be in expression. channel: [id: 0x7091849f, L:/172.16.156.8:38216 - R:r-bp128ubvf0obdjoh62.redis.rds.aliyuncs.com/172.16.156.9:6379] command: (EVAL), params: [local rate = redis.call('hget', KEYS[1], 'rate');local interval = redis.call('hget', KEYS[1], 'inter..., 3, live:rate-limiter:119.126.28.207:1000, {live:rate-limiter:119.126.28.217:1000}:value, {live:rate-limiter:119.126.28.207:1000}:value:3a0eaa24-eead-492b-990f-458f32dcc846, 1, 3a0eaa24-eead-492b-990f-458f32dcc846]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:371)
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:215)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:153)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:122)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:682)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:617)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:534)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:906)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
config：
ReplicatedServersConfig replicatedServersConfig = config.useReplicatedServers()
// 主节点变化扫描间隔时间
.setScanInterval(2000)
.addNodeAddress(aliyunRedisAddress);
        if (redisConfig.hasPassword()) {
            replicatedServersConfig.setPassword(redisConfig.getPassword());
        }

redissonClient = Redisson.create(config);
redis:  aliyun redis cluster
redisson: 3.12.5
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2755
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
https://github.com/redisson/redisson/wiki/7.-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E5%90%88#711-%E6%98%A0%E5%B0%84map%E7%9A%84%E5%85%83%E7%B4%A0%E6%B7%98%E6%B1%B0eviction%E6%9C%AC%E5%9C%B0%E7%BC%93%E5%AD%98localcache%E5%92%8C%E6%95%B0%E6%8D%AE%E5%88%86%E7%89%87sharding这篇文章中对Redisson中本地缓存Map的淘汰策略方式，SOFT和WAKE的注释是不是写反了
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2756
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I use Redisson-Tomcat with update mode AFTER_REQUEST. I'd like to do an update to a specific session attribute before the request gets to the UpdateValve. I think (ignoring for the moment ClassLoader issues) I can do something like redissonManager.getTopic().publish(new AttributeUpdateMessage(redissonManager.getNodeId(), session.getId(), "qq", "vv", encoder)); but is there a better way?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2757
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Environment:

RHEL 7.7
Apache Tomcat 9.0.31
AWS ElastiCache/Redis

Scenario:
An app is hosted by two tomcat instances, Tomcat A, and Tomcat B, both are configured with AWS ElastiCache/Redis. The host is registered with AWS Application Load Balancer (sticky enabled).

The user logon to Tomcat A, and the session is cached by Redis -- good.
I killed Tomcat A
Load balancer started forwarding the traffic to Tomcat B -- Expected
The user continue to work wit the app
Tomcat B detect the change, and try to fetch session id from Redis, the I get this error, see stack dump:



conext.xml
readMode="MEMORY" updateMode="DEFAULT" broadcastSessionEvents="true"


redisson.yaml
singleServerConfig:
address: "redis://*********************:6379"
pingConnectionInterval: 60000
timeout: 60000
nettyThreads: 256
codec: !<org.redisson.codec.KryoCodec> {}


Redis/Kryo libraries:
reflectasm-1.11.9.jar
redisson-tomcat-9-3.12.5.jar
redisson-all-3.12.5.jar
objenesis-2.1.jar
kryo-serializers-0.45.jar
kryo-4.0.2.jar
minlog-1.3.0.jar


Stack dump


Caused by: com.esotericsoftware.kryo.KryoException: Class cannot be created (missing no-arg constructor): org.apache.catalina.realm.GenericPrincipal
at com.esotericsoftware.kryo.Kryo$DefaultInstantiatorStrategy.newInstantiatorOf(Kryo.java:1319) ~[kryo-4.0.2.jar:?]
at com.esotericsoftware.kryo.Kryo.newInstantiator(Kryo.java:1127) ~[kryo-4.0.2.jar:?]
at com.esotericsoftware.kryo.Kryo.newInstance(Kryo.java:1136) ~[kryo-4.0.2.jar:?]
at com.esotericsoftware.kryo.serializers.FieldSerializer.create(FieldSerializer.java:562) ~[kryo-4.0.2.jar:?]
at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:538) ~[kryo-4.0.2.jar:?]
at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:816) ~[kryo-4.0.2.jar:?]
at org.redisson.codec.KryoCodec$1.decode(KryoCodec.java:63) ~[redisson-all-3.12.5.jar:3.12.5]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:368) ~[redisson-all-3.12.5.jar:3.12.5]
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:412) ~[redisson-all-3.12.5.jar:3.12.5]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:377) ~[redisson-all-3.12.5.jar:3.12.5]
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:196) ~[redisson-all-3.12.5.jar:3.12.5]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:134) ~[redisson-all-3.12.5.jar:3.12.5]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:104) ~[redisson-all-3.12.5.jar:3.12.5]
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:498) ~[redisson-all-3.12.5.jar:3.12.5]
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) ~[redisson-all-3.12.5.jar:3.12.5]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2758
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When calling RedissonTransactionalMapCache.put(K key, V value, long ttl, TimeUnit ttlUnit, long maxIdleTime, TimeUnit maxIdleUnit), the TTL for cache entries is not set correctly.  The problem is that putAsync is passing the expiration timestamp into putOperationAsync.  However, the code in expect it to be a passed the actual TTL value.
What happens is that when we get here (in BaseTransactionalMapCache)
 public RFuture<V> putOperationAsync(K key, V value, long ttlTimeout, long maxIdleTimeout, long maxIdleDelta) {
        long threadId = Thread.currentThread().getId();
        return putOperationAsync(key, value, new MapCachePutOperation(map, key, value, 
                ttlTimeout, TimeUnit.MILLISECONDS, maxIdleTimeout, TimeUnit.MILLISECONDS, transactionId, threadId));
    }

The ttlTimeout is a timestamp (number of ms since the epoch) rather than the timeout.  This results in the entries being created with what is effectively an infinite TTL.
Expected behavior
Entries are created with the provided TTL
Actual behavior
Entries are created with a TTL of ~50 years
Steps to reproduce or test case
RTransaction trans = getClient().createTransaction(TransactionOptions.defaults());
RMapCache<String, RedissonCachedValue> map = trans.getMapCache(...)
long ttl = 10;
String key = "key";
Object valueToAdd = createNewValue();
Object oldValue = map.put(key, valueToAdd, ttl, TimeUnit.SECONDS, ttl, TimeUnit.SECONDS);
trans.commit();

If you check the TTL, using map.remainTimeToLive(key), you will see that it is well over 600.  The value you get back is approximately System.currentTimeMillis() + 10000
Redisson version
3.12.4
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2759
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is the order in which async operations are submitted to the Redisson client guaranteed to match the order in which they are actually executed?
For context, I am using RStream.addAllAsync to submit items to a stream, and I need the items stream order to exactly match the addAllAsync call order. Are there any race conditions possible with rapid calls to this method (1-2ms delays between calls) that would result in out-of-order insertion?
Thanks in advance!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2760
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is it really necessary? since this value isn't updated concurrenlty.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2761
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RSet obj = redissonObj.getSet("xxx")
... // todo
Now, I can only get All members, but I cant make sure of  member in set or not in set.
Thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2762
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I have 3 different processes accessing Redis. I am using the below code to make sure only one node gets hold of the resource for the specified time.
RRateLimiter limiter = redisson.getRateLimiter("test");
//1 permit for every 60 seconds
limiter.trySetRate(RateType.OVERALL, 1, 60, RateIntervalUnit.SECONDS);
My understanding here is 1 permit is available for every 60 seconds. If one node is processing the code after acquiring the permit, other nodes trying to call acquire should get as false.
limiter.tryAcquire(1, 2, RateIntervalUnit.SECONDS)
Here, other nodes are able to acquire the lock without 60 seconds delay. Is there something wrong with the usage? Please help me understand how would I hold the access on the resource for the specified time.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2763
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2764
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[local expiredValues = redis.call('zrangebyscore', KEYS[2], 0, ARGV[1], 'limit', 0, ARGV[2]); if #exp..., 3, timer_queue, redisson_delay_queue_timeout:{timer_queue}, redisson_delay_queue:{timer_queue}, 1588874410282, 100]
org.redisson.client.RedisException: ERR READONLY You can't write against a read only instance. channel:
redisson版本3.10.6
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2765
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2766
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redisson version：3.7.5
I created a redis cluster of three masters and three slaves in the virtual machine.
192.168.10.139 master  0-5460
192.168.10.140 master  5461-10922
192.168.10.141 master  10923-16383
192.168.10.142 slave
192.168.10.143 slave
192.168.10.144 slave
I want to test whether the scoresortedset supports clustering.So I wrote a unit test class
@before
public void setUp(){
Config config = new Config();
config.useClusterServers()
.setPassword("123456")
.setScanInterval(2000) // 集群状态扫描间隔时间，单位是毫秒
.addNodeAddress("redis://192.168.10.139:6379", "redis://192.168.10.140:6379")
.addNodeAddress("redis://192.168.10.141:6379", "redis://192.168.10.142:6379")
.addNodeAddress("redis://192.168.10.143:6379", "redis://192.168.10.144:6379");
redissonClient = Redisson.create(config);
}
@test
public void redisClusterTest(){
RScoredSortedSet set = redissonClient.getScoredSortedSet("xuyikai");
for(int i=1;i<=10;i++){
boolean isAdd = set.tryAdd(i, "key：" + i);
log.info("isAdd:{}",isAdd);
}
log.info("set size:{}",set.size());
Collection<ScoredEntry> scoredEntries = set.entryRange(0,10);
for (ScoredEntry entry : scoredEntries) {
String key = entry.getValue();
Double score = entry.getScore();
log.info("key:{},score:{}",key,score);
}
}
I found that the key and score can be inserted normally in the scoreportedset, but when I try to read the size of the current scoreportedset, I find that the return value is 0.
This is the output：
2020-05-13 22:29:17,531 [main] INFO  org.redisson.Version# logVersion : 41 - Redisson 3.7.5
2020-05-13 22:29:18,230 [main] INFO  o.r.cluster.ClusterConnectionManager#  : 120 - Redis cluster nodes configuration got from 192.168.10.139/192.168.10.139:6379:
3d1cc11809e1e057a0f4347df55ac5497035bc59 192.168.10.142:6379@16379 slave e1d330c89353464f871e4fe37ed2bb744e26d9f1 0 1589380157345 4 connected
ed84d533c89be5b453349be85ea62236b7e388fd 192.168.10.140:6379@16379 master - 0 1589380157553 2 connected 5461-10922
e1d330c89353464f871e4fe37ed2bb744e26d9f1 192.168.10.141:6379@16379 master - 0 1589380156277 3 connected 10923-16383
c699c611bb722a38588acd51a561755598fbdda7 192.168.10.139:6379@16379 myself,master - 0 1589380156000 1 connected 0-5460
68a78c982c84cc39fb0a500be9007cf08df2d1eb 192.168.10.143:6379@16379 slave c699c611bb722a38588acd51a561755598fbdda7 0 1589380157000 5 connected
0bf30336b5397e3172bbc39827375bfbadbd500e 192.168.10.144:6379@16379 slave ed84d533c89be5b453349be85ea62236b7e388fd 0 1589380157764 6 connected
2020-05-13 22:29:18,252 [redisson-netty-1-2] INFO  o.r.cluster.ClusterConnectionManager# operationComplete : 244 - slaves: [redis://192.168.10.143:6379] added for slot ranges: [[0-5460]]
2020-05-13 22:29:18,256 [redisson-netty-1-5] INFO  o.r.cluster.ClusterConnectionManager# operationComplete : 244 - slaves: [redis://192.168.10.144:6379] added for slot ranges: [[5461-10922]]
2020-05-13 22:29:18,275 [redisson-netty-1-7] INFO  o.r.cluster.ClusterConnectionManager# operationComplete : 244 - slaves: [redis://192.168.10.142:6379] added for slot ranges: [[10923-16383]]
2020-05-13 22:29:18,291 [redisson-netty-1-5] INFO  o.r.c.p.MasterPubSubConnectionPool# operationComplete : 144 - 1 connections initialized for 192.168.10.141/192.168.10.141:6379
2020-05-13 22:29:18,298 [redisson-netty-1-12] INFO  o.r.c.pool.PubSubConnectionPool# operationComplete : 144 - 1 connections initialized for 192.168.10.144/192.168.10.144:6379
2020-05-13 22:29:18,299 [redisson-netty-1-2] INFO  o.r.c.pool.PubSubConnectionPool# operationComplete : 144 - 1 connections initialized for 192.168.10.142/192.168.10.142:6379
2020-05-13 22:29:18,299 [redisson-netty-1-11] INFO  o.r.c.p.MasterPubSubConnectionPool# operationComplete : 144 - 1 connections initialized for 192.168.10.140/192.168.10.140:6379
2020-05-13 22:29:18,343 [redisson-netty-1-8] INFO  o.r.c.pool.PubSubConnectionPool# operationComplete : 144 - 1 connections initialized for 192.168.10.143/192.168.10.143:6379
2020-05-13 22:29:18,345 [redisson-netty-1-9] INFO  o.r.c.pool.MasterConnectionPool# operationComplete : 144 - 32 connections initialized for 192.168.10.140/192.168.10.140:6379
2020-05-13 22:29:18,345 [redisson-netty-1-1] INFO  o.r.c.pool.MasterConnectionPool# operationComplete : 144 - 32 connections initialized for 192.168.10.139/192.168.10.139:6379
2020-05-13 22:29:18,346 [redisson-netty-1-10] INFO  o.r.c.p.MasterPubSubConnectionPool# operationComplete : 144 - 1 connections initialized for 192.168.10.139/192.168.10.139:6379
2020-05-13 22:29:18,348 [redisson-netty-1-10] INFO  o.r.cluster.ClusterConnectionManager# operationComplete : 267 - master: redis://192.168.10.139:6379 added for slot ranges: [[0-5460]]
2020-05-13 22:29:18,352 [redisson-netty-1-2] INFO  o.r.c.pool.SlaveConnectionPool# operationComplete : 144 - 32 connections initialized for 192.168.10.144/192.168.10.144:6379
2020-05-13 22:29:18,352 [redisson-netty-1-3] INFO  o.r.c.pool.SlaveConnectionPool# operationComplete : 144 - 32 connections initialized for 192.168.10.142/192.168.10.142:6379
2020-05-13 22:29:18,352 [redisson-netty-1-5] INFO  o.r.c.pool.MasterConnectionPool# operationComplete : 144 - 32 connections initialized for 192.168.10.141/192.168.10.141:6379
2020-05-13 22:29:18,352 [redisson-netty-1-9] INFO  o.r.cluster.ClusterConnectionManager# operationComplete : 267 - master: redis://192.168.10.140:6379 added for slot ranges: [[5461-10922]]
2020-05-13 22:29:18,354 [redisson-netty-1-5] INFO  o.r.cluster.ClusterConnectionManager# operationComplete : 267 - master: redis://192.168.10.141:6379 added for slot ranges: [[10923-16383]]
2020-05-13 22:29:18,357 [redisson-netty-1-7] INFO  o.r.c.pool.SlaveConnectionPool# operationComplete : 144 - 32 connections initialized for 192.168.10.143/192.168.10.143:6379
2020-05-13 22:29:18,371 [main] INFO  com.mbkj.mall.RedisClusterTest# redisClusterTest : 65 - isAdd:true
2020-05-13 22:29:18,372 [main] INFO  com.mbkj.mall.RedisClusterTest# redisClusterTest : 65 - isAdd:true
2020-05-13 22:29:18,373 [main] INFO  com.mbkj.mall.RedisClusterTest# redisClusterTest : 65 - isAdd:true
2020-05-13 22:29:18,374 [main] INFO  com.mbkj.mall.RedisClusterTest# redisClusterTest : 65 - isAdd:true
2020-05-13 22:29:18,375 [main] INFO  com.mbkj.mall.RedisClusterTest# redisClusterTest : 65 - isAdd:true
2020-05-13 22:29:18,376 [main] INFO  com.mbkj.mall.RedisClusterTest# redisClusterTest : 65 - isAdd:true
2020-05-13 22:29:18,377 [main] INFO  com.mbkj.mall.RedisClusterTest# redisClusterTest : 65 - isAdd:true
2020-05-13 22:29:18,378 [main] INFO  com.mbkj.mall.RedisClusterTest# redisClusterTest : 65 - isAdd:true
2020-05-13 22:29:18,379 [main] INFO  com.mbkj.mall.RedisClusterTest# redisClusterTest : 65 - isAdd:true
2020-05-13 22:29:18,381 [main] INFO  com.mbkj.mall.RedisClusterTest# redisClusterTest : 65 - isAdd:true
2020-05-13 22:29:18,382 [main] INFO  com.mbkj.mall.RedisClusterTest# redisClusterTest : 68 - set size:0
I tried distributed lock under this condition. It seems that there is no problem, so I am confused about the above problems
I hope you can answer my question, thank you
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2767
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I use org.redisson:redisson-spring-boot-starter:3.12.5.
When spring-boot app with spring yaml redis section
redis:
password: "X"
sentinel:
password: "X"
master: mymaster
nodes: XXX:26379
started i see in log file
[redisson-netty-2-18] WARN  o.r.c.SentinelConnectionManager updateSentinels sentinel: redis://10.110.22.88:26379 was down
09:40:12 [redisson-netty-2-17] INFO  o.r.c.SentinelConnectionManager lambda$null$7 sentinel: redis://10.148.2.50:26379 added
09:40:15 [redisson-netty-2-26] INFO  o.r.c.SentinelConnectionManager lambda$null$7 sentinel: redis://10.110.22.88:26379 added
09:40:16 [redisson-netty-2-2] WARN  o.r.c.SentinelConnectionManager updateSentinels sentinel: redis://10.148.11.233:26379 was down
09:40:17 [redisson-netty-2-21] WARN  o.r.c.SentinelConnectionManager updateSentinels sentinel: redis://10.110.22.88:26379 was down
09:40:17 [redisson-netty-2-5] INFO  o.r.c.SentinelConnectionManager lambda$null$7 sentinel: redis://10.148.11.233:26379 added
09:40:20 [redisson-netty-2-30] INFO  o.r.c.SentinelConnectionManager lambda$null$7 sentinel: redis://10.110.22.88:26379 added
09:40:21 [redisson-netty-2-26] WARN  o.r.c.SentinelConnectionManager updateSentinels sentinel: redis://10.110.22.88:26379 was down
09:40:25 [redisson-netty-2-19] INFO  o.r.c.SentinelConnectionManager lambda$null$7 sentinel: redis://10.110.22.88:26379 added
.....
09:57:38 [redisson-netty-2-10] WARN  o.r.c.SentinelConnectionManager updateSentinels sentinel: redis://10.110.22.88:26379 was down
09:57:42 [redisson-netty-2-1] INFO  o.r.c.SentinelConnectionManager lambda$null$7 sentinel: redis://10.110.22.88:26379 added
09:57:43 [redisson-netty-2-10] WARN  o.r.c.SentinelConnectionManager updateSentinels sentinel: redis://10.110.22.88:26379 was down
09:57:47 [redisson-netty-2-9] INFO  o.r.c.SentinelConnectionManager lambda$null$7 sentinel: redis://10.110.22.88:26379 added
09:57:48 [redisson-netty-2-11] WARN  o.r.c.SentinelConnectionManager updateSentinels sentinel: redis://10.110.22.88:26379 was down
What's wrong?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2768
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The trace log as below:
field "liveStreamUrl" decode error
[05-14 16:09:10] [TRACE] [redisson-netty-] org.redisson.client.handler.CommandEncoder         - channel: [id: 0xad3d7088, L:/172.16.155.255:37622 - R:172.16.156.8/172.16.156.8:6379] message: *2
$3
GET
$18
show:1021:ex-basic
[05-14 16:09:10] [TRACE] [redisson-netty-] org.redisson.client.handler.CommandDecoder         - reply: $905
{"@Class":"com.xiaoyun.show.cache.buckets.live.ActivityLiveBasicExtention","activityId":"1021","likesNum": 51931727,"liveScenceList":["java.util.ArrayList",[{"@Class":"com.xiaoyun.show.cache.buckets.live.ActivityLiveBasicExtention$Scene","endDate":["java.util.Date", 158
9384580000],"name":"第一场","startDate":["java.util.Date", 1589373780000]},{"@Class":"com.xiaoyun.show.cache.buckets.live.ActivityLiveBasicExtention$Scene","name":"第二场"},{"@Class":"com.xiaoyun.show.cache.buckets.live.ActivityLiveBasicExtention$Scene","name":"第三场"}
,{"@Class":"com.xiaoyun.show.cache.buckets.live.ActivityLiveBasicExtention$Scene","name":"第四场"},{"@Class":"com.xiaoyun.show.cache.buckets.live.ActivityLiveBasicExtention$Scene","name":"第五场"}]],"onlineUsers": 0,"productDeposit": 10000,"repeatBuySwitch": true,"sixNu
m": 52471575,"userNum": 0,"liveStreamUrl": http://ivi.bupt.edu.cn/hls/zjhd.m3u8}
, channel: [id: 0xad3d7088, L:/172.16.155.255:37622 - R:172.16.156.8/172.16.156.8:6379], command: CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@5c3ce058(incomplete)], command=(GET), params=[show:1021:ex-basic], codec=org.redisson.
codec.JsonJacksonCodec]
[05-14 16:09:10] [ERROR] [redisson-netty-] org.redisson.client.handler.CommandDecoder         - Unable to decode data. channel: [id: 0xad3d7088, L:/172.16.155.255:37622 - R:172.16.156.8/172.16.156.8:6379], reply: ReplayingDecoderByteBuf(ridx=913, w
idx=913), command: (GET), params: [show:1021:ex-basic]
com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'http': was expecting ('true', 'false' or 'null')
at [Source: (io.netty.buffer.ByteBufInputStream); line: 1, column: 874]
at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804)
at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:703)
at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._reportInvalidToken(UTF8StreamJsonParser.java:3532)
at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2627)
at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextFieldName(UTF8StreamJsonParser.java:1053)
at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:295)
at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:189)
at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:161)
at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedForId(AsPropertyTypeDeserializer.java:130)
at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:97)
at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromAny(AsPropertyTypeDeserializer.java:193)
at com.fasterxml.jackson.databind.deser.std.UntypedObjectDeserializer$Vanilla.deserializeWithType(UntypedObjectDeserializer.java:712)
at com.fasterxml.jackson.databind.deser.impl.TypeWrappedDeserializer.deserialize(TypeWrappedDeserializer.java:68)
at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4013)
at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3070)
at org.redisson.codec.JsonJacksonCodec$2.decode(JsonJacksonCodec.java:95)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:384)
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:215)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:153)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:122)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:682)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:617)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:534)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:906)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
redis data as below:
{
"@Class": "com.xiaoyun.show.cache.buckets.live.ActivityLiveBasicExtention",
"activityId": "1021",
"likesNum": 51931727,
"liveScenceList": [
"java.util.ArrayList",
[
{
"@Class": "com.xiaoyun.show.cache.buckets.live.ActivityLiveBasicExtention$Scene",
"endDate": [
"java.util.Date",
1589384580000
],
"name": "第一场",
"startDate": [
"java.util.Date",
1589373780000
]
},
{
"@Class": "com.xiaoyun.show.cache.buckets.live.ActivityLiveBasicExtention$Scene",
"name": "第二场"
},
{
"@Class": "com.xiaoyun.show.cache.buckets.live.ActivityLiveBasicExtention$Scene",
"name": "第三场"
},
{
"@Class": "com.xiaoyun.show.cache.buckets.live.ActivityLiveBasicExtention$Scene",
"name": "第四场"
},
{
"@Class": "com.xiaoyun.show.cache.buckets.live.ActivityLiveBasicExtention$Scene",
"name": "第五场"
}
]
],
"onlineUsers":   0,
"productDeposit":   10000,
"repeatBuySwitch":   true,
"sixNum":   52471575,
"userNum":   0,
"liveStreamUrl": "http://ivi.bupt.edu.cn/hls/zjhd.m3u8"
}
redis : 5.0.4 (open source product)
redisson: 3.12.5
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2769
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
https://www.javadoc.io/doc/org.redisson/redisson/latest/org/redisson/api/RMapCache.html#setMaxSize-int-
Does setMaxSize( ) always successfully apply the size limit on cache?
(Why do we have two methods: maxSize and tryMaxSize)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2770
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We have a Redis cluster(running in Sentinel mode) with 3 nodes and we are using Redisson (version 3.10.7) to interact with Redis.
Since last one week, we are facing an issue in our Development environment wherein the client application is not able to connect to the cluster. Continuously older connections are being dropped and new connections are being created. Below is the snapshot for the logger.
12:01:00.832 [redisson-netty-2-6] DEBUG org.redisson.connection.ClientConnectionsEntry - new connection created: RedisConnection@483495011 [redisClient=[addr=redis://10.79.9.163:6379], channel=[id: 0x767f3c87, L:/192.168.7.24:60173 - R:10.79.9.163/10.79.9.163:6379], command=null]
12:01:00.832 [redisson-netty-2-6] DEBUG org.redisson.connection.ClientConnectionsEntry - new connection created: RedisConnection@1510307492 [redisClient=[addr=redis://10.79.9.163:6379], channel=[id: 0xa8c01128, L:/192.168.7.24:60183 - R:10.79.9.163/10.79.9.163:6379], command=null]
12:01:00.832 [redisson-netty-2-6] DEBUG org.redisson.connection.ClientConnectionsEntry - new connection created: RedisConnection@425141862 [redisClient=[addr=redis://10.79.9.164:6379], channel=[id: 0x19afdfb8, L:/192.168.7.24:60199 - R:10.79.9.164/10.79.9.164:6379], command=null]
12:01:00.832 [redisson-netty-2-6] DEBUG org.redisson.connection.ClientConnectionsEntry - new connection created: RedisConnection@457747719 [redisClient=[addr=redis://10.79.9.164:6379], channel=[id: 0xf2431dfb, L:/192.168.7.24:60211 - R:10.79.9.164/10.79.9.164:6379], command=null]
12:01:00.832 [redisson-netty-2-6] DEBUG org.redisson.connection.ClientConnectionsEntry - new connection created: RedisConnection@1595469651 [redisClient=[addr=redis://10.79.9.164:6379], channel=[id: 0x3226faec, L:/192.168.7.24:60204 - R:10.79.9.164/10.79.9.164:6379], command=null]
12:01:00.922 [pool-2-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@541871189 [redisClient=[addr=redis://10.79.9.164:6379], channel=[id: 0x5396b42d, L:/192.168.7.24:59969 ! R:10.79.9.164/10.79.9.164:6379], command=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@3ecd3a79(failure: java.util.concurrent.CancellationException)], command=(PING), params=[], codec=org.redisson.client.codec.StringCodec]] to 10.79.9.164/10.79.9.164:6379 
12:01:00.929 [pool-2-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@495642036 [redisClient=[addr=redis://10.79.9.164:6379], channel=[id: 0xfa2f4f52, L:/192.168.7.24:59973 ! R:10.79.9.164/10.79.9.164:6379], command=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@28c788eb(failure: java.util.concurrent.CancellationException)], command=(PING), params=[], codec=org.redisson.client.codec.StringCodec]] to 10.79.9.164/10.79.9.164:6379 
12:01:00.931 [pool-2-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@169281839 [redisClient=[addr=redis://10.79.9.164:6379], channel=[id: 0xf365bc68, L:/192.168.7.24:59976 ! R:10.79.9.164/10.79.9.164:6379], command=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@6bd0d406(failure: java.util.concurrent.CancellationException)], command=(PING), params=[], codec=org.redisson.client.codec.StringCodec]] to 10.79.9.164/10.79.9.164:6379 
12:01:00.931 [pool-2-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@65640722 [redisClient=[addr=redis://10.79.9.165:6379], channel=[id: 0x03c68dcf, L:/192.168.7.24:59226 ! R:10.79.9.165/10.79.9.165:6379], command=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@520c88b3(failure: java.util.concurrent.CancellationException)], command=(PING), params=[], codec=org.redisson.client.codec.StringCodec]] to 10.79.9.165/10.79.9.165:6379 
12:01:00.932 [pool-2-thread-1] DEBUG org.redisson.client.handler.ConnectionWatchdog - reconnecting RedisConnection@1365249560 [redisClient=[addr=redis://10.79.9.165:6379], channel=[id: 0x0722fcc6, L:/192.168.7.24:59262 ! R:10.79.9.165/10.79.9.165:6379], command=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@50c8b29f(failure: java.util.concurrent.CancellationException)], command=(PING), params=[], codec=org.redisson.client.codec.StringCodec]] to 10.79.9.165/10.79.9.165:6379 
12:01:01.080 [redisson-netty-2-8] DEBUG org.redisson.connection.ClientConnectionsEntry - new connection created: RedisConnection@1230181180 [redisClient=[addr=redis://10.79.9.163:6379], channel=[id: 0x148352d3, L:/192.168.7.24:60224 - R:10.79.9.163/10.79.9.163:6379], command=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@19cb007f(incomplete)], command=(PING), params=[], codec=org.redisson.client.codec.StringCodec]]
12:01:01.082 [redisson-netty-2-5] DEBUG org.redisson.connection.ClientConnectionsEntry - new connection created: RedisConnection@1221343292 [redisClient=[addr=redis://10.79.9.163:6379], channel=[id: 0xc4ff65cd, L:/192.168.7.24:60229 - R:10.79.9.163/10.79.9.163:6379], command=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@1891a694(incomplete)], command=(PING), params=[], codec=org.redisson.client.codec.StringCodec]]
12:01:01.082 [redisson-netty-2-7] DEBUG org.redisson.connection.ClientConnectionsEntry - new connection created: RedisConnection@2036916006 [redisClient=[addr=redis://10.79.9.163:6379], channel=[id: 0xff04b8ab, L:/192.168.7.24:60223 - R:10.79.9.163/10.79.9.163:6379], command=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@1618e7eb(incomplete)], command=(PING), params=[], codec=org.redisson.client.codec.StringCodec]]
12:01:01.082 [redisson-netty-2-9] DEBUG org.redisson.connection.ClientConnectionsEntry - new connection created: RedisConnection@1460667823 [redisClient=[addr=redis://10.79.9.163:6379], channel=[id: 0xbdc0d69e, L:/192.168.7.24:60222 - R:10.79.9.163/10.79.9.163:6379], command=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@139695d9(incomplete)], command=(PING), params=[], codec=org.redisson.client.codec.StringCodec]]

We tried below points to investigate the issue:

Restart the client application.
Restart Redis cluster nodes.

Post these restarts as well, the same issue persisted. We were able to resolve the issue by changing the "timeout" property from 0 to 10 seconds in server.conf of Redis. On reverting timeout back to 0 also is not causing the issue again.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2771
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We have a Redis cluster(running in Sentinel mode) with 3 nodes and we are using Redisson (version 3.10.7) to interact with Redis. While checking for some other issue, we noticed a high number of client being connected to server.
On further investigation, we noticed the below scenarios.
+-------------+-----------------------+
|Client         | Connections         |
+-------------------------------------+
|Client A at T0 |   33                |
|               |(default by Reddison)|
|Client A at T1 |99                   |
|               |(post network glitch |
|               |or server crash)     |
|Client A at T2 | 33                  |
|               |  (post restart app) |
|               |                     |
+-------------------------------------+

In case app restart is not done as well, connection remains open even though we have a "timeout" set at server level. Is Redisson leaving the older connection open  and creates a new one in case of redis server crash or network glitch?
Also, I noticed that with each client connection to Redis server,Redis is opening 4 file descriptor. Is this normal?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2772
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I want to know what is the >redis-cli scan 0 COUNT 20 equivalent in redisson. I have 4  million records in redis and want to iterate through them (with a key pattern)
I tried using Stream getKeysStreamByPattern(String var1, int var2); and Iterable getKeysByPattern(String var1, int var2); but it hangs infinitly.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2773
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
1.Return List whose size is 2 when use jedis brpop method, the first is the queue name,and the second is the value.
2.pollLastFromAny() only return the value
So how can i get the matching queue name with the value.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2774
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Logout without nullpointer exception
Actual behavior
Logout throws this exception
java.lang.NullPointerException: map value can't be null
at org.redisson.RedissonMap.checkValue(RedissonMap.java:605)
at org.redisson.RedissonMap.fastPutAsync(RedissonMap.java:920)
at org.redisson.RedissonMap.fastPut(RedissonMap.java:936)
at org.redisson.tomcat.RedissonSession.fastPut(RedissonSession.java:239)
at org.redisson.tomcat.RedissonSession.setAuthType(RedissonSession.java:263)
at org.apache.catalina.authenticator.AuthenticatorBase.register(AuthenticatorBase.java:1165)
at org.apache.catalina.authenticator.AuthenticatorBase.register(AuthenticatorBase.java:1100)
at org.apache.catalina.authenticator.AuthenticatorBase.logout(AuthenticatorBase.java:1306)
at org.apache.catalina.connector.Request.logout(Request.java:2765)
at org.apache.catalina.connector.RequestFacade.logout(RequestFacade.java:1092)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at org.jboss.resteasy.core.ContextParameterInjector$GenericDelegatingProxy.invoke(ContextParameterInjector.java:79)
at com.sun.proxy.$Proxy60.logout(Unknown Source)
at nl.intus.rest.ESSService.logoutInner(ESSService.java:247)
at nl.intus.rest.ESSService.logout(ESSService.java:234)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at org.jboss.resteasy.core.MethodInjectorImpl.invoke(MethodInjectorImpl.java:138)
at org.jboss.resteasy.core.ResourceMethodInvoker.internalInvokeOnTarget(ResourceMethodInvoker.java:517)
at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTargetAfterFilter(ResourceMethodInvoker.java:406)
at org.jboss.resteasy.core.ResourceMethodInvoker.lambda$invokeOnTarget$0(ResourceMethodInvoker.java:370)
at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:356)
at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget(ResourceMethodInvoker.java:372)
at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:344)
at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:317)
at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:440)
at org.jboss.resteasy.core.SynchronousDispatcher.lambda$invoke$4(SynchronousDispatcher.java:229)
at org.jboss.resteasy.core.SynchronousDispatcher.lambda$preprocess$0(SynchronousDispatcher.java:135)
at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:356)
at org.jboss.resteasy.core.SynchronousDispatcher.preprocess(SynchronousDispatcher.java:138)
at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:215)
at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service(ServletContainerDispatcher.java:227)
at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:56)
at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:51)
at javax.servlet.http.HttpServlet.service(HttpServlet.java:741)
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
at nl.intus.main.CorsFilter.handleNonCORS(CorsFilter.java:449)
at nl.intus.main.CorsFilter.doFilter(CorsFilter.java:190)
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)
at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139)
at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
at org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:690)
at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
at org.apache.coyote.ajp.AjpProcessor.service(AjpProcessor.java:432)
at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590)
at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
at java.lang.Thread.run(Thread.java:748)
Steps to reproduce or test case
Login using Tomcat realm and start session, logout
Redis version
keydb-5.3.3-1.el7.x86_64
Redisson version
redisson-tomcat-9-3.12.5-SNAPSHOT.jar.zip
from : #2589
Redisson configuration
redisson.conf:
singleServerConfig:
idleConnectionTimeout: 10000
connectTimeout: 10000
timeout: 3000
retryAttempts: 3
retryInterval: 1500
password: null
subscriptionsPerConnection: 5
clientName: null
address: "redis://10.2.2.71:6379"
subscriptionConnectionMinimumIdleSize: 1
subscriptionConnectionPoolSize: 50
connectionMinimumIdleSize: 24
connectionPoolSize: 64
database: 0
dnsMonitoringInterval: 5000
threads: 16
nettyThreads: 32
codec: !<org.redisson.codec.FstCodec> {}
transportMode: "NIO"
context.xml:

        WEB-INF/web.xml
    <Manager        className="org.redisson.tomcat.RedissonSessionManager" 
                    configPath="${catalina.base}/conf/redisson.conf" 
                    readMode="REDIS" 
                    updateMode="DEFAULT" 
                    broadcastSessionEvents="false" 
                    keyPrefix="pzdproductie"
    />


Tested with updateMode="AFTER_REQUEST" at first, changed to DEFAULT later, exception is still thrown.
It doesn't really affect the application as it happens after destroying the session but it does fill up application logfiles.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2775
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Not much to mention, the title says it all I guess. It's a nice feature but it seems to be missing in the documentation.
Best regards,
Werner
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2776
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
This pull request corresponds to issue #2777
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2777
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
RedissonKeys.unlink(...) should execute unlink command
Actual behavior
RedissonKeys.unlink(...) should execute del command
Steps to reproduce or test case
Use method RedissonKeys.unlink(...)
Redis version
5.0.5
Redisson version
3.12.5
Redisson configuration
Default single server configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2778
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2779
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Add method to find all stored entiry ids by specified entityClass.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2780
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I have created RRateLimiter instance and want to update interval field. If I call trySetRate() it is not updating.
RRateLimiter limiter = redisson.getRateLimiter("myLimiter");
// Initialization required only once.
// 5 permits per 5 seconds
limiter.trySetRate(RateType.OVERALL, 5, 5, RateIntervalUnit.SECONDS);
// 5 permits per 2 seconds
limiter.trySetRate(RateType.OVERALL, 5, 2, RateIntervalUnit.SECONDS);
If I remove the item and create again it works. Is there a way to update RateLimiter instance without removing the item?
Please let me know.
Thanks,
Ravindra
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2781
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When using the periodic scheduling method（e.g. RScheduledExecutorService.scheduleAtFixedRate）, I want to stop scheduling after a specified number of times. What should I do?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2782
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When using the periodic scheduling method（e.g. RScheduledExecutorService.scheduleAtFixedRate）, I want to stop scheduling after a specified number of times. What should I do?
Thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2783
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
每隔一段时间获取分布式锁的时候就会抛出这个异常，抛出异常前主节点曾宕掉，哨兵选举出主节点后就出现了这个问题
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2784
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Part of the source code of the RedissonExecutorService class:
    @Override
    public RScheduledFuture<?> scheduleAsync(Runnable task, CronSchedule cronSchedule) {
        check(task);
        ClassBody classBody = getClassBody(task);
        byte[] state = encode(task);
        /**
          *  I want to know whether it is possible
          *  to pass in the (new Date () ) part as a method parameter.
          */
        Date startDate = cronSchedule.getExpression().getNextValidTimeAfter(new Date());
        if (startDate == null) {
            throw new IllegalArgumentException("Wrong cron expression! Unable to calculate start date");
        }
        long startTime = startDate.getTime();
        
        ScheduledCronExpressionParameters params = new ScheduledCronExpressionParameters();
        params.setClassName(classBody.getClazzName());
        params.setClassBody(classBody.getClazz());
        params.setLambdaBody(classBody.getLambda());
        params.setState(state);
        params.setStartTime(startTime);
        params.setCronExpression(cronSchedule.getExpression().getCronExpression());
        params.setTimezone(cronSchedule.getExpression().getTimeZone().getID());
        params.setExecutorId(executorId);
        RemotePromise<Void> result = (RemotePromise<Void>) asyncScheduledServiceAtFixed.schedule(params);
        addListener(result);
        RedissonScheduledFuture<Void> f = new RedissonScheduledFuture<Void>(result, startTime) {
            public long getDelay(TimeUnit unit) {
                return unit.convert(startDate.getTime() - System.currentTimeMillis(), TimeUnit.MILLISECONDS);
            };
        };
        storeReference(f, result.getRequestId());
        return f;
    }
As the remark above says,It is possible new Date () as a method parameter.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2785
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Count LiveObjects with specified conditions
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2786
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2787
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Nevermind, I think I figured it out.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2788
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In this case, I configured the all intranet domain sentinel node list info。
like this
spring:
    redis:
        sentinel:
          nodes:
            - inner.domain1:port
            - inner.domain2:port
            - inner.domain3:port
          master: master_name
But I can't start redisson successfully,  it throws a RedisConnectionException with 'SENTINEL SENTINELS command returns less than 2 nodes..' message
Because the first configured sentinel node will be used to execute the SENTINEL SENTINELS MASTER_NAME command when initializing the SentinelConnectionManager, and then try to connect to the returned node list.
But the IP:PORT information of the sentinel node list we return is inaccessible by the current machine（By default, we only allow access via intranet domain）, So all these sentinel node failed to register, except the current node（It uses intranet domain access）。
List<Map<String, String>> sentinelSentinels = connection.sync(StringCodec.INSTANCE, RedisCommands.SENTINEL_SENTINELS, cfg.getMasterName());
List<RFuture<Void>> connectionFutures = new ArrayList<>(sentinelSentinels.size());
for (Map<String, String> map : sentinelSentinels) {
	if (map.isEmpty()) {
		continue;
	}

	String ip = map.get("ip");
	String port = map.get("port");

	RedisURI sentinelAddr = toURI(ip, port);
	// I cannot register this node 
	// because I cannot access it use this ip and port
	RFuture<Void> future = registerSentinel(sentinelAddr, this.config);
	connectionFutures.add(future);
}
RedisURI currentAddr = toURI(client.getAddr().getAddress().getHostAddress(), "" + client.getAddr().getPort());
RFuture<Void> f = registerSentinel(currentAddr, this.config);


Can we add an option to directly use the configured node list without having to execute the  SENTINEL SENTINELS MASTER_NAME command to get the list?
Now, I called dba to restart the sentinel node list, and replaced the sentinel list information, so that the information returned by sentinel list api can be accessed by my current machine, temporarily solved this problem.
However, if my new machine in another network cluster also needs to use redisson to connect to this sentinel cluster, things will become more troublesome.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2789
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello:
I am new to Redis. And I wrote a simple code to test hashmap objects in a Redis cluster of 3 nodes.
final ClusterServersConfig clusterconfig = config.useClusterServers();
clusterconfig.addNodeAddress(clusternodeurl1);
clusterconfig.addNodeAddress(clusternodeurl2);
clusterconfig.addNodeAddress(clusternodeurl3);
redisson = Redisson.create(config);
map = redisson.getMapCache("test");
map.put("key1", "value1");
map.put("key2", "value2");

Then I try the redis-cli to get all hashmap objects. it seems that all pairs are stored on the same cluster node instead of round-robin.
192.168.5.66:6379> HGETALL test
-> Redirected to slot [6918] located at 192.168.5.62:6379

"\xfc\x04key1"
"\x00\x00\x00\x00\x00\x00\x00\x00\b\x00\x00\x00\x00\x00\x00\x00\xfc\x06value1"
"\xfc\x04key2"
"\x00\x00\x00\x00\x00\x00\x00\x00\b\x00\x00\x00\x00\x00\x00\x00\xfc\x06value2"

However, when I use the redis-cli to put key and value pairs into the cluster, I can see it is round-robin.
May I know how to put hashmap object in the round-robin way?
In my test environment, redission maven

org.redisson
redisson
3.12.3

redis server 6.0.1.
Thanks.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2790
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello,
spring-application using redisson-spring-boot-starter:3.12.5, kill the redisServer, and send a request to call the tryLock, the thread will fall into waiting state.
Running the redisServer again does not resolve the issue.
In particular, Scheduler threads cause serious problems.
Is there a solution?
Below is the test code.
public class RedisRockTest {

    @Test
    public void test() throws InterruptedException, ExecutionException {
        RedissonClient redisson = Redisson.create();

        RLock lock = redisson.getLock("myLock");
        // kill RedisServer while main thread is sleeping.
        Thread.sleep(5000);
        boolean res = lock.tryLock(5, 10, TimeUnit.SECONDS);
        if (res) {
            System.out.println("Somethings to do. but not work.");
            lock.unlock();
        }

        System.out.println("No printing...");
    }

}

This result is Thread dump.
"main" #1 prio=5 os_prio=31 cpu=1036.24ms elapsed=42.82s tid=0x00007faeb300e000 nid=0x1803 in Object.wait()  [0x000070000363c000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(java.base@11.0.2/Native Method)
	- waiting on <0x000000061f2a24a0> (a io.netty.util.concurrent.ImmediateEventExecutor$ImmediatePromise)
	at java.lang.Object.wait(java.base@11.0.2/Object.java:328)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:252)
	- waiting to re-lock in wait() <0x000000061f2a24a0> (a io.netty.util.concurrent.ImmediateEventExecutor$ImmediatePromise)
	at org.redisson.misc.RedissonPromise.await(RedissonPromise.java:110)
	at org.redisson.misc.RedissonPromise.await(RedissonPromise.java:35)
	at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:139)
	at org.redisson.RedissonObject.get(RedissonObject.java:90)
	at org.redisson.RedissonLock.tryAcquire(RedissonLock.java:221)
	at org.redisson.RedissonLock.tryLock(RedissonLock.java:394)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2791
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2792
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2793
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2794
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2795
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2796
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Currently I am using Redisson for locks with the RedissonClient that gets automatically configured via the spring.redis.(host|port|password) properties in the application.yaml which is super convenient.
Now I wanted to include some message handling via reactive topics to return a Flux for a websocket-based subscription. Thus I attempted to autowire a RedissonReactiveClient and noticed it isn't autoconfigured.
I am curious what the proposed way to expose a RedissonReactiveClient bean with the same configuration would look like.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2797
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redisson 3.12.5
redis 3.2.9
I meet this problem when project startup with multiple replicas in kubernetes, some of replicas with following errors, but some are fine:
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'projectModuleServiceImpl': Unsatisfied dependency expressed through field 'redissonClient'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'redissonClient' defined in class path resource [org/maxfaith/config/RedissonConfig.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.redisson.api.RedissonClient]: Factory method 'getRedissonClient' threw exception; nested exception is org.redisson.client.RedisConnectionException: Can't init enough connections amount! Only 0 from 30 were initialized. Server: miop-redis/10.233.105.119:6379
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2798
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I want to use to hibernate level2 cache as flow config.
@Getter
@Entity
public class Personnel{
@Id
@GeneratedValue(strategy = GenerationType.AUTO)
private Long id;
@Column
private String name;
@Id
@GeneratedValue(strategy = GenerationType.AUTO)
 private Long id;
private String name;
 @ManyToOne(fetch = FetchType.LAZY)
private Post post;
}
Now for get object at the first time, all things are ok! (that means I want to load 'post' from personnel)
But when I call this function for a second time, in my personnel object the 'post' is null and I get an error as below:
Caused by: java.lang.reflect.InvocationTargetException: null at sun.reflect.GeneratedMethodAccessor167.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.dozer.util.ReflectionUtils.invoke(ReflectionUtils.java:323) ... 132 common frames omitted Caused by: org.hibernate.LazyInitializationException: could not initialize proxy - no Session at org.hibernate.proxy.AbstractLazyInitializer.initialize(AbstractLazyInitializer.java:146) at org.hibernate.proxy.AbstractLazyInitializer.getImplementation(AbstractLazyInitializer.java:259) at org.hibernate.proxy.pojo.javassist.JavassistLazyInitializer.invoke(JavassistLazyInitializer.java:73) at org.model.core.Post_$$_jvstb54_2a.getId(Post_$$_jvstb54_2a.java)
Hibernate 5.2
Radisson 3.12.5
spring-boot 2.1.1
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2799
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Using this simple code at android (java):
`
private RList<MyObject> connect(String address) {

    Config config = new Config();

    config.useSingleServer().setAddress(address);

    RedissonClient client = Redisson.create(config);

    return client.getList("Section::Unit"); }

`
I get this IllegalStateException:
Caused by: java.lang.IllegalStateException: java.lang.reflect.InvocationTargetException at org.redisson.command.RedisExecutor.getCodec(RedisExecutor.java:692) at org.redisson.command.RedisExecutor.execute(RedisExecutor.java:113) at org.redisson.command.CommandAsyncService.async(CommandAsyncService.java:612) at org.redisson.command.CommandAsyncService.readAsync(CommandAsyncService.java:369) at org.redisson.RedissonList.getAsync(RedissonList.java:296) at org.redisson.RedissonList.getValue(RedissonList.java:325) at org.redisson.RedissonList$1.getValue(RedissonList.java:500)
Caused by: java.lang.NullPointerException: Attempt to invoke virtual method 'boolean java.lang.Class.isPrimitive()' on a null object reference at org.objenesis.ObjenesisBase.getInstantiatorOf(ObjenesisBase.java:86) at org.nustaq.serialization.FSTObjenesisInstantiator.<init>(FSTObjenesisInstantiator.java:38) at org.nustaq.serialization.FSTConfiguration$4.getInstantiator(FSTConfiguration.java:403) at org.redisson.codec.FstCodec.copy(FstCodec.java:200)
Looking inside code I found that this function (file FstCodec.java):
`
package org.redisson.codec;
public FstCodec(ClassLoader classLoader, FstCodec codec) {
    this(copy(classLoader, codec));
}

`
... call private copy function and this one call def.setInstantiator(codec.config.getInstantiator(null)).
The problem is, at android, FstCodec call this function:
`
package org.nustaq.serialization;
 protected static FSTConfiguration createAndroidDefaultConfiguration(ConcurrentHashMap<FieldKey,FSTClazzInfo.FSTFieldInfo> shared) {
    final Objenesis genesis = new ObjenesisStd();
    FSTConfiguration conf = new FSTConfiguration(shared) {
        @Override
        public FSTClassInstantiator getInstantiator(Class clazz) {
            return new FSTObjenesisInstantiator(genesis,clazz);
        }
    };

`
... that override default getInstantiator(class class2instantiate) that must not receive parameter as null.
I'm using:
implementation 'de.ruedigermoeller:fst:2.57'
implementation 'org.redisson:redisson:3.12.5'
at gradle dependency
and redis 6.0.3 version running at docker.
android compileSdkVersion 29 (android 10.0 Q)
Thanks for this incredible program,
I holpe that this help you to improve it.
hipolito
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2800
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Caused by: org.redisson.client.RedisConnectionException: Not all slots are covered! Only 10923 slots are avaliable
I use the 7000 port node to create a redis cluster. When the cluster is running normally, the client connection to the cluster is normal. When the 7000 port is the master, there will be an error. 0-5000 solt cannot be added. But when the 7000 port is the slave, it is normal. But in a moment, there will be three retry failures and the connection problem cannot be found
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2801
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
tryLock() method return false after certain time when redis is not available
Actual behavior
tryLock() method is hanging forever
Steps to reproduce or test case
boolean res = lock.tryLock(1, 1, TimeUnit.SECONDS);
if (res) {
   try {
     ...
   } finally {
       lock.unlock();
   }
}

when application starts, the redis server is there, then bring down the redis.
Redis version
5.0
Redisson version
3.12.5
Redisson configuration
local redis docker without authentication
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2802
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
use new master and everything is OK
Actual behavior
use connection of the shutdown master
Steps to reproduce or test case
cluster three master and three slave
master A, slave B
kill A, then B as master
start A, then A as slave of B
kill B, then A as master
start B, then B as slave of A
kill A, then B as master
now cluster status is OK,
but throw WriteRedisConnectionException because try to use connect of A
Redis version
5.0.8
Redisson version
3.12.5
Redisson configuration
ClusterServersConfig clusterServersConfig = config.useClusterServers()
                .addNodeAddress(hosts.split(","))
                .setScanInterval(3000)
                .setTimeout(6000)
                .setRetryAttempts(5)
                .setRetryInterval(2000)
                .setMasterConnectionPoolSize(4096)
                .setSlaveConnectionPoolSize(4096)
                .setFailedSlaveCheckInterval(60000)
                .setFailedSlaveReconnectionInterval(2000);
ClusterConnectionManager log
2020-05-28 11:18:56.940  INFO 26538 --- [redisson-netty-2-32] o.r.c.pool.MasterPubSubConnectionPool    : 1 connections initialized for /127.0.0.1:6302
2020-05-28 11:18:56.943  INFO 26538 --- [redisson-netty-2-48] o.r.cluster.ClusterConnectionManager     : slave redis://127.0.0.1:6302 removed for slot ranges: [[10923-16383]]
2020-05-28 11:18:56.944  INFO 26538 --- [redisson-netty-2-48] o.r.cluster.ClusterConnectionManager     : 5461 slots removed from redis://127.0.0.1:6302
2020-05-28 11:18:56.961  INFO 26538 --- [redisson-netty-2-48] o.r.cluster.ClusterConnectionManager     : 5461 slots found to add
2020-05-28 11:18:56.971  INFO 26538 --- [redisson-netty-2-17] o.r.c.pool.PubSubConnectionPool          : 1 connections initialized for localhost/127.0.0.1:6302
2020-05-28 11:18:56.971  INFO 26538 --- [redisson-netty-2-20] o.r.connection.pool.SlaveConnectionPool  : 24 connections initialized for localhost/127.0.0.1:6302
2020-05-28 11:18:56.970  INFO 26538 --- [redisson-netty-2-34] o.redisson.connection.MasterSlaveEntry   : master localhost/127.0.0.1:6302 used as slave
2020-05-28 11:18:56.971  INFO 26538 --- [redisson-netty-2-34] o.redisson.connection.MasterSlaveEntry   : master localhost/127.0.0.1:6303 has changed to localhost/127.0.0.1:6302
2020-05-28 11:18:56.972  INFO 26538 --- [redisson-netty-2-34] o.r.c.pool.MasterConnectionPool          : 24 connections initialized for localhost/127.0.0.1:6302
2020-05-28 11:18:59.966 DEBUG 26538 --- [redisson-netty-2-3] o.r.cluster.ClusterConnectionManager     : cluster nodes state got from /127.0.0.1:6302:
5ec50797bf8d7a08a20897c4526cf5c79ae3141a 127.0.0.1:6301@16301 master - 0 1590635939847 1401 connected 5461-10922
836876ef2f59d27763ac6d544646ba7e09a0a14b 127.0.0.1:6300@16300 slave a193501df69576dad18211c0a1a83b7fc3b420bf 0 1590635939000 1397 connected
9248c2d8804c57a69caf7609cb366fafc41079c5 127.0.0.1:6303@16303 master,fail - 1590635928512 1590635927000 1404 disconnected
a27f76d092ec9962d6cdd82a688c3ba1ac15be2d 127.0.0.1:6302@16302 myself,master - 0 1590635937000 1405 connected 10923-16383
86a07d1c4dd106159160330bf77fa58c325269ca 127.0.0.1:6305@16305 slave 5ec50797bf8d7a08a20897c4526cf5c79ae3141a 0 1590635939344 1401 connected
a193501df69576dad18211c0a1a83b7fc3b420bf 127.0.0.1:6304@16304 master - 0 1590635939545 1397 connected 0-5460

WriteRedisConnectionException
2020-05-28 11:19:35.162 ERROR 26538 --- [http-nio-9009-exec-8] h.g.d.r.e.GlobalExceptionHandler         : [GET /api/account/profile] WriteRedisConnectionException, Unable to write command into connection! Node source: NodeSource [slot=16115, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=value:50:queue:0, freeConnectionsAmount=23, freeConnectionsCounter=value:4096:queue:0, freezed=false, freezeReason=null, client=[addr=redis://127.0.0.1:6303], nodeType=MASTER, firstFail=0]]], connection: RedisConnection@1887531326 [redisClient=[addr=redis://127.0.0.1:6303], channel=[id: 0x901eed94, L:0.0.0.0/0.0.0.0:45234], currentCommand=null], command: (EVAL), params: [local value = redis.call('hget', KEYS[1], ARGV[2]); if value == false then return nil; end; local t,..., 5, CN:realme_useragent_record, redisson__timeout__set:{CN:realme_useragent_record}, redisson__idle__set:{CN:realme_useragent_record}, redisson__map_cache__last_access__set:{CN:realme_useragent_record}, {CN:realme_useragent_record}:redisson_options, 1590635964663, PooledUnsafeDirectByteBuf(ridx: 0, widx: 122, cap: 256)] after 5 retry attempts, WriteRedisConnectionException

org.redisson.client.WriteRedisConnectionException: Unable to write command into connection! Node source: NodeSource [slot=16115, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=value:50:queue:0, freeConnectionsAmount=23, freeConnectionsCounter=value:4096:queue:0, freezed=false, freezeReason=null, client=[addr=redis://127.0.0.1:6303], nodeType=MASTER, firstFail=0]]], connection: RedisConnection@1887531326 [redisClient=[addr=redis://127.0.0.1:6303], channel=[id: 0x901eed94, L:0.0.0.0/0.0.0.0:45234], currentCommand=null], command: (EVAL), params: [local value = redis.call('hget', KEYS[1], ARGV[2]); if value == false then return nil; end; local t,..., 5, CN:realme_useragent_record, redisson__timeout__set:{CN:realme_useragent_record}, redisson__idle__set:{CN:realme_useragent_record}, redisson__map_cache__last_access__set:{CN:realme_useragent_record}, {CN:realme_useragent_record}:redisson_options, 1590635964663, PooledUnsafeDirectByteBuf(ridx: 0, widx: 122, cap: 256)] after 5 retry attempts
	at org.redisson.command.RedisExecutor.checkWriteFuture(RedisExecutor.java:270) ~[redisson-3.12.5.jar!/:3.12.5]
	at org.redisson.command.RedisExecutor.access$100(RedisExecutor.java:58) ~[redisson-3.12.5.jar!/:3.12.5]
	at org.redisson.command.RedisExecutor$1.operationComplete(RedisExecutor.java:155) ~[redisson-3.12.5.jar!/:3.12.5]
	at org.redisson.command.RedisExecutor$1.operationComplete(RedisExecutor.java:152) ~[redisson-3.12.5.jar!/:3.12.5]
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577) ~[netty-common-4.1.48.Final.jar!/:4.1.48.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551) ~[netty-common-4.1.48.Final.jar!/:4.1.48.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490) ~[netty-common-4.1.48.Final.jar!/:4.1.48.Final]
	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615) ~[netty-common-4.1.48.Final.jar!/:4.1.48.Final]
	at io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:608) ~[netty-common-4.1.48.Final.jar!/:4.1.48.Final]
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117) ~[netty-common-4.1.48.Final.jar!/:4.1.48.Final]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:993) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:865) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final]
	at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1104) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final]
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164) ~[netty-common-4.1.48.Final.jar!/:4.1.48.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472) ~[netty-common-4.1.48.Final.jar!/:4.1.48.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[netty-common-4.1.48.Final.jar!/:4.1.48.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.48.Final.jar!/:4.1.48.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.48.Final.jar!/:4.1.48.Final]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_191]
Caused by: java.nio.channels.ClosedChannelException: null
	at io.netty.channel.AbstractChannel$AbstractUnsafe.newClosedChannelException(AbstractChannel.java:957) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final]
	... 12 common frames omitted

Everything is OK after restart java application.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2803
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
use redisson and spring-integration
  @Bean
    public RedisLockRegistry redisLockRegistry(RedisConnectionFactory redisConnectionFactory){
        return new RedisLockRegistry(redisConnectionFactory,"spring-cloud");
    }

    @Component
    public class Run implements CommandLineRunner {

        @Autowired
        private RedisLockHelper redisLockHelper;



        @Autowired
        private RedisLockRegistry springRedisLock;

        @Override
        public void run(String... args) throws Exception {
            String uuid = UUID.randomUUID().toString();


            springRedisLock.obtain("lock").lock();

            springRedisLock.obtain("lock").unlock();


            for (;;){}
        }
    }


 <dependency>
            <groupId>org.redisson</groupId>
            <artifactId>redisson-spring-boot-starter</artifactId>
            <version>3.12.5</version>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-integration</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.integration</groupId>
            <artifactId>spring-integration-redis</artifactId>
        </dependency>
spring-boot version 2.2.5
Expected behavior
unlock success
Actual behavior
unlock error
java.lang.StackOverflowError: null
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]
	at org.springframework.data.redis.connection.DefaultedRedisConnection.unlink(DefaultedRedisConnection.java:83) ~[spring-data-redis-2.2.5.RELEASE.jar:2.2.5.RELEASE]


Steps to reproduce or test case
default Long unlink(byte[]... keys) {
		return keyCommands().unlink(keys);
	}


this keyCommands()  retuen this OBJECT  occur  recursion.
Maybe,we need override method unlink in RedissonConnection
Redis version
Redisson version

org.redisson
redisson-spring-boot-starter
3.12.5

Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2804
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
org.redisson.client.RedisException: Unexpected exception while processing command
at org.redisson.command.CommandAsyncService.convertException(CommandAsyncService.java:353)
at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:150)
at org.redisson.RedissonObject.get(RedissonObject.java:90)
at org.redisson.RedissonMap.get(RedissonMap.java:267)
at org.redisson.spring.cache.RedissonCache.get(RedissonCache.java:73)
at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:73)
at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:554)
at org.springframework.cache.interceptor.CacheAspectSupport.findCachedItem(CacheAspectSupport.java:519)
at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:401)
at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:345)
at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:61)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:88)
at com.alsc.saas.crm.commons.log.aspect.LogAspect.doAroundAdvice(LogAspect.java:36)
at com.alsc.saas.crm.commons.log.aspect.LogInfrastructureAspect.doAroundAdvice(LogInfrastructureAspect.java:25)
at sun.reflect.GeneratedMethodAccessor139.invoke(Unknown Source)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:644)
at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:633)
at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:689)
at com.alsc.saas.promobatch.infrastructure.intergration.activity.BizCacheSnapshotClientImpl$$EnhancerBySpringCGLIB$$d1d96015.queryUserByCustomerIdCache()
at com.alsc.saas.promobatch.application.hander.activity.common.SimpleCustomerVoucherSendProcessor.checkIn(SimpleCustomerVoucherSendProcessor.java:29)
at com.alsc.saas.promobatch.application.hander.activity.common.SimpleCustomerVoucherSendProcessor.checkIn(SimpleCustomerVoucherSendProcessor.java:21)
at com.alsc.saas.promobatch.application.hander.activity.AbstractVoucherSendProcessorHandler.processRecord(AbstractVoucherSendProcessorHandler.java:70)
at com.alsc.saas.promobatch.application.hander.activity.AbstractVoucherSendProcessorHandler.processRecord(AbstractVoucherSendProcessorHandler.java:34)
at com.alsc.saas.crmbatch.interfaces.processor.ProcessorFacade.process(ProcessorFacade.java:182)
at com.alibaba.schedulerx.worker.container.ThreadContainer.start(ThreadContainer.java:84)
at com.alibaba.schedulerx.worker.container.ThreadContainer.run(ThreadContainer.java:57)
at com.alibaba.schedulerx.worker.container.ThreadContainer.start(ThreadContainer.java:113)
at com.alibaba.schedulerx.worker.container.ThreadContainer.run(ThreadContainer.java:57)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1152)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:627)
at java.lang.Thread.run(Thread.java:861)
at com.alibaba.wisp.engine.WispTask$CacheableCoroutine.run(WispTask.java:213)
at java.dyn.CoroutineBase.startInternal(CoroutineBase.java:60)
I use spirng cache and throw this exception  I can't see what is the real exception it throw
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2805
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Unable to decode data. channel: [id: 0x571044ad,] message: +PONG
+PONG
+PONG
:2
+PONG
+PONG
*2
$1
0
*0
+PONG
+PONG
+PONG
$-1
+PONG
+PONG
+PONG
+PONG
+PONG
:1
+PONG
+PONG
+PONG
+PONG
+PONG
:2
+PONG
+PONG
:1
+PONG
+PONG
+PONG
:1
+PONG
+PONG
+PONG
$-1
+PONG
+PONG
+PONG
:1
+PONG
+PONG
+PONG
+PONG
+PONG
$-1
+PONG
+PONG
+PONG
:0
+PONG
+PONG
+PONG
+PONG
+PONG
+PONG
$34
+PONG
+PONG
+PONG
......
java.lang.ClassCastException: null
大佬们能帮忙看看redisson在什么情况下才会返回以上这些+PONG的信息，现在一直不能重现上面的返回内容。
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2806
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2807
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi all,
I am facing strange problems with Redisson lock.
I use the lock without expiration - which means is that watchdog mechanism in-charge of updating the lease time of the lock in redis.
Threads that are using the lock, lock it for time ranging from couple of seconds to 300 seconds or even more.
The problem:
sometimes when a thread(that acquired it) tries to release the lock the thread receives IllegalMonitorStateException , which means that this lock is already released.
One solution was to increase the watchdog timeout - I increased it to 100 seconds and it decreased the number of errors but they still occur from time to time...
I don't want to increase the timeout even more because this doesn't address the root problem.
How can I solve this? is anyone else encountered this behaviour?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2808
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
This should work according to examples
    var executor = redisson.getExecutorService("scheduled-executor");
    executor.registerWorkers(WorkerOptions.defaults());
    executor.schedule((Runnable & Serializable) () -> {
      System.out.println("task has been executed!");
    }, 10, TimeUnit.SECONDS);

Actual behavior
Throws exception
2020-05-31 19:53:29.726 | WARN  | rrent.DefaultPromise:580   | An exception was thrown by org.redisson.misc.RedissonPromise$$Lambda$797/0x00000008006ec440.operationComplete()
java.lang.ClassCastException: class java.lang.String cannot be cast to class org.redisson.remote.RemoteServiceRequest (java.lang.String is in module java.base of loader 'bootstrap'; org.redisson.remote.RemoteServiceRequest is in unnamed module of loader 'app')
	at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:187) ~[redisson-3.13.0.jar:3.13.0]
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577) ~[netty-common-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:570) ~[netty-common-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:549) ~[netty-common-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490) ~[netty-common-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615) ~[netty-common-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604) ~[netty-common-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104) ~[netty-common-4.1.49.Final.jar:4.1.49.Final]
	at org.redisson.misc.RedissonPromise.trySuccess(RedissonPromise.java:82) ~[redisson-3.13.0.jar:3.13.0]
	at org.redisson.command.RedisExecutor.handleReference(RedisExecutor.java:481) ~[redisson-3.13.0.jar:3.13.0]
	at org.redisson.command.RedisExecutor.handleSuccess(RedisExecutor.java:474) ~[redisson-3.13.0.jar:3.13.0]
	at org.redisson.command.RedisExecutor.handleResult(RedisExecutor.java:459) ~[redisson-3.13.0.jar:3.13.0]
	at org.redisson.command.RedisExecutor.checkAttemptPromise(RedisExecutor.java:445) ~[redisson-3.13.0.jar:3.13.0]
	at org.redisson.command.RedisExecutor.lambda$execute$3(RedisExecutor.java:163) ~[redisson-3.13.0.jar:3.13.0]
	at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:187) ~[redisson-3.13.0.jar:3.13.0]
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577) [netty-common-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:570) [netty-common-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:549) [netty-common-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490) [netty-common-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615) [netty-common-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604) [netty-common-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104) [netty-common-4.1.49.Final.jar:4.1.49.Final]
	at org.redisson.misc.RedissonPromise.trySuccess(RedissonPromise.java:82) [redisson-3.13.0.jar:3.13.0]
	at org.redisson.client.handler.CommandDecoder.completeResponse(CommandDecoder.java:444) [redisson-3.13.0.jar:3.13.0]
	at org.redisson.client.handler.CommandDecoder.handleResult(CommandDecoder.java:439) [redisson-3.13.0.jar:3.13.0]
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:370) [redisson-3.13.0.jar:3.13.0]
	at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:196) [redisson-3.13.0.jar:3.13.0]
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:134) [redisson-3.13.0.jar:3.13.0]
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:104) [redisson-3.13.0.jar:3.13.0]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:501) [netty-codec-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) [netty-codec-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276) [netty-codec-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) [netty-transport-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) [netty-transport-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) [netty-transport-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714) [netty-transport-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650) [netty-transport-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576) [netty-transport-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) [netty-transport-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) [netty-common-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [netty-common-4.1.49.Final.jar:4.1.49.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-common-4.1.49.Final.jar:4.1.49.Final]
	at java.lang.Thread.run(Thread.java:834) [?:?]

Steps to reproduce or test case
Redis version
6.x
Redisson version
3.13.0
Redisson configuration
  @Bean
  public RedissonClient redis(){
    Config config = new Config();
    config.useClusterServers().addNodeAddress(url);
    config.setCodec(StringCodec.INSTANCE);
    return Redisson.create(config);
  }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2809
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2810
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
shall this versoin be 3.13.0?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2811
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
behavior like #2217
Redission version
3.12.0
redission-spring-data-22 version
3.12.0
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2812
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redisson version: 3.12.1

  
    
      redisson/redisson/src/main/java/org/redisson/api/BatchOptions.java
    
    
        Lines 88 to 101
      in
      0259701
    
  
  
    

        
          
               /** 
        

        
          
                * Defines timeout for Redis response.  
        

        
          
                * Starts to countdown when Redis command has been successfully sent. 
        

        
          
                * <p> 
        

        
          
                * Default is <code>3000 milliseconds</code> 
        

        
          
                *  
        

        
          
                * @param timeout value 
        

        
          
                * @param unit value 
        

        
          
                * @return self instance 
        

        
          
                */ 
        

        
          
               public BatchOptions responseTimeout(long timeout, TimeUnit unit) { 
        

        
          
                   this.responseTimeout = unit.toMillis(timeout); 
        

        
          
                   return this; 
        

        
          
               } 
        
    
  


For example, in comment it says default value is 3000 ms, but it's actually 0. Does this mean RBatch execution will not timeout and could block the netty channel for quite long time?
Should the BatchOptions like timeout, retryAttempts use the values from RedissonClient?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2813
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2814
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
You need judge the size of set when executing hdel
return commandExecutor.evalWriteAsync(BugfixRedissonSetMultimap.this.getName(), codec, RedisCommands.EVAL_BOOLEAN_AMOUNT,
        "local count = redis.call('srem', KEYS[2], unpack(ARGV, 2, #ARGV));" + 
        "if count > 0 then " + 
            "if redis.call('scard', KEYS[2]) == 0 then " +
                "redis.call('hdel', KEYS[1], ARGV[1]); " +
            "end;" +
            "return 1;" +
        "end;" +
         "return 0; ",
    Arrays.<Object>asList(BugfixRedissonSetMultimap.this.getName(), setName), 
    args.toArray());
Actual behavior
RedissonSetMultimap Line 192
return commandExecutor.evalWriteAsync(RedissonSetMultimap.this.getName(), codec, RedisCommands.EVAL_BOOLEAN_AMOUNT,
        "local count = redis.call('srem', KEYS[2], unpack(ARGV, 2, #ARGV));" + 
        "redis.call('hdel', KEYS[1], ARGV[1]); " +
        "if count > 0 then "
          + "return 1;"
    + "end;" +
       "return 0; ",
    Arrays.<Object>asList(RedissonSetMultimap.this.getName(), setName), 
    args.toArray());
Steps to reproduce or test case
RSetMultimap<String, Long> testMap = redisson.getSetMultimap( "test-2" );
testMap.clear();
testMap.put( "t1", 1L );
testMap.put( "t1", 2L );
testMap.put( "t1", 3L );
RSet<Long> set = testMap.get( "t1" );
set.removeAll( Arrays.asList( 1L, 2L ) );
for( long l : set ) {
	System.out.println( l );
}
System.out.println( testMap.size() + " " + testMap.get( "t1" ).size() );
testMap.clear();
System.out.println( testMap.size() + " " + testMap.get( "t1" ).size() );
Result is
3
0 1
0 1
Redis version
Redisson version
3.13.0
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2815
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
When call

RBlockingQueueReactive.poll(limit),

I expect it returns

Flux

Actual behavior
But it returns below error, and the non-reactive lib is OK, is the reactive function provided in redisson PRO only?

java.lang.ClassCastException: class reactor.core.publisher.MonoLift cannot be cast to class reactor.core.publisher.Flux (reactor.core.publisher.MonoLift and reactor.core.publisher.Flux are in unnamed module of loader 'app')
at com.sun.proxy.$Proxy199.poll(Unknown Source)
Suppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException:

Steps to reproduce or test case
`


@GetMapping(value = "/redis/pop")
public Flux pop() {
RBlockingQueueReactive rbq = redissonClient.getBlockingQueue("RRedis-BQ");
return rbq.poll(3);
}
`
Redisson version
3.12.* , 3.13.0
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2816
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Scenario:
We configured Redisson with 2 AWS DNS endpoints: Primary and Reader. Primary has one node and Reader has 2.
After failover, one of the read replicas got promoted as the primary. Technically, since this happened behind the scene in AWS, we should not see any change to the Primary and Reader.
However, in Redisson log, we saw the type of the Reader endpoint got changed to be Master
Before failover:
redis://primary.dns - Type: Master
After failover:
redis://reader.dns - Type: Master
Wonder if this is a bug or we didn't configure our Redisson correctly. Any help would be greatly appreciated
Redisson version: 3.10.4
Configuration:

ReplicatedServers
ReadMode.MASTER
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2817
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2818
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2819
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2820
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2821
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2822
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2823
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2824
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2825
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2826
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2827
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2828
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2829
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2830
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2831
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2832
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2833
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2834
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2835
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2836
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2837
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2838
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2839
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2840
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2841
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2842
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2843
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2844
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2845
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2846
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2847
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2848
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2849
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2850
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2851
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2852
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2853
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2854
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2855
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2856
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2857
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2858
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2859
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2860
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2861
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2862
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2863
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2864
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2865
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2866
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2867
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2868
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2869
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2870
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2871
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2872
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2873
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2874
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2875
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2876
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2877
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2878
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2879
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2880
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2881
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2882
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2883
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2884
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2885
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2886
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2887
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2888
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2889
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2890
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2891
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2892
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2893
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2894
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2895
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2896
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2897
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2898
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2899
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2900
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2901
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2902
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2903
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2904
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2905
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2906
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2907
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2908
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2909
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2910
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2911
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2912
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2913
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2914
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2915
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2916
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2917
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2918
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2919
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2920
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2921
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2922
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2923
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2924
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2925
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2926
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2927
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2928
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2929
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2930
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2931
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2932
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2933
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2934
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2935
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2936
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2937
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2938
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2939
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2940
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2941
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2942
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2943
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2944
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2945
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello,
I have an application on Spring boot 2.2.6 using Caffeine Cache with @EnableCaching and @Cachable annotations.
@Bean
    fun cacheManager(caffeineConfig: CaffeineConfig): CacheManager {
        val caches: MutableList<CaffeineCache> = ArrayList()
        for (cacheMap in caffeineConfig.caches) {
            val entry: Map.Entry<String, String> = cacheMap.entries.iterator().next()
            val cacheName: String = entry.key
            val cacheSpec: CaffeineSpec = CaffeineSpec.parse(entry.value)
            val caffeineCache: CaffeineCache = CaffeineCache(cacheName, Caffeine.from(cacheSpec).recordStats().build())
            caches.add(caffeineCache)
        }

        val simpleCacheManager: SimpleCacheManager = SimpleCacheManager()
        simpleCacheManager.setCaches(caches)
        return simpleCacheManager
    }

And I'm trying to integrate redisson 3.12.5 to only read from a Redis cache.
@Bean
    @Profile("!dev")
    fun reboundDataCache(): RedissonClient {
        val config = Config()
        config.useClusterServers()
            .addNodeAddress(this.redisHost)
            .setReadMode(ReadMode.MASTER_SLAVE)
            .setTimeout(this.readTimeout)
            .setConnectTimeout(this.connectTimeout)
            .setCheckSlotsCoverage(false)

        return Redisson.create(config)
    }

When the app is starting up I'm getting this error and the app fails to start:
020-07-28 16:42:14.305 main ERROR org.springframework.boot.SpringApplication Application run failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'meterRegistryPostProcessor' defined in class path resource [org/springframework/boot/actuate/autoconfigure/metrics/MetricsAutoConfiguration.class]: Initialization of bean failed; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.cache.annotation.ProxyCachingConfiguration': Initialization of bean failed; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.cache.config.internalJCacheAdvisor' defined in class path resource [org/springframework/cache/jcache/config/ProxyJCacheConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.cache.jcache.interceptor.BeanFactoryJCacheOperationSourceAdvisor]: Factory method 'cacheAdvisor' threw exception; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'jCacheOperationSource' defined in class path resource [org/springframework/cache/jcache/config/ProxyJCacheConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.cache.jcache.interceptor.JCacheOperationSource]: Factory method 'cacheOperationSource' threw exception; nested exception is java.lang.NoSuchFieldError: cacheManager
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:603)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:207)
	at org.springframework.context.support.PostProcessorRegistrationDelegate.registerBeanPostProcessors(PostProcessorRegistrationDelegate.java:240)
	at org.springframework.context.support.AbstractApplicationContext.registerBeanPostProcessors(AbstractApplicationContext.java:722)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:535)
	at org.springframework.boot.web.reactive.context.ReactiveWebServerApplicationContext.refresh(ReactiveWebServerApplicationContext.java:66)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:747)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1226)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1215)
	at com.expedia.api.customer.ApplicationKt.main(Application.kt:17)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.cache.annotation.ProxyCachingConfiguration': Initialization of bean failed; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.cache.config.internalJCacheAdvisor' defined in class path resource [org/springframework/cache/jcache/config/ProxyJCacheConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.cache.jcache.interceptor.BeanFactoryJCacheOperationSourceAdvisor]: Factory method 'cacheAdvisor' threw exception; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'jCacheOperationSource' defined in class path resource [org/springframework/cache/jcache/config/ProxyJCacheConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.cache.jcache.interceptor.JCacheOperationSource]: Factory method 'cacheOperationSource' threw exception; nested exception is java.lang.NoSuchFieldError: cacheManager
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:603)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:409)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1338)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1177)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:557)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:207)
	at org.springframework.aop.framework.autoproxy.BeanFactoryAdvisorRetrievalHelper.findAdvisorBeans(BeanFactoryAdvisorRetrievalHelper.java:91)
	at org.springframework.aop.framework.autoproxy.AbstractAdvisorAutoProxyCreator.findCandidateAdvisors(AbstractAdvisorAutoProxyCreator.java:109)
	at org.springframework.aop.framework.autoproxy.AbstractAdvisorAutoProxyCreator.findEligibleAdvisors(AbstractAdvisorAutoProxyCreator.java:94)
	at org.springframework.aop.framework.autoproxy.AbstractAdvisorAutoProxyCreator.getAdvicesAndAdvisorsForBean(AbstractAdvisorAutoProxyCreator.java:76)
	at org.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator.wrapIfNecessary(AbstractAutoProxyCreator.java:347)
	at org.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator.postProcessAfterInitialization(AbstractAutoProxyCreator.java:299)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsAfterInitialization(AbstractAutowireCapableBeanFactory.java:431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1800)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:595)
	... 15 more
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.cache.config.internalJCacheAdvisor' defined in class path resource [org/springframework/cache/jcacDisconnected from the target VM, address: '127.0.0.1:57790', transport: 'socket'

Any clue?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2946
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Using Redisson client to connect to the Redis server. My Java Object has changed recently, added a new variable into my Java Object.
Started seeing this exception since then. How can I use the updated Object.
Caused by: java.io.IOException: java.io.IOException: Failed to read the next byte
at org.redisson.codec.FstCodec$FSTDefaultStreamCoderFactory$1.readStringUTF(FstCodec.java:146) ~[redisson-3.11.5.jar:3.11.5]
at org.nustaq.serialization.FSTClazzNameRegistry.decodeClass(FSTClazzNameRegistry.java:168) ~[fst-2.57.jar:?]
at org.nustaq.serialization.coders.FSTStreamDecoder.readClass(FSTStreamDecoder.java:478) ~[fst-2.57.jar:?]
at org.nustaq.serialization.FSTObjectInput.readClass(FSTObjectInput.java:939) ~[fst-2.57.jar:?]
at org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:347) ~[fst-2.57.jar:?]
at org.nustaq.serialization.FSTObjectInput.readObjectFields(FSTObjectInput.java:713) ~[fst-2.57.jar:?]
at org.nustaq.serialization.FSTObjectInput.instantiateAndReadNoSer(FSTObjectInput.java:566) ~[fst-2.57.jar:?]
at org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:374) ~[fst-2.57.jar:?]
at org.nustaq.serialization.FSTObjectInput.readObjectInternal(FSTObjectInput.java:331) ~[fst-2.57.jar:?]
at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:311) ~[fst-2.57.jar:?]
at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:245) ~[fst-2.57.jar:?]
at org.redisson.codec.FstCodec$1.decode(FstCodec.java:250) ~[redisson-3.11.5.jar:3.11.5]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:378) ~[redisson-3.11.5.jar:3.11.5]
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:422) ~[redisson-3.11.5.jar:3.11.5]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:387) ~[redisson-3.11.5.jar:3.11.5]
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:422) ~[redisson-3.11.5.jar:3.11.5]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:387) ~[redisson-3.11.5.jar:3.11.5]
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:209) ~[redisson-3.11.5.jar:3.11.5]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:147) ~[redisson-3.11.5.jar:3.11.5]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:117) ~[redisson-3.11.5.jar:3.11.5]
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[netty-codec-4.1.31.Final.jar:4.1.31.Final]
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) ~[netty-codec-4.1.31.Final.jar:4.1.31.Final]
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278) ~[netty-codec-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:648) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:583) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:500) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:462) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897) ~[netty-common-4.1.31.Final.jar:4.1.31.Final]
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.31.Final.jar:4.1.31.Final]
at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_181]
Caused by: java.io.IOException: Failed to read the next byte
at org.nustaq.serialization.coders.FSTStreamDecoder.readFByte(FSTStreamDecoder.java:294) ~[fst-2.57.jar:?]
at org.nustaq.serialization.coders.FSTStreamDecoder.readFInt(FSTStreamDecoder.java:252) ~[fst-2.57.jar:?]
at org.nustaq.serialization.coders.FSTStreamDecoder.readStringUTF(FSTStreamDecoder.java:77) ~[fst-2.57.jar:?]
at org.redisson.codec.FstCodec$FSTDefaultStreamCoderFactory$1.readStringUTF(FstCodec.java:142) ~[redisson-3.11.5.jar:3.11.5]
at org.nustaq.serialization.FSTClazzNameRegistry.decodeClass(FSTClazzNameRegistry.java:168) ~[fst-2.57.jar:?]
at org.nustaq.serialization.coders.FSTStreamDecoder.readClass(FSTStreamDecoder.java:478) ~[fst-2.57.jar:?]
at org.nustaq.serialization.FSTObjectInput.readClass(FSTObjectInput.java:939) ~[fst-2.57.jar:?]
at org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:347) ~[fst-2.57.jar:?]
at org.nustaq.serialization.FSTObjectInput.readObjectFields(FSTObjectInput.java:713) ~[fst-2.57.jar:?]
at org.nustaq.serialization.FSTObjectInput.instantiateAndReadNoSer(FSTObjectInput.java:566) ~[fst-2.57.jar:?]
at org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:374) ~[fst-2.57.jar:?]
at org.nustaq.serialization.FSTObjectInput.readObjectInternal(FSTObjectInput.java:331) ~[fst-2.57.jar:?]
at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:311) ~[fst-2.57.jar:?]
at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:245) ~[fst-2.57.jar:?]
at org.redisson.codec.FstCodec$1.decode(FstCodec.java:250) ~[redisson-3.11.5.jar:3.11.5]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:378) ~[redisson-3.11.5.jar:3.11.5]
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:422) ~[redisson-3.11.5.jar:3.11.5]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:387) ~[redisson-3.11.5.jar:3.11.5]
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:422) ~[redisson-3.11.5.jar:3.11.5]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:387) ~[redisson-3.11.5.jar:3.11.5]
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:209) ~[redisson-3.11.5.jar:3.11.5]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:147) ~[redisson-3.11.5.jar:3.11.5]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:117) ~[redisson-3.11.5.jar:3.11.5]
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[netty-codec-4.1.31.Final.jar:4.1.31.Final]
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) ~[netty-codec-4.1.31.Final.jar:4.1.31.Final]
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278) ~[netty-codec-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:648) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:583) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:500) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:462) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897) ~[netty-common-4.1.31.Final.jar:4.1.31.Final]
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.31.Final.jar:4.1.31.Final]
at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_181]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2947
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case
use chaosblade, set losspackage 50% and 200ms delay in redis port, keep 5min
start 50 thread to use redisson to read redis (client.getBucket("testkey").get())
Redis version
5.0.8
Redisson version
3.11.0
Redisson configuration
config.setCodec(getCodec("org.redisson.client.codec.StringCodec"));
config.useSentinelServers()
.setMasterName("xxxxx")
.addSentinelAddress(sentinelAddress)
.setPassword("xxxxx")
.setPingConnectionInterval(5000)
.setDatabase(0);
(default masterConnectionMinimumIdleSize,slaveConnectionMinmumIdkeSize is 32, masterConnectionPoolSize,slaveConnectionPoolSize is 64)
when chaosblade execute finished,i find 2 bugs:


i find there are some closed connection(channel) in the free connection pool
i use arthas to attach process, and watch org.redisson.command.CommandAsyncService#async(...int attempt, ...)
when chaosblade execute finished,also have method invoke with attempt > 0,than i find async(attempt > 0) only called by org.redisson.command.CommandAsyncService$6(it's a anonymous TimerTask)#run, getconnection() succes and call sendcommand() but netty writefuture not complete,than trigger the TimerTask, and i watch org.redisson.command.CommandAsyncService#sendCommand, find any connections is closed....and i use netstat -nt to confirm the connection is closed, but their also in the freeConnectionPool.....


the find freeConnectionCounter is bigger than slaveConnectionPoolSize, and freeConnection, allconnection also unlimit at sometime and sometime freeConnections size is bigger than allConnection......
it just like #2929 (comment)
and i reproduce it without RBatch command


i don't know why not check connection and drop it when getconnection?(
in org.redisson.connection.pool.ConnectionPool#connectTo, poll() get a connection,the connection is not actived,just trySetupFistFail?)
and i want know this bug is fixed in 3.13.xx?
thanks for you~
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2948
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello,
I've encountered a  bug when using EntryRemovedListener .
mappCache.addListener(new EntryRemovedListener() {
@OverRide
public void onRemoved(EntryEvent event) {
System.out.println("onRemoved name " + event.getKey());
        }

When i run test , i got the errors .
Caused by: java.io.CharConversionException: Invalid UTF-32 character 0x1ff0000 (above 0x0010ffff) at char #2, byte #11)
at com.fasterxml.jackson.core.io.UTF32Reader.reportInvalid(UTF32Reader.java:195)
at com.fasterxml.jackson.core.io.UTF32Reader.read(UTF32Reader.java:158)
at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._loadMore(ReaderBasedJsonParser.java:250)
at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._skipWSOrEnd(ReaderBasedJsonParser.java:2378)
at com.fasterxml.jackson.core.json.ReaderBasedJsonParser.nextToken(ReaderBasedJsonParser.java:672)
at com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4620)
at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4469)
at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3471)
at org.redisson.codec.JsonJacksonCodec$2.decode(JsonJacksonCodec.java:95)
at org.redisson.codec.BaseEventCodec.decode(BaseEventCodec.java:53)
at org.redisson.codec.MapCacheEventCodec$1.decode(MapCacheEventCodec.java:42)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:378)
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:422)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:387)
at org.redisson.client.handler.CommandPubSubDecoder.decodeCommand(CommandPubSubDecoder.java:71)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:134)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:91)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:501)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
... 17 common frames omitted
But, another listener as EntryExpiredListener works well
My setup:
redisson 3.13.2 run on window with oracle java 11.0.7
Redis version=6.0.5 on docker
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2949
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
when I use redistemplate, I can do this:
template.setKeySerializer(stringRedisSerializer);
template.setValueSerializer(redisSerializer);
template.setHashKeySerializer(stringRedisSerializer);
template.setHashValueSerializer(redisSerializer);
how can I set Serializer for hashkey or key independently
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2950
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Follow the issue: #2949
when I use redistemplate, I can do this:
template.setKeySerializer(stringRedisSerializer);
template.setValueSerializer(redisSerializer);
template.setHashKeySerializer(stringRedisSerializer);
template.setHashValueSerializer(redisSerializer);

I hava known this method, just like
RMap<Long, String> rMap = client.getMap("user:info", new JsonJacksonCodec());
but my hahkey want to use StringCodec, not JacksonCodec, how can I set codec just for hashkey separately.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2951
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
BloomFilter  has 2 module
bitSet  and config
rename BloomFilter should be rename all of them
Actual behavior
just rename bitSet ,no config
Steps to reproduce or test case
Redis version
4.0.10
Redisson version
3.13.1
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2952
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello
I want to write junit test in redisson to check my problem with Sentinel.
I found test org.redisson.RedissonBlockingQueueTest#testTakeReattachSentinel and wanted to use it as example for
Sentinel setup, but it's failing to run.
What am i doing wrong?

all other tests run fine

enviroment: Linux Mint 20 Cinnamon, jdk 11.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2953
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
We are using Redisson for AWS elasticache cluster and established connection should work consistently without any exception or error.
Actual behavior
Redisson client fails with the following exception  randomly , have to restart the application.
org.redisson.client.RedisConnectionException: SlaveConnectionPool no available Redis entries. Master entry host: NA:6379 Disconnected hosts: [NA:6379]
at org.redisson.connection.pool.ConnectionPool.get(ConnectionPool.java:218)
at org.redisson.connection.pool.SlaveConnectionPool.get(SlaveConnectionPool.java:30)
at org.redisson.connection.balancer.LoadBalancerManager.nextConnection(LoadBalancerManager.java:254)
at org.redisson.connection.MasterSlaveEntry.connectionReadOp(MasterSlaveEntry.java:480)
at org.redisson.connection.MasterSlaveConnectionManager.connectionReadOp(MasterSlaveConnectionManager.java:641)
at org.redisson.command.RedisExecutor.getConnection(RedisExecutor.java:643)
at org.redisson.command.RedisExecutor.execute(RedisExecutor.java:115)
at org.redisson.command.RedisExecutor$2.run(RedisExecutor.java:243)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:672)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:747)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:472)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base/java.lang.Thread.run(Thread.java:834)
Steps to reproduce or test case
We are using redis in our multiple microservices and  the above exception happens very randomly in any of the services after some days.
Redis version
AWS elastic cluster.

Redisson version
Tried both 3.13.1 and 3.13.2 but same issue .
Redisson configuration
           Config config = new Config();
	config.useClusterServers()
			.setMasterConnectionMinimumIdleSize(10)
			.setMasterConnectionPoolSize(10)
			.setSlaveConnectionPoolSize(10)
			.setSlaveConnectionMinimumIdleSize(10)
			.addNodeAddress(REDIS_URL_PREFIX + redisUrl + ":" + redisPort);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2954
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Please add same condition to releaseSubscribeConnection method and sign DCO.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2955
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
o is not empty,o1 is not empty;
Actual behavior
The first getMap execution result is not empty, and the second getMap execution result is null;
Steps to reproduce or test case
@jackygurui
-----------!!!!
127.0.0.1:6384> cluster slots



(integer) 5461
(integer) 10922


"127.0.0.1"
(integer) 6384
"4a5c09af2a6d65317216c152a80b9292f0070bfe"




"127.0.0.1"
(integer) 6386
"e80ed5831c610bebd8b799a3811a6d4a4ebd9852"






(integer) 10923
(integer) 16383


"127.0.0.1"
(integer) 6385
"65b4da8b421bdffbe1e3a77809008e26ffc88735"




"127.0.0.1"
(integer) 6387
"1c8583a3254c96f5174f9edd81b9a269608d65d2"






(integer) 0
(integer) 5460


"127.0.0.1"
(integer) 6383
"5d795b06238ec47845ad8d04aea8bfb285f3bdec"




"127.0.0.1"
(integer) 6388
"86abff0208c1bc528a003345fb6f5ce744f5dfc0"





only keyslot  5461-10922  behavior normal
-----------!!!!
//case1
String userIdKey = "user:" + 37;
RBatch batch = redissonClient.createBatch();
RFuture async = batch.getMap(userIdKey).getAsync(User.LOGIN);
BatchResult<?> execute = batch.execute();
Object o = async.get(); //--not null
Object o1 = redissonClient.getMap(userIdKey).get(User.LOGIN);
System.out.println(o1);//-- null
//case2
String userIdKey = "user:" + 37;
Object o1 = redissonClient.getMap(userIdKey).get(User.LOGIN);
RBatch batch = redissonClient.createBatch();
RFuture async = batch.getMap(userIdKey).getAsync(User.LOGIN);
BatchResult<?> execute = batch.execute();
Object o = async.get(); //--null
System.out.println(o1);//-- not null
Redis version
6.0.5
Redisson version
3.13.1
Redisson configuration
clusterServersConfig:
idleConnectionTimeout: 10000
pingTimeout: 1000
connectTimeout: 10000
timeout: 3000
retryAttempts: 3
retryInterval: 1500
failedSlaveReconnectionInterval: 3000
failedSlaveCheckInterval: 3
password: '123456'
subscriptionsPerConnection: 5
clientName: "redisson-demo"
loadBalancer:
class: "org.redisson.connection.balancer.RandomLoadBalancer"
slaveSubscriptionConnectionMinimumIdleSize: 1
slaveSubscriptionConnectionPoolSize: 50
slaveConnectionMinimumIdleSize: 32
slaveConnectionPoolSize: 64
masterConnectionMinimumIdleSize: 32
masterConnectionPoolSize: 64
readMode: "MASTER_SLAVE"
nodeAddresses:
- "redis://127.0.0.1:6383"
- "redis://127.0.0.1:6384"
- "redis://127.0.0.1:6385"
- "redis://127.0.0.1:6386"
- "redis://127.0.0.1:6387"
- "redis://127.0.0.1:6388"
scanInterval: 1000
threads: 0
nettyThreads: 0
codec:
class: "org.redisson.codec.JsonJacksonCodec"
transportMode: "NIO"
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2956
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2957
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
以云托管模式部署在k8s集群中，redis.default.svc.cluster.local作为redis的host，使用actuator作为HealthCheck的框架，进行如下操作：

pingAll() -> redis状态：UP
redis.default.svc.cluster.local修改成一个不存在的host（如redis.default.svc.cluster.local222）-> redis状态：DOWN
改回redis.default.svc.cluster.local -> redis状态：UP
再次改成不存在的host -> redis状态：UP

expect：随着host的变化，redis状态发生变化
Actual behavior
Steps to reproduce or test case
Redis version
4.0.12
Redisson version
3.11.5
Redisson configuration
    @Bean(destroyMethod = "shutdown")
    public RedissonClient redissonClient(
        @Value("${spring.redis.host}") final String[] hosts,
        @Value("${spring.redis.port}") final Integer port,
        @Value("${spring.redis.database:#{0}}") final Integer database,
        @Value("${spring.redis.scan_interval:#{10000}}") final Integer scanInterval) {
        final String[] url = Arrays.stream(hosts)
            .map(host -> "redis://" + host + ":" + port)
            .collect(Collectors.toList()).toArray(String[]::new);

        final Config config = new Config();
        config.setThreads(Runtime.getRuntime().availableProcessors() * MULTIPLE_NUM)
            .setNettyThreads(Runtime.getRuntime().availableProcessors() * MULTIPLE_NUM)
            .setCodec(new JsonJacksonCodec())
            .useReplicatedServers()
            .setDatabase(database)
            .addNodeAddress(url)
            .setScanInterval(scanInterval);

        log.info("Created Redisson client: url={}", (Object) url);
        return Redisson.create(config);
    }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2958
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2959
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
list of PendingMessage
Actual behavior
org.redisson.client.RedisException: ERR syntax error. channel: [id: 0x622755ea, L:/192.168.96.10:58442 - R:redis/192.168.96.5:6379] command: (XPENDING), params: [consumer_group:test, -, +, 2]
Steps to reproduce or test case
use pending(K key, String group, Range<?> range, long count)
      redisTemplate
          .opsForStream()
// error occurs regardless of range; Range.from(lowestId, highestId), ...
          .pending(streamName, groupName, Range.unbounded(), count)
Redis version
5.0.4
Spring boot starter version
2.3.2.RELEASE
Redisson version
3.13.2
Redisson configuration
none (only spring.redis.host is set)
Seems like command for connection should be XPENDING_ENTRIES, not XPENDING
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2960
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
int j =0;
public void Redis() throws InterruptedException {
    int i=0;
    while (i<100) {
        i++;
        Thread ts1 = new Thread(() -> {
            while (true) {
                RLock lock = redisson.getFairLock("frozen");
                try {
                    lock.lock(-1, null);
                    log.info(String.valueOf(j++));
                }finally {
                    if (lock.isHeldByCurrentThread()) {
                        lock.unlock();
                    } else {
                        log.error("获取了锁，但是却不能解锁？？");
                    }
                }
            }
        });
        ts1.start();
    }
    Thread.sleep(1000000000);
}

this is my code.the log will not print after a few minute.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2961
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
target：aaa
stored in redis ：\xFC\x01aaa
RBucket<Object result = thisredissonClient.getBucket(key)
if(!resultisExists()){
  result.set("aaa",5,TimeUnit.MINUTES);
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2962
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
类似 https://docs.spring.io/spring-data/redis/docs/2.2.x/api/org/springframework/data/redis/stream/StreamMessageListenerContainer.html 这个；
eg：当消息进入group之后，通知 消费者（当前group下）去处理消息；（类似RTopic的广播）
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2963
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Test setup:
Expected behavior
Failure reported as original failure cause (RedisTimeoutException)
Actual behavior
Null pointer when Redisson updates stats bean
Notice the explicit null argument https://github.com/redisson/redisson/blob/master/redisson/src/main/java/org/redisson/misc/RedissonPromise.java#L183
Then the boolean unboxing in the listener https://github.com/redisson/redisson/blob/master/redisson/src/main/java/org/redisson/jcache/JCache.java#L1720
This causes NullPointerException
Steps to reproduce or test case
Have several JCache caches. Start application. Suspend Redis server to force connection timeouts. Call removeAll() on an existing JCache
Redis version
6.0.4
Redisson version
3.13.3
Redisson configuration
Default SingleServer connecting to localhost with FstCodec
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2964
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
o.r.c.handler.ErrorsLoggingHandler - Exception occured. Channel: [id: xx, L:/XX.XX.XX.XX:XX - R:r-XX/XX.XX.XX.XX:6379]
io.netty.handler.codec.DecoderException: java.lang.NullPointerException
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:421)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:648)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:583)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:500)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:462)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException: null
	at org.redisson.client.handler.CommandPubSubDecoder.messageDecoder(CommandPubSubDecoder.java:212)
	at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:426)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:387)
	at org.redisson.client.handler.CommandPubSubDecoder.decodeCommand(CommandPubSubDecoder.java:71)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:134)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:91)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502)
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
	
o.r.c.handler.CommandPubSubDecoder - Unable to decode data. channel: [id: xx, L:/XX.XX.XX.XX:XX - R:r-XX/XX.XX.XX.XX:6379], reply: ReplayingDecoderByteBuf(ridx=94, widx=94)
java.lang.NullPointerException: null
    at org.redisson.client.handler.CommandPubSubDecoder.messageDecoder(CommandPubSubDecoder.java:212)
    at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:426)
    at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:387)
    at org.redisson.client.handler.CommandPubSubDecoder.decodeCommand(CommandPubSubDecoder.java:71)
    at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:134)
    at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:91)
    at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502)
    at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
    at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
    at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
    at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
    at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
    at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
    at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965)
    at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
    at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:648)
    at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:583)
    at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:500)
    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:462)
    at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
    at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    at java.lang.Thread.run(Thread.java:748)

Redis version
5.0
Redisson version
3.13.2
Redisson configuration
@Configuration
public class RedissonClientConfig {
    @Value("${act.redis.host}")
    private String host;

    @Value("${act.redis.port}")
    private String port;

    @Value("${act.redis.password:}")
    private String password;

    @Bean
    public RedissonClient redissonClient() {
        Config config = new Config();
        SingleServerConfig singleServerConfig = config.useSingleServer().setAddress("redis://" + host + ":" + port);
        if (StringUtils.isNotEmpty(password)) {
            singleServerConfig.setPassword(password);
        }
        //序列化方式设置为fastJson
        config.setCodec(new FastJsonCodec());
        return Redisson.create(config);
    }

}

public class FastJsonCodec extends BaseCodec {
    private final Encoder encoder = in -> {
        ByteBuf out = ByteBufAllocator.DEFAULT.buffer();
        try {
            ByteBufOutputStream os = new ByteBufOutputStream(out);
            JSON.writeJSONString(os, in,SerializerFeature.WriteClassName);
            return os.buffer();
        } catch (IOException e) {
            out.release();
            throw e;
        } catch (Exception e) {
            out.release();
            throw new IOException(e);
        }
    };

    private final Decoder<Object> decoder = (buf, state) ->
            JSON.parseObject(new ByteBufInputStream(buf), Object.class);

    @Override
    public Decoder<Object> getValueDecoder() {
        return decoder;
    }
    @Override
    public Encoder getValueEncoder() {
        return encoder;
    }
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2965
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2966
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2967
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
code like as below:
// batch persist
List persistResut = RLiveObjectService.persist(XXXXXX1, XXXXX2, XXXXX3);
// story result
Map map = RedissonLocalCacheMap;
for(XXXX xxx : persistResut){
map.put(xxx.id, xxxx);
}
result will throw exception:
Exception in thread java.lang.IllegalArgumentException: REntity should be attached to Redisson before save.
i think ,current object:xxx always java object, not link to redisson object , if i add some code ,will be normal.
eg:
for(XXXX xxx : persistResut){
// new link to redisson object
xxx = RLiveObjectService.get(XXXXX, PersistName);
map.put(xxx.id, xxxx);
}
so i think batch persist result why not link to redisson object automatic ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2968
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
after long running, application gets oom
Steps to reproduce or test case
our app runs about 1 month
Redis version
cloud service, not sure
Redisson version
3.11.2
Redisson configuration
very big array(1048576 size) in each threadlocal, new array was created in old-gen and always fail
stacktrace.log
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2969
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I'm using Redisson distributed executor service. A task class A is designed to process a given queue identified by its queue ID. There are multiple such queues. I need to ensure for any time in the cluster, there are no more than one instance of task class A that works on the same queue.
Allowed:
Task class A instance1 working on queue1    
Task class A instance2 working on queue2

Not allowed:
Task class A instance1 working on queue1
Task class A instance2 working on queue1

There are a large number of such queues and they change dynamically. So pre-allocation of task instances may not be an option, because the queue ID is dynamic.
How can this be achieved with Redisson executor? If not directly, can this be achieved with some distributed lock or queue?
I have the same question on Stackoverflow as well: https://stackoverflow.com/questions/63267465/distributed-exclusive-task-with-redisson
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2970
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
`RScoredSortedSet set = redisson.getScoredSortedSet(key);
CustomObj obj = new CustomObj(1,2);
set.add(obj);
set.remove(obj); // this is not removing obj from sorted set`
I have code like above in my application. i am not able to remove custom obj from RScoredSortedSet.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2971
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
try{
      lock.tryLock(300, TimeUnit.SECONDS);
      Thread.sleep(60000L);
    } catch (InterruptedException e) {
      System.out.println("timeout!")
    } finally {
      lock.unlock();
    }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2972
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I am facing problem in redisson after a while of running the application. it threw an exception with the following stack trace.

and it failed to recover from that state untill the application is restarted. we also found another exception with the same stack trace
org.redisson.RedissonShutdownException: Redisson is shutdown at org.redisson.command.RedisExecutor.execute(RedisExecutor.java:109) at org.redisson.command.CommandAsyncService.async(CommandAsyncService.java:610) at org.redisson.command.CommandAsyncService.writeAsync(CommandAsyncService.java:595) at org.redisson.RedissonLock.isHeldByThread(RedissonLock.java:543) at org.redisson.RedissonLock.isHeldByCurrentThread(RedissonLock.java:538) 
Redisson version: 3.13.2
can anyone help me how shall we recover from this problem without restarting application? also what is the cause of that problem?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2973
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2974
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
can i use spring.redis.pool.size to  change connectionPoolSize? although use redisson.yaml can set this parameter. however, I want to only set parameters in application.properties, then i can put application.properties in git which used in spring-cloud-config.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2975
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is there any way to change the redissonClient hostname at runtime and force the connexion to the new ip:port ?
I tried to remove listener from the previous client, shutdown and then create a new RedissonClient and a listener with the updated config but when I receive the first message, Redisson is shutdown and throw an exception.
It is possible to use the @RefreshScope from spring boot to achieve this goal ?
Thanks you !
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2976
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redisson version 3.13.3
After upgrading to 3.13.3, the problem has not been solved.
Report an error every morning, usually once. Both errors occur at the same time.
error 1：
slave **** has been disconnected after 500 ms interval since moment of the first failed connection.
error2:
org.redisson.client.RedisConnectionException:SlaveConnectionPool no available Redis entries.  Disconnected hosts: [*****]
at org.redisson.connection.pool.ConnectionPool.get(ConnectionPool.java:219)
at org.redisson.connection.pool.SlaveConnectionPool.get(SlaveConnectionPool.java:30)
at org.redisson.connection.balancer.LoadBalancerManager.nextConnection(LoadBalancerManager.java:248)
at org.redisson.connection.MasterSlaveEntry.connectionReadOp(MasterSlaveEntry.java:464)
at org.redisson.connection.MasterSlaveConnectionManager.connectionReadOp(MasterSlaveConnectionManager.java:621)
at org.redisson.command.RedisExecutor.getConnection(RedisExecutor.java:644)
at org.redisson.command.RedisExecutor.execute(RedisExecutor.java:116)
at org.redisson.command.RedisExecutor$2.run(RedisExecutor.java:244)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:682)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:757)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:485)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2977
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
User should be able to register arbitrary Kotlin classes.
Actual behavior
ByteBuddy throws new IllegalArgumentException("Cannot subclass primitive, array or final types: " + superType); on normal class declarations. This is because Kotlin's classes are final by default. However, to allow sub-classes, even after the open keyword is applied, and constructor keyword declared. ByteBuddy is still failing, with: java.lang.IllegalArgumentException: Can't find default constructor for class Customer$ByteBuddy$sa6Yvns1.
Steps to reproduce or test case
import kotlinx.coroutines.*
import org.redisson.Redisson
import org.redisson.api.RLiveObjectService
import org.redisson.api.RedissonClient
import org.redisson.api.annotation.REntity
import org.redisson.api.annotation.RId
import org.redisson.api.annotation.RIndex

@REntity
open class Customer constructor(@RId val id: Int, @RIndex var name: String?, @RIndex var city: String?)

@ExperimentalCoroutinesApi
@InternalCoroutinesApi
fun main(): Unit {
        val client: RedissonClient = Redisson.create() // connects to 127.0.0.1:6379 by default
        val service: RLiveObjectService = client.liveObjectService
        service.registerClass(Customer::class.java)
        val customers: List<Customer> = listOf(
            Customer(1, "angela", "LA"),
            Customer(2, "svetlana", "moscow"),
            Customer(3, "juliana", "kiev")
        )
        customers.forEach { service.persist(it) }
}

Redis version
6.0.1
Redisson version
3.13.3
Redisson configuration
default
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2978
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
我需要实现一个类似
scan 10 match test* count 10
这样的命令，RKeys.getKeysByPattern(String,int)，其中的int应该只能设置获取的条数，如何实现设置起始下标呢
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2979
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2980
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have specified redisson-jcache.yaml in my resources folder.
If I add the codec property in the configuration then get java.lang.IllegalStateException: Default configuration hasn't been specified! 
If I remove the codec configuration property then everything works fine.
Expected behavior
Config should be parsed successfully with codec property.
Actual behavior
Caused by: java.lang.IllegalStateException: Default configuration hasn't been specified!
at org.redisson.jcache.JCacheManager.createCache(JCacheManager.java:118)
Steps to reproduce or test case
Please use the config below and run
		MutableConfiguration<String, String> config = new MutableConfiguration<>();
		CacheManager manager = Caching.getCachingProvider().getCacheManager();
		Cache<String, String> cache = manager.createCache("namedCache", config);

Comment the codec part in config and run agian.
Redis version
https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/WhatIs.html
Redisson version
3.13.3
jackson-dataformat-avro
2.11.2
netty-tcnative-boringssl-static
2.0.31.Final
Redisson configuration
---
clusterServersConfig:
  password: "pass"
  clientName: clisrvet
  sslProvider: OPENSSL
  keepAlive: true
  nodeAddresses:
    - "rediss://no-user-name-for-redis:pass@host:port"
codec: !<org.redisson.codec.AvroJacksonCodec> {}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2981
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redis Setup:
Nodes: 1 Primary and 2 Replica Nodes
002 is Primary, rest 2 are replica node.
What I want to acheive
I want to configure Redis as a distributed l2 cache to improve my application's performance as ~70% of my traffic is read only. I am using hibernate as my ORM, thus don't want to write lots of custom code when there is a standard implementation provided by redisson.
My Configuration:
Config config = new Config()
.setTransportMode(TransportMode.NIO)
.setCodec(new SnappyCodecV2())
.useReplicatedServers()
.setTimeout(10000)
.addNodeAddress(
	String.format("redis://%s:%s", "mercuryredis-002.xxx.cache.amazonaws.com", port), 
        String.format("redis://%s:%s", "mercuryredis-001.xxx.cache.amazonaws.com", port),
	String.format("redis://%s:%s", "mercury-redis-003.xxx.cache.amazonaws.com", port))
.setIdleConnectionTimeout(10000);

Issue:
I see all the cache hits are from the master node meaning every write, as well as read, is just happening from the master node.
I went through all the issues reported till now to find the solution but none of them were around hibernate l2 cache. Finally found #2165 where its mentioned "RMapCache.get operations modifies data so it can't use slave node. This method updates idletimeout and lasttimeaccess parameters per entry.
You could use RMap object in this case."
And After looking at the code here I found we are using RMapCache<Object,Object> for each region.
This indicates we can't use it correctly for Hibernate L2 Cache as every time I try to fetch a cached object, redisson will write to the master node and my entire traffic will become dependent on a single master node. Which is not very reliable.
Please help with this.
Proof

Cache Hit Rate: You can clearly see its just hitting primary node.

Cache Hits: You can clearly see its just hitting primary node.

Cache Misses:

### Version used:

org.redisson
redisson
3.13.2


org.redisson
redisson-hibernate-4
3.13.2
`
Happy to provide more details.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2982
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Incidentally zmscore was recently added to Redis after five years.. redis/redis#2344 but it's not available just yet.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2983
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2984
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
When using redisson-tomcat to provide a SessionManager for our tomcat installation, we expect the classloader used to instantiate objects should be the current thread classloader, regardless of which Codec is being used. Using FSTCodec this worked as expected. This is to allow the right classloader, Tomcat vs WAR classloader to create the objects which it knows how to create.
Actual behavior
After the switch to the MarshallingCodec as default we are running into issues with the RiverUnmarshaller is throwing errors after calling classResolver.resolveClass(). When a thread from my WAR attempts to unmarshall a class it has loaded, for example org.springframework.security.web.savedrequest.DefaultSavedRequest the classresolver on the RiverUnmarshaller for some threads points to tomcat’s Classloader (URLClassLoader with apache-tomcat paths)
This RiverUnmashaller is a FastThreadLocal<Unmarshaller> decoderThreadLocal which is field on the MarshallingCodec.
I can see in the debugger that the MarshallingCodec has classLoader field of my WAR’s class loader, not a reference to tomcat’s. The configuration object on the same MarshallingCodec also points to the WAR class loader.
The number of threads in this broken state where the classloader being used to unmarshall isn't shared by the MarshallingCodec seems to change on each run, but reproduced pretty consistently.

Steps to reproduce or test case
Running Tomcat 8.5.57.0, deploy a WAR with a context xml with a manager as described https://github.com/redisson/redisson/tree/master/redisson-tomcat#1-add-redissonsessionmanager
Place objects onto the session and attempt to retrieve them that are instances of classes not on the tomcat classpath directly (only within the war, spring security for example)
See requests fail sometimes, depending which thread picks up the work.
Redis version
6.0.6
Redisson version
3.13.3
Redisson configuration
singleServerConfig:
  address: "redis://redis-server:6379"
  password: "${REDIS_PASSWORD}"
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2985
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
mvn 依赖redisson-spring-boot-starter以后
redisTemplate.opsForValue().setIfAbsent 返回null， 但是值已经被设置。
这是什么问题？
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2986
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We have an AWS Elasticache cluster, with cluster mode enabled - multiple shards, NO replicas.
When ever a node is replaced, after new node comes up, Redission is not able to discover the new node, fails with
RedisNodeNotFoundException
Exception trace:
org.redisson.client.RedisNodeNotFoundException: Node for slot: 7727 hasn't been discovered yet. Check cluster slots coverage using CLUSTER NODES command
at org.redisson.connection.MasterSlaveConnectionManager.createNodeNotFoundFuture(MasterSlaveConnectionManager.java:613) ~[Redisson-3.11.x.jar:?]
at org.redisson.connection.MasterSlaveConnectionManager.connectionWriteOp(MasterSlaveConnectionManager.java:567) ~[Redisson-3.11.x.jar:?]
at org.redisson.command.RedisExecutor.getConnection(RedisExecutor.java:645) ~[Redisson-3.11.x.jar:?]
at org.redisson.command.RedisExecutor.execute(RedisExecutor.java:116) ~[Redisson-3.11.x.jar:?]
at org.redisson.command.RedisExecutor$2.run(RedisExecutor.java:245) ~[Redisson-3.11.x.jar:?]
Expected behavior
Redisson to discover new replaced node without any issue
Actual behavior
Redisson fails to discover new node with RedisNodeNotFoundException.
Redis version
5.0.4
Redisson version
3.11.6
Redisson configuration
More logs:
During node replacement:
04:41.9 | 11 Aug 2020 06:04:40,996   �[1;31m[ERROR]�[m    (redisson-netty-5-7) org.redisson.cluster.ClusterConnectionManager:   Can't connect to master: redis://10.0.61.52:6379 with slot ranges:   [[7168-8191]]



04:41.6
11 Aug 2020 06:04:40,840   �[32m[INFO]�[m    (redisson-netty-5-5) org.redisson.cluster.ClusterConnectionManager:   slave redis://10.0.61.52:6379 removed for slot ranges: [[7168-8191]]



After node replacement:



03:47.7
11 Aug 2020 06:03:47,711   �[32m[INFO]�[m    (redisson-netty-5-33)   org.redisson.connection.pool.SlaveConnectionPool: 24 connections initialized   for 10.0.61.52/10.0.61.52:6379




org.redisson.client.RedisNodeNotFoundException: Node for slot: 7727 hasn't been discovered yet. Check cluster slots coverage using CLUSTER NODES command




---  Put and Deletes are failing
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2987
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I currently have an application where I first create a RRateLimiter. I then acquire one permit in a loop and do an operation. This application is intended to run in a distributed fashion. To test the behavior, I set off concurrent invocations of this program. While it works well for the most part, it does throw an error occasionally as described below.
Expected behavior
No error. The thread waits to acquire a permit and does so.
Actual behavior
Occasionally, the  limiter.acquire() in the below code throws the following error -
org.redisson.client.RedisException: ERR Error running script (call to f_df5536206d0c440727a5f17ab38851a31af682c7): @user_script:1: user_script:1: bad argument #2 to 'unpack' (string expected, got nil) . channel: [id: 0x21ed2b8c, L:/169.254.76.1:60060 - R:/10.24.141.126:6379] command: (EVAL), params: [local rate = redis.call('hget', KEYS[1], 'rate');local interval = redis.call('hget', KEYS[1], 'inter..., 5, test, {test}:value, {test}:value:a070c033-9d81-4fd9-b2f7-55a15a4cc468, {test}:permits, {test}:permits:a070c033-9d81-4fd9-b2f7-55a15a4cc468, 1, 1597793996430, -2193289253268890349] 
Steps to reproduce or test case
Code snippet in AWS lambda talking to elasticache -
RRateLimiter limiter = redisson.getRateLimiter("test");
limiter.trySetRate(RateType.OVERALL, 1, 2, RateIntervalUnit.SECONDS);
while (true) {
                try {
                    limiter.acquire();
                    context.getLogger().log("get semaphore");
                    sqs.sendMessage(new SendMessageRequest()
                            .withQueueUrl("https://sqs_url")
                            .withMessageBody(new Date().toString()));
                    context.getLogger().log("sent to sqs");
                }
                catch (Exception ex) {
                    context.getLogger().log("Error in loop:" + ex);
                }
            }

Redis version
Elasticache, 5.0.6
Redisson version
3.13.3
Redisson configuration
Elasticache cluster config
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2988
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi, I am facing error while connecting to cluster.
It is giving following error::
java.lang.IllegalArgumentException: port out of range:-1
at java.net.InetSocketAddress.checkPort(InetSocketAddress.java:143)
at java.net.InetSocketAddress.(InetSocketAddress.java:224)
at org.redisson.client.RedisClient.(RedisClient.java:93)
at org.redisson.connection.MasterSlaveConnectionManager.createClient(MasterSlaveConnectionManager.java:310)
at org.redisson.cluster.ClusterConnectionManager.connect(ClusterConnectionManager.java:150)
at org.redisson.cluster.ClusterConnectionManager.(ClusterConnectionManager.java:81)
at org.redisson.config.ConfigSupport.createConnectionManager(ConfigSupport.java:172)
at org.redisson.Redisson.(Redisson.java:103)
at org.redisson.Redisson.create(Redisson.java:133)
Actually it not generating ClientPartition.getMasterAddress() properly.
Address is //127.0.0.1:8001@18001 as recorded by CLUSTER_NODES, but it reads it as host: 18001 and port=-1.
Cluster config from CLUSTER_NODES::
[ClusterNodeInfo [nodeId=4317f285b359ddc3ac08bb85239924509146e475, address=//127.0.0.1:8003@18003, flags=[SLAVE], slaveOf=4118a348827e6107d7e35522a251fd39c5a8f82b, slotRanges=[]], ClusterNodeInfo [nodeId=2f7b93c80d3721b3fb26fe87bc28ed04a63fe0ec, address=//127.0.0.1:8005@18005, flags=[SLAVE], slaveOf=8b81c3e1acb4e1959a83267540058d1a6bffa12f, slotRanges=[]], ClusterNodeInfo [nodeId=4118a348827e6107d7e35522a251fd39c5a8f82b, address=//127.0.0.1:8001@18001, flags=[MASTER], slaveOf=null, slotRanges=[[5461-10922]]], ClusterNodeInfo [nodeId=a0770863d893a5b8106a83e247cea2544f99ef36, address=//127.0.0.1:8004@18004, flags=[SLAVE], slaveOf=6b9da1bbe38b978a3017406e5c1e310f4706cfc8, slotRanges=[]], ClusterNodeInfo [nodeId=8b81c3e1acb4e1959a83267540058d1a6bffa12f, address=//127.0.0.1:8000@18000, flags=[MYSELF, MASTER], slaveOf=null, slotRanges=[[0-5460]]], ClusterNodeInfo [nodeId=6b9da1bbe38b978a3017406e5c1e310f4706cfc8, address=//127.0.0.1:8002@18002, flags=[MASTER], slaveOf=null, slotRanges=[[10923-16383]]]]
My code is ::
Config config = new Config();
config.useClusterServers()
.addNodeAddress("redis://127.0.0.1:8000");
RedissonClient redisson = Redisson.create(config);
RMap<String, String> map = redisson.getMap("simpleMap");
map.put("mapKey", "This is a map value");
String mapValue = map.get("mapKey");
System.out.println("stored map value: " + mapValue);
redisson.shutdown();
Also, tried with
.addNodeAddress("127.0.0.1:8000");
Dependencies::
 
     org.redisson
     redisson
     2.3.0
 
Let me know if any other detail is required.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2989
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redis 4
Tomcat 9
Redisson 3.13.3
The session details are maintained in a  Vector class which doesn't have a default constructor
Sample class below:
public class Test1 extends Vector implements Serializable
{
private String cName;
            public Test1(String sName)      # This is the only constructor
            {
                            c = sName;
            }

}
While deserialising session data , we are getting following error
[redisson-netty-2-12] ERROR org.redisson.client.handler.CommandDecoder - Unable to decode data. channel: [id: 0x62b212db, L:/192.168.15.3:51412 - R:redis-svc/[ip:port], reply: ReplayingDecoderByteBuf(ridx=187, widx=416), command: (HGETALL), params: [redisson:tomcat_session:8F92D92D6DFCA04B858558540BB52535]
java.io.IOException: java.lang.InstantiationException: Test1
at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:247)
at org.redisson.codec.FstCodec$1.decode(FstCodec.java:228)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:384)
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:428)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:393)
…
Caused by: java.lang.InstantiationException: Test1
at java.lang.Class.newInstance(Class.java:427)
at org.nustaq.serialization.serializers.FSTCollectionSerializer.instantiate(FSTCollectionSerializer.java:83)
at org.nustaq.serialization.FSTObjectInput.instantiateAndReadWithSer(FSTObjectInput.java:501)
at org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:370)
at org.nustaq.serialization.FSTObjectInput.readObjectInternal(FSTObjectInput.java:331)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2990
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
We are using RedissonSessionManager to store tomcat sessions to Redis. When session object contains object of type Java Vector  without default constructor, it  throws a deserialisation exception
[redisson-netty-2-12] ERROR org.redisson.client.handler.CommandDecoder - Unable to decode data. channel: [id: 0x62b212db, L:/192.168.15.3:51412 - R:redis-svc/[ip:port], reply: ReplayingDecoderByteBuf(ridx=187, widx=416), command: (HGETALL), params: [redisson:tomcat_session:8F92D92D6DFCA04B858558540BB52535]
java.io.IOException: java.lang.InstantiationException: Test1
at org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:247)
at org.redisson.codec.FstCodec$1.decode(FstCodec.java:228)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:384)
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:428)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:393)
…
Caused by: java.lang.InstantiationException: Test1
at java.lang.Class.newInstance(Class.java:427)
at org.nustaq.serialization.serializers.FSTCollectionSerializer.instantiate(FSTCollectionSerializer.java:83)
at org.nustaq.serialization.FSTObjectInput.instantiateAndReadWithSer(FSTObjectInput.java:501)
at org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:370)
at org.nustaq.serialization.FSTObjectInput.readObjectInternal(FSTObjectInput.java:331)
Actual behavior
Session should get stored and retrieved from redis
Steps to reproduce or test case
The session details are maintained in a Vector class which doesn't have a default constructor. When we try to add this to redis session it fails
Sample class below:
public class Test1 extends Vector implements Serializable
{
private String cName;
        public Test1(String sName)      # This is the only constructor
        {
                        cName = sName;
        }

}
Redis version
Redisson version
Redis 4
Redisson configuration
singleServerConfig:
idleConnectionTimeout: 10000
connectTimeout: 10000
timeout: 3000
retryAttempts: 3
retryInterval: 1500
password: null
subscriptionsPerConnection: 5
clientName: null
address: "redis://IP:6379"
subscriptionConnectionMinimumIdleSize: 1
subscriptionConnectionPoolSize: 50
connectionMinimumIdleSize: 24
connectionPoolSize: 64
database: 0
dnsMonitoringInterval: 5000
threads: 16
nettyThreads: 32
codec: !<org.redisson.codec.FstCodec> {}
transportMode: "NIO"
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2991
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
anotherValue
Actual behavior
null
Steps to reproduce or test case

  @Test
  public void test() {
    RMapCache<String, String> testRMapCache = redissonClient.getMapCache(RedissonTest.testRMapCache);
    testRMapCache.fastPut("key", "value", 20, TimeUnit.SECONDS);
    try {
      //wait for key timeout
      Thread.sleep(21 * 1000);
    } catch (InterruptedException e) {
      e.printStackTrace();
    }
    //try to put "key-anotherValue", then get the "key", but the "result" is null
    testRMapCache.put("key", "anotherValue");
    String result = testRMapCache.get("key");
    System.out.println("result: " + result);// null
  }

Redis version
docker redis 5.0.5
Redisson version
redisson-spring-boot-starter
3.13.1
Redisson configuration
redisson-spring-boot-starter default config and localhost redis
spring.redis.host=192.168.85.253
spring.redis.port=6379
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2992
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Delayed Queue 在 CLUSTER 模式下无法准时将数据存放到目标队列中，在下一次offer时才会将超时的数据放入目标队列中
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2993
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2994
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Facing the following issue during HA testing the application wtih Redisson Client:::
Redisson Version: 3.11.6
Redis Cluster: 3M + 2S
Steps:

Kill one of the masters, the slave becomes the master.
Make the master up after a minute, it then becomes the slave.
Kill the master node(which was slave), the slave becomes the master.
Sometimes its not reproducible in one shot, need to do this 3-4 times.

At this point, redisson is not able to read/write anything to that redis partition  because the client is still taking the previous master(which was killed) and not the promoted slave node.
As per below logs, port 8000 was the master node, which was killed, and the slave node 9000 was promoted to master. But still Redisson is sending the command to the previous master node. We need to restart the application to make it working or make the previous master up.
Redis Cluster Nodes Command:::
10.32.xxx.xx:8000 master,fail - 1597924494641 1597924493739 29 connected
10.32.xxx.xx:8002 master - 0 1597924565415 3 connected 10923-16383
10.32.xxx.xx:9001 slave e0633f21c6a79ad10c9a8696a45991867aabc879 0 1597924566919 2 connected
10.32.xxx.xx:9000 master - 0 1597924566417 30 connected 0-5460
10.32.xxx.xx:8001 myself,master - 0 0 2 connected 5461-10922
Logs:::::
org.redisson.client.WriteRedisConnectionException: Unable to write command into connection! Node source: NodeSource [slot=5048, addr=null, redi
sClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=value:50:qu
eue:0, freeConnectionsAmount=24, freeConnectionsCounter=value:64:queue:0, freezed=false, freezeReason=null, client=[addr=redis://10.32.xxx.xx:8000], nodeType=MASTER, firstFail=0]]], connection: RedisConnection@427802830 [redisClient=[addr=redis://10.32.xxx.xx:8000], channel=[id: 0xda6d
e1f2, L:0.0.0.0/0.0.0.0:35504], currentCommand=null]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2995
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2996
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We had an issue where the IP address of the Redis server changed. We saw logs like these from the DNSMonitor:
Detected DNS change. Master rediss://{host}:{port} has changed ip from IP1 to IP2
Unable to find master entry for host/{IP1}:port. Multiple IP bindings for single hostname supported only in Redisson PRO!
I saw in response to a similar issue the recommendation to disable DNS monitoring. I tried to prototype (with 3.13.3) on a local PC using the hosts file to simulator a DNS change. But Redisson continues to use the earlier resolved IP address instead of resolving the hostname again. I confirmed with InetAddress.getByName() that I can retrieve the updated IP address, but Redisson is still trying to use the old one.
I also tried to detect the connection drop when the IP changes (using ConnectionListener) and then completely recreate the Config and RedissonClient objects with the hostname, but still the older IP is used, and shown in the exception after failure to connect. I guess it remains cached somewhere?
Exception in thread "Thread-0" org.redisson.client.RedisConnectionException: Unable to connect to Redis server: host/{IP1}:6379
Is there any way to force a new attempt to resolve the IP?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2997
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In cluster mode, delayed queue can't put the data to the target queue on time. The timeout data will be put into the target queue when the next offer is made
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2998
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
i use the RedissonQueue 'pollAsync(int limit)' method,
after i poll some elements, the capacity of the queue did not recovery,
at last, the capacity becomes 0, wow , i can not offer element any more!!!!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/2999
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@mrniko ptal before releasing 3.13.4
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3000
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@mrniko sorry, didn't see this until we deployed to staging redis cluster with read slaves.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3001
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
UP
Actual behavior
DOWN because of the exception
`2020-08-21 15:02:50.698  WARN 1 --- [oundedElastic-1] o.s.b.a.r.RedisReactiveHealthIndicator   : Redis health check failed
java.lang.ClassCastException: class com.sun.proxy.$Proxy122 cannot be cast to class org.redisson.Redisson (com.sun.proxy.$Proxy122 and org.redisson.Redisson are in unnamed module of loader org.springframework.boot.loader.LaunchedURLClassLoader @1d56ce6a)
at org.redisson.spring.data.connection.RedissonConnectionFactory.getReactiveConnection(RedissonConnectionFactory.java:149) ~[redisson-spring-data-23-3.13.2.jar!/:3.13.2]
at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]
at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
at java.base/java.lang.reflect.Method.invoke(Method.java:567) ~[na:na]
at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:282) ~[spring-core-5.2.8.RELEASE.jar!/:5.2.8.RELEASE]
at org.springframework.cloud.context.scope.GenericScope$LockedScopedProxyFactoryBean.invoke(GenericScope.java:499) ~[spring-cloud-context-2.2.4.RELEASE.jar!/:2.2.4.RELEASE]
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar!/:5.2.8.RELEASE]
at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) ~[spring-aop-5.2.8.RELEASE.jar!/:5.2.8.RELEASE]
at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:691) ~[spring-aop-5.2.8.RELEASE.jar!/:5.2.8.RELEASE]
at org.redisson.spring.data.connection.RedissonConnectionFactory$$EnhancerBySpringCGLIB$$503ddcc5.getReactiveConnection() ~[redisson-spring-data-23-3.13.2.jar!/:3.13.2]
at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:85) ~[reactor-core-3.3.9.RELEASE.jar!/:3.3.9.RELEASE]
at reactor.core.publisher.FluxSubscribeOnCallable$CallableSubscribeOnSubscription.run(FluxSubscribeOnCallable.java:225) ~[reactor-core-3.3.9.RELEASE.jar!/:3.3.9.RELEASE]
at reactor.core.scheduler.SchedulerTask.call(SchedulerTask.java:68) ~[reactor-core-3.3.9.RELEASE.jar!/:3.3.9.RELEASE]
at reactor.core.scheduler.SchedulerTask.call(SchedulerTask.java:28) ~[reactor-core-3.3.9.RELEASE.jar!/:3.3.9.RELEASE]
at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[na:na]
at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) ~[na:na]
at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) ~[na:na]
at java.base/java.lang.Thread.run(Thread.java:830) ~[na:na]`
Steps to reproduce or test case
Create a project that use org.springframework.cloud.context.config
`@Configuration
public class RedisConfig {
@Autowired
private BeanFactory factory;

@Bean
@RefreshScope
public RedisConfigurationProperties properties() {
    return new RedisConfigurationProperties();
}

@Bean
@RefreshScope
public RedissonClient redissonClient(RedisConfigurationProperties props) {
    Config config = new Config();
    config.useSingleServer().setAddress(String.format("redis://%s:%s", props.getHost(), props.getPort()));

    RedissonClient redissonClient = Redisson.create(config);

    return redissonClient;
}

@Bean
@RefreshScope
public RedissonConnectionFactory redissonConnectionFactory(RedissonClient redisson) {
    return new RedissonConnectionFactory(redisson);
}

}`
Do a get on /actuator/health
Redisson version
3.13.3, with redisson-spring-boot-starter (3.13.3) and redisson-spring-data-23 (3.13.3)
Redisson configuration
Single server
host: localhost
port: 6379
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3002
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is there an interface I can use to do get, set and del operations with byte[] keys?
public byte[] get(byte[] key) {
      if (key == null) {
         return new byte[0];
      }
      return redissonClient.getBucket(key);
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3003
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3004
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Threads that are alive and waiting for a RedissionFairLock will always get ownership of the lock it tried to acquire.
Actual behavior
When a RedissonFairLock is locked by long-running Thread T1, and other Threads (T2, ..., Tn) attempts to access the lock and waits for longer than 5 minutes (the default threadWaitTime), even when T1 releases the lock all waiting Threads T2 to Tn hang indefinitely.
This is due to future threads removing "expired" threads from the Queue, when in reality these threads are still alive and waiting for the lock. These "expired" threads never receive the PUBLISH message on unlock.
Steps to reproduce or test case
import org.redisson.Redisson;
import org.redisson.api.RLock;

import java.util.concurrent.CountDownLatch;
import java.util.concurrent.Executors;
import java.util.function.Supplier;

class Example {

    public static void main(String[] args) throws InterruptedException {
        final var redis = Redisson.create();
        final Supplier<RLock> lockSupplier = () -> redis.getFairLock("fair-lock");
        final var exec = Executors.newCachedThreadPool();

        final var lockAcquiredLatch = new CountDownLatch(1);
        final var lockReleasedLatch = new CountDownLatch(1);
        final var finishedLatch = new CountDownLatch(1);

        // start Thread 1 and acquire the Lock first, release after default threadWaitTime = 60000 * 5
        exec.submit(() -> {
            final var lock = lockSupplier.get();
            lock.lock();
            lockAcquiredLatch.countDown();
            try {
                Thread.sleep(60000 * 5 + 2000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            lockReleasedLatch.countDown();
            lock.unlock();
        });

        // start Thread 2 right after Lock is acquired, we expect program to terminate as Thread 2 acquires lock
        exec.submit(() -> {
            final var lock = lockSupplier.get();
            try {
                lockAcquiredLatch.await();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            lock.lock();
            lock.unlock();
            finishedLatch.countDown();
        });

        // start Thread 3 just before Thread 1 releases the lock, so Thread 2 entry will expire
        exec.submit(() -> {
            final var lock = lockSupplier.get();
            try {
                lockAcquiredLatch.await();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            lock.lock();
            lock.unlock();
        });

        finishedLatch.await();
        System.out.println("ALL TASKS COMPLETE");
    }
}

Redis version
6.0.6
Redisson version
3.13.3
Redisson configuration
Default configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3005
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Regarding #2932, when we confirmed the effect using 3.12.3, the phenomenon was not resolved.
After the failover is complete, access to the new master keeps failing.
Could you please provide the conditions and details of the bugs that have been corrected?
f220d92
I don't know if it is related to this case,
I'm currently using it in a non-cluster mode configuration where Redisson's addNodeAddress specifies the primary endpoint of the node group.
According to the issue below, you are asked to specify the endpoint of each node.
#2644　[Redisson Configuration For AWS ElastiCache]
Is it related to this phenomenon?
※ As a test, I fixed it so that the endpoint of each node was specified, and the phenomenon that it continued to fail after failover did not occur.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3006
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
one GET command results in one tcp request and done
Actual behavior
one GET command results in tens of tcp request
Steps to reproduce or test case
very hard to reproduce, don't know what caused this
Redis version
4.0
Redisson version
3.11.2
Redisson configuration
redisson-spring-boot-starter 3.11.2 default config
tcpdump below is from a container without error log now(used to have 2 days ago), the application execute scheduled task every 30 seconds so more easy to analyze
some code samples:
@scheduled(fixedDelay = 30000L)
public void refresh() {
long currentVersion = 0L;
try {
currentVersion = redissonClient.getAtomicLong(RedisConstant.DIALOG_CONFIG_VERSION).get();
} catch (Exception e) {
}
if (currentVersion > oldVersion) {
doBusiness();
}
}
in some application, this causes to much request and finally command timeout:
Caused by: org.redisson.client.RedisTimeoutException: Unable to send command! Try to increase 'nettyThreads' and/or connection pool size settings Node source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=value:50:queue:0, freeConnectionsAmount=23, freeConnectionsCounter=value:63:queue:0, freezed=false, freezeReason=null, client=[addr=redis://**********:6379], nodeType=MASTER, firstFail=0]]], connection: RedisConnection@461031069 [redisClient=[addr=redis://***:6379], channel=[id: 0xf6f78dd7, L:/172.18.7.150:41846 - R:/10.210.0.239:6379], currentCommand=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@15bd3b82(failure: java.util.concurrent.CancellationException)], command=(INFO DEFAULT), params=[], codec=org.redisson.client.codec.StringCodec]], command: (EVAL), params: [if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then return nil;end; local counter = redis.call('h..., 2, blacklist-write-81581, redisson_lock__channel:{blacklist-write-81581}, 0, 30000, a5d12374-6c70-4851-96f0-9278a25e428e:69] after 3 retry attempts
application-redis-tcpdump.log
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3007
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi!
I wan't to use redis scan operation via redisson (like in Jedis).
I'm checked next solution.
For example, i have 3 objects inside Redis and want to retrieve only 2
 val keysIterator = redissonClient.keys.getKeysByPattern("some-pattern", 2).iterator()
 while (keysIterator.hasNext()) {
        println(keysIterator.next())
}

But instead of retriving 2 objects, getKeysByPattern("some-pattern", 2) returns all keys from redis.
This behaviour is correct?
Anyway, i'am trying to use SCAN operator via Lua scripts.
val lua = "return {redis.call('SCAN',ARGV[1],'MATCH',ARGV[2],'COUNT',ARGV[3])}"
redissonClient
                .getScript(StringCodec.INSTANCE)
                .eval<List<List<String>>>(RScript.Mode.READ_ONLY,
                        lua,
                        RScript.ReturnType.MAPVALUELIST,
                        listOf(),
                        0,
                        "some-pattern",
                        2)

And this aproach is working one.
But why keys.getKeysByPattern(pattern, count) returns all keys instead of count?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3008
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
If we have configured the org.apache.catalina.authenticator.SingleSignOn valve in our application, does Redisson push the ssoId also to Redis? Do we have to make any other configuration changes other than what's mentioned in redisson-tomcat Readme for this to work?
Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3009
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi
We are using Redisson to connect to ElastiCache to get RBucket in the AWS lambda. The trigger of the AWS lambda is a SQS(with batch size 10). The logic for this lambda is to get the RBucket for each message from SQS.(Redisson.get(BUCKET_KEY))
When traffic is low, no exception happens(TPS is around 50), but when traffic becomes higher(Max TPS is around 900), the invocation and concerencent number for lambda function is getting higher, and then some RedisTimeoutExceptions are thrown by Redisson. Therefore, the backlog of the SQS is increasing.
Here is the detailed Exception log when executing Redisson.get():
2020-08-20 00:11:57 ##redisson-netty-1-3 ERROR ReplicatedConnectionManager:193 - Command execution timeout for default-replication-group.no4.ng.0001.euw1.cache.amazonaws.com/10.0.14.79:6379
org.redisson.client.RedisTimeoutException: Command execution timeout for default-replication-group.no2m94.ng.0001.euw1.cache.amazonaws.com/10.0.14.79:6379
	at org.redisson.client.RedisConnection$2.run(RedisConnection.java:193) [Redisson-3.x.jar:?]
	at io.netty.util.concurrent.PromiseTask.runTask(PromiseTask.java:98) [netty-all-4.1.jar:4.1.48.Final]
	at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:170) [netty-all-4.1.jar:4.1.48.Final]
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164) [netty-all-4.1.jar:4.1.48.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472) [netty-all-4.1.jar:4.1.48.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500) [netty-all-4.1.jar:4.1.48.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) [netty-all-4.1.jar:4.1.48.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [netty-all-4.1.jar:4.1.48.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-all-4.1.jar:4.1.48.Final]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_201]

Here is the current Redisson Config, the other
final Config config = new Config();
config.setCodec(new JsonJacksonCodec(new ObjectMapper()));
config.setNettyThreads(64);
config.useReplicatedServers()
    .setReadMode(ReadMode.SLAVE)
    .setTimeout(60000)
    .addNodeAddress(redisUrl);
return Redisson.create(config);

Here are some question I want to get cleared:


I'm wondering what the detailed root cause for org.redisson.client.RedisTimeoutException: Command execution timeout for . Is that means the Redisson configtimout is shorter than expected? But I think purely increasing the timeout seems cannot scale up the capacity to handle the high TPS.


To resolve this issue, how can I modify the Redisson Config to handle such a high traffic? I followed the Redisson FAQ to scale up the config, but not sure how to come up with a suitable config.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3010
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
An error occurred when setting the expiration time ：
java.lang.ClassCastException: com.model.test.JobRecordRedisEntity cannot be cast to org.redisson.api.RMap
JobRecordRedisEntity entity = new JobRecordRedisEntity();
entity.setFireInstanceId("q"+i);
entity.setJobId("111111");
entity.setFailcount(4);
entity.setCreatetime(3333333333333l);
entity.setScheduleFireTime("q");
entity.setNextFireTime("w");
entity.setExecutedTime("w"+i);
entity.setRunningResult("seccess");
entity.setMisfired("3");
entity.setRecordId("123456qaz");
        boolean exists = service.isExists(service.get(JobRecordRedisEntity.class, entity.getRecordId()));
        if (exists){
            service.merge(entity);
        }else {
            service.persist(entity);
        }

        **service.asRMap(entity).expire(3, TimeUnit.SECONDS);**
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3011
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello,
I see that there is the 'touch' operation on the RObject class but I don't see any method to retrieve the value for last access time.
Maybe is missing the command 'OBJECT IDLETIME'
If yes I can try to add that command.
Thanks.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3012
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
After successfully setting up Redisson as Tomcat session manager I get the following exception when trying to access the application:
java.io.NotSerializableException: de.schlund.pfixxml.serverutil.SessionAdmin
I also received another exception pointing to jboss-Marschalling also in regards to NotSerializableException.
As far as I understood the documentation, it would not be required to fix application code to move tomcat sessions to Redis via redisson. Am I wrong with my assumption?
Trying to solve this issue with different codecs did not work either.
Tomcat Version: 9.0.22
Redisson Version: all: 3.13.3, tomcat 9-3.10.6
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3013
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
Is it possible to find an example where a Redisson Map<String,SomeObject> is serialized to the Redis DB by a process P1. This Map is then accessed in another process  P2, also P2 should get notified about the updates made to this map by Process P1.
Any pointers to get started with this?
I see MapWriter example on Wiki. Does that example assume Oracle DB beneath?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3014
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi There,
I am using Redis library in my application.
Now I am planning to use RLiveObjectService  for search page (instead of DB will read from Redis Cache).
I do see that there are methods available  in RLiveObjectService for find , get , detele and instert to update Cache
I am looking for method like mergeAll or persistAll using which I can initialize cache during application startup.
Is there any way to achieve this.?
Thanks in Advance.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3015
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi guys,
I stumble upon a weird issue for my project. I am trying to delete RMap key by a pattern. I follow the documentation and it seems I could do that by getting the keyset and passing the pattern, and delete the found keys via the fastRemove method.
However It does not work for me.
I am using redisson library version 3.12.3 for Java, and the cache is deployed through elastic cache AWS.
The setup is like the following:
the RMap name is jsonCollectionV3 and the item key inside the map I tried to delete is  100011176limit5offset2 the pattern I am using is 100011176*
Please find below the code I am trying to use to fetch the key pattern from the map and using the fastRemove to delete the key retrieved.

However as per log below and entry in Redis desktop manager, the key is not removed from the map, the size still one.


If you guys can help me point out where did I do wrong, that will be great! thanks a lot. I have tried changing the key format for storing the records and it is not working as well.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3016
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
In one of my java application we are connected with Redis Server running on low compute machine (2 GB Ram, 1 Core) just for shared memory purpose.
Configuration of Redisson is as below
Config config = new Config();
config.useSingleServer().setPingConnectionInterval(0).setKeepAlive(true).setDnsMonitoringInterval(-1);
config.setNettyThreads(0);
redisson = Redisson.create(config);
At Redis server side, we also changed tcp-keepalive and timeout as 0 value.
But i am not getting any exception and application is closing after 1 hour. I just only received the update in shutdownhook and thread dump is as below.
"Reference Handler"
java.lang.Thread.State: RUNNABLE
at java.base@11.0.8/java.lang.ref.Reference.waitForReferencePendingList(Native Method)
at java.base@11.0.8/java.lang.ref.Reference.processPendingReferences(Reference.java:241)
at java.base@11.0.8/java.lang.ref.Reference$ReferenceHandler.run(Reference.java:213)
"Finalizer"
java.lang.Thread.State: WAITING
at java.base@11.0.8/java.lang.Object.wait(Native Method)
at java.base@11.0.8/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:155)
at java.base@11.0.8/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:176)
at java.base@11.0.8/java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:170)
"Signal Dispatcher"
java.lang.Thread.State: RUNNABLE
"Common-Cleaner"
java.lang.Thread.State: TIMED_WAITING
at java.base@11.0.8/java.lang.Object.wait(Native Method)
at java.base@11.0.8/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:155)
at java.base@11.0.8/jdk.internal.ref.CleanerImpl.run(CleanerImpl.java:148)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
at java.base@11.0.8/jdk.internal.misc.InnocuousThread.run(InnocuousThread.java:134)
"pool-3-thread-1"
java.lang.Thread.State: TIMED_WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:234)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2123)
at java.base@11.0.8/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
at java.base@11.0.8/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"MQTT Rec: device_155"
java.lang.Thread.State: RUNNABLE
at java.base@11.0.8/java.net.SocketInputStream.socketRead0(Native Method)
at java.base@11.0.8/java.net.SocketInputStream.socketRead(SocketInputStream.java:115)
at java.base@11.0.8/java.net.SocketInputStream.read(SocketInputStream.java:168)
at java.base@11.0.8/java.net.SocketInputStream.read(SocketInputStream.java:140)
at java.base@11.0.8/sun.security.ssl.SSLSocketInputRecord.read(SSLSocketInputRecord.java:467)
at java.base@11.0.8/sun.security.ssl.SSLSocketInputRecord.readHeader(SSLSocketInputRecord.java:461)
at java.base@11.0.8/sun.security.ssl.SSLSocketInputRecord.bytesInCompletePacket(SSLSocketInputRecord.java:70)
at java.base@11.0.8/sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1349)
at java.base@11.0.8/sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:958)
at java.base@11.0.8/sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:865)
at java.base@11.0.8/java.io.DataInputStream.readByte(DataInputStream.java:270)
at app//org.eclipse.paho.client.mqttv3.internal.wire.MqttInputStream.readMqttWireMessage(MqttInputStream.java:92)
at app//org.eclipse.paho.client.mqttv3.internal.CommsReceiver.run(CommsReceiver.java:136)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"MQTT Snd: device_155"
java.lang.Thread.State: WAITING
at java.base@11.0.8/java.lang.Object.wait(Native Method)
at java.base@11.0.8/java.lang.Object.wait(Object.java:328)
at app//org.eclipse.paho.client.mqttv3.internal.ClientState.get(ClientState.java:825)
at app//org.eclipse.paho.client.mqttv3.internal.CommsSender.run(CommsSender.java:128)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"MQTT Call: device_155"
java.lang.Thread.State: WAITING
at java.base@11.0.8/java.lang.Object.wait(Native Method)
at java.base@11.0.8/java.lang.Object.wait(Object.java:328)
at app//org.eclipse.paho.client.mqttv3.internal.CommsCallback.run(CommsCallback.java:180)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"MQTT Ping: device_155"
java.lang.Thread.State: TIMED_WAITING
at java.base@11.0.8/java.lang.Object.wait(Native Method)
at java.base@11.0.8/java.util.TimerThread.mainLoop(Timer.java:553)
at java.base@11.0.8/java.util.TimerThread.run(Timer.java:506)
"redisson-netty-2-1"
java.lang.Thread.State: RUNNABLE
at java.base@11.0.8/sun.nio.ch.EPoll.wait(Native Method)
at java.base@11.0.8/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:120)
at java.base@11.0.8/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:124)
at java.base@11.0.8/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:136)
at app//io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at app//io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:807)
at app//io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at app//io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
at app//io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at app//io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"redisson-netty-2-2"
java.lang.Thread.State: RUNNABLE
at java.base@11.0.8/sun.nio.ch.EPoll.wait(Native Method)
at java.base@11.0.8/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:120)
at java.base@11.0.8/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:124)
at java.base@11.0.8/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
at app//io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
at app//io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
at app//io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at app//io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
at app//io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at app//io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"redisson-timer-4-1"
java.lang.Thread.State: TIMED_WAITING
at java.base@11.0.8/java.lang.Thread.sleep(Native Method)
at app//io.netty.util.HashedWheelTimer$Worker.waitForNextTick(HashedWheelTimer.java:569)
at app//io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:465)
at app//io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"redisson-3-1"
java.lang.Thread.State: WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)
at java.base@11.0.8/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:433)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at app//io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"queueMessageReceive#0"
java.lang.Thread.State: WAITING
at java.base@11.0.8/java.lang.Object.wait(Native Method)
at java.base@11.0.8/java.lang.Object.wait(Object.java:328)
at app//io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:252)
at app//org.redisson.misc.RedissonPromise.await(RedissonPromise.java:110)
at app//org.redisson.misc.RedissonPromise.await(RedissonPromise.java:35)
at app//org.redisson.command.CommandAsyncService.getInterrupted(CommandAsyncService.java:156)
at app//org.redisson.RedissonBlockingQueue.take(RedissonBlockingQueue.java:81)
at app//com.iotplatform.client.redis.QueueHandler.run(QueueHandler.java:32)
at java.base@11.0.8/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
at java.base@11.0.8/java.util.concurrent.FutureTask.run(FutureTask.java:264)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"DestroyJavaVM"
java.lang.Thread.State: RUNNABLE
"pool-4-thread-1"
java.lang.Thread.State: WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)
at java.base@11.0.8/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1170)
at java.base@11.0.8/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"redisson-3-2"
java.lang.Thread.State: WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)
at java.base@11.0.8/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:433)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at app//io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"pool-5-thread-1"
java.lang.Thread.State: WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)
at java.base@11.0.8/java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:417)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"redisson-3-3"
java.lang.Thread.State: WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)
at java.base@11.0.8/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:433)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at app//io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"pool-5-thread-2"
java.lang.Thread.State: WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)
at java.base@11.0.8/java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:417)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"redisson-3-4"
java.lang.Thread.State: WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)
at java.base@11.0.8/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:433)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at app//io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"pool-7-thread-1"
java.lang.Thread.State: TIMED_WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:234)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2123)
at java.base@11.0.8/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
at java.base@11.0.8/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"redisson-3-5"
java.lang.Thread.State: WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)
at java.base@11.0.8/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:433)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at app//io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"pool-4-thread-2"
java.lang.Thread.State: WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)
at java.base@11.0.8/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1170)
at java.base@11.0.8/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"redisson-3-6"
java.lang.Thread.State: WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)
at java.base@11.0.8/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:433)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at app//io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"pool-5-thread-3"
java.lang.Thread.State: WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)
at java.base@11.0.8/java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:417)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"redisson-3-7"
java.lang.Thread.State: WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)
at java.base@11.0.8/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:433)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at app//io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"pool-5-thread-4"
java.lang.Thread.State: WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)
at java.base@11.0.8/java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:417)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"redisson-3-8"
java.lang.Thread.State: WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)
at java.base@11.0.8/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:433)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at app//io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"redisson-3-9"
java.lang.Thread.State: WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)
at java.base@11.0.8/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:433)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at app//io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"redisson-3-10"
java.lang.Thread.State: WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)
at java.base@11.0.8/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:433)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at app//io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"redisson-3-11"
java.lang.Thread.State: WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)
at java.base@11.0.8/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:433)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at app//io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"redisson-3-12"
java.lang.Thread.State: WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)
at java.base@11.0.8/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:433)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at app//io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"redisson-3-13"
java.lang.Thread.State: WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)
at java.base@11.0.8/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:433)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at app//io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"redisson-3-14"
java.lang.Thread.State: WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)
at java.base@11.0.8/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:433)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at app//io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"redisson-3-15"
java.lang.Thread.State: WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)
at java.base@11.0.8/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:433)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at app//io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"redisson-3-16"
java.lang.Thread.State: WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)
at java.base@11.0.8/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:433)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at app//io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"Attach Listener"
java.lang.Thread.State: RUNNABLE
"RMI TCP Accept-0"
java.lang.Thread.State: RUNNABLE
at java.base@11.0.8/java.net.PlainSocketImpl.socketAccept(Native Method)
at java.base@11.0.8/java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:458)
at java.base@11.0.8/java.net.ServerSocket.implAccept(ServerSocket.java:565)
at java.base@11.0.8/java.net.ServerSocket.accept(ServerSocket.java:533)
at jdk.management.agent@11.0.8/sun.management.jmxremote.LocalRMIServerSocketFactory$1.accept(LocalRMIServerSocketFactory.java:52)
at java.rmi@11.0.8/sun.rmi.transport.tcp.TCPTransport$AcceptLoop.executeAcceptLoop(TCPTransport.java:394)
at java.rmi@11.0.8/sun.rmi.transport.tcp.TCPTransport$AcceptLoop.run(TCPTransport.java:366)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"RMI Scheduler(0)"
java.lang.Thread.State: WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
at java.base@11.0.8/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)
at java.base@11.0.8/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1170)
at java.base@11.0.8/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"process reaper"
java.lang.Thread.State: TIMED_WAITING
at java.base@11.0.8/jdk.internal.misc.Unsafe.park(Native Method)
at java.base@11.0.8/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:234)
at java.base@11.0.8/java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:462)
at java.base@11.0.8/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:361)
at java.base@11.0.8/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:937)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1053)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114)
at java.base@11.0.8/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"SIGHUP handler"
java.lang.Thread.State: WAITING
at java.base@11.0.8/java.lang.Object.wait(Native Method)
at java.base@11.0.8/java.lang.Thread.join(Thread.java:1305)
at java.base@11.0.8/java.lang.Thread.join(Thread.java:1380)
at java.base@11.0.8/java.lang.ApplicationShutdownHooks.runHooks(ApplicationShutdownHooks.java:107)
at java.base@11.0.8/java.lang.ApplicationShutdownHooks$1.run(ApplicationShutdownHooks.java:46)
at java.base@11.0.8/java.lang.Shutdown.runHooks(Shutdown.java:130)
at java.base@11.0.8/java.lang.Shutdown.exit(Shutdown.java:174)
at java.base@11.0.8/java.lang.Terminator$1.handle(Terminator.java:51)
at java.base@11.0.8/jdk.internal.misc.Signal$1.run(Signal.java:220)
at java.base@11.0.8/java.lang.Thread.run(Thread.java:834)
"Thread-11"
java.lang.Thread.State: RUNNABLE
at java.management@11.0.8/sun.management.ThreadImpl.getThreadInfo1(Native Method)
at java.management@11.0.8/sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:190)
at app//com.nec.client.OnStartup.generateThreadDump(OnStartup.java:154)
at app//com.nec.client.OnStartup$1.run(OnStartup.java:133)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3017
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I'm trying to setup redisson for tomcat 8, and i'm getting this exception at the start:
org.codehaus.groovy.runtime.typehandling.GroovyCastException: Cannot cast object 'UNKNOWN-UNKNOWN' with class 'eu.bitwalker.useragentutils.UserAgent' to class 'eu.bitwalker.useragentutils.UserAgent'
I think it may be related to incorrect dependencies? In order to get the tomcat to start withouth errors, i had to manually add some libraries to the tomcat instance because redisson was failing with multiple exceptions related to classNotFound, these are the dependecies i had to add:

fst-2.57.jar
objenesis-3.1.jar
UserAgentUtils-1.21.jar

This is the redisson.conf i'm using
{ "singleServerConfig": { "idleConnectionTimeout": 10000, "connectTimeout": 10000, "timeout": 3000, "retryAttempts": 3, "retryInterval": 1500, "password": null, "subscriptionsPerConnection": 5, "clientName": null, "address": "redis://xxxxx.0001.use1.cache.amazonaws.com:6379", "subscriptionConnectionMinimumIdleSize": 1, "subscriptionConnectionPoolSize": 50, "connectionMinimumIdleSize": 24, "connectionPoolSize": 64, "database": 0, "dnsMonitoringInterval": 5000 }, "threads": 16, "nettyThreads": 32, "codec": null, "transportMode": "NIO" }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3018
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have a question about lock acquisition.
assume two services A and B acquire locks to access shared resources.

A has acquired the lock.
When B tries to acquire the lock. it will find the lock is held by other service(A).
So B will subscribe to the channel, for acquiring the lock.
before B subscribe to the channel,A release the lock and publish some messages.
What happens next?
B is waiting for the messages that is published by the lock holder(A), but A has published the messages and released the lock.
How did you solve it?

I'm sorry I didn't understand the source code,Thank you very much for your work.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3019
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Faced a problem while using redisson client after random period of time. the generated stack trace is:
org.redisson.client.RedisConnectionException: SlaveConnectionPool no available Redis entries. Master entry host: /10.183.127.25:6379 Disconnected hosts: [k-dtce-rb-prd42/10.183.127. 25:6379] at org.redisson.connection.pool.ConnectionPool.get(ConnectionPool.java:218) at org.redisson.connection.pool.SlaveConnectionPool.get(SlaveConnectionPool.java:30) at org.redisson.connection.balancer.LoadBalancerManager.nextConnection(LoadBalancerManager.java:254) at org.redisson.connection.MasterSlaveEntry.connectionReadOp(MasterSlaveEntry.java:499) at org.redisson.connection.MasterSlaveConnectionManager.connectionReadOp(MasterSlaveConnectionManager.java:641) at org.redisson.command.RedisExecutor.getConnection(RedisExecutor.java:640) at org.redisson.command.RedisExecutor.execute(RedisExecutor.java:115) at org.redisson.command.RedisExecutor$2.run(RedisExecutor.java:243) at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:672) at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:747) at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:472) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.lang.Thread.run(Thread.java:748) $$$
the problem that the client does not recover until the application is restarted while another instances using that client is working normally.
Config:
redis.bulk_size=10000
redis.timeout=3000
redis.connection.timeout=10000
redis.idle.connection.timeout=10000
redis.retry.attempts=3
redis.retry.interval=1500
redis.batch.retry.attempts=3
redis.batch.retry.interval=1500
redis.batch.response.timeout=3000
redis.lock.wait.time.milliseconds=1000
redis.lock.lease.time.milliseconds=1000
redis.netty.threads=32
Redis Cluster Configs
redis.cluster.master.pool.size=64
redis.cluster.slave.pool.size=64
redis.cluster.master.minimum.idle.size=24
redis.cluster.slave.minimum.idle.size=24
redis.ping.connection.interval=2000
redis.keep.alive=true
redis.tcp.no.delay=true
CLient: redisson 3.13.2
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3020
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
As far as I know, when I put a value to the queue,it will check the size of queue,the value is maintained at the key named redisson_bqs:... ,if the redisson_bqs's value <=0,it won't put any more.
This is the command for method poll():
org.redisson.RedissonBoundedBlockingQueue#pollAsync()
local res = redis.call('lpop', KEYS[1]);if res ~= false then local value = redis.call('incrby', KEYS[2], ARGV[1]); redis.call('publish', KEYS[3], value); end;return res;
If it gets the value,  it will increment the value of redisson_bqs by 1.
The following is the command for method poll(int limit)
org.redisson.RedissonQueue#pollAsync(int)
local result = {};for i = 1, ARGV[1], 1 do local value = redis.call('lpop', KEYS[1]);if value ~= false then table.insert(result, value);else return result;end;end; return result;
It doesn't increment the value of redisson_bqs. When The number of times I put reaches the initial capacity, it won't put any more.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3021
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
调用代码：
List resultList = redisTemplate.executePipelined((RedisCallback)connection -> {
for (Long id: idList) {
connection.get(key.getBytes());
}
return null;
}, redisTemplate.getValueSerializer());
Expected behavior
Actual behavior
Caused by: java.lang.UnsupportedOperationException
at java.util.AbstractList.remove(AbstractList.java:161)
at org.redisson.spring.data.connection.RedissonConnection.filterResults(RedissonConnection.java:1534)
at org.redisson.spring.data.connection.RedissonConnection.closePipeline(RedissonConnection.java:162)
Steps to reproduce or test case
Redis version
5.0
Redisson version
3.13.1
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3022
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Regarding the execution of "API: org.redisson.api.RBucket#set(V value, long timeToLive, TimeUnit timeUnit)", is there a way to call multiple using a netty thread?
I tried the following, but it did not run in multi.
Map<K, V> values = new new HashMap<K, V>();
for (Entry<K, V> entry : values.entrySet()) {
    bucket.set(ObjectMapper.writeValueAsString(entry.getValue()), 10, TimeUnit.SECONDS);
}
redisson.json
{
  "clusterServersConfig": {
    "subscriptionConnectionMinimumIdleSize": 1,
    "subscriptionConnectionPoolSize": 150,
    "slaveConnectionMinimumIdleSize": 1,
    "slaveConnectionPoolSize": 150,
    "masterConnectionMinimumIdleSize": 1,
    "masterConnectionPoolSize": 150,
    "readMode": "MASTER_SLAVE",
    "nodeAddresses": [
      "redis://[redis endpoint]:6379"
    ],
    "scanInterval": 600000,
    "retryAttempts": 5,
    "retryInterval": 15000
  }
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3023
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@mrniko

RBucket.set() method is fully thread-safe, but I wouldn't recommend to use blocking operations in netty threads

Doesn't it mean that the blocking operation (such as "RBucket.set()") cannot be thread-managed (multithreaded) only by the logic in redisson without using another library (such as "Spring's ThreadPoolTaskExecutor")?
Originally posted by @mrniko in #3022 (comment)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3024
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@mrniko

RBucket.set() method is fully thread-safe, but I wouldn't recommend to use blocking operations in netty threads

Doesn't it mean that the blocking operation (such as "RBucket.set()") cannot be thread-managed (multithreaded(parallelization)) only by the logic in redisson without using another library (such as "Spring's ThreadPoolTaskExecutor")?
Originally posted by @mrniko in #3022 (comment)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3025
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
My Code
private RRateLimiter rt;

@PostConstruct
 public void init(){
     rt = redissonClient.getRateLimiter("rt2");
     rt.trySetRate(RateType.OVERALL, 100, 5, RateIntervalUnit.SECONDS);
 }

@GetMapping("")
    public void test(){

        System.out.println(rt.availablePermits());

        rt.acquire(1);

        System.out.println(rt.availablePermits());
    }

Expected behavior
Actual behavior
first call test() function， works fine， but after 5 SECONDS（after one period）， will throw exception
org.redisson.client.RedisException: ERR Error running script (call to f_a953e1748e38137c3168a683556aa561bd05b340): @user_script:1: user_script:1: bad argument #2 to 'unpack' (data string too short) . channel: [id: 0x36f2cda8, L:/10.2.47.198:60323 - R:fenbi-notify-push-redis-dev.redis.rds.aliyuncs.com/10.13.160.82:6379] command: (EVAL), params: [local rate = redis.call('hget', KEYS[1], 'rate');local interval = redis.call('hget', KEYS[1], 'inter..., 5, rt2, {rt2}:value, {rt2}:value:f45a9de8-95b9-47f1-aef2-759c37d9f60a, {rt2}:permits, {rt2}:permits:f45a9de8-95b9-47f1-aef2-759c37d9f60a, 1599018405084]
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:365) ~[redisson-3.13.3.jar:3.13.3]
	at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:196) ~[redisson-3.13.3.jar:3.13.3]
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:134) ~[redisson-3.13.3.jar:3.13.3]
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:104) ~[redisson-3.13.3.jar:3.13.3]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:501) ~[netty-codec-4.1.51.Final.jar:4.1.51.Final]
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) ~[netty-codec-4.1.51.Final.jar:4.1.51.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276) ~[netty-codec-4.1.51.Final.jar:4.1.51.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.51.Final.jar:4.1.51.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.51.Final.jar:4.1.51.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[netty-transport-4.1.51.Final.jar:4.1.51.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[netty-transport-4.1.51.Final.jar:4.1.51.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.51.Final.jar:4.1.51.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.51.Final.jar:4.1.51.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[netty-transport-4.1.51.Final.jar:4.1.51.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) ~[netty-transport-4.1.51.Final.jar:4.1.51.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714) ~[netty-transport-4.1.51.Final.jar:4.1.51.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650) ~[netty-transport-4.1.51.Final.jar:4.1.51.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576) ~[netty-transport-4.1.51.Final.jar:4.1.51.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[netty-transport-4.1.51.Final.jar:4.1.51.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[netty-common-4.1.51.Final.jar:4.1.51.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.51.Final.jar:4.1.51.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.51.Final.jar:4.1.51.Final]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_202]

Steps to reproduce or test case
Redis version
Redisson version
     <dependency>
        <groupId>org.redisson</groupId>
        <artifactId>redisson-spring-data-18</artifactId>
        <version>3.13.3</version>
    </dependency>
    <dependency>
        <groupId>org.redisson</groupId>
        <artifactId>redisson-spring-boot-starter</artifactId>
        <version>3.13.3</version>
    </dependency>

Only 3.13.3 have this problem
There is no problem on 3.13.2
Redisson configuration
config.setCodec(JsonJacksonCodec.INSTANCE);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3026
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The amount of data is very large, I want to put it in a parent folder，help me
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3027
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
After the network between redisson and redis server recoveried from disconnection, Redisson is able to open a healthy connection pool to each of the nodes
Actual behavior
Connection never recover until we restart the service. This situation  Occasionally happens.
Redisson version
3.11.4
Redisson spring-data version
3.13.1
Config
Config config = new Config();
config.setCodec(new org.redisson.client.codec.ByteArrayCodec());
config.useSingleServer().setAddress("redis://xxxx");
config.useSingleServer().setConnectionPoolSize(500);
config.useSingleServer().setRetryAttempts(5);
config.useSingleServer().setPingConnectionInterval(10000);
config.useSingleServer().setKeepAlive(true);
config.setNettyThreads(512);

Error Log
We only log the exception message like this
2020-09-01 00:56:22 [ERROR] [RedissonTool] Unable to get connection! Try to increase 'nettyThreads' and/or connection pool size settingsNode source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=value:50:queue:0, freeConnectionsAmount=0, freeConnectionsCounter=value:0:queue:106, freezed=false, freezeReason=null, client=[addr=redis://xxxxxx], nodeType=MASTER, firstFail=0]]], command: (SET), params: [[50, 57, 50, ...], [31, -117, 8, 0, 0, 0, 0, 0, 0, 0, ...]] after 0 retry attempts; nested exception is org.redisson.client.RedisTimeoutException: Unable to get connection! Try to increase 'nettyThreads' and/or connection pool size settingsNode source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=value:50:queue:0, freeConnectionsAmount=0, freeConnectionsCounter=value:0:queue:106, freezed=false, freezeReason=null, client=[addr=redis://xxxxxx], nodeType=MASTER, firstFail=0]]], command: (SET), params: [[50, 57, 50, 51, 49, 48, 51, 52, 53, 50, ...], [31, -117, 8, 0, 0, 0, 0, 0, 0, 0, ...]] after 0 retry attempts


2020-09-01 00:56:06 [ERROR] [RedissonTool][get]redisson happened error!Unable to get connection! Try to increase 'nettyThreads' and/or connection pool size settingsNode source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=value:50:queue:0, freeConnectionsAmount=23, freeConnectionsCounter=value:1100:queue:0, freezed=false, freezeReason=null, client=[addr=redis://xxxxxx], nodeType=MASTER, firstFail=0]]], command: (GET), params: [[50, 53, 48, 53, 57, 55, 52, 50, 53, 49, ...]] after 5 retry attempts; nested exception is org.redisson.client.RedisTimeoutException: Unable to get connection! Try to increase 'nettyThreads' and/or connection pool size settingsNode source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=value:50:queue:0, freeConnectionsAmount=23, freeConnectionsCounter=value:1100:queue:0, freezed=false, freezeReason=null, client=[addr=redis://xxxxxx], nodeType=MASTER, firstFail=0]]], command: (GET), params: [[50, 53, 48, 53, 57, 55, 52, 50, 53, 49, ...]] after 5 retry attempts


I am curious about some question:

why some log shows "after 0retry attempts"? Does the retryAttempt not work?
What's the meaning of the freeConnectionsCounter and freeConnectionsAmount in the log? The value of  freeConnectionsCounter in the log is 1100 and even bigger than the connectionPoolSize, is that ok?
why the connection never recover?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3028
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
version: 3.11.6


config:


	<Manager className="org.redisson.tomcat.RedissonSessionManager" configPath="${catalina.base}/src/test/webapp/WEB-INF/redisson.yaml" readMode="REDIS" updateMode="DEFAULT" broadcastSessionEvents="true"/>

question:

we have two server: A, B


when session.setAttribute(key, value); on A server


session.invalidate(); on B server.


session.setAttribute(key, value); on A server,


now session.getAttribute(key); on B server will return null


why this happened?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3029
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Exception in thread "redisson-3-22" java.lang.ClassCastException: java.lang.String cannot be cast to [B
at org.redisson.spring.data.connection.RedissonSubscription$2.onPatternMessage(RedissonSubscription.java:85)
at org.redisson.client.RedisPubSubConnection.onMessage(RedisPubSubConnection.java:84)
at org.redisson.client.handler.CommandPubSubDecoder.lambda$enqueueMessage$0(CommandPubSubDecoder.java:181)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3030
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
There is no configuration for sentinel password, you are using the same password flag to be used for sentinel and redis, and by that way I am obliged to set the same password for redis and sentinel, so can't we have a different yml property special for sentinel password?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3031
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RBloomFilter<String> bloomFilter = DrpRedissonClusterPool.get().getBloomFilter("getBloomFilter", new FstCodec());
    bloomFilter.delete();
    bloomFilter.tryInit(40000, 0.01);
    System.out.println(bloomFilter.getSize() / 8 / 1024 / 1024);
    System.out.println(bloomFilter.count());
    bloomFilter.add("111");
    bloomFilter.add("111");
    bloomFilter.add("111");
    System.out.println(bloomFilter.getSize());
    System.out.println(bloomFilter.count());
    System.out.println(bloomFilter);
    System.out.println(bloomFilter.contains("111"));


run bloomFilter.contains("111")
Exception in thread "main" org.redisson.client.RedisMovedException
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:339)
at org.redisson.client.handler.CommandDecoder.decodeCommandBatch(CommandDecoder.java:266)
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:207)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:134)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:104)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:501)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:745)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3032
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3033
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3034
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3035
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3036
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3037
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3038
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3039
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3040
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3041
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3042
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3043
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3044
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3045
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3046
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3047
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3048
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3049
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3050
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3051
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3052
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3053
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3054
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3055
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3056
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3057
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3058
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3059
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3060
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3061
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3062
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3063
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3064
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3065
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3066
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3067
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3068
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3069
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3070
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3071
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3072
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3073
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3074
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3075
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3076
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3077
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3078
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3079
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3080
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3081
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3082
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3083
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3084
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3085
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3086
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3087
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3088
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3089
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3090
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3091
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3092
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3093
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3094
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3095
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3096
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3097
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3098
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3099
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3100
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3101
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3102
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3103
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3104
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3105
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3106
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3107
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3108
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3109
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3110
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3111
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3112
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3113
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3114
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3115
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3116
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3117
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3118
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3119
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3120
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3121
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3122
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3123
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3124
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3125
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3126
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3127
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3128
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3129
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3130
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3131
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3132
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3133
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3134
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3135
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3136
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3137
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3138
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3139
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3140
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3141
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3142
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3143
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
使用最新版的redisson，看了一下autoconfig。。。一言难尽啊
比如我在使用druid连接池的时候，为了防止忘记设置某一个值，可以使用EnvironmentPostProcessor来初始化一份配置文件，然后由项目组来根据实际场景修改某一个值。
但是这里的配置是通过yaml文件字符串进行读取，和使用环境变量做替换，这。。。感觉有点别扭了
有计划在哪个版本来升级一下autoconfig吗？
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3144
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
阿里云集群版redis限制了使用EVAL命令，以前也测试过确实会报错，但我现在不知道怎么重现那个错误了，想确认下是不是现在redisson底层处理了什么，让它能用阿里云的集群版redis了
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3145
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Since timeseries is a sorted collection I'd expect iterator() to respect the ordering. There's a range method which in fact returns the values in order, however it returns Mono<Collection> instead of Flux which means entire set is loaded into the memory, while I'd like to read it reactively in chunks.
Actual behavior
redisson.getTimeSeries("").iterator().next().block() != redisson.first.block()
Steps to reproduce or test case

add multiple elements into the timeseries collection
open a redis desktop manager or use the cli to check the elements are indeed ordered by score
call iterator() method and check the ordering

I've checked also the non-reactive version and seems to work in the same way.
Redis version
5.0.8
Redisson version
3.13.4
Redisson configuration
singleServerConfig:
address: "redis://127.0.0.1:6379"
database: 2
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3146
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is your feature request related to a problem? Please describe.
I'd like to have a possibility to set eviction for a given element while inserting into the collection that keeps the insertion order.
Describe the solution you'd like
Similar to the MapCache and SetCache I think there's a need for a ListCache as neither of the previous ones keep the ordering.
Describe alternatives you've considered
SetCache but it lacks ordering.
TimeSeries but as per issue 3145 the iterator() method does not return the values according to the score.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3147
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello, I'm getting null pointer exception when try to destroy RMapCache in EvictionScheduler line 74 (remove(String name)). Error occuring on tasks object.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3148
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3149
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
利用Redisson按天做限流，历史生成的限流key不会自动清除，这个如何处理，可以设置缓存过期时间吗？
// rate limit 100 times per day
String date = DateFormatUtils.format(new Date(), BaseConstants.DATE_FORMAT_LEAN);
RRateLimiter timesPerDayRateLimiter = redissonClient.getRateLimiter(String.format(RedisConstants.TOKEN_REFRESH_TIMES_PER_DAY_RATE_LIMIT, date, userId));
timesPerDayRateLimiter.trySetRate(RateType.OVERALL, tokenProperties.getTokenRefreshTimesPerDayRateLimit(), 1, RateIntervalUnit.DAYS);

该历史缓存会清除
{token:refresh:20201021:68155c4000eb4d79a3f9516bfc51f9c5}:value
该历史缓存未清除
token:refresh:20201021:68155c4000eb4d79a3f9516bfc51f9c5
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3150
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
在低并发时无此现象  当并发达到一定量级后出现如下错误(版本3.0.1)：
org.redisson.client.RedisException: Unexpected exception while processing command
at org.redisson.command.CommandAsyncService.convertException(CommandAsyncService.java:307) ~[redisson-3.0.1.jar:?]
at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:150) ~[redisson-3.0.1.jar:?]
at org.redisson.command.CommandSyncService.evalWrite(CommandSyncService.java:83) ~[redisson-3.0.1.jar:?]
at org.redisson.RedissonLock.unlock(RedissonLock.java:354) ~[redisson-3.0.1.jar:?]
at com.oppo.ocloud.file.common.tool.lock.RedissonLock.unlock(RedissonLock.java:76) ~[ocloud-file-common-tool-1.0.5-SNAPSHOT.jar:?]
at com.oppo.ocloud.file.common.service.ReplaceFileIdService.doReplace(ReplaceFileIdService.java:165) ~[ocloud-file-common-job-1.0-SNAPSHOT.jar:?]
at com.oppo.ocloud.file.common.service.ReplaceFileIdService.lambda$processReplaceFileIdJob$1(ReplaceFileIdService.java:109) ~[ocloud-file-common-job-1.0-SNAPSHOT.jar:?]
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
at java.lang.Thread.run(Thread.java:834) [?:?]
Caused by: org.redisson.RedissonShutdownException: Redisson is shutdown
at org.redisson.command.CommandAsyncService.async(CommandAsyncService.java:463) ~[redisson-3.0.1.jar:?]
at org.redisson.command.CommandAsyncService.evalAsync(CommandAsyncService.java:439) ~[redisson-3.0.1.jar:?]
at org.redisson.command.CommandAsyncService.evalWriteAsync(CommandAsyncService.java:381) ~[redisson-3.0.1.jar:?]
at org.redisson.command.CommandSyncService.evalWrite(CommandSyncService.java:82) ~[redisson-3.0.1.jar:?]
... 9 more
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3151
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version 6.0.5
Redisson version 3.13.1
Redisson configuration
singleServerConfig:
password:
连接空闲超时，单位：毫秒
idleConnectionTimeout: 10000
连接超时，单位：毫秒
connectTimeout: 10000
命令等待超时，单位：毫秒
timeout: 3000
命令失败重试次数,如果尝试达到 retryAttempts（命令失败重试次数） 仍然不能将命令发送至某个指定的节点时，将抛出错误。
如果尝试在此限制之内发送成功，则开始启用 timeout（命令等待超时） 计时。
retryAttempts: 3
命令重试发送时间间隔，单位：毫秒
retryInterval: 1500
单个连接最大订阅数量
subscriptionsPerConnection: 5
客户端名称
clientName: null
发布和订阅连接的最小空闲连接数
subscriptionConnectionMinimumIdleSize: 1
发布和订阅连接池大小
subscriptionConnectionPoolSize: 50
最小空闲连接数
connectionMinimumIdleSize: 32
连接池大小
connectionPoolSize: 64
sentinelAddresses:

"redis://192.168.101.153:26379"
"redis://192.168.101.153:26380"
"redis://192.168.101.128:26379"
masterName: "mymaster",

数据库编号
database: 0
DNS监测时间间隔，单位：毫秒
dnsMonitoringInterval: 5000
线程池数量,默认值: 当前处理核数量 * 2
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3152
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
there are three sentinel node, and one master node and on slave node.
redis and sentinel config file in attachment file.
redisson version:3.12.2
Redis server v=4.0.10
config.zip
error/info log as below:
2020-10-22-T18:07:36.018+0800 | lrc3vm16 | | redisson-netty-2-10 | INFO  | org.redisson.connection.SingleEntry | master 172.18.81.17/172.18.81.17:6379 has changed to 172.18.81.16/172.18.81.16:6379
2020-10-22-T18:07:38.018+0800 | lrc3vm16 | | redisson-netty-2-10 | INFO  | org.redisson.connection.SingleEntry | master 172.18.81.16/172.18.81.16:6379 has changed to 172.18.81.17/172.18.81.17:6379
2020-10-22-T18:07:40.026+0800 | lrc3vm16 | | redisson-netty-2-7 | INFO  | org.redisson.connection.SingleEntry | master 172.18.81.17/172.18.81.17:6379 has changed to 172.18.81.16/172.18.81.16:6379
2020-10-22-T18:07:41.035+0800 | lrc3vm16 | | redisson-netty-2-12 | INFO  | org.redisson.connection.SingleEntry | master 172.18.81.16/172.18.81.16:6379 has changed to 172.18.81.17/172.18.81.17:6379
2020-10-22-T18:07:42.037+0800 | lrc3vm16 | | redisson-netty-2-8 | INFO  | org.redisson.connection.SingleEntry | master 172.18.81.17/172.18.81.17:6379 has changed to 172.18.81.16/172.18.81.16:6379
2020-10-22-T18:07:43.135+0800 | lrc3vm16 | | redisson-netty-2-10 | INFO  | org.redisson.connection.SingleEntry | master 172.18.81.16/172.18.81.16:6379 has changed to 172.18.81.17/172.18.81.17:6379
2020-10-22-T18:07:44.052+0800 | lrc3vm16 | | redisson-netty-2-4 | INFO  | org.redisson.connection.SingleEntry | master 172.18.81.17/172.18.81.17:6379 has changed to 172.18.81.16/172.18.81.16:6379
2020-10-22-T18:07:46.066+0800 | lrc3vm16 | | redisson-netty-2-4 | INFO  | org.redisson.connection.SingleEntry | master 172.18.81.16/172.18.81.16:6379 has changed to 172.18.81.17/172.18.81.17:6379
2020-10-22-T18:07:48.106+0800 | lrc3vm16 | | redisson-netty-2-11 | INFO  | org.redisson.connection.SingleEntry | master 172.18.81.17/172.18.81.17:6379 has changed to 172.18.81.16/172.18.81.16:6379
2020-10-22-T18:07:50.105+0800 | lrc3vm16 | | redisson-netty-2-6 | INFO  | org.redisson.connection.SingleEntry | master 172.18.81.16/172.18.81.16:6379 has changed to 172.18.81.17/172.18.81.17:6379
2020-10-22-T18:07:51.107+0800 | lrc3vm16 | | redisson-netty-2-4 | INFO  | org.redisson.connection.SingleEntry | master 172.18.81.17/172.18.81.17:6379 has changed to 172.18.81.16/172.18.81.16:6379
2020-10-22-T18:07:59.133+0800 | lrc3vm16 | | redisson-netty-2-3 | INFO  | org.redisson.connection.SingleEntry | master 172.18.81.16/172.18.81.16:6379 has changed to 172.18.81.17/172.18.81.17:6379
2020-10-22-T18:08:02.334+0800 | lrc3vm16 | | redisson-netty-2-6 | INFO  | org.redisson.connection.SingleEntry | master 172.18.81.17/172.18.81.17:6379 has changed to 172.18.81.16/172.18.81.16:6379
2020-10-22-T18:08:04.470+0800 | lrc3vm16 | | redisson-netty-2-10 | INFO  | org.redisson.connection.SingleEntry | master 172.18.81.16/172.18.81.16:6379 has changed to 172.18.81.17/172.18.81.17:6379
There are no other debug logs here. For example, I want to print the following log, How should I configure log4j?
log.debug("Request sent to resolve ip address for master host: {}", entry.getKey().getHost());
log.debug("Resolved ip: {} for master host: {}", future.getNow().getAddress(), entry.getKey().getHost());
log.info("Detected DNS change. Master {} has changed ip from {} to {}",  entry.getKey(),
currentMasterAddr.getAddress().getHostAddress(), newMasterAddr.getAddress().getHostAddress());
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3153
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Calling RedissonConnection.del() with multiple keys when using a clustered connection should delete the keys without error

public Long del(byte[]... keys)

Actual behavior
"CROSSSLOT" exception is thrown
Steps to reproduce or test case
Should be able to reproduce by simply trying to delete multiple keys that aren't in the same slot using a ReddisonConnection that is clustered.
In my example

Using redis-spring-data with redisson-spring-data
Using clustered connection
Using "@CacheEvict(allEntries = true)" annotation
This calls

RedisCache.clear()
DefaultRedisCacheWriter.clean()
RedissonConnection.del(byte[][] keys)



Redis version
5.0.3 (AWS)
Redisson version
redis-spring-data
3.12.5+  ("redisson-spring-data23:3.13.6" is where I have tested)
Redisson configuration
Clustered
I ran into this when upgrading from Spring 2.2.x to 2.3.x (Redisson 3.12.0 to 3.13.6)
This appears to have been broken when the check for clustered connection was removed as part of this commit: 8be9008
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3154
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
阿里云集群版redis限制了EVAL命令，按理来说用redisson会报错用不了，但是我测试了没有报错，想问下要怎么重现
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3155
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Rkeys does not contains RLock keys.  Only me?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3156
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have this RMapCache<String, String> stored in redis. Each key has a 30s TTL
Everything behaves normally but from time to time I get this class cast exception which causes a lot of issues down the line.
Caused by: java.lang.ClassCastException: java.util.ArrayList cannot be cast to java.util.Map
	at org.redisson.client.protocol.decoder.MapCacheScanResultReplayDecoder.decode(MapCacheScanResultReplayDecoder.java:35)
	at org.redisson.client.protocol.decoder.MapCacheScanResultReplayDecoder.decode(MapCacheScanResultReplayDecoder.java:30)
	at org.redisson.client.protocol.decoder.ListMultiDecoder2.decode(ListMultiDecoder2.java:46)
	at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:421)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:377)
	at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:196)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:134)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:104)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:498)
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:745)

I can't tell why this is happening , I am using redisson 3.12.5
Any idea what is happening over here ?
We have multiple nodes that are updating the same map inserting and deleting keys , different TTL's for each.
All nodes are time synced
Any help will be greatly apreciated.
Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3157
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is your feature request related to a problem? Please describe.
I initially discussed this idea in #3136.
Describe the solution you'd like
I'd like an RQueue implementation that allows to ack() elements to improve reliability and ensure that an object has been processed by one of the queue's consumers. The following example demonstrates the feature request:
RQueue<E> q;
E element = q.poll(); // prevents other clients to poll the same element but does not finally remove from queue
processElement(element); // do something with it
q.ack(element); // acknowledges processing of element and removes element from queue
If the consumer that q.poll()ed the element crashes or shuts down before finishing the processing and calling q.ack(), the element will automatically be "unlocked" for another consumer to poll next (e.g. via a watch dog similar to RLocks).
Describe alternatives you've considered

As shown in #3136 I considered using RStream but decided against doing so because the RStreams are far too complicated for simple use cases with only a small number of consumers.
My current solution involves using q.pollLastAndOfferFirstTo(...) and creating locks for the elements that should be marked as in progress to check whether the consumer working on an element is still alive or not. This also involves a periodic task that performs such a check on all items in the "in-progress-queue". This works but it would be great if this could be a feature of Redisson so I could reduce my code to someting similar as shown in the small example above.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3158
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
When having one producer and at least two consumer threads (or instances of an application) I expect RQueue's removeIf(lambda) method to remove elements without negative side effects.
I expect the same when using an iterator to iterate over the queue and calling remove() on the iterator.
Actual behavior
There are multiple types of errors that I observed:

I've seen NullPointerExceptions inside the removeIf lambda (e.g. q.removeIf(element -> element.getId().equals("id"))), where element is null (we don't add null elements to the queue).
Other times removeIf does not actually remove the elements from the queue, probably because it did not find the elements in the first place.

As the default implementation of removeIf uses the iterator my guess is that basically the iterator causes this issue and may not work properly when another consumer of a queue modifies the queue while it is used.
Steps to reproduce or test case
I have the following test case which can be used to reproduce the issue. It uses Lombok, Awaitility and Apache's RandomStringUtils for convenience (in case you want to run it without modification). Below I will explain steps to modify the test to get different results.
The test has one producer thread pushing 200 random Strings (wrapped with QueueEntry objects) and one or more consumer threads "processing" these objects (parking them in an "in-progress-queue" - which is the problematic queue).
    @Data
    @NoArgsConstructor
    @AllArgsConstructor
    static class QueueEntry {
        private String data;
        private UUID uuid;

        public QueueEntry(String data) {
            this.data = data;
            this.uuid = UUID.randomUUID();
        }
    }

    @Test
    void testParallelAccess() {
        final RBlockingDeque<QueueEntry> testQueue = redissonClient.getBlockingDeque("test-queue");
        final RBlockingQueue<QueueEntry> testQueueInProgress = redissonClient.getBlockingQueue("test-queue-in-progress");
        //final RLock inProgressQueueLock = redissonClient.getLock("test-queue-in-progress-lock"); // (1)

        final int items = 200;
        CountDownLatch latch = new CountDownLatch(items);
        Thread producer = new Thread(() -> {
            for (int i = 0; i < items; i++) {
                final String string = RandomStringUtils.random(20, true, false);
                testQueue.addFirst(new QueueEntry(string));
            }
        });
        producer.setDaemon(true);
        AtomicBoolean shouldRun = new AtomicBoolean(true);
        final List<Thread> consumers = new ArrayList<>();
        try {
            for (int i = 0; i < 4; i++) { // (4) set the number to >1 to actually parallelize the test and see it fail
                final Thread t = new Thread(() -> {
                    while (shouldRun.get()) {
                        try {
                            final QueueEntry queueEntry = testQueue.pollLastAndOfferFirstTo("test-queue-in-progress", 1, TimeUnit.MINUTES);
                            Thread.sleep(10); // pretend to process the element
                            //inProgressQueueLock.lock(); // (1)
                            testQueueInProgress.removeIf(entry -> entry.getUuid().equals(queueEntry.getUuid())); // (2)
                            //testQueueInProgress.remove(queueEntry); // (3)
                        } catch (InterruptedException e) {
                            // ok
                        } finally {
                            //inProgressQueueLock.unlock(); // (1)
                        }
                        latch.countDown();
                    }
                });
                t.setDaemon(true);
                consumers.add(t);
            }
            consumers.forEach(Thread::start);
            producer.start();

            latch.await(60, TimeUnit.SECONDS);

            Awaitility.waitAtMost(30, TimeUnit.SECONDS).until(() -> testQueue.isEmpty() && testQueueInProgress.isEmpty());
        } catch (InterruptedException e) {
            fail("Probably failed to consume all events!", e);
        } finally {
            redissonClient.shutdown();
            shouldRun.set(false);
        }
    }
If you run the test as it is here it will fail because the "in-progress-queue" is not empty.
Modifications to change the test results:

Change the number of consumer threads to 1 in the line marked with (4). Now the test should pass. Change the number back to something larger than 1.
Comment in the RLock and its usages marked with (1). Now the test should pass. Comment the lines out again.
Comment out the removeIf(...) statement (marked with (2)) and comment in the remove(...) statement (marked with (3)) instead. Now the test should pass.

Instead of using removeIf() you could also modify the test to use an iterator and remove elements with it. The results will be similar.
Redis version
6.0.8
Redisson version
3.13.6
Redisson configuration
Default single server config with JsonJacksonCodec.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3159
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have a map stored in redis cluster. When I try to get this map to know if a given key exists in it, I am using
        String key = "mykey";
        RMap<String, String> rmap = redissonClient.getMap("mapK", new StringCodec());
        if(rmap.isEmpty() || rmap.get(key) == null){
            throw new RuntimeException("no value found with key: " + key);
        }
        ....

It works at most times. But somehow the RuntimeException I defined above will be throw out sometimes unexpectedly. Which means rMap.isEmpty returns true with no exception, while the fact is we do have this key stored in redis.
In addition, I found a exception in another thread,
[redisson-timer-4-1] o.r.cluster.ClusterConnectionManager     : Can't execute CLUSTER_NODES with /10.211.63.61:6379
org.redisson.client.RedisTimeoutException: Command execution timeout for command: (CLUSTER NODES), params: [], Redis client: [addr=redis://10.211.63.61:6379]
	at org.redisson.client.RedisConnection.lambda$async$1(RedisConnection.java:207) ~[redisson-3.13.3.jar!/:3.13.3]
        .....

Does this exception impact the result when I was calling `rMap.isEmpty()'?  And how can I avoid this problem?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3160
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3161
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Let me explain why this change is important.
We use a configuration with 200+ application servers and a Redis cluster with 50+ nodes. We have configured the scan cluster value for 1000 milliseconds. When 200+ applications send CLUSTER NODES to the same Redis node, it leads to very high CPU usage on that Redis node. As a workaround, we changed the cluster scan time to 10 seconds.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3162
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Getting following error:
org.redisson.client.RedisException: MOVED redirection loop detected. Node redis://xxxxx-cache-0001-001.xxxxx-cache.yyyyy.usw2.cache.amazonaws.com:6379 has further redirect to redis://xxxxx-cache-0001-001.xxxxx-cache.yyyyy.usw2.cache.amazonaws.com:6379
We are using redisson 3.13.4 ( tried with 3.13.6 also) with AWS Elasticache Redis.
For our internal testing we created AWS Elasticache Redis cluster with following configuration:
Shards: 1
replica: 1
Engine compatibilty: 5.0.6
readMode=MASTER.
Connecting to configuration endpoind.
In the error you see 'redis://' but we are using 'rediss://' , there is another bug in RedisException where 'redis://' ( without extra 's') is hardcoded.
It was working fine till last week.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3163
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
wiki的原文
7.6. 字典排序集（LexSortedSet）
它 公式 还保证了字符串元素的唯一性。
正确的词是不是这样
它 同时 还保证了字符串元素的唯一性。
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3164
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Will RList<>.add(V) return false ever?
It looks like RedisCommands.RPUSH_BOOLEAN command always return true based on below convertor implementation, can you please let's know will it every return false assuming there is no RedisTimeoutException?
public class TrueReplayConvertor implements Convertor<Boolean> {
    @Override
    public Boolean convert(Object obj) {
        return true;
    }
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3165
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi!
Is your feature request related to a problem? Please describe.
We use redisson with spring-boot-starter in our project. Unfortunately, sometimes we need to disable caching (f.e. on some environments we don't have redis). When it comes to a spring-data-redis we can just set property:
spring.cache.type: NONE

and caching is disabled, but if we use Redisson then his auto-configuration doesn't let us run the application without a worked Redis connection.
Describe the solution you'd like
Disable the whole auto-configuration when
spring.cache.type: NONE

Describe alternatives you've considered
We can add a new maven profile and exclude the redisson dependency but it doesn't sound well because we get a new profile to maintain.
My current solution

I excluded autoconfigurations:

@EnableAutoConfiguration(exclude = { RedissonAutoConfiguration.class, RedisAutoConfiguration.class })


I made my own auto configuration (based on redisson's autoconfiguration) where I've added @ConditionalOnExpression("'${spring.cache.type}' == 'redis'")

@Configuration
@ConditionalOnClass(RedisOperations.class)
@EnableConfigurationProperties({RedisProperties.class, RedissonProperties.class})
@ConditionalOnExpression("'${spring.cache.type}' == 'redis'")
public class RedisConfiguration {

  private static final String REDIS_PROTOCOL_PREFIX = "redis://";
  private static final String REDISS_PROTOCOL_PREFIX = "rediss://";

  @Bean
  public RedisTemplate<Object, Object> redisTemplate(
      RedisConnectionFactory redisConnectionFactory) {
    RedisTemplate<Object, Object> template = new RedisTemplate<>();
    template.setConnectionFactory(redisConnectionFactory);
    return template;
  }

  @Bean
  @ConditionalOnMissingBean
  public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) {
    StringRedisTemplate template = new StringRedisTemplate();
    template.setConnectionFactory(redisConnectionFactory);
    return template;
  }

  @Bean
  public RedissonConnectionFactory redissonConnectionFactory(RedissonClient redisson) {
    return new RedissonConnectionFactory(redisson);
  }


  @Bean(destroyMethod = "shutdown")
  @ConditionalOnMissingBean(RedissonClient.class)
  public RedissonClient redisson(RedissonProperties redissonProperties, ApplicationContext ctx,
      RedisProperties redisProperties) throws IOException {
    Config config = null;
    Method clusterMethod = ReflectionUtils.findMethod(RedisProperties.class, "getCluster");
    Method timeoutMethod = ReflectionUtils.findMethod(RedisProperties.class, "getTimeout");
    Object timeoutValue = ReflectionUtils.invokeMethod(timeoutMethod, redisProperties);
    int timeout;
    if (null == timeoutValue) {
      timeout = 10000;
    } else if (!(timeoutValue instanceof Integer)) {
      Method millisMethod = ReflectionUtils.findMethod(timeoutValue.getClass(), "toMillis");
      timeout = ((Long) ReflectionUtils.invokeMethod(millisMethod, timeoutValue)).intValue();
    } else {
      timeout = (Integer) timeoutValue;
    }

    if (redissonProperties.getFile() != null) {
      InputStream is = getConfigStream(redissonProperties, ctx);
      config = Config.fromYAML(is);

    } else if (redisProperties.getSentinel() != null) {
      Method nodesMethod = ReflectionUtils.findMethod(Sentinel.class, "getNodes");
      Object nodesValue = ReflectionUtils.invokeMethod(nodesMethod, redisProperties.getSentinel());

      String[] nodes;
      if (nodesValue instanceof String) {
        nodes = convert(Arrays.asList(((String) nodesValue).split(",")));
      } else {
        nodes = convert((List<String>) nodesValue);
      }

      config = new Config();
      config.useSentinelServers()
          .setMasterName(redisProperties.getSentinel().getMaster())
          .addSentinelAddress(nodes)
          .setDatabase(redisProperties.getDatabase())
          .setConnectTimeout(timeout)
          .setPassword(redisProperties.getPassword());
    } else if (clusterMethod != null
        && ReflectionUtils.invokeMethod(clusterMethod, redisProperties) != null) {
      Object clusterObject = ReflectionUtils.invokeMethod(clusterMethod, redisProperties);
      Method nodesMethod = ReflectionUtils.findMethod(clusterObject.getClass(), "getNodes");
      List<String> nodesObject = (List) ReflectionUtils.invokeMethod(nodesMethod, clusterObject);

      String[] nodes = convert(nodesObject);

      config = new Config();
      config.useClusterServers()
          .addNodeAddress(nodes)
          .setConnectTimeout(timeout)
          .setPassword(redisProperties.getPassword());
    } else {
      config = new Config();
      String prefix = REDIS_PROTOCOL_PREFIX;
      Method method = ReflectionUtils.findMethod(RedisProperties.class, "isSsl");
      if (method != null && (Boolean) ReflectionUtils.invokeMethod(method, redisProperties)) {
        prefix = REDISS_PROTOCOL_PREFIX;
      }

      config.useSingleServer()
          .setAddress(prefix + redisProperties.getHost() + ":" + redisProperties.getPort())
          .setConnectTimeout(timeout)
          .setDatabase(redisProperties.getDatabase())
          .setPassword(redisProperties.getPassword());
    }

    return Redisson.create(config);
  }

  private String[] convert(List<String> nodesObject) {
    List<String> nodes = new ArrayList<>(nodesObject.size());
    for (String node : nodesObject) {
      if (!node.startsWith(REDIS_PROTOCOL_PREFIX) && !node.startsWith(REDISS_PROTOCOL_PREFIX)) {
        nodes.add(REDIS_PROTOCOL_PREFIX + node);
      } else {
        nodes.add(node);
      }
    }
    return nodes.toArray(new String[nodes.size()]);
  }

  private InputStream getConfigStream(RedissonProperties redissonProperties, ApplicationContext ctx)
      throws IOException {
    Resource resource = ctx.getResource(redissonProperties.getFile());
    return resource.getInputStream();
  }
}
If you agree then I will push a pull request with changes.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3166
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
add amend
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3167
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
amend
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3168
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3169
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
reopen with antoher pull request
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3170
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
close with another pull request under my corp account
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3171
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
close with another pull request under my corp account
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3172
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Session attributes modified without calling setAttribute are not stored properly in Redis.
The following snippet sets an empty list as a session attribute ("foo") on the first call. Any subsequent call gets the attribute and appends an item ("bar") to the list without calling setAttribute.
public class RedissonTestServlet extends HttpServlet {
  @Override
  protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws IOException {
    final HttpSession session = req.getSession();
    if (session.getAttribute("foo") == null) {
      session.setAttribute("foo", new ArrayList());
    } else {
      List list = (List) session.getAttribute("foo");
      list.add("bar");
      //session.setAttribute("foo", list);
    }
  }
}

Expected behavior
With updateMode AFTER_REQUEST the changes should be persisted to Redis after each request regardless of the missing setAttribute.
So the list should expand by one item on every call.
Actual behavior
In Redis there is always only an empty list.
Steps to reproduce or test case
test project
Redis version
6.0.8
Redisson version
3.13.6
Redisson configuration
<Context>
  <Manager className="org.redisson.tomcat.RedissonSessionManager"
           configPath="redisson.conf"
           readMode="REDIS"
           updateMode="AFTER_REQUEST"
           broadcastSessionEvents="false"
           keyPrefix=""/>
</Context>
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3173
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Env setup:
redisson client : 3.13.6
redis-cli
127.0.0.1:6379> hmset "u:id-1" f1 "id-1_f1" f2 "id-1_f2" f3 "id-1_f3"
127.0.0.1:6379> hmset "u:id-2" f1 "id-2_f1" f2 "id-2_f2" f3 "id-2_f3"
127.0.0.1:6379> hmset "u:id-3" f1 "id-3_f1" f2 "id-3_f2" f3 "id-3_f3"
Expected Output
# evalsha 9ad57862683cb52805f941819a65cc502a1bc0de 3 "u:id-1" "u:id-2" "u:id-3" 
1) 1) "id-1_f1"
2) "id-1_f2"
3) "id-1_f3"
2) 1) "id-2_f1"
2) "id-2_f2"
3) "id-2_f3"
3) 1) "id-3_f1"
2) "id-3_f2"
3) "id-3_f3"


Lua Script
final RScript script = redisson.getScript(StringCodec.INSTANCE);
String luaScript = "local data = {} for i=1,#KEYS do local fields = redis.call('hmget', KEYS[i], 'f1', 'f2', 'f3', 'f4') data[i] = fields end return data";
       
String sha = script.scriptLoadAsync(luaScript);
System.out.println(sha)
final ImmutableList<String> immutableList = ImmutableList.of("u:id-1", "u:id-2", "u:id-3");
// tried ReturnType.MAPVALUE , ReturnType. MAPVALUELIST
List<Object> results = redisson.getScript().evalSha(RScript.Mode.READ_ONLY,  sha,  RScript.ReturnType.MULTI,  Collections.singletonList(immutableList))
for (List<String> stringList : (List<List<String>>) result) {
      System.out.println(stringList.size());
      System.out.println(stringList);
 }

Actual output:
9ad57862683cb52805f941819a65cc502a1bc0de
4
[null, null, null, null]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3174
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
TTL same as in the settings
Actual behavior
TTL +10x higher
Steps to reproduce or test case
Set session-timeout in minutes, get the TTL in redis after the session creation, its way higher.
  <!-- ==================== Default Session Configuration ================= -->
  <!-- You can set the default session timeout (in minutes) for all newly   -->
  <!-- created sessions by modifying the value below. 

    <session-config>
        <session-timeout>10080</session-timeout>
        <tracking-mode>COOKIE</tracking-mode>
    </session-config>

redis:6379> TTL redisson:tomcat_session:XXXXXX
(integer) 36287980
(TTL reply in seconds)

Redis version
5.0.7
Redisson version
3.12.5
Tomcat 9.0.38
Redisson configuration
{
   "singleServerConfig":{
      "idleConnectionTimeout":10000,
      "connectTimeout":10000,
      "timeout":3000,
      "retryAttempts":3,
      "retryInterval":1500,
      "password":null,
      "subscriptionsPerConnection":5,
      "clientName":null,
      "address": "redis://redis:6379",
      "subscriptionConnectionMinimumIdleSize":1,
      "subscriptionConnectionPoolSize":50,
      "connectionMinimumIdleSize":32,
      "connectionPoolSize":64,
      "database":0,
      "dnsMonitoringInterval":5000
   },
   "threads":16,
   "nettyThreads":32,
   "codec":{
      "class":"org.redisson.codec.FstCodec"
   },
   "transportMode":"NIO"
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3175
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
How can I set the sessionIdLength in the context.xml?
<Manager sessionIdLength="64" className="org.redisson.tomcat.RedissonSessionManager" configPath="${catalina.base}/conf/redisson.conf" broadcastSessionEvents="true" readMode="MEMORY" updateMode="DEFAULT"/>

This didn't worked, the default is 16.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3176
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am not very clear about the specific role of readmode="MEMORY". If readmode="MEMORY" should be enabled at the same time broadcastSessionEvents="true" this attribute to ensure the consistency of multiple copies of the session? Does readmode="MEMORY" just store an extra session in the tomcat memory? When I simulate redis downtime, redisson will not directly read the cache from tomcat, but continue to connect to redis to get the session.I need help,thanks.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3177
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
My env: SpringBoot 2.3.3.RELASE, JDK 8, Redis 5.0.6, redisson-spring-boot-starter 3.13.6
Base config demo as follows:
Config config = new Config();
...
config.useSingleServer().setRetryAttempts(10);
config.useSingleServer().setRetryInterval(10000);
...

My test scene:

Firstly shutdown my redis server
Then start my springboot application
Then restart my redis server

What I expect is: Redisson in the app will retry to connect to  the redis server until connect successfully and the app started normal. But actually redisson didn't retry to do this and the following exception is thrown:
Caused by: org.redisson.client.RedisConnectionException: Unable to connect to Redis server: /10.213.120.82:6379
    at org.redisson.connection.pool.ConnectionPool$1.lambda$run$0 (ConnectionPool.java:159)
    ...
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3178
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is there anything else I should do or provide?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3179
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
This is difficult to add test. This change is related to network.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3180
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
springboot version : 2.3.3.RELEASE
spring data redis dependency
<dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-data-redis</artifactId>
        </dependency>

Redis version
null
Redisson version
<dependency>
            <groupId>org.redisson</groupId>
            <artifactId>redisson-spring-boot-starter</artifactId>
            <version>3.13.6</version>
        </dependency>

Redisson configuration
public class RedissonSpringDataConfig {
    @Value("${spring.redis.cluster.nodes}")
    String redisNodes;
    @Value("${spring.redis.password}")
    String redisPass;

    @Bean
    public RedissonConnectionFactory redissonConnectionFactory(RedissonClient redisson) {
        return new RedissonConnectionFactory(redisson);
    }

    @Bean(destroyMethod = "shutdown")
    public RedissonClient redisson() throws Exception {
        if (StringUtils.isEmpty(redisNodes)) {
            throw new Exception("redis cluster nodes must not be null");
        }
        Config config = new Config();
        config.useClusterServers()
                .addNodeAddress(
                        Arrays.stream(redisNodes.split(",")).map(item -> "redis://" + item).toArray(String[]::new)
                ).setPassword(redisPass);
        return Redisson.create(config);
    }

}

Expected behavior
I want to use redisTemplate and redissonClient at the same time. Based on the above configuration, using redisTemplate can set the value during operation. But the get value is always null
When I remove the RedissonConnectionFactory injected in RedissonSpringDataConfig, redisTemplate will use lettuceConnectionFactory by default. At this time, there is no problem using redisTemplate's get method and set method. The get method can also return normal values.
Actual behavior
redisTemplate's get method always return null
Steps to reproduce or test case
null
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3181
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is your feature request related to a problem? Please describe.
In highload systems, it may be too expensive to make requests to Redis too often. Using a not reactive approach, it's possible to enable local caching and use RLocalCachedMap to reduce amount of requests to Redis. However, in a reactive system, currenty it's not an option.
Describe the solution you'd like
I think it would be very nice to be able to use RLocalCachedMap reactively.
Describe alternatives you've considered
As an alternative, I have to implement a custom caching logic to reduce amount of requests to Redis.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3182
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
With retries enabled WriteRedisConnectionException shouldn't happen.
Actual behavior
We have set netty threads and max connections to 250. When Redission is retrying will it use different netty connection, or attempt using same channel which is throwing newClosedChannelException/ClosedChannelException? It's not clear from below error what other tuning is required in application code.
"org.redisson.client.WriteRedisConnectionException: Unable to write command into connection! Node source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=value:50:queue:0, freeConnectionsAmount=5, freeConnectionsCounter=value:106:queue:0, freezed=false, freezeReason=null, client=[addr=redis://172.26.45.181:6379], nodeType=MASTER, firstFail=0]]], connection: RedisConnection@1729007529 [redisClient=[addr=redis://172.26.45.181:6379], channel=[id: 0xe8e83a99, L:/172.26.134.191:53989 - R:172.26.45.181/172.26.45.181:6379], currentCommand=null], command: (RPUSH), params: [usermessage_queue2, PooledUnsafeDirectByteBuf(ridx: 0, widx: 1281, cap: 4096)] after 3 retry attempts\n\tat org.redisson.command.RedisExecutor.checkWriteFuture(RedisExecutor.java:270)\n\tat org.redisson.command.RedisExecutor.access$100(RedisExecutor.java:58)\n\tat org.redisson.command.RedisExecutor$1.operationComplete(RedisExecutor.java:155)\n\tat org.redisson.command.RedisExecutor$1.operationComplete(RedisExecutor.java:152)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:608)\n\tat io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:993)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:865)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:715)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:762)\n\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1089)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.nio.channels.ClosedChannelException: null\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.newClosedChannelException(AbstractChannel.java:957)\n\t... 12 common frames omitted\n",
Steps to reproduce or test case
Intermittent exception noticed in production logs.
Redis version
5.0.6
Redisson version
3.12.4
Redisson configuration
Config config = new Config();
config.setCodec(StringCodec.INSTANCE);
config.setNettyThreads(CacheConstants.MAX_TOTAL_CONNECTIONS);

SentinelServersConfig serverConfig = config.useSentinelServers()
				.setMasterName(CacheConstants.MASTER_NAME)
				.setScanInterval(2000) 
				.setReadMode(READ_MODE)
				.setTimeout(CacheConstants.TIMEOUT) 
				.setMasterConnectionMinimumIdleSize(CacheConstants.MIN_IDLE_CONNECTIONS)
				.setMasterConnectionPoolSize(CacheConstants.MAX_TOTAL_CONNECTIONS)
				.setSlaveConnectionMinimumIdleSize(CacheConstants.MIN_IDLE_CONNECTIONS)
				.setSlaveConnectionPoolSize(CacheConstants.MAX_TOTAL_CONNECTIONS)
				.setKeepAlive(true)
				.setPingConnectionInterval(CacheConstants.PING_INTERVAL)
				.setCheckSentinelsList(false);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3183
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I am trying to set the TTL on the cache map as shown in the snippet below but I am noticing that the TTL is set to -1 and not the value I am passing. Is this the right way to go about setting the TTL for the cache maps? If not what is the right way?
private RedissonClient client;
.
.
.
public <K, V> RMap<K, V> getCachedMap(String key, long expiry, TimeUnit timeUnit) {
    if (!isConnectionAlive()) {
        return null;
    }
    try {
        RMap<K, V> map = client.getMap(key);
        map.expire(expiry, timeUnit);
        return map;
    } catch (RedisTimeoutException | RedisConnectionException e) {
        setConnectionAlive(false);
        logger.error("RedisTimeoutException | RedisConnectionException occurred.", e);
        return null;
    }
}

This is what I see on enabling the debug logs:
acquired connection for command (PEXPIRE) and params [INTERACTIVE:event.9cf3de43-8c57-4247-a454-78c615cfdf1a.instance.acc38bdd-fdcb-4232-a701-eb7dadda894a..., 86400000] from slot NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=50, freeSubscribeConnectionsCounter=value:50:queue:0, freeConnectionsAmount=49, freeConnectionsCounter=value:199:queue:0, freezed=false, freezeReason=null, client=[addr=redis://redis:6379], nodeType=MASTER, firstFail=0]]] using node redis/169.254.169.3:6379... RedisConnection@1303942170 [redisClient=[addr=redis://redis:6379], channel=[id: 0x3a5aaba3, L:/169.254.169.30:53094 - R:redis/169.254.169.3:6379], currentCommand=null]
So looks like it is indeed trying to set the TTL.
I am using redisson version 3.13.1
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3184
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Demo Code
        RLock[] rLockArr = new RLock[needLocks.size()];
        for (int i = 0; i < locks.size(); i++) {
            RReadWriteLock rwlock = redissonService.getReadWriteLock(DistributedLockKeyEnum.D_LOCK_KEY.getKey(needLocks.get(i)));
            rLockArr[i] = rwlock.readLock();
        }
        RedissonMultiLock lock = new RedissonMultiLock(rLockArr);
当运行到org.redisson.RedissonReadLock#tryLockInnerAsync时，会发生异常。
由于Redis Cluster使用lua脚本有限制，不允许有多个Key，对于多个Key的情况需要使用{}包起来，但是如下getName()方法中没有做这方面的处理。
    @Override
    <T> RFuture<T> tryLockInnerAsync(long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand<T> command) {
        internalLockLeaseTime = unit.toMillis(leaseTime);

        return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command,
                                "local mode = redis.call('hget', KEYS[1], 'mode'); " +
                                "if (mode == false) then " +
                                  "redis.call('hset', KEYS[1], 'mode', 'read'); " +
                                  "redis.call('hset', KEYS[1], ARGV[2], 1); " +
                                  "redis.call('set', KEYS[2] .. ':1', 1); " +
                                  "redis.call('pexpire', KEYS[2] .. ':1', ARGV[1]); " +
                                  "redis.call('pexpire', KEYS[1], ARGV[1]); " +
                                  "return nil; " +
                                "end; " +
                                "if (mode == 'read') or (mode == 'write' and redis.call('hexists', KEYS[1], ARGV[3]) == 1) then " +
                                  "local ind = redis.call('hincrby', KEYS[1], ARGV[2], 1); " + 
                                  "local key = KEYS[2] .. ':' .. ind;" +
                                  "redis.call('set', key, 1); " +
                                  "redis.call('pexpire', key, ARGV[1]); " +
                                  "redis.call('pexpire', KEYS[1], ARGV[1]); " +
                                  "return nil; " +
                                "end;" +
                                "return redis.call('pttl', KEYS[1]);",
                        // getName() 方法中，没有对Key进行处理，造成lua脚本执行报错
                        Arrays.<Object>asList(getName(), getReadWriteTimeoutNamePrefix(threadId)), 
                        internalLockLeaseTime, getLockName(threadId), getWriteLockName(threadId));
    }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3185
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In my Spring Boot project, I have one redis container deployed in Docker swarm cluster. I use it as Hibernate 2nd level cache for the application. I use Redisson client to manually clear the cache using the following code
Config config = new Config();
config.useSingleServer().setAddress("redis://" + redisProperties.getHost() + ":" + redisProperties.getPort());
RedissonClient redisson = Redisson.create(config);
redisson.getKeys().flushdb();
logger.info("Successfully cleared the Redis Cache");
redisson.shutdown();

Now I would like to scale it to multiple containers to withstand failover and distribute the load. If I do that, how can I clear the cache in 2 or more containers at the same time?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3186
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3187
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello everyone,
Couldn't find my answer in docs or by looking briefly at the implementation, so posting the question here.
Let's assume a system, where X instances of the same application are working concurrently on processing some data. In general, the instances can work concurrently, but some specific data items must not be processed at the same time by more than one instance, as this would produce race condition.
To synchronize application instances and avoid race conditions, we've set up a Redis instance, and we use Redisson's locking mechanism to achieve exclusive execution. In general, the workflow for an instance looks like this:
(take a lock A) -> (process data) -> (release lock A)
Then, obviously, the other instances, that want to process the conflicting data item, need to wait for lock A to be released. Processing an item can take anywhere between several seconds and several days. so a lock might be held for a long time (and we use this auto-renewal feature for locks to have the lock prolonged as needed behind the scenes by Redisson).
My question is - what happens if an instance, that is currently holding the lock, loses connectivity to Redis (and therefore the lock times out and is then taken by another instance), and then after some time it regains the connectivity? Will it finish processing the data without holding the lock, and then fail on releasing the lock? Or maybe something else would happen?
I'd really appreciate your feedback on this.
Best Regards,
Paweł
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3188
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
This should not throw an error. It should convert the number to long but it is converting to int
Actual behavior
RedisExeption is thrown
message: Unable to decode data. channel: [id: 0x9866744b, L:/172.18.167.145:48328 - R:xxxxx-0001-001.xxxxx.oi7ujc.use1.cache.amazonaws.com/10.75.xxx.xx:6379], reply: ReplayingDecoderByteBuf(ridx=18, widx=18), command: (HINCRBYFLOAT), params: [BucketUpdates_urn:aaid:yyyyyyyyy:xxxxxxxx-6aa7-4a52-xxxx-xxxxxxxxxxxx, PooledUnsafeDirectByteBuf(ridx: 0, widx: 23, cap: 256), -12218]
Stack trace:
stack_trace: java.lang.NumberFormatException: For input string: "-3753018785"
at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
at java.base/java.lang.Integer.parseInt(Integer.java:652)
at java.base/java.lang.Integer.parseInt(Integer.java:770)
at org.redisson.client.protocol.convertor.NumberConvertor.convert(NumberConvertor.java:42)
at org.redisson.client.handler.CommandDecoder.handleResult(CommandDecoder.java:441)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:377)
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:196)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:134)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:104)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:505)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:283)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1475)
at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1224)
at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1271)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:505)
at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:444)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:283)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1421)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:697)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511)
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base/java.lang.Thread.run(Thread.java:834)
Steps to reproduce or test case
Map<String, Number> nonZeroBucketUpdates;
RMap<String, Number> distributedBucketUpdates =redissonClient.getMap("BucketUpdates_urn:aaid:yyyyyyyyy:xxxxxxxx-6aa7-4a52-xxxx-xxxxxxxxxxxx");
nonZeroBucketUpdates.forEach(distributedBucketUpdates::addAndGet);
Redis version
5.0.6
Redisson version
3.13.1
Redisson configuration
redissonConfig.setCodec(new JsonJacksonCodec())
.setNettyThreads(64)
.setReadMode(ReadMode.MASTER)
.addNodeAddress(redisProperties.getNodes().toArray(new String[] {}))
.setPassword(redisProperties.getAuthToken())
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3189
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
HI there,
it seems like the Redisson authentication is broken for the current release 3.13.6 in combination with a Redis 6.0.9 and a Sentinel setup. I provide the password with the config object:
config.useSentinelServers() .setMasterName("sentinel-master") .addSentinelAddress("redis://127.0.0.1:26379") .setPassword("redis");
I suspect the implementation of the checkAuth() and createRedisConfig(...) methods in SentinelConnectionManager.
Since the default of usePassword is false, this results in the provided password being set to null in createRedisConfig(..), which subsequently causes checkAuth() to fail prematurely on line 213 client.connect() with a RedisConnectionException caused by an RedisAuthRequiredException. Therefore, usePassword is never set to true and the Redission Sentinel config is broken for secured Sentinel instances.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3190
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello Everyone,
The Local cache map data types for key is CacheKey and for value is CacheValue. The CacheKey contains the hashed value of encoded original key object. Due to this, when ever redisson tries to retrieve from the local cache, it has to encode the key and convert to hash value and get value from the local cache.
Is there any specific reason behind this approach? What if the CacheKey stores the original key directly? Will that improves the local cache performance?
Best Regards
Sai
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3191
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
run success
Actual behavior
with exception  Can't parse config
Steps to reproduce or test case
Redis version
Redisson version
redisson-spring-boot-starter:3.13.6
Redisson configuration
singleServerConfig:
  idleConnectionTimeout: 10000
#  pingTimeout: 1000 # not exist in properties
  connectTimeout: 10000
  timeout: 3000
  retryAttempts: 3
  retryInterval: 1500
#  reconnectionTimeout: 3000 # not exist in properties
#  failedAttempts: 3 # not exist in properties
  password:
  subscriptionsPerConnection: 5
  clientName: yitu
  address: redis://127.0.0.1:6379
  subscriptionConnectionMinimumIdleSize: 1
  subscriptionConnectionPoolSize: 50
  connectionMinimumIdleSize: 32
  connectionPoolSize: 64
  database: 0
#  dnsMonitoring: false # not exist in properties
  dnsMonitoringInterval: 5000
threads: 0
nettyThreads: 0
codec: !<org.redisson.codec.JsonJacksonCodec> {}
transportMode: NIO
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3192
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3193
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3194
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case
1.使用redisson加锁
redissonClient.getLock("LOCK_NAME").Lock()
2.加锁成功后断开本地与redis服务器的网络，使redisson的watchdog报错
ERROR org.redisson.RedissonLock - Can't update lock LOCK_NAME expiration org.redisson.client.RedisResponseTimeoutException: Redis server response timeout (3000 ms) occured after 3 retry attempts. Increase nettyThreads and/or timeout settings. Try to define pingConnectionInterval setting. Command: null, params: null, channel: [id: 0x1e676dd8, L:/192.168.20.49:58477 - R:/192.168.2.21:6379] at org.redisson.command.RedisExecutor$3.run(RedisExecutor.java:333) at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:672) at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:747) at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:472) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.lang.Thread.run(Thread.java:748)
`
3.让网络恢复正常，且"LOCK_NAME"这个锁自动失效后，再使用redissonClient.getLock("LOCK_NAME").Lock()加锁后watchdog就不再生效了
Redis version
3.13.6
Redisson version
4.0.9
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3195
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3196
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
I point RedissonSessionManager at a YAML config file. I don't get a deprecation warning about using JSON config files.
Actual behavior
I point RedissonSessionManager at a YAML config file. I do get a deprecation warning about using JSON config files.
Steps to reproduce or test case
Point RedissonSessionManager at a YAML config file. Get a deprecation warning about using JSON config files.
Redis version
6.0.8
Redisson version
3.13.6
Redisson configuration
singleServerConfig:
  address: "redis://127.0.0.1:${REDIS_PORT:-6379}"
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3197
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
working normally
Actual behavior
throw exception:bad argument #2 to 'unpack' (string expected, got nil)
Steps to reproduce or test case
    public static void main(String[] args) throws InterruptedException {
        RRateLimiter rateLimiter = createLimiter();
        System.out.println(rateLimiter.tryAcquire(1));
        Thread.sleep(1000 * 6);
        System.out.println(rateLimiter.tryAcquire(6));
    }

    public static RRateLimiter createLimiter() {
        Config config = new Config();
        config.useSingleServer()
                .setTimeout(1000000)
                .setAddress("redis://127.0.0.1:6379");

        RedissonClient redisson = Redisson.create(config);
        RRateLimiter rateLimiter = redisson.getRateLimiter("myRateLimiter");
        rateLimiter.trySetRate(RateType.OVERALL, 1, 1, RateIntervalUnit.SECONDS);
        return rateLimiter;
    }
Redis version
5.0.4
Redisson version
3.13.6
Redisson configuration
such as case
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3198
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3199
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3200
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3201
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3202
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The waiting time is necessary. Because we don’t know whether last thread is completed or not. I finally thought this way to make each redission fair lock client has status. But this may affect tps a little. Kindly help to advise
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3203
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Getting below exception intermittently during execution of a multi-threaded batch process.
org.redisson.client.RedisTimeoutException: Command still hasn't been written into connection! Increase nettyThreads and/or retryInterval settings. Payload size in bytes: 9. Node source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=4, freeSubscribeConnectionsCounter=value:299:queue:0, freeConnectionsAmount=52, freeConnectionsCounter=value:492:queue:0, freezed=false, freezeReason=null, client=[addr=redis://xx.xx.xx.xxx:xxxx], nodeType=MASTER, firstFail=0]]], connection: RedisConnection@1880328440 [redisClient=[addr=redis://xx.xx.xx.xxx:xxxx], channel=[id: 0x7dfdf73d, L:/xx.xx.xx.xxx:xxxx - R:/xx.xx.xx.xxx:xxxx], currentCommand=null], command: (HGET), params: [ABC_CACHE_REGION$ABC_CODE, PooledUnsafeDirectByteBuf(ridx: 0, widx: 9, cap: 256)] after 3 retry attempts,
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3204
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
用的阿里云的集群版redis，会偶发这个错误，但是不确定是执行什么出的错
[] [ERROR] 2020-11-11 15:10:13.897 [redisson-netty-2-8] org.redisson.client.handler.CommandPubSubDecoder - Unable to decode data. channel: [id: 0xcbbfbec3, L:/10.11.9.221:33926 - R:r-uf6lps934bbmd03q4e.redis.rds.aliyuncs.com/10.11.9.239:6379], reply: ReplayingDecoderByteBuf(ridx=140, widx=362)
java.lang.NullPointerException: null
[] [WARN ] 2020-11-11 15:10:13.897 [redisson-netty-2-8] io.netty.channel.DefaultChannelPipeline - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
io.netty.handler.codec.DecoderException: java.lang.NullPointerException
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:421)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:377)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:355)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:377)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
要怎么排查是具体什么的错啊，要怎么解决
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3205
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
While working on memory improvements for Redis, I came across with an issue where I have observed that Redis is using huge memory for RMap compared to normal object.
I have execute below code and I observed below things:

I could see memory occupied in Redis for key abcd-abcd:map is 10728729 bytes(10.72 MB), I have used command MEMORY USAGE abcd-abcd:map.
I could see memory occupied in Redis for key abcd-abcd is 1170360 bytes(1.17 MB), I used command MEMORY USAGE abcd-abcd

My question is if I am saving one object(hashmap) as an RMap and saving the same object(hashmap) as a value in another Map then why the object saved in RMap is occupying huge amount of memory compared to other case?
Please note currently I kept SIZE as 100000, but in my case I need to save 1-2 million(or more than that) objects in RMap and in that case I can see huge memory utilization in Redis.
Can someone please review this and share their thoughts?
public class RedisTest {
  
  private static final int SIZE = 100000;
  private static Codec compositeCodec = new 
      CompositeCodec(new StringCodec(), new LZ4Codec(new SerializationCodec()),  new SerializationCodec());
  private static String initId = "abcd-abcd";

  public static void main(String[] args) {
    Config config = new Config();
    config.useSingleServer().setAddress("redis://127.0.0.1:6379");
    RedissonClient redissonClient = Redisson.create(config);
    RMap<String,String> rmap = redissonClient.getMap(initId + ":map", compositeCodec);
    Map<String, String> hashMap = getMap();
    rmap.putAll(hashMap);
    RMap<Object, Object> rootMap = redissonClient.getMap(initId, compositeCodec);
    rootMap.put("object", hashMap);
    redissonClient.shutdown();
  }
  
  private static Map<String, String> getMap() {
    Map<String, String> hashMap = new HashMap<>();
    for (int i = 0; i < SIZE; i++) {
      hashMap.put("keykeykeykeykeykeykeykeykeykeykeykey"+i, "valuevaluevaluevaluevaluevaluevaluevaluevalue"+i);
    }
    return hashMap;
  }

}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3206
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is your feature request related to a problem? Please describe.
We are using redisson-spring-boot-starter. We were hoping that we could configure Redisson with a redisson.yml, but also configure more dynamic properties from our application.yml.
# application.yml
spring:
  redis:
    host: ${REDIS_HOSTNAME}
    redisson: 
      file: classpath:redisson.yaml
When we run in a different environment we can overwrite the Redis hostname by setting an environment variable. With Spring Boot profiles (for example "local"), we could have an application-local.yml that contains the following:
# application-local.yml
spring:
  redis:
    host: localhost
Or set the placeholder itself:
# application-local.yml
REDIS_HOSTNAME: localhost
That way we would be able to have different configurations for our local run configuration compared to what we use in our production systems. Detailed properties for Redisson (described in redisson.yml) are the same for all environment, while things like the host, port or ssl properties can change depending on the environment where the application is running.
Describe the solution you'd like
If the merging of application.yml(or application-local.yml) with redisson.yml is not possible, can we then maybe have some feature where we fill variables with Spring Boot values. That way the redisson.yml would be able to look like:
# redisson.yml
singleServerConfig:
  idleConnectionTimeout: 10000
  connectTimeout: 10000
  timeout: 3000
  retryAttempts: 3
  retryInterval: 1500
  subscriptionsPerConnection: 5
  address: "redis://${REDIS_HOSTNAME}:6379"
  subscriptionConnectionMinimumIdleSize: 1
  subscriptionConnectionPoolSize: 50
  connectionMinimumIdleSize: 10
  connectionPoolSize: 64
  dnsMonitoringInterval: 5000
In such a way, we would be able to create an application-local.yml that looks like this:
# application-local.yml
REDIS_HOSTNAME: localhost
With Spring Boot values I mean the values described by externalized configuration here. That way there are many ways to inject variables into the configuration of Redisson.
Describe alternatives you've considered
We currently are using the following as an application.yml:
# application.yml
spring:
  redis:
    redisson:
      config: |
        singleServerConfig:
          idleConnectionTimeout: 10000
          connectTimeout: 10000
          timeout: 3000
          retryAttempts: 3
          retryInterval: 1500
          subscriptionsPerConnection: 5
          address: "redis://${ELASTICACHE_URL}:6379"
          subscriptionConnectionMinimumIdleSize: 1
          subscriptionConnectionPoolSize: 50
          connectionMinimumIdleSize: 10
          connectionPoolSize: 64
          dnsMonitoringInterval: 5000
This works for us but puts a lot of detail for a specific dependency in the application.yml. These fields are never changed. The values are prone to mistakes.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3207
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Environment:
spring-boot: 2.3.4.RELEASE
hibernate-core: 5.4.21.Final
redisson-spring-boot-starter: 3.13.6
redisson-hibernate-53: 3.13.6
Expected behavior
Setting CACHE_REGION_PREFIX for hibernate should be used by redisson hibernate and the entities should be stored under the entity key with the defined prefix.
Actual behavior
The prefix is not used and the entities are stored under the default keyspace.
Steps to reproduce or test case
Redis version
6.0.9
Redisson version
3.13.6
Redisson configuration
    @Bean
    public LocalContainerEntityManagerFactoryBean entityManagerFactory(DataSource dataSource) {
        LocalContainerEntityManagerFactoryBean emFactoryBean = new LocalContainerEntityManagerFactoryBean();
        emFactoryBean.setDataSource(dataSource);
        emFactoryBean.setPackagesToScan(new String[]{ENTITY_PACKAGE});

        JpaVendorAdapter vendorAdapter = getJpaVendorAdapter();
        emFactoryBean.setJpaVendorAdapter(vendorAdapter);

        Map<String, Object> properties = emFactoryBean.getJpaPropertyMap();

        String ddlAction = Action.NONE.name().toLowerCase();
        properties.put(AvailableSettings.HBM2DDL_AUTO, ddlAction);
        properties.put(AvailableSettings.USE_SECOND_LEVEL_CACHE, true);
        properties.put(AvailableSettings.USE_QUERY_CACHE, true);
        properties.put(AvailableSettings.JPA_SHARED_CACHE_MODE, SharedCacheMode.ALL);
        properties.put(AvailableSettings.DEFAULT_CACHE_CONCURRENCY_STRATEGY, CacheConcurrencyStrategy.TRANSACTIONAL);
        properties.put(AvailableSettings.CACHE_REGION_FACTORY, regionFactory);
        properties.put(AvailableSettings.CACHE_KEYS_FACTORY, SecondLevelCacheKeysFactory.class);

        // REGION PREFIX IS IGNORED
        properties.put(AvailableSettings.CACHE_REGION_PREFIX, DomainCachingConfiguration.NAMESPACE);

        return emFactoryBean;
    }
@Configuration
@Conditional(OnRedisCondition.class)
public class RedissonPersistenceCachingConfiguration extends RedissonRegionFactory {
    /**
     * To avoid loading the redisson config file. There's no file existing. Config programmatically.
     * @param properties
     * @return
     */
    @Override
    protected RedissonClient createRedissonClient(Map properties) {
        return RedisCachingConfiguration.REDISSON_CLIENT_PERSISTENCE;
    }
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3208
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
When a fresh copy of the repository is cloned, the tests of should all pass.
Actual behavior
When running mvn clean install in the redisson-spring-boot-starter module the build failed on failing tests. I got the following error:
com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'ï': was expecting (JSON String, Number, Array, Object or token 'null', 'true' or 'false')
 at [Source: (String)"ï»¿singleServerConfig:
  address: "redis://127.0.0.1:6379""; line: 1, column: 2]

When I run the tests with an IntelliJ run configuration the test does pass.
Steps to reproduce or test case
OS: Windows
Edition: Windows 10 Enterprise
Version: 2004
OS build 19041.572
JDK: AdoptOpenJDK 8u275-b01
Maven: 3.6.3
IntelliJ: 2020.2
git clone git@github.com:redisson/redisson.git
mvn clean install

Redis version
I think this is not relevant, but it Redis 6.0.6 running on Docker.
Redisson version
3.13.7-SNAPSHOT
Redisson configuration
None
What is the actual problem?
I think you'll see in the above exception log that there are some (probably) unexpected character in the redisson.yaml that is used by the tests for redisson-spring-boot-starter. I looked at the encoding of the redisson.yaml by using Notepad++. The result is that the encoding for the redisson.yaml file is: "UTF-8-BOM".
How to solve this issue?
Setting the encoding of this file to "UTF-8" results in the maven tests passing. After doing this, and looking into the git diff shows the following:
diff --git a/redisson-spring-boot-starter/src/test/resources/redisson.yaml b/redisson-spring-boot-starter/src/test/resources/redisson.yaml
index 28466f3ba..6d8f6d7f0 100644
--- a/redisson-spring-boot-starter/src/test/resources/redisson.yaml
+++ b/redisson-spring-boot-starter/src/test/resources/redisson.yaml
@@ -1,2 +1,2 @@
-<EF><BB><BF>singleServerConfig:
-  address: "redis://127.0.0.1:6379"
\ No newline at end of file
+singleServerConfig:
+  address: "redis://127.0.0.1:6379"

I am not sure what are the "".
Can I create a PR for this?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3209
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3210
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
no exception when use default config
Actual behavior
have exception, but if i set codec to JsonJacksonCodec, everything works
Steps to reproduce or test case
use defatult config with default MarshallingCodec
Redis version
redis 5, 6
Redisson version
3.13.0 - 3.13.6
Redisson configuration
Config config = new Config();
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3211
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am currently using AWS Redis Elasticache cluster with a simple setup
Redis Version 5.X
1 shard, 2 replica
final RBatch batch = redissonClient.createBatch();
batch.getKeys().deleteByPatternAsync(keyPattern.toString());
return batch.executeAsync()
                     .exceptionally(t -> LOG.warn("error when deleting"));

I sometimes get an error like below where keyPattern is "test-key*" which is confusing considering that I only have 1 shard.
org.redisson.client.RedisException: ERR Error running script (call to f_101594a3a4c130bec4a4a379cda6d00cb1c5ff1a): @user_script:1: @user_script: 1: Lua script attempted to access a non local key in a cluster node . channel: [id: 0xf885399a, L:/172.25.76.177:60542 - R:/172.18.11.62:6379] command: (EVAL), params: [local keys = redis.call('keys', ARGV[1]) local n = 0 for i=1, #keys,5000 do n = n + redis.call('del'..., 0, test-key*] (Most recent call first)
Any idea what could be going here?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3212
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Can we share sharing the same Redisson client for both Hibernate L2 cache and Spring Cache Abstraction?
I am configuring redisson as my l2 cache in application.propeties
  region:
    factory_class: org.redisson.hibernate.RedissonRegionFactory
  redisson:
    config: redisson.json

Currently, I am creating a Cache manager bean using the below code, which creates a new connection to redis.
    @Bean
    public RedissonClient redissonClient() throws IOException {
        Resource resource = resourceLoader.getResource("classpath:/" + redissonConfigFile);
        Config config = Config.fromYAML(resource.getInputStream());
        return Redisson.create(config);
    }

    @Bean
    public CacheManager cacheManager(RedissonClient redissonClient) {
        return new RedissonSpringCacheManager(redissonClient);
    }

I want to create a Cache Manager bean use the same connection configured in application properties. Is it possible to do that?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3213
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
public static void main(String[] args) {
        Config config = new Config();
        config.useSingleServer().setAddress("redis://localhost:6379").setDatabase(15);
        config.setCodec(new JsonJacksonCodec());
        config.setThreads(16);
        config.setNettyThreads(32);
        config.setTransportMode(TransportMode.NIO);
        RedissonClient redissonClient = Redisson.create(config);

        ExecutorOptions options = ExecutorOptions.defaults();
        RExecutorService executor = redissonClient.getExecutorService("myExecutor",options);
        RExecutorFuture<TenantPO> submit = executor.submitAsync(new Task());
    }

    public static class Task implements Callable<Long>{

        @Override
        public Long call() throws Exception {
            System.out.println("task over");
            return 233L;
        }
    }
我用15号库想提交一个任务，但是没有执行，结果发现，任务信息保存在0号库里，想问下为什么
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3214
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case
` RMap<Integer, Classify> map = redissonClient.getMap(RedisNameSpace.PermanentCache.classify);
    for (Map.Entry<Integer, Classify> integerClassifyEntry : map.entrySet()) {  //here is ok
        System.out.println(integerClassifyEntry); // printData:9241=Classify(id=9241)
    }

    for (Integer integer : map.keySet()) { //here will throw java.lang.ClassCastException: java.lang.String cannot be cast to 
                                                               //java.lang.Integer
        System.out.println(integer); 
    }`

Redis version
Redisson version
3.13.6
Redisson configuration
default config
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3215
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3216
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
public class RedisTest extends BaseTest {
@Autowired
private RedisTemplate redisTemplate;

@Test
public void testGeo() {
    String key = "test_geo_key";
    Point point = new Point(116.401001, 40.119499);
    redisTemplate.opsForGeo().add(key, point, "a");

    point = new Point(111.545998, 36.133499);
    redisTemplate.opsForGeo().add(key, point, "b");

    point = new Point(111.483002, 36.030998);
    redisTemplate.opsForGeo().add(key, point, "c");
    Circle within = new Circle(116.401001, 40.119499, 80000);
    RedisGeoCommands.GeoRadiusCommandArgs args = RedisGeoCommands.GeoRadiusCommandArgs.newGeoRadiusArgs().includeCoordinates();
    GeoResults<RedisGeoCommands.GeoLocation<String>> res = redisTemplate.opsForGeo().radius(key, within, args);
    System.out.println(res);
}

}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3217
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
I should be able to serialize any Pojo.
Actual behavior
java.lang.IllegalArgumentException: Class is not registered: com.rakuten.rapid.cache.v2.entity.TopEntity
Note: To register this class use: kryo.register(com.rakuten.rapid.cache.v2.entity.TopEntity.class);
at com.esotericsoftware.kryo.Kryo.getRegistration(Kryo.java:512)
at com.esotericsoftware.kryo.util.DefaultClassResolver.writeClass(DefaultClassResolver.java:119)
at com.esotericsoftware.kryo.Kryo.writeClass(Kryo.java:546)
at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:641)
at org.redisson.codec.KryoCodec$2.encode(KryoCodec.java:87)

Steps to reproduce or test case
With those versions of Redisson and Kryo. Just set up a simple client. The boolean "RegistrationRequired" is true by default now on Kryo and any new serialization will fail.
Redis version
Any
Redisson version
3.13.6
Redisson configuration
Use KryoCodec
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3218
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3219
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3220
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
i have seen on the wiki that currently redisson officially supports spring-boot up to version 2.3, the same for spring-session and spring-data. which version of reddisson library should I use when running with spring-boot 2.4.0 and spring-session 2020.0.1?
compile 'org.springframework.session:spring-session-core:2.3.1.RELEASE'
compile 'org.redisson:redisson-spring-data-23:3.13.6'
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3221
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is your feature request related to a problem? Please describe.
I have an application that is using Hazelcast "near cache" extensively and I'm evaluating a migration to Redis using Redisson "local cache" because I would like to use the AWS ElastiCache Redis service. This application does thousands of cache reads for every user request, so the "local cache" is really needed.
For testing purposes, I launched the same request twice to this application using Hazelcast and twice using Redis, and I saw that the second execution time for the Redis application was higher than the second execution time for the Hazelcast application. It was very surprising considering that the second request should read the data from the "local cache" (redisson).
I debugged the application code and I found that it does hundreds of cache misses. On the othe hand, I found that Redisson only updates the local cache when reading the map value from redis gives a not null value. This redisson code is in RedissonLocalCachedMap.getAsync():
future.onComplete((value, e) -> {
    (...)
    if (value != null) {
        cachePut(cacheKey, key, value);
    }
});
So, considering that our application does hundreds of cache misses and that Redisson local cache always tries to read the value from redis (even when it tried to read the same key before), it is reasonable that our application performs worse than expected.
Describe the solution you'd like
In order to improve our application performance when using Redis I think that it would be helpful to be able to add null values to the Redisson local cache, maybe adding an extra option in LocalCachedMapOptions; something like cacheNullValues, with a false value by default. I think that something related was fixed in #928 and #853
Describe alternatives you've considered
I have not considered an alternative 😞
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3222
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3223
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am trying to synchronise my APIs using Redisson semaphores. Here is the code:
`@Aspect
@component
@slf4j
public class SerialiseRequestsOnDistributedMutexAspect {
private final String lockOn = "LockOn";
@Autowired(required = false)
RedissonClient client;
@around("@annotation(somepath)")
@SuppressWarnings("unchecked")
public DeferredResult<ResponseEntity<?>> controllerProxy(ProceedingJoinPoint pjp)
throws Throwable {
try {

  Long startTime = System.currentTimeMillis();

  //extract parameters from the request
  Map<String, String> parameters = getParameters(pjp);
  
  //the semaphore key
  String lockOn = parameters.get(this.lockOn);
  
  RPermitExpirableSemaphore semaphore = client.getPermitExpirableSemaphore(lockOn);

  semaphore.trySetPermits(1);

  DeferredResult<ResponseEntity<?>> dr;

  MDC.clear();

  String permitId = getPermit(semaphore);

  if (null != permitId) {

    semaphore.updateLeaseTime(
        permitId, 60_000l, TimeUnit.MILLISECONDS);
    semaphore.expire(60_000l, TimeUnit.MILLISECONDS);

    try {
      Object result = pjp.proceed();
      dr = (DeferredResult<ResponseEntity<?>>) result;
      addCallbacksOnDeferredResult(dr, semaphore);
    } catch (Exception e) {
      semaphore.release(permitId);
      throw e;
    }
  } else {
    throw new RuntimeException("Similar request in progress");
  }
  return dr;
} catch (Exception e) {
  throw e;
}

}
private String getPermit(RPermitExpirableSemaphore semaphore) {
return semaphore.tryAcquire();
}
private void addCallbacksOnDeferredResult(
DeferredResult<ResponseEntity<?>> dr,
RPermitExpirableSemaphore lock) {
dr.onCompletion(
() -> {
MDC.clear();
lock.release(requestMetadata.permitId());
});
dr.onTimeout(
() -> {
MDC.clear();
lock.release(requestMetadata.permitId());
});
dr.onError(
(err) -> {
MDC.clear();
lock.release(requestMetadata.permitId());
});
}
}`
I have observed certain cases where the LockOn object in Redis is has its TTL set to -1. What this means that there is no TTL. But I am clearly setting it to 60s on a successful acquisition.
Steps To Reproduce: This happens only for a bunch of requests and is intermittent.
Redisson version: 3.13.4
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3224
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am trying to synchronise my APIs using Redisson semaphores. Here is the code:
@Aspect
@Component
@Slf4j
public class SerialiseRequestsOnDistributedMutexAspect {

  private final String lockOn = "LockOn";

  @Autowired(required = false)
  RedissonClient client;


  @Around("@annotation(somepath)")
  @SuppressWarnings("unchecked")
  public DeferredResult<ResponseEntity<?>> controllerProxy(ProceedingJoinPoint pjp)
      throws Throwable {

    try {

      Long startTime = System.currentTimeMillis();

      //extract parameters from the request
      Map<String, String> parameters = getParameters(pjp);
      
      //the semaphore key
      String lockOn = parameters.get(this.lockOn);
      
      RPermitExpirableSemaphore semaphore = client.getPermitExpirableSemaphore(lockOn);

      semaphore.trySetPermits(1);

      DeferredResult<ResponseEntity<?>> dr;

      MDC.clear();

      String permitId = getPermit(semaphore);

      if (null != permitId) {

        semaphore.updateLeaseTime(
            permitId, 60_000l, TimeUnit.MILLISECONDS);
        semaphore.expire(60_000l, TimeUnit.MILLISECONDS);

        try {
          Object result = pjp.proceed();
          dr = (DeferredResult<ResponseEntity<?>>) result;
          addCallbacksOnDeferredResult(dr, semaphore);
        } catch (Exception e) {
          semaphore.release(permitId);
          throw e;
        }
      } else {
        throw new RuntimeException("Similar request in progress");
      }
      return dr;
    } catch (Exception e) {
      throw e;
    }
  }

  private String getPermit(RPermitExpirableSemaphore semaphore) {
    return semaphore.tryAcquire();
  }

  private void addCallbacksOnDeferredResult(
      DeferredResult<ResponseEntity<?>> dr,
      RPermitExpirableSemaphore lock) {
    dr.onCompletion(
        () -> {
          MDC.clear();
          lock.release(requestMetadata.permitId());
        });
    dr.onTimeout(
        () -> {
          MDC.clear();
          lock.release(requestMetadata.permitId());
        });
    dr.onError(
        (err) -> {
          MDC.clear();
          lock.release(requestMetadata.permitId());
        });
  }
}

I have observed certain cases where the LockOn object in Redis is has its TTL set to -1. What this means that there is no TTL. But I am clearly setting it to 60s on a successful acquisition.
Steps To Reproduce: This happens only intermittently. I have been unable to reproduce it myself.
Redisson version: 3.13.4
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3225
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3226
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3227
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3228
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3229
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3230
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3231
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3232
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3233
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3234
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3235
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3236
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3237
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3238
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3239
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3240
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3241
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3242
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3243
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3244
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3245
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3246
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3247
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3248
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3249
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3250
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3251
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3252
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3253
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3254
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3255
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3256
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3257
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3258
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3259
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3260
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3261
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3262
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3263
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3264
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3265
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3266
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3267
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3268
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3269
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3270
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3271
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3272
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3273
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3274
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3275
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3276
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3277
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3278
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3279
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3280
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3281
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3282
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3283
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3284
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3285
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3286
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3287
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3288
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3289
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3290
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3291
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3292
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3293
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3294
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3295
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3296
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3297
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3298
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3299
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3300
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3301
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3302
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3303
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3304
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3305
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3306
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3307
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3308
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3309
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3310
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3311
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3312
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3313
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3314
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3315
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3316
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3317
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3318
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3319
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3320
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3321
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3322
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3323
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3324
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3325
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3326
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3327
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3328
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3329
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3330
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3331
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3332
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3333
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3334
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3335
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3336
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3337
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3338
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3339
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3340
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3341
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3342
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3343
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3344
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3345
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
flags field that “sentinel slaves xxx” command result contains “s_down” or “disconnected”, manager will freezed the node,
but master-link-status than “sentinel slaves xxx” command result is “err”, slave node is in “LOADING Redis is loading the dataset in memory” status, why not add this condition in slave node state check? just like
String ip = map.get("ip");
String port = map.get("port");
String flags = map.get("flags");
String masterHost = map.get("master-host");
String masterPort = map.get("master-port");
String masterLinkStatus = map.get("master-link-status");

RedisURI slaveAddr = toURI(ip, port);
if (flags.contains("s_down") || flags.contains("disconnected") || masterLinkStatus.contains("err")) {
    slaveDown(slaveAddr);
    continue;
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3346
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redis集群某节点发生主备切换后，开始报以下错误
error.log中报
org.redisson.client.RedisNodeNotFoundException: Node for slot: 1888 hasn't been discovered yet. Check cluster slots coverage using CLUSTER NODES command. Increase value of retryAttempts and/or retryInterval settings.
at org.redisson.connection.MasterSlaveConnectionManager.createNodeNotFoundFuture(MasterSlaveConnectionManager.java:578)
at org.redisson.connection.MasterSlaveConnectionManager.connectionReadOp(MasterSlaveConnectionManager.java:562)
at org.redisson.command.RedisExecutor.getConnection(RedisExecutor.java:648)
at org.redisson.command.RedisExecutor.execute(RedisExecutor.java:116)
at org.redisson.command.RedisExecutor$2.run(RedisExecutor.java:244)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:672)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:747)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:472)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
info.log中报（几分钟会报一次）
2021-01-15 11:19:16,155 [redisson-netty-5-5] INFO  o.r.cluster.ClusterConnectionManager.shutdownEntry(ClusterConnectionManager.java:254) - /172.28.9.49:9004 master and related slaves: [addr=redis://172.28.9.48:9001] removed
2021-01-15 11:19:16,155 [redisson-netty-5-5] INFO  o.r.cluster.ClusterConnectionManager.checkSlotsMigration(ClusterConnectionManager.java:701) - 5461 slots removed from redis://172.28.9.49:9004
2021-01-15 11:19:16,677 [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver.getClusterEndpoints(ConfigClusterResolver.java:43) - Resolving eureka endpoints via configuration
2021-01-15 11:19:46,256 [redisson-netty-5-3] INFO  o.r.c.p.MasterPubSubConnectionPool.lambda$run$0(ConnectionPool.java:167) - 1 connections initialized for /172.28.9.49:9004
2021-01-15 11:19:46,264 [redisson-netty-5-6] INFO  o.r.c.pool.MasterConnectionPool.lambda$run$0(ConnectionPool.java:167) - 24 connections initialized for /172.28.9.49:9004
2021-01-15 11:19:46,267 [redisson-netty-5-26] INFO  o.r.c.pool.PubSubConnectionPool.lambda$run$0(ConnectionPool.java:167) - 1 connections initialized for /172.28.9.48:9001
2021-01-15 11:19:46,290 [redisson-netty-5-16] INFO  o.r.cluster.ClusterConnectionManager.lambda$null$5(ClusterConnectionManager.java:325) - slaves: [redis://172.28.9.48:9001] added for slot ranges: [[0-5460]]
2021-01-15 11:19:46,291 [redisson-netty-5-16] INFO  o.r.cluster.ClusterConnectionManager.lambda$null$5(ClusterConnectionManager.java:332) - master: redis://172.28.9.49:9004 added for slot ranges: [[0-5460]]
2021-01-15 11:19:46,291 [redisson-netty-5-16] INFO  o.r.c.pool.SlaveConnectionPool.lambda$run$0(ConnectionPool.java:167) - 100 connections initialized for /172.28.9.48:9001
2021-01-15 11:19:51,317 [redisson-netty-5-5] INFO  o.r.cluster.ClusterConnectionManager.shutdownEntry(ClusterConnectionManager.java:254) - /172.28.9.49:9004 master and related slaves: [addr=redis://172.28.9.48:9001] removed
2021-01-15 11:19:51,318 [redisson-netty-5-5] INFO  o.r.cluster.ClusterConnectionManager.checkSlotsMigration(ClusterConnectionManager.java:701) - 5461 slots removed from redis://172.28.9.49:9004
2021-01-15 11:19:56,326 [redisson-netty-5-4] INFO  o.r.c.p.MasterPubSubConnectionPool.lambda$run$0(ConnectionPool.java:167) - 1 connections initialized for /172.28.9.49:9004
2021-01-15 11:19:56,334 [redisson-netty-5-7] INFO  o.r.c.pool.MasterConnectionPool.lambda$run$0(ConnectionPool.java:167) - 24 connections initialized for /172.28.9.49:9004
2021-01-15 11:19:56,338 [redisson-netty-5-3] INFO  o.r.c.pool.PubSubConnectionPool.lambda$run$0(ConnectionPool.java:167) - 1 connections initialized for /172.28.9.48:9001
2021-01-15 11:19:56,365 [redisson-netty-5-17] INFO  o.r.cluster.ClusterConnectionManager.lambda$null$5(ClusterConnectionManager.java:325) - slaves: [redis://172.28.9.48:9001] added for slot ranges: [[0-5460]]
2021-01-15 11:19:56,367 [redisson-netty-5-17] INFO  o.r.cluster.ClusterConnectionManager.lambda$null$5(ClusterConnectionManager.java:332) - master: redis://172.28.9.49:9004 added for slot ranges: [[0-5460]]
2021-01-15 11:19:56,367 [redisson-netty-5-17] INFO  o.r.c.pool.SlaveConnectionPool.lambda$run$0(ConnectionPool.java:167) - 100 connections initialized for /172.28.9.48:9001
redis集群信息CLUSTER NODES如下
CLUSTER NODES
d167ab629fd9e804b7b94d250b60634239899a77 172.28.9.48:9002@19002 myself,slave 3aa09cb227f90313f452c399c015767e2735dc19 0 1610699693000 2 connected
496cff30335016523fc8af38b3d2a64608e65afc 172.28.9.49:9003@19003 master - 0 1610699694293 3 connected 5461-10922
ef77423d42bde0d88f123f6bfdd235138b4ba864 172.28.9.48:9001@19001 slave b301296b5218c22332f77b1da719e5bb985170c2 0 1610699694000 9 connected
b301296b5218c22332f77b1da719e5bb985170c2 172.28.9.49:9004@19004 master - 0 1610699695295 9 connected 0-5460
eadbd9cc11b85bcf289b8a5963a99dcfff4b292a 172.28.9.50:9006@19006 slave 496cff30335016523fc8af38b3d2a64608e65afc 0 1610699693285 3 connected
3aa09cb227f90313f452c399c015767e2735dc19 172.28.9.50:9005@19005 master - 0 1610699696298 5 connected 10923-16383
Steps to reproduce or test case
网络波动时，某节点发生主备切换，才报以上错误，后续在redis安装的linux 中 ps -ef|grep redis 命令查看 实际redis服务所有节点都在运行，实际没有宕机
后续我将Redisson版本降至3.13.6后，没有报错，恢复正常
Redisson版本在3.10.6也不会报错
Redis version
4.0.14
Redisson version
3.14.1
Redisson configuration
	String redissonNodes = "172.28.9.48:9001,172.28.9.48:9002,172.28.9.49:9003,172.28.9.49:9004,172.28.9.50:9005,172.28.9.50:9006";
	String redissonPassword = "";
	Integer masterConnectionPoolSize = 200;
	Integer slaveConnectionPoolSize = 400;
	Integer slaveConnectionMinimumIdleSize = 100;
	Integer connectTimeout = 10000;
	Integer timeout = 10000;
	
	String[] hosts = redissonNodes.split(",");
	List<String> nodeList = new ArrayList<String>();
	for (String node : hosts) {
		nodeList.add("redis://" + node);
	}
	Config config = new Config();
	config.setCodec(new org.redisson.client.codec.StringCodec());
	ClusterServersConfig clusterServersConfig = config.useClusterServers().addNodeAddress(nodeList.toArray(new String[nodeList.size()]));
	if (redissonPassword != null && !"".equals(redissonPassword)) {
		clusterServersConfig.setPassword(redissonPassword);
	}
	clusterServersConfig.setMasterConnectionPoolSize(masterConnectionPoolSize);// 设置对于master节点的连接池中最大连接数
	clusterServersConfig.setSlaveConnectionPoolSize(slaveConnectionPoolSize);// 设置对于slave节点的连接池中最大连接数
	clusterServersConfig.setSlaveConnectionMinimumIdleSize(slaveConnectionMinimumIdleSize);
	clusterServersConfig.setConnectTimeout(connectTimeout);
	clusterServersConfig.setTimeout(timeout);
	return Redisson.create(config);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3347
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
env info：
jdk：1.8
redis：5.0.6
redission: 3.11.5
There are two data processing services here. When I use MapReduce to process data, the timeout (30 s) is set. However, when one of the services in the process of reducing data goes down unexpectedly, there is still no response from the map after the timeout, Does the data processed by the down service need to be reallocated to other machines? What is the specific meaning of this timeout? Is there something wrong with my use?
The following pictures are related information:
This is the normal data processing service:

This is a service that has been down unexpectedly:

This is the configuration code information:

This is the now time:

@mrniko   thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3348
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am using RMapCache<String,Object> with map option with write mode as WRITE_BEHIND
now when i put something in cache after particular delay it is getting executed after dealy provided,
but what i need is map writer should pick entry from map unless it is cache but it is not doing so it is only getting executed once.
Can anyone help what can i do in this case or there is any alternative?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3349
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RedissonLock uses pubsub mechanism to get notified about changes to lock. According to the cluster spec (https://redis.io/topics/cluster-spec), currently messages are simply broadcasted to all nodes in the cluster. It makes this lock inefficient in clusters with more than 5 nodes.
It would be great to have a spin lock with exponential backoff, because it works well with Redis's horizontal scaling.
If the idea seems fine to you, I can prepare a PR in a few days, just let me know. If not - sorry for taking your time, feel free to close the feature request.
Best regards,
Danila Varatyntsev
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3350
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3351
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
when i use redisson in spring cloud getway filter ,
public class AuthenticationFilter implements GlobalFilter {
    @Override
    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        // authenticate token
        RLock rLock = redissonClient.getLock("authenticate");
        try {
            boolean res = rLock.tryLock(0, TimeUnit.SECONDS);
            if(res) {
                // get lock success
                return chain.filter(exchange).then(Mono.fromRunnable(() -> {
                    // unlock
                    rLock.unlock();
                    }));
            }
        }
    }
}
but when i unlock this rLock report error log not locked by current thread , this rLock is not the same thread when i locked, how can i fix this problem
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3352
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3353
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redisson 3.14 - Redis Cluster with cluster-require-full-coverage=no throwing NPE
I believe the NullPointerException happens because the slot is not allocated.  "MasterSlaveEntry msEntry = getEntry(source);"
returns null, and then get() is called with a null parameter, which is not allowed by the ConcurrentHashMap
Entry entry = commands.get(msEntry);
java.lang.NullPointerException
at java.util.concurrent.ConcurrentHashMap.get(ConcurrentHashMap.java:947)
at org.redisson.command.BaseRedisBatchExecutor.addBatchCommandData(BaseRedisBatchExecutor.java:72)
at org.redisson.command.RedisBatchExecutor.execute(RedisBatchExecutor.java:53)
at org.redisson.command.CommandBatchService.async(CommandBatchService.java:144)
at org.redisson.command.CommandAsyncService.readAsync(CommandAsyncService.java:367)
at org.redisson.RedissonMap.getAllOperationAsync(RedissonMap.java:260)
at org.redisson.RedissonMap.getAllAsync(RedissonMap.java:226)

Could this be updated to return a Redisson exception?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3354
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior

org.redisson.client.RedisException: Unexpected exception while processing command

	at org.redisson.command.CommandAsyncService.convertException(CommandAsyncService.java:351)
	at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:148)
	at org.redisson.RedissonScript.eval(RedissonScript.java:229)
	at org.redisson.RedissonScript.eval(RedissonScript.java:85)
	at com.github.**.redis.**.next(RedisUnifiedIdExtension.java:88)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:220)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:53)
Caused by: java.io.IOException: Unsupported protocol version 51
	at org.jboss.marshalling.river.RiverUnmarshaller.start(RiverUnmarshaller.java:1360)
	at org.redisson.codec.MarshallingCodec$3.decode(MarshallingCodec.java:150)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:356)
	at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:400)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:365)
	at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:178)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:117)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:102)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502)
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:648)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:583)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:500)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:462)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)


Steps to reproduce or test case

lua

local array = {};
array[1]= redis.call('GET',KEYS[1]);
array[2]= redis.call('INCRBY', KEYS[1], 1);
return array;


java

        Object obj = script.eval(RScript.Mode.READ_WRITE, SCRIPT_AND_GET_BATCH, RScript.ReturnType.VALUE, keys,
                size);



Redis version
# Server
redis_version:6.0.9
redis_git_sha1:00000000
redis_git_dirty:0
redis_build_id:ff6bfe6a96f5bb05
redis_mode:standalone
os:Linux 3.10.0-1062.12.1.el7.x86_64 x86_64

Redisson version
3.14.1
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3355
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3356
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3357
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
redis cluster master down one by one.After a period of time, restart master node, redisson client can't update cluster state
Actual behavior
redisson can't write command to master, and report error.
Steps to reproduce or test case
It doesn't have to happen
1.test case
3 master and 3 slave

master 1 down and wait slave 1 become master
master 2 down and wait slave 2 become master
master 3 down and wait slave 3 become master
restart all master and There's a certain probability

2.redisson can't update cluster state exception
WriteRedisConnectionException: Unable to write command into connection! Node source: NodeSource [slot=9394, addr=null, redisClient=null, redirect=null, entry=null], connection:
	at org.redisson.command.RedisExecutor.checkWriteFuture(RedisExecutor.java:271) ~[redisson-3.14.0.jar:3.14.0]
	at org.redisson.command.RedisExecutor.access$100(RedisExecutor.java:58) ~[redisson-3.14.0.jar:3.14.0]
	at org.redisson.command.RedisExecutor$1.operationComplete(RedisExecutor.java:156) ~[redisson-3.14.0.jar:3.14.0]
	at org.redisson.command.RedisExecutor$1.operationComplete(RedisExecutor.java:153) ~[redisson-3.14.0.jar:3.14.0]
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578) ~[netty-common-4.1.54.Final.jar:4.1.54.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552) ~[netty-common-4.1.54.Final.jar:4.1.54.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491) ~[netty-common-4.1.54.Final.jar:4.1.54.Final]
	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616) ~[netty-common-4.1.54.Final.jar:4.1.54.Final]
	at io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:609) ~[netty-common-4.1.54.Final.jar:4.1.54.Final]
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117) ~[netty-common-4.1.54.Final.jar:4.1.54.Final]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:1009) ~[netty-transport-4.1.54.Final.jar:4.1.54.Final]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:870) ~[netty-transport-4.1.54.Final.jar:4.1.54.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367) ~[netty-transport-4.1.54.Final.jar:4.1.54.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717) ~[netty-transport-4.1.54.Final.jar:4.1.54.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764) ~[netty-transport-4.1.54.Final.jar:4.1.54.Final]
	at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071) ~[netty-transport-4.1.54.Final.jar:4.1.54.Final]
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164) ~[netty-common-4.1.54.Final.jar:4.1.54.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472) ~[netty-common-4.1.54.Final.jar:4.1.54.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500) ~[netty-transport-4.1.54.Final.jar:4.1.54.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[netty-common-4.1.54.Final.jar:4.1.54.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.54.Final.jar:4.1.54.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.54.Final.jar:4.1.54.Final]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]
Caused by: io.netty.channel.StacklessClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source) ~[netty-transport-4.1.54.Final.jar:4.1.54.Final]
3. a redisson-netty thread is runnable and recursion all the time
"redisson-netty-2-19" #31 prio=5 os_prio=0 tid=0x00007fac4c03c800 nid=0x4cd5 runnable [0x00007fac9c511000]
   java.lang.Thread.State: RUNNABLE
	at java.lang.Throwable.fillInStackTrace(Native Method)
	at java.lang.Throwable.fillInStackTrace(Throwable.java:783)
	- locked <0x00000000fbf21860> (a org.redisson.client.RedisConnectionException)
	at java.lang.Throwable.<init>(Throwable.java:265)
	at java.lang.Exception.<init>(Exception.java:66)
	at java.lang.RuntimeException.<init>(RuntimeException.java:62)
	at org.redisson.client.RedisException.<init>(RedisException.java:35)
	at org.redisson.client.RedisConnectionException.<init>(RedisConnectionException.java:28)
	at org.redisson.connection.pool.ConnectionPool.get(ConnectionPool.java:218)
	at org.redisson.connection.pool.PubSubConnectionPool.get(PubSubConnectionPool.java:32)
	at org.redisson.connection.pool.PubSubConnectionPool.get(PubSubConnectionPool.java:39)
	at org.redisson.connection.balancer.LoadBalancerManager.nextPubSubConnection(LoadBalancerManager.java:204)
	at org.redisson.connection.MasterSlaveEntry.nextPubSubConnection(MasterSlaveEntry.java:519)
	at org.redisson.pubsub.PublishSubscribeService.nextPubSubConnection(PublishSubscribeService.java:267)
	at org.redisson.pubsub.PublishSubscribeService.connect(PublishSubscribeService.java:273)
	at org.redisson.pubsub.PublishSubscribeService.access$200(PublishSubscribeService.java:55)
	at org.redisson.pubsub.PublishSubscribeService$1.run(PublishSubscribeService.java:164)
	at org.redisson.pubsub.AsyncSemaphore.tryRun(AsyncSemaphore.java:86)
	at org.redisson.pubsub.AsyncSemaphore.acquire(AsyncSemaphore.java:66)
	at org.redisson.pubsub.PublishSubscribeService.subscribe(PublishSubscribeService.java:150)
	at org.redisson.pubsub.PublishSubscribeService.lambda$subscribe$0(PublishSubscribeService.java:127)
	at org.redisson.pubsub.PublishSubscribeService$$Lambda$68/1506703662.run(Unknown Source)
	at org.redisson.pubsub.AsyncSemaphore.tryRun(AsyncSemaphore.java:86)
	at org.redisson.pubsub.AsyncSemaphore.acquire(AsyncSemaphore.java:66)
	at org.redisson.pubsub.PublishSubscribeService.subscribe(PublishSubscribeService.java:121)
	at org.redisson.pubsub.PublishSubscribeService.subscribe(PublishSubscribeService.java:115)
	at org.redisson.pubsub.PublishSubscribeService.subscribe(PublishSubscribeService.java:575)
	at org.redisson.pubsub.PublishSubscribeService.lambda$subscribe$8(PublishSubscribeService.java:578)
	at org.redisson.pubsub.PublishSubscribeService$$Lambda$108/720202126.accept(Unknown Source)
	at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:183)
	at org.redisson.misc.RedissonPromise$$Lambda$2/1011276990.operationComplete(Unknown Source)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:571)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:550)
	at io.netty.util.concurrent.DefaultPromise.access$200(DefaultPromise.java:35)
	at io.netty.util.concurrent.DefaultPromise$1.run(DefaultPromise.java:502)
	at io.netty.util.concurrent.ImmediateEventExecutor.execute(ImmediateEventExecutor.java:118)
	at io.netty.util.concurrent.DefaultPromise.safeExecute(DefaultPromise.java:842)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:499)
	at io.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:184)
	at org.redisson.misc.RedissonPromise.onComplete(RedissonPromise.java:181)
	at org.redisson.pubsub.PublishSubscribeService.subscribe(PublishSubscribeService.java:576)
	at org.redisson.pubsub.PublishSubscribeService.lambda$subscribe$8(PublishSubscribeService.java:578)
	at org.redisson.pubsub.PublishSubscribeService$$Lambda$108/720202126.accept(Unknown Source)
	at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:183)
	at org.redisson.misc.RedissonPromise$$Lambda$2/1011276990.operationComplete(Unknown Source)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)
	at io.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:184)
	at org.redisson.misc.RedissonPromise.onComplete(RedissonPromise.java:181)
	at org.redisson.pubsub.PublishSubscribeService.subscribe(PublishSubscribeService.java:576)
	at org.redisson.pubsub.PublishSubscribeService.lambda$subscribe$8(PublishSubscribeService.java:578)
	at org.redisson.pubsub.PublishSubscribeService$$Lambda$108/720202126.accept(Unknown Source)
	at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:183)
	at org.redisson.misc.RedissonPromise$$Lambda$2/1011276990.operationComplete(Unknown Source)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)
	at io.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:184)
	at org.redisson.misc.RedissonPromise.onComplete(RedissonPromise.java:181)
	at org.redisson.pubsub.PublishSubscribeService.subscribe(PublishSubscribeService.java:576)
	at org.redisson.pubsub.PublishSubscribeService.lambda$subscribe$8(PublishSubscribeService.java:578)
	at org.redisson.pubsub.PublishSubscribeService$$Lambda$108/720202126.accept(Unknown Source)
	at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:183)
	at org.redisson.misc.RedissonPromise$$Lambda$2/1011276990.operationComplete(Unknown Source)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)
	at io.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:184)
	at org.redisson.misc.RedissonPromise.onComplete(RedissonPromise.java:181)
	at org.redisson.pubsub.PublishSubscribeService.subscribe(PublishSubscribeService.java:576)
	at org.redisson.pubsub.PublishSubscribeService.lambda$subscribe$8(PublishSubscribeService.java:578)
	at org.redisson.pubsub.PublishSubscribeService$$Lambda$108/720202126.accept(Unknown Source)
	at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:183)
	at org.redisson.misc.RedissonPromise$$Lambda$2/1011276990.operationComplete(Unknown Source)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)
	at io.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:184)
	at org.redisson.misc.RedissonPromise.onComplete(RedissonPromise.java:181)
	at org.redisson.pubsub.PublishSubscribeService.subscribe(PublishSubscribeService.java:576)
	at org.redisson.pubsub.PublishSubscribeService.lambda$subscribe$8(PublishSubscribeService.java:578)
	at org.redisson.pubsub.PublishSubscribeService$$Lambda$108/720202126.accept(Unknown Source)
	at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:183)
	at org.redisson.misc.RedissonPromise$$Lambda$2/1011276990.operationComplete(Unknown Source)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)
	at io.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:184)
	at org.redisson.misc.RedissonPromise.onComplete(RedissonPromise.java:181)
	at org.redisson.pubsub.PublishSubscribeService.subscribe(PublishSubscribeService.java:576)
	at org.redisson.pubsub.PublishSubscribeService.lambda$subscribe$8(PublishSubscribeService.java:578)
	at org.redisson.pubsub.PublishSubscribeService$$Lambda$108/720202126.accept(Unknown Source)
	at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:183)
	at org.redisson.misc.RedissonPromise$$Lambda$2/1011276990.operationComplete(Unknown Source)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)
	at io.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:184)
	at org.redisson.misc.RedissonPromise.onComplete(RedissonPromise.java:181)
	at org.redisson.pubsub.PublishSubscribeService.subscribe(PublishSubscribeService.java:576)
	at org.redisson.pubsub.PublishSubscribeService.lambda$reattachPubSubListeners$7(PublishSubscribeService.java:568)
	at org.redisson.pubsub.PublishSubscribeService$$Lambda$107/1175549604.accept(Unknown Source)
	at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:187)
	at org.redisson.misc.RedissonPromise$$Lambda$2/1011276990.operationComplete(Unknown Source)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)
	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)
	at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:605)
	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)
	at org.redisson.misc.RedissonPromise.trySuccess(RedissonPromise.java:82)
	at org.redisson.pubsub.PublishSubscribeService$5$1$1.onStatus(PublishSubscribeService.java:430)
	at org.redisson.pubsub.PubSubConnectionEntry$1.onStatus(PubSubConnectionEntry.java:187)
	at org.redisson.client.RedisPubSubConnection.onMessage(RedisPubSubConnection.java:72)
	at org.redisson.client.RedisPubSubConnection$1.operationComplete(RedisPubSubConnection.java:116)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:571)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:550)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)
	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)
	at io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:609)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:1009)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:870)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)
	at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(Redefined)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
	at io.netty.channel.nio.NioEventLoop.run(Redefined)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:745)
4.Redis version
6.0.9
5.Redisson version
3.14.1
6.Redisson configuration
clusterServersConfig:
  idleConnectionTimeout: 60000
  connectTimeout: 10000
  timeout: 60000
  retryAttempts: 3
  retryInterval: 3000
  failedSlaveReconnectionInterval: 3000
  failedSlaveCheckInterval: 60000
  password: "xuanwu-T3st*17"
  subscriptionsPerConnection: 5
  clientName: null
  loadBalancer: !<org.redisson.connection.balancer.RoundRobinLoadBalancer> {}
  subscriptionConnectionMinimumIdleSize: 1
  subscriptionConnectionPoolSize: 4
  slaveConnectionMinimumIdleSize: 16
  slaveConnectionPoolSize: 64
  masterConnectionMinimumIdleSize: 16
  masterConnectionPoolSize: 64
  readMode: "MASTER_SLAVE"
  subscriptionMode: "SLAVE"
  nodeAddresses:
    - "redis://172.16.0.114:8001"
    - "redis://172.16.0.114:8002"
    - "redis://172.16.0.114:8003"
    - "redis://172.16.0.115:8001"
    - "redis://172.16.0.115:8002"
    - "redis://172.16.0.115:8003"
  scanInterval: 2000
  pingConnectionInterval: 5000
  keepAlive: true
  tcpNoDelay: true
codec: !<org.redisson.codec.JsonJacksonCodec> {}
transportMode: "NIO"
useScriptCache: true
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3358
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3359
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Got this exception continuously for a minute and then became fine. Would like to know what is the root cause of this.
Using Redisson : 3.13.2
org.redisson.client.RedisTimeoutException: Command still hasn’t been written into connection!
Increase nettyThreads and/or retryInterval settings.
Payload size in bytes: 0. Node source: NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry
[masterEntry=[freeSubscribeConnectionsAmount=4, freeSubscribeConnectionsCounter=value:50:queue:0, freeConnectionsAmount=33,
freeConnectionsCounter=value:62:queue:0, freezed=false,
freezeReason=null, client=[addr=], nodeType=MASTER,
firstFail=0]]], connection: RedisConnection@145638153
[redisClient=[addr=], channel=[id: 0x20213438,
L:/10.20.13.18:45856 - R:*****], currentCommand=null],
command: null, params: null after 3 retry attempts
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3360
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redisson-all-3.12.1
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3361
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3362
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3363
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Use version redisson-all-3.12.1
Data abnormal under high concurrency
normal data
"roleId2": "ROLEINFO#7001#21693#4002#4",
Fault data
"roleId2": "com.game.logical.role.beans.OtherHeroBean@5300e72",
"roleId2": [10006,10001,10007,12001],
"roleId2": [],
All of the places we assign are strings
Under what circumstances does this happen to the data or is it a bug that has been fixed? If so, in what version did you change those things
我们有个数据是string  所有赋值的地方也是string  数据会莫名其妙变成对象 不知道是写的问题还是读的问题  取出错误数据后使用会造成jvm宕机 不是必现 有概率出现
什么情况下数据会出现这种情况  还是这是个bug 已经修复  如果已经修复 是在哪个版本 修改了那些东西
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3364
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3365
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I want to implement query the message that exists in the RDelayQueue, and remove if it exists function.
The message DelayEvent is
`
@DaTa
@builder
@NoArgsConstructor
@AllArgsConstructor
@accessors(chain = true)
@EqualsAndHashCode(of = {"id"})
public class DelayEvent implements Serializable {
/**
 * PkId
 */
private String id;

/**
 * DelayEventEnum
 */
private E eventType;

}
`
The value is ture about this TestCase:
`
@SneakyThrows
@Test
public void isContain() {

    DelayEvent<DelayEventEnum> delayEvent = new DelayEvent<>();
    delayEvent.setId("123");
    delayEvent.setEventType(DelayEventEnum.CNFC_CLEAR_EVENT);

    redissonMessageTemplate.sendWithDelay("testQ", delayEvent, 600000);

    DelayEvent<DelayEventEnum> delayEventAlready = new DelayEvent<>();
    delayEventAlready.setId("123");
    delayEventAlready.setEventType(DelayEventEnum.CNFC_CLEAR_EVENT);
    boolean isContain = redissonMessageTemplate.valExists("testQ", delayEventAlready);
    Assert.assertTrue(isContain);  //true
}

`
The value is false about TestCase in the below:
`
@SneakyThrows
@Test
public void isContain() {

    DelayEvent<DelayEventEnum> delayEvent = new DelayEvent<>();
    delayEvent.setId("123");
    delayEvent.setEventType(DelayEventEnum.CNFC_CLEAR_EVENT);

    redissonMessageTemplate.sendWithDelay("testQ", delayEvent, 600000);

    DelayEvent<DelayEventEnum> delayEventAlready = new DelayEvent<>();
    delayEventAlready.setId("123");
    boolean isContain = redissonMessageTemplate.valExists("testQ", delayEventAlready);
    Assert.assertTrue(isContain); //false
}

`
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3366
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi, I used redisson-tomcat-7 in my project.
Everything is ok.
and I tested how to works when redis down. Tomcat returned 500 Error.
org.redisson.client.WriteRedisConnectionException: Unable to write command into connection! Node source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null], connection: RedisConnection@1177986280 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x015ae5b0, L:0.0.0.0/0.0.0.0:58778], currentCommand=null], command: (HSET), params: [xxxxxx:redisson:tomcat_session:17BE13F676058A28AEBA5A80A5D29AF4.xxxxxx11, PooledUnsafeDirectByteBuf(ridx: 0, widx: 24, cap: 256), PooledUnsafeDirectByteBuf(ridx: 0, widx: 32, cap: 256)] after 3 retry attempts
        at org.redisson.command.RedisExecutor.checkWriteFuture(RedisExecutor.java:271)
        at org.redisson.command.RedisExecutor.access$100(RedisExecutor.java:58)
        at org.redisson.command.RedisExecutor$1.operationComplete(RedisExecutor.java:156)
        at org.redisson.command.RedisExecutor$1.operationComplete(RedisExecutor.java:153)
        at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)
        at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)
        at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)
        at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)
        at io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:609)
        at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:1009)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:870)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)
        at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
Caused by: io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)

My question is

Have a Bypass Mode? when redis down.(Use Local stored sessions)
If exist, Let me know how to use Bypass Mode.

Thanks.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3367
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3368
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Can RLocalCachedMap be used with Broadcast mode tracking?
In Redis CLI we would enable this as "CLIENT TRACKING on REDIRECT 10 BCAST PREFIX"
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3369
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redisson version
<dependency>
    <groupId>org.redisson</groupId>
    <artifactId>redisson-spring-boot-starter</artifactId>
    <version>3.14.0</version>
</dependency>
config
@Bean
RedisMessageListenerContainer container(RedisConnectionFactory redisConnectionFactory) {
    RedisMessageListenerContainer container = new RedisMessageListenerContainer();
    container.setConnectionFactory(redisConnectionFactory);

    container.addMessageListener(new MyListener(), new PatternTopic("__keyspace@0__:mykey"));
    container.addMessageListener(new MyListener(), new PatternTopic("__keyevent@0__:del"));
    return container;
}

static class MyListener implements MessageListener {
    @Override
    public void onMessage(Message message, byte[] pattern) {
        printMsg("my custom", message);
    }
}

public static void printMsg(String prefix, Message message) {
    System.out.println(prefix + " -> body: " + new String(message.getBody()));
    System.out.println(prefix + " -> channel: " + new String(message.getChannel()));
}
test
@Test
public void test02(){
    redisTemplate.opsForValue().set("mykey", "2");
    redisTemplate.delete("mykey");
    String next = new Scanner(System.in).next();
}
When not using reidsson
my listener -> body: set;  channel: __keyspace@0__:mykey
my listener -> body: del;  channel: __keyspace@0__:mykey
my listener -> body: mykey;  channel: __keyevent@0__:del

use redisson

How can I get the same result as above?

my listener -> body: set;  channel: __keyspace@0__:mykey
my listener -> body: set;  channel: __keyspace@0__:mykey
my listener -> body: del;  channel: __keyspace@0__:mykey
my listener -> body: mykey;  channel: __keyevent@0__:del
my listener -> body: mykey;  channel: __keyevent@0__:del
my listener -> body: del;  channel: __keyspace@0__:mykey
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3370
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Redisson should not exhaust the connection pool. In other words, it should release connections after every successful command.
And even if the pool is exhausted that should not make Redisson freeze completely until restarted I guess.
Actual behavior
We have experienced this error in production and now I have managed to reproduce the error with a clean Spring Boot project and one endpoint that executes a lua script on a redis cluster. I am using Locust (locust.io) for load testing.
More on how to reproduce the error later.
The screenshot shows an example Locust load test result: the first couple minutes are fine, I get around 1000 req per second and no errors.
But then requests start to fail and response times go up to ~6 seconds. Sometimes it takes around 5 minutes as the test is a bit random.
This is the log for one of those failed requests:
2021-01-21 10:41:17.497 ERROR 11426 --- [nio-8080-exec-2] o.a.c.c.C.[.[.[/].[dispatcherServlet]    : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.redisson.client.RedisTimeoutException: Unable to acquire connection! Increase connection pool size and/or retryInterval settings Node source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null], command: (EVAL), params: [local count
local ttl
count = redis.call("incr",KEYS[1])
ttl = redis.call("ttl",KEYS[1])
if tonumber..., 1, RATE_LIMIT_222.111.0.24, PooledUnsafeDirectByteBuf(ridx: 0, widx: 2, cap: 256)] after 0 retry attempts] with root cause

org.redisson.client.RedisTimeoutException: Unable to acquire connection! Increase connection pool size and/or retryInterval settings Node source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null], command: (EVAL), params: [local count
local ttl
count = redis.call("incr",KEYS[1])
ttl = redis.call("ttl",KEYS[1])
if tonumber..., 1, RATE_LIMIT_222.111.0.24, PooledUnsafeDirectByteBuf(ridx: 0, widx: 2, cap: 256)] after 0 retry attempts
	at org.redisson.command.RedisExecutor$2.run(RedisExecutor.java:181) ~[redisson-3.14.1.jar:3.14.1]
	at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:672) ~[netty-common-4.1.58.Final.jar:4.1.58.Final]
	at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:747) ~[netty-common-4.1.58.Final.jar:4.1.58.Final]
	at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:472) ~[netty-common-4.1.58.Final.jar:4.1.58.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.58.Final.jar:4.1.58.Final]
	at java.base/java.lang.Thread.run(Thread.java:834) ~[na:na]

Once this happens, even if you stop the test, Redisson no longer recovers. All requests fail after 6 seconds and you have to restart the server for it to work again.
By the way, those 6 seconds seem to be related to retryAttempts and retryInterval settings, but even if I set retryAttempts to zero, it still takes 1.5 seconds for each request to fail. Why?
Anyways, the main problem is that it fails.
Steps to reproduce or test case
I have created a clean spring boot project with one endpoint that executes a lua script. The script is basically rate limiting:
local count
local ttl
count = redis.call("incr",KEYS[1])
ttl = redis.call("ttl",KEYS[1])
if tonumber(ttl) == -1 then
    redis.call("expire",KEYS[1],ARGV[1])
end
return count

The endpoint just takes the IP of the request (from a "True-client-ip" header) and executes the script with it, returning the IP and the number of requests made so far this minute so you can see if it is working or not.
And the test makes a bunch of requests to this endpoint, faking the True-client-ip header with 50 different IPs in an attempt to simulate a realistic environment.
So, how to test:
demo.zip

Download and extract the demo project
Change RedissonConfiguration to connect to a redis cluster. Ours has 3 master and 3 slaves.
Start the server and see if localhost:8080/redisson works on your browser.
Start Locust with locust -f demo.py from the root project directory (you will need to install locust with pip3 install locust)
Open Locust UI on your browser (localhost:8089) and enter the following parameters:
20 users, 5 spawn rate, http://localhost:8080
Wait a couple minutes for the server to explode (hopefully)

Redis version
Redis server v=4.0.6
Redisson version
3.14.1
Redisson configuration
Nothing fancy:
clusterConfig.setMasterConnectionPoolSize(100);
clusterConfig.setSlaveConnectionPoolSize(64);
[and the redis cluster nodes]

And those numbers probably are not even important, but now that I have managed to reproduce the error I don't want to change them.
Check RedissonConfiguration for the details.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3371
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3372
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I am working on a API which is a high TPS one (around 10000 TPS) for both read and write.My API makes use of Redisson Open Source to connect to AWS Redis and I am making use of RLocalCachedMap so that frequently used objects will be fetched directly from LocalCache. I have the following questions:

What is the unit of cacheSize? Is it the number of records. If it is number of records that this local cache can hold, then I am getting many errors related to server crash and restart if I increase the count to higher values. Each object size should be around 800 bytes. I am not sure why that is happening. Do you think it might be with the RAM of the server on which it is deployed?
What happens if I dont set the cacheSize. Per documentation it is unbounded (default value is 0). So what would be the max limit this local cache size occupies and does it do the cache eviction internally if the LocalCacheMap feels the memory is nearing its capacity.
This question is with respect to the Redisson default Thread Pool size. Right now, I am using the default thread pool options. Do I need to fine tune the thread pools or the default thread pools can handle 10000 TPS
This question is with respect to CODEC Types.



I am having an object which has generic as one of its attribute. When I push the object to AWS Redis through redission using the codec types SNAPPYV2, SNAPPY it pushes the value and while retrieving from AWS Redis I could see the object having the values populated except the values of generics attribute (guess this codec type skips the generics at the time of deserialization). If I use JSON Jackson Codec, I could see the complete values being retrieved from AWS Redis. Would there be any codec that you suggest that handles generics or do i need to write custom serialization logic to handle.


What would be the best codec type if I am going to push the object as Map<String, Object> to AWS Redis. I ran performance test with different codec types and almost each of them returned in the same time (JSON Jackson COdec being little faster).


To meet the High TPS, what should be the object i need to consider while inserting it into AWS Redis, should the object be the regular POJO or can I have it as Map<String, Object>


Also, it would be helpful, if you can share any articles that helps in improving the performance using Redisson to connect to AWS Redis
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3373
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
It's not an issue, it's a question I have not found an answer to in documentation.
Will tasks that were submitted via redisson ExecutorService be executed if redis instance is restarted?
For example, a task is submitted with a delay 10mins and right after it was submitted, redis is restarted. What will happen with that submitted task?
What if I have AWS ElastiCache with Redis Replication Group and Multi-AZ enabled - will that task be executed if it was successfully replicated to read instances and primary instance failed?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3374
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello everybody,
I try to use Redisson  as second level cache in my jpa spring boot application it works fine i see that it cache entities in redis it just i need to set a time to live and time to idle on cache entries i use this configuration below but it doesn't work:
`spring.jpa.properties.hibernate.cache.use_second_level_cache=true
spring.cache.type=redis
hibernate.cache.redisson.entity.expiration.time_to_live=1000
hibernate.cache.redisson.entity.expiration.max_idle_time=1000
hibernate.cache.redisson.collection.expiration.time_to_live=1000
hibernate.cache.redisson.collection.expiration.max_idle_time=1000
spring.jpa.properties.hibernate.cache.region.factory_class=org.redisson.hibernate.RedissonRegionFactory
spring.jpa.properties.hibernate.cache.redisson.config=redisson/redisson-dev.yaml
spring.jpa.properties.hibernate.cache.redisson.fallback=true
spring.jpa.properties.javax.persistence.sharedCache.mode=ENABLE_SELECTIVE
server.port=8888
spring.datasource.url=jdbc:h2:mem:testdb
spring.datasource.driverClassName=org.h2.Driver
spring.datasource.username=sa
spring.datasource.password=
spring.jpa.database-plateform=org.hibernate.dialect.H2Dialect
spring.jpa.hibernate.ddl-auto=update
spring.h2.console.enabled=true
logging.level.org.hibernate.SQL=DEBUG
logging.level.org.hibernate.type=TRACE
`
i use  redisson-hibernate-53  as dependancy
Any help on this will help ,thank you.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3375
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am trying to use this library as my cache engine in my JPA application. As of now I understand if I configure this in my app - the app won't start if the Redis isn't running. Can I make this a soft dependency like if Redis server isn't running start the app without L2 cache?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3376
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3377
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
When redis runs for a period of time, there will be abnormal connection
Actual behavior
Steps to reproduce or test case
Redis version
Redis 5.0
Redisson version
3.14.0
Redisson configuration
Caused by: org.redisson.client.WriteRedisConnectionException: Unable to write command into connection! Node source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null], connection: RedisConnection@1080288245 [redisClient=[addr=redis://r-wz958c8j0wv3627b5h.redis.rds.aliyuncs.com:6379], channel=[id: 0x3d7905c2, L:/10.0.103.116:53932 ! R:r-wz958c8j0wv3627b5h.redis.rds.aliyuncs.com/10.0.103.175:6379], currentCommand=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@443b360c(failure: java.util.concurrent.CancellationException)], command=(PING), params=[], codec=org.redisson.client.codec.StringCodec]], command: (GET), params: [[115, 121, 110, 99, 84, 114, 97, 100, 101, 58, ...]] after 3 retry attempts
	at org.redisson.command.RedisExecutor.checkWriteFuture(RedisExecutor.java:271)
	at org.redisson.command.RedisExecutor.access$100(RedisExecutor.java:58)
	at org.redisson.command.RedisExecutor$1.operationComplete(RedisExecutor.java:156)
	at org.redisson.command.RedisExecutor$1.operationComplete(RedisExecutor.java:153)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:485)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:121)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1391)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:464)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more

Unable to write command into connection! Node source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null], connection: RedisConnection@1080288245 [redisClient=[addr=redis://r-wz958c8j0wv3627b5h.redis.rds.aliyuncs.com:6379], channel=[id: 0x3d7905c2, L:/10.0.103.116:53932 ! R:r-wz958c8j0wv3627b5h.redis.rds.aliyuncs.com/10.0.103.175:6379], currentCommand=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@443b360c(failure: java.util.concurrent.CancellationException)], command=(PING), params=[], codec=org.redisson.client.codec.StringCodec]], command: (GET), params: [[115, 121, 110, 99, 84, 114, 97, 100, 101, 58, ...]] after 3 retry attempts; nested exception is org.redisson.client.WriteRedisConnectionException: Unable to write command into connection! Node source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null], connection: RedisConnection@1080288245 [redisClient=[addr=redis://r-wz958c8j0wv3627b5h.redis.rds.aliyuncs.com:6379], channel=[id: 0x3d7905c2, L:/10.0.103.116:53932 ! R:r-wz958c8j0wv3627b5h.redis.rds.aliyuncs.com/10.0.103.175:6379], currentCommand=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@443b360c(failure: java.util.concurrent.CancellationException)], command=(PING), params=[], codec=org.redisson.client.codec.StringCodec]], command: (GET), params: [[115, 121, 110, 99, 84, 114, 97, 100, 101, 58, ...]] after 3 retry attempts
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3378
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3379
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I m exploring the use of write behind strategy, just wonder is it guarantee data sync to DB.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3380
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3381
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3382
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
Caused by: org.redisson.remote.RemoteServiceTimeoutException: No response after 1000ms
at org.redisson.remote.BaseRemoteProxy$1.run(BaseRemoteProxy.java:149)
at io.netty.util.concurrent.PromiseTask.runTask(PromiseTask.java:98)
at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:170)
at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)
... 4 more
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3383
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I got it wrong.Excuse me.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3384
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3385
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3386
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
what the optimal configuration when we use redisson as session manager and as a cache service , and the Redis cache provided by AWS elastic cache with a single endpoint that had replicas in the case of AZ failure ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3387
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RPC  very slowly. It takes about 1 second to get data for 10 times. How to solve this problem
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3388
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi
can I make redis strong consistency in active-active HA environment through Redisson config? We need a synchronous replication between redis nodes.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3389
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
RMapCacheReactive.getLock should return an instance of org.redisson.api.RLockReactive
Actual behavior
RMapCacheReactive.getLock returns an instance of org.redisson.RedissonLock and throws exception:
java.lang.ClassCastException: class org.redisson.RedissonLock cannot be cast to class org.redisson.api.RLockReactive (org.redisson.RedissonLock and org.redisson.api.RLockReactive are in unnamed module of loader 'app')

Steps to reproduce or test case
Start Redis from docker: docker run -p 6379:6379 redis:latest
Run the following code:
    RedissonReactiveClient redissonClient = Redisson.createReactive();
    RMapCacheReactive<Object, Object> rMapCache = redissonClient.getMapCache("test-cache");
    RLockReactive lock = rMapCache.getLock("key1");

Redis version
6.0
Redisson version
3.14.1
Redisson configuration
Defaults
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3390
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In cluster environment batch executed in map\reduce way. It aggregates commands for each node and sends them simultaneously, then result got from each node added to common result list.


    /**
     * Executes all operations accumulated during async methods invocations.
     * <p>
     * If cluster configuration used then operations are grouped by slot ids
     * and may be executed on different servers. Thus command execution order could be changed
     *
     * @return List with result object for each command
     * @throws RedisException in case of any error
     *
     */
    BatchResult<?> execute() throws RedisException;

Read above tips, I was not sure about responses order for origin commands.
Could you help me make sure about this?
1.When commands send group by slots, but I want know responses order is right with original commands?
thx~
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3391
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
If readLock is blocked by writeLock then readLock.isLocked() should return true (see step 4 below)
Actual behavior
If readLock is blocked by writeLock then readLock.isLocked() returns false. (see step 4 below)
Note: readlock.tryLock() behaves as expected
Steps to reproduce or test case

RLock writeLock = redissonClient.getReadWriteLock("some-id").writeLock()
RLock readLock = redissonClient.getReadWriteLock("some-id").readLock()
writeLock.tryLock(...)
readLock.isLocked()
writeLock.unlock()

Redis version
4.0.14
Redisson version
3.14.1
Redisson configuration
keepAlive: true
sslEnableEndpointIdentification: true
useSingleServer
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3392
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redisson-all-3.12.1.jar  upgrade  redisson-all-3.14.0.jar
compiler error
org.nustaq.serialization.annotations.Version;    cannot find      so  add  fst-2.57.jar
start fail
java.lang.NoClassDefFoundError: org/objenesis/Objenesis
at org.redisson.codec.FstCodec.(FstCodec.java:182)
at com.game.logical.global.RedissonUtils.buildRedissonConfig(RedissonUtils.java:45)
at com.game.logical.global.RedissonUtils.(RedissonUtils.java:35)
Caused by: java.lang.ClassNotFoundException: org.objenesis.Objenesis
at java.net.URLClassLoader$1.run(URLClassLoader.java:372)
at java.net.URLClassLoader$1.run(URLClassLoader.java:361)
at java.security.AccessController.doPrivileged(Native Method)
at java.net.URLClassLoader.findClass(URLClassLoader.java:360)
at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
add objenesis-2.5.1.jar
normal start
org.redisson.transaction.TransactionException: Unable to execute transaction
at org.redisson.transaction.RedissonTransaction.commit(RedissonTransaction.java:287)
at org.redisson.transaction.RedissonTransaction.commit(RedissonTransaction.java:258)
Caused by: org.redisson.client.RedisException: ERR unknown command 'WAIT'. channel: [id: 0x7208d34e, L:/10.2.100.83:20976 - R:/10.2.12.183:6379] command: (WAIT), params: [1, 5000]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:343)
at org.redisson.client.handler.CommandDecoder.decodeCommandBatch(CommandDecoder.java:247)
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:189)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:117)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:102)
redisson-all-3.12.1.jar  升级到  redisson-all-3.14.0.jar
Import  org.nustaq.serialization.annotations.Version  报错  我就添加了 fst-2.57.jar
启动时报错
java.lang.NoClassDefFoundError: org/objenesis/Objenesis
at org.redisson.codec.FstCodec.(FstCodec.java:182)
at com.game.logical.global.RedissonUtils.buildRedissonConfig(RedissonUtils.java:45)
at com.game.logical.global.RedissonUtils.(RedissonUtils.java:35)
Caused by: java.lang.ClassNotFoundException: org.objenesis.Objenesis
at java.net.URLClassLoader$1.run(URLClassLoader.java:372)
at java.net.URLClassLoader$1.run(URLClassLoader.java:361)
at java.security.AccessController.doPrivileged(Native Method)
at java.net.URLClassLoader.findClass(URLClassLoader.java:360)
at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
Could you tell me how to resolve this problem
我就添加了
add objenesis-2.5.1.jar
能正常启动 但是在执行事务是异常  事务混滚
org.redisson.transaction.TransactionException: Unable to execute transaction
at org.redisson.transaction.RedissonTransaction.commit(RedissonTransaction.java:287)
at org.redisson.transaction.RedissonTransaction.commit(RedissonTransaction.java:258)
Caused by: org.redisson.client.RedisException: ERR unknown command 'WAIT'. channel: [id: 0x7208d34e, L:/10.2.100.83:20976 - R:/10.2.12.183:6379] command: (WAIT), params: [1, 5000]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:343)
at org.redisson.client.handler.CommandDecoder.decodeCommandBatch(CommandDecoder.java:247)
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:189)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:117)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:102)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3393
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redisson version:3.12.5
redis version:5.0.7
redis cluster mode: 3 master 3 slave deployed in  vm
question descript:
In my production environment, a thread(dubheTaskExecutor-pool-2-thread-836) hangs up forever  whe invokes RedissonLock.unlock() . And I never found any error  in my application log. I am desired to find out if is a bug in redisson 3.12.5.The thread dump file is below(core part) :
"dubheTaskExecutor-pool-2-thread-836" #12180 prio=5 os_prio=0 tid=0x00007f9bc003b000 nid=0x38a6 in Object.wait() [0x00007f9c660de000]
java.lang.Thread.State: WAITING (on object monitor)
at java.lang.Object.wait(Native Method)
at java.lang.Object.wait(Object.java:502)
at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:252)
- locked <0x00000006a4b32a10> (a io.netty.util.concurrent.ImmediateEventExecutor$ImmediatePromise)
at org.redisson.misc.RedissonPromise.await(RedissonPromise.java:110)
at org.redisson.misc.RedissonPromise.await(RedissonPromise.java:35)
at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:139)
at org.redisson.RedissonObject.get(RedissonObject.java:90)
at org.redisson.RedissonLock.unlock(RedissonLock.java:477)
at com.sf.beic.common.autoconfig.redisson.DistributedLockerImpl.unlock(DistributedLockerImpl.java:57)
at com.sf.beic.common.autoconfig.redisson.RedissonDistributedLockerUtil.unlock(RedissonDistributedLockerUtil.java:37)
at com.sf.dubhe.pay.gateway.task.ThirdTransferQueryTask$1.run(ThirdTransferQueryTask.java:162)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:748)
-------------all redisson-netty thread state information---------------------
"redisson-netty-2-30" #151 prio=5 os_prio=0 tid=0x00007f9ccc001000 nid=0xfe runnable [0x00007f9c9cefa000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x0000000692fcb3f8> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x0000000692fcb3e8> (a java.util.Collections$UnmodifiableSet)
- locked <0x0000000692fcb3a0> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-32" #152 prio=5 os_prio=0 tid=0x00007f9cdc01e000 nid=0xfd runnable [0x00007f9c9cffb000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x0000000693130300> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x00000006931358b8> (a java.util.Collections$UnmodifiableSet)
- locked <0x00000006930fd730> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-31" #150 prio=5 os_prio=0 tid=0x00007f9cdc01d000 nid=0xfc runnable [0x00007f9ce41ed000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x0000000693000418> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x0000000693000408> (a java.util.Collections$UnmodifiableSet)
- locked <0x00000006930003c0> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-29" #149 prio=5 os_prio=0 tid=0x00007f9ce001f000 nid=0xfb runnable [0x00007f9ce42ee000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x0000000692ff1228> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x0000000692ff1218> (a java.util.Collections$UnmodifiableSet)
- locked <0x0000000692ff11d0> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-28" #148 prio=5 os_prio=0 tid=0x00007f9cb8002800 nid=0xfa runnable [0x00007f9ce43ef000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x0000000693032ec0> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x0000000693032eb0> (a java.util.Collections$UnmodifiableSet)
- locked <0x0000000693032e68> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-27" #147 prio=5 os_prio=0 tid=0x00007f9ce001d800 nid=0xf9 runnable [0x00007f9ce44f0000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x000000069304c450> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x000000069304c440> (a java.util.Collections$UnmodifiableSet)
- locked <0x000000069304c3f8> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-26" #146 prio=5 os_prio=0 tid=0x00007f9cdc01b000 nid=0xf8 runnable [0x00007f9ce45f1000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x00000006930b1790> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x00000006930b1780> (a java.util.Collections$UnmodifiableSet)
- locked <0x00000006930b1738> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-25" #145 prio=5 os_prio=0 tid=0x00007f9ce001b800 nid=0xf7 runnable [0x00007f9ce46f2000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x00000006930fb330> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x0000000693019980> (a java.util.Collections$UnmodifiableSet)
- locked <0x00000006930fb298> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-24" #144 prio=5 os_prio=0 tid=0x00007f9cdc019800 nid=0xf6 runnable [0x00007f9ce57f4000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x000000069304c5c0> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x000000069304c5b0> (a java.util.Collections$UnmodifiableSet)
- locked <0x000000069304c568> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-23" #143 prio=5 os_prio=0 tid=0x00007f9cdc017800 nid=0xf5 runnable [0x00007f9ce68f6000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x0000000693000588> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x0000000693000578> (a java.util.Collections$UnmodifiableSet)
- locked <0x0000000693000530> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-22" #142 prio=5 os_prio=0 tid=0x00007f9ce001a000 nid=0xf4 runnable [0x00007f9ce69f7000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x0000000693033030> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x0000000693033020> (a java.util.Collections$UnmodifiableSet)
- locked <0x0000000693032fd8> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-21" #141 prio=5 os_prio=0 tid=0x00007f9ce0018000 nid=0xf3 runnable [0x00007f9ce6af8000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x0000000692ff1398> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x0000000692ff1388> (a java.util.Collections$UnmodifiableSet)
- locked <0x0000000692ff1340> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-19" #139 prio=5 os_prio=0 tid=0x00007f9cd8019000 nid=0xf2 runnable [0x00007f9ce6bf9000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x000000069304c730> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x000000069304c720> (a java.util.Collections$UnmodifiableSet)
- locked <0x000000069304c6d8> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-20" #140 prio=5 os_prio=0 tid=0x00007f9cdc015000 nid=0xf1 runnable [0x00007f9ce6cfa000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x00000006930b1900> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x00000006930b18f0> (a java.util.Collections$UnmodifiableSet)
- locked <0x00000006930b18a8> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-17" #138 prio=5 os_prio=0 tid=0x00007f9ce0016000 nid=0xf0 runnable [0x00007f9ce6dfb000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x00000006931b66e8> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x00000006931b66d8> (a java.util.Collections$UnmodifiableSet)
- locked <0x00000006931b6690> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-18" #137 prio=5 os_prio=0 tid=0x00007f9cdc013800 nid=0xef runnable [0x00007f9ce6efc000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x00000006930f6410> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x00000006930199f0> (a java.util.Collections$UnmodifiableSet)
- locked <0x00000006930f6378> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-16" #136 prio=5 os_prio=0 tid=0x00007f9cd8017800 nid=0xee runnable [0x00007f9ce6ffd000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x00000006930006f8> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x00000006930006e8> (a java.util.Collections$UnmodifiableSet)
- locked <0x00000006930006a0> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-14" #135 prio=5 os_prio=0 tid=0x00007f9ce0014800 nid=0xed runnable [0x00007f9d041ed000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x00000006930331a0> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x0000000693033190> (a java.util.Collections$UnmodifiableSet)
- locked <0x0000000693033148> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-15" #134 prio=5 os_prio=0 tid=0x00007f9cd8015800 nid=0xec runnable [0x00007f9d042ee000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x000000069304c8a0> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x000000069304c890> (a java.util.Collections$UnmodifiableSet)
- locked <0x000000069304c848> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-12" #133 prio=5 os_prio=0 tid=0x00007f9cdc011800 nid=0xeb runnable [0x00007f9d043ef000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x00000006930b1a70> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x00000006930b1a60> (a java.util.Collections$UnmodifiableSet)
- locked <0x00000006930b1a18> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-13" #132 prio=5 os_prio=0 tid=0x00007f9cd8014000 nid=0xea runnable [0x00007f9d044f0000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x0000000693000868> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x0000000693000858> (a java.util.Collections$UnmodifiableSet)
- locked <0x0000000693000810> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-11" #131 prio=5 os_prio=0 tid=0x00007f9ce0013000 nid=0xe9 runnable [0x00007f9d045f1000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x0000000693136e88> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x0000000693019a60> (a java.util.Collections$UnmodifiableSet)
- locked <0x0000000693136df0> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-10" #130 prio=5 os_prio=0 tid=0x00007f9cec001000 nid=0xe8 runnable [0x00007f9d046f2000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x0000000692ff1508> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x0000000692ff14f8> (a java.util.Collections$UnmodifiableSet)
- locked <0x0000000692ff14b0> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-9" #129 prio=5 os_prio=0 tid=0x00007f9ce8001000 nid=0xe7 runnable [0x00007f9d047f3000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x000000069304ca10> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x000000069304ca00> (a java.util.Collections$UnmodifiableSet)
- locked <0x000000069304c9b8> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-8" #128 prio=5 os_prio=0 tid=0x00007f9cf4002800 nid=0xe6 runnable [0x00007f9d048f4000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x00000006930009d8> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x00000006930009c8> (a java.util.Collections$UnmodifiableSet)
- locked <0x0000000693000980> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-7" #127 prio=5 os_prio=0 tid=0x00007fa03bc0a800 nid=0xe5 runnable [0x00007f9d069f7000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x00000006930b1be0> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x00000006930b1bd0> (a java.util.Collections$UnmodifiableSet)
- locked <0x00000006930b1b88> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-6" #126 prio=5 os_prio=0 tid=0x00007fa03adb7800 nid=0xe4 runnable [0x00007f9d06af8000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x0000000693033310> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x0000000693033300> (a java.util.Collections$UnmodifiableSet)
- locked <0x00000006930332b8> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-5" #125 prio=5 os_prio=0 tid=0x00007fa03a9f0000 nid=0xe3 runnable [0x00007f9d06bf9000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x0000000692ff1678> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x0000000692ff1668> (a java.util.Collections$UnmodifiableSet)
- locked <0x0000000692ff1620> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-4" #124 prio=5 os_prio=0 tid=0x00007f9d000f1800 nid=0xe2 runnable [0x00007f9d06cfa000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x0000000693132018> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x0000000693135698> (a java.util.Collections$UnmodifiableSet)
- locked <0x0000000693131f80> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
--
"redisson-netty-2-3" #122 prio=5 os_prio=0 tid=0x00007f9d080ae800 nid=0xdf runnable [0x00007f9d07ffe000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x0000000692fcb568> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x0000000692fcb558> (a java.util.Collections$UnmodifiableSet)
- locked <0x0000000692fcb510> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
--
"redisson-netty-2-2" #120 prio=5 os_prio=0 tid=0x00007fa03bbaa800 nid=0xdd runnable [0x00007f9d852e1000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x0000000693019b28> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x0000000693019b18> (a java.util.Collections$UnmodifiableSet)
- locked <0x0000000693019ad0> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
"redisson-netty-2-1" #119 prio=5 os_prio=0 tid=0x00007fa03a89c000 nid=0xdc runnable [0x00007f9d855e2000]
java.lang.Thread.State: RUNNABLE
at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
- locked <0x0000000692ff1968> (a io.netty.channel.nio.SelectedSelectionKeySet)
- locked <0x0000000692ff1958> (a java.util.Collections$UnmodifiableSet)
- locked <0x0000000692ff1910> (a sun.nio.ch.EPollSelectorImpl)
at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3394
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is your feature request related to a problem? Please describe.
配置yml的时候没有提示语
Describe the solution you'd like
加个metada.json
Describe alternatives you've considered
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3395
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Dead Connection automatically reconnect after channel inactive.
Actual behavior
In org.redisson.client.handler.CommandsQueue, we only call sendNextCommand to poll command if server responded with data or write was failed in the first place.
But if client write was successful and server is not responding, our QueueCommand is still staying at the front of queue, next time we call sendData, org.redisson.client.protocol.QueueCommandHolder#trySend will return false and nothing happens.
So eachtime we use that connection to write something, we got  RedisTimeoutException:  Command still hasn't been written into connection!
Redisson version
3.13.1
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3396
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi ,
I am implementing redis based tomcat session management using redisson. I want to filter out some of the session attributes which gets saved in my redis database session. Is there any way to do so through configuration? Something similar to SetAttributeFilter in MemcachedBackupSessionManager?
Here is the single instance config YAML file i have used:
singleServerConfig:
idleConnectionTimeout: 10000
connectTimeout: 10000
timeout: 3000
retryAttempts: 3
retryInterval: 1500
password: null
subscriptionsPerConnection: 5
clientName: null
address: "redis://127.0.0.1:6379"
subscriptionConnectionMinimumIdleSize: 1
subscriptionConnectionPoolSize: 50
connectionMinimumIdleSize: 24
connectionPoolSize: 64
database: 0
dnsMonitoringInterval: 5000
threads: 16
nettyThreads: 32
codec: !<org.redisson.codec.FstCodec> {}
transportMode: "NIO"
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3397
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is your feature request related to a problem? Please describe.
Add a "setPassword" method to org.redisson.config.Config;
Motivation:
I'd like to configure everything EXCEPT the password in .yaml.
But allow a programatic setting of just the password after the .yaml config loads.
This way I can pull that "secret" out of a "vault"   ( hashicorp vault, azure key vault, amazon aws kms, etc)...and set it at run time.

  
    
      redisson/redisson/src/main/java/org/redisson/config/BaseConfig.java
    
    
         Line 145
      in
      fe25a7f
    
  
  
    

        
          
           public T setPassword(String password) { 
        
    
  


Describe the solution you'd like
org.redisson.config.Config;
Since we do not have access to the "inner" objects
https://github.com/redisson/redisson/blob/master/redisson/src/main/java/org/redisson/config/Config.java#L48L56
( private SentinelServersConfig sentinelServersConfig;
private MasterSlaveServersConfig masterSlaveServersConfig;

private SingleServerConfig singleServerConfig;

private ClusterServersConfig clusterServersConfig;

private ReplicatedServersConfig replicatedServersConfig;)

provide a method on
org.redisson.config.Config;
for "setPassword"
that will allow the setting of the inner object (if available)
(or throw exception if not available)
OR
if you want to do it "functionally"...create an overload
public Config(Config oldConf, String newPassword) {
}
https://github.com/redisson/redisson/blob/master/redisson/src/main/java/org/redisson/config/Config.java#L110
Describe alternatives you've considered
No alternatives.
Below shows the idea:
`
//import org.redisson.Redisson;
//import org.redisson.api.RMapCache;
//import org.redisson.api.RedissonClient;
//import org.redisson.config.Config;
public static final String REDISSON_JCACHE_YAML = "/redisson-jcache.yaml";


        Config config = null;
        try {
            // YAML configuration
            URL redissonConfigUri = MyThing.class.getResource(REDISSON_JCACHE_YAML);

            if (null == redissonConfigUri) {
                throw new NullPointerException("My Message");
            }
            config = Config.fromYAML(redissonConfigUri);

            if (null == config) {
                throw new NullPointerException("My Other Message");
            }

            String myPassword = /* read from a vault here */;
            config.setPassword(myPassword);

        } catch (Exception ex) {
            throw new RuntimeException("Yet Another Explicit Message", ex);
        }
        RedissonClient client = Redisson.create(config);

`
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3398
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redisson:3.15.0
redis:4.0.9
org.redisson.api.RAtomicLong#expireAt(long)
Cannot find the key of aKey after execution
Why is this ?
java code
        Config config = new Config();
        config.useSingleServer()
                .setAddress("redis://127.0.0.1:6379")
                .setDatabase(0);
        RedissonClient redissonClient = Redisson.create(config);

        String aKey = "aKey";
        RAtomicLong aAtomic = redissonClient.getAtomicLong(aKey);
        long aValue0 = aAtomic.get();
        LOG.info("aKey-value0[{}]", aValue0);

        aAtomic.incrementAndGet();
        long aValue1 = aAtomic.get();
        LOG.info("aKey-value1[{}]", aValue1);
        aAtomic.expireAt(1000 * 60 * 60);

        long aValue2 = aAtomic.get();
        LOG.info("aKey-value2[{}]", aValue2);

        LOG.info("---------------------------------------------------------");

        String bKey = "bKey";
        RAtomicLong bAtomic = redissonClient.getAtomicLong(bKey);
        long bValue0 = bAtomic.get();
        LOG.info("bKey-value0[{}]", bValue0);

        bAtomic.incrementAndGet();
        bAtomic.expire(10, TimeUnit.HOURS);

        long bValue1 = bAtomic.get();
        LOG.info("bKey-value1[{}]", bValue1);

        LOG.info("---------------------------------------------------------");

        String cKey = "cKey";
        RAtomicLong cAtomic = redissonClient.getAtomicLong(cKey);
        long cValue0 = cAtomic.get();
        LOG.info("cKey-value0[{}]", cValue0);

        cAtomic.incrementAndGet();

        long cValue1 = cAtomic.get();
        LOG.info("cKey-value1[{}]", cValue1);

        redissonClient.shutdown();

log...
15:45:35.913 [main] INFO org.redisson.Version - Redisson 3.15.0
15:45:36.804 [redisson-netty-2-17] INFO org.redisson.connection.pool.MasterPubSubConnectionPool - 1 connections initialized for /127.0.0.1:6379
15:45:36.817 [redisson-netty-2-17] INFO org.redisson.connection.pool.MasterConnectionPool - 24 connections initialized for /127.0.0.1:6379
15:45:36.877 [main] INFO RedissonClient - aKey-value0[0]
15:45:36.880 [main] INFO RedissonClient - aKey-value1[1]
15:45:36.881 [main] INFO RedissonClient - aKey-value2[0]
15:45:36.881 [main] INFO RedissonClient - ---------------------------------------------------------
15:45:36.882 [main] INFO RedissonClient - bKey-value0[0]
15:45:36.886 [main] INFO RedissonClient - bKey-value1[1]
15:45:36.887 [main] INFO RedissonClient - ---------------------------------------------------------
15:45:36.887 [main] INFO RedissonClient - cKey-value0[0]
15:45:36.889 [main] INFO RedissonClient - cKey-value1[1]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3399
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3400
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
An exception in adding a cluster member connection should not result in a connection leak
Actual behavior
Our redis cluster had two nodes which had configured themselves as "127.0.0.1:6379" in the cluster configuration.  Upon connecting two this cluster, redisson properly threw exception
org.redisson.client.RedisConnectionException: Unable to connect to Redis server: /127.0.0.1:6379

Later in the logs we find, repeatedly
Can't connect to master: redis://127.0.0.1:6379 with slot ranges: [[0-5461]]

Each of these subsequent attempts appear to leave a new connection open to the redis node from which redisson is gathering cluster nodes information.  Over the course of ~2h, this used the remainder of that redis node's 10k connection limit.
Steps to reproduce or test case
I'm not sure how our redis server came to this state originally, but I was able to reproduce by stopping a cluster member, changing the address field in the "myself" line in the cluster config (in our case, /var/lib/redis/redis-6379.conf) from
172.16.10.11:6379@16379
to
127.0.0.1:6379@16379
Redis version
6.0.9
Redisson version
3.15.0
Redisson configuration
    fun redissonClient(): RedissonClient {
        val config = Config()
        config.useClusterServers()
            .addNodeAddress("redis://$redisHost")
        config.codec = StringCodec.INSTANCE
        val redisson: RedissonClient = Redisson.create(config)
        val topic: RTopic = redisson.getTopic(testTopic)
        topic.addListener(Any::class.java) { channel, msg ->
            log.info { "$channel - $msg" }
        }
        return redisson
    }

Where $redisHost resolves by dns to A records for each node in the redis cluster.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3401
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3402
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
文档里的依赖描述

代码里的依赖结果


上面描述的是，24对应Spring Boot 2.4.x，而项目引入的Spring Boot 2.4.1，而下面的却是 redisson-spring-data-23，按照文档应该是redisson-spring-data-24 才对。望改正！
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3403
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is support for storing data locally provided so that number of calls to redis can be reduced?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3404
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
exception log
Can't execute SENTINEL commands on /192.168.28.129:63376

org.redisson.client.RedisTimeoutException: Command execution timeout for command: (SENTINEL SENTINELS), params: [mymaster], Redis client: [addr=redis://192.168.28.129:63376]
	at org.redisson.client.RedisConnection.lambda$async$1(RedisConnection.java:207)
	at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:672)
	at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:747)
	at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:472)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)

There are three sentinels in total. This anomaly occurs every time you start it. A sentinel anomaly appears randomly, but it can be used normally.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3405
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
使用redisson阻塞队列（带超时时间的阻塞方式poll(timeout,timeunit)或者pollAsync(timeout,timeunit)）的这种场景下：
如果我开启了Ping，就会有如下几种异常出现：
1、PingConnectionHandler类报异常，之前分析过这个类，这个异常报得特别多 一晚上将近10w条
PingConnectionHandler第89行报错 ：
2021-02-04 18:47:53.613 [TID: N/A] ERROR 16545 --- [redisson-timer-4-1] o.r.c.h.PingConnectionHandler           :89 : {} Unable to send PING command over channel: [id: 0xe7012642, L:/xxxxxxxx:50954 ! R:/xxxxxx:6379]
org.redisson.client.RedisTimeoutException: Command execution timeout for command: (PING), params: [], Redis client: [addr=redis://xxxx:6379]
at org.redisson.client.RedisConnection.lambda$async$1(RedisConnection.java:207) ~[redisson-3.15.0.jar!/:3.15.0]
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:672) [netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:747) [netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:472) [netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
2、RedisExecutor类异常，堆栈如下
at org.redisson.command.RedisExecutor$2.run(RedisExecutor.java:205) ~[redisson-3.15.0.jar!/:3.15.0]
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:672) ~[netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:747) ~[netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:472) ~[netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
3、Caused by: org.redisson.client.WriteRedisConnectionException: Channel has been closed!
org.redisson.client.WriteRedisConnectionException: Unable to write command into connection! Node source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null], connection: RedisConnection@1927498671 [redisClient=[addr=redis://xxxx:6379], channel=[id: 0x5fdf22a7, L:/10.65.140.249:11565 ! R:/10.111.17.89:6379], currentCommand=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@23022fc(failure: org.redisson.client.RedisTimeoutException: Command execution timeout for command: (PING), params: [], Redis client: [addr=redis://xxx:6379])], command=(PING), params=[], codec=org.redisson.client.codec.StringCodec]], command: (BLPOP), params: [KEC:MESSAGE:MIGRATE_VM_TO_DEDICATED_QUEUE:cn-shanghai-fin, 14] after 3 retry attempts
at org.redisson.command.RedisExecutor.checkWriteFuture(RedisExecutor.java:275) ~[redisson-3.15.0.jar!/:3.15.0]
at org.redisson.command.RedisExecutor.access$100(RedisExecutor.java:58) ~[redisson-3.15.0.jar!/:3.15.0]
at org.redisson.command.RedisExecutor$1.operationComplete(RedisExecutor.java:156) ~[redisson-3.15.0.jar!/:3.15.0]
at org.redisson.command.RedisExecutor$1.operationComplete(RedisExecutor.java:153) ~[redisson-3.15.0.jar!/:3.15.0]
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577) ~[netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551) ~[netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490) ~[netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615) ~[netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:608) ~[netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117) ~[netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at org.redisson.client.handler.CommandsQueue.channelInactive(CommandsQueue.java:74) ~[redisson-3.15.0.jar!/:3.15.0]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:260) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:246) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:239) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at org.redisson.client.handler.ConnectionWatchdog.channelInactive(ConnectionWatchdog.java:82) ~[redisson-3.15.0.jar!/:3.15.0]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:260) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:246) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:239) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:260) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:246) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:818) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164) ~[netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472) ~[netty-common-4.1.45.Final.jar!/:4.1.45.Final]
如果我关闭了PING则会出现下面这样一种异常：
2021-02-07 10:35:57.250 [TID: N/A] ERROR 32018 --- [redisson-timer-4-1] o.r.c.h.PingConnectionHandler           :89 : {} Unable to send PING command over channel: [id: 0x2c682c89, L:/1xxx:16100 ! R:/10xxx9:6379]
org.redisson.client.WriteRedisConnectionException: Channel has been closed! Can't write command: (PING), params: [] to channel: [id: 0x50381f72, L:/10.111.17.89:21618 ! R:/10.111.17.89:6379]
at org.redisson.client.handler.CommandsQueue.channelInactive(CommandsQueue.java:76) ~[redisson-3.15.0.jar!/:3.15.0]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:260) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:246) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:239) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at org.redisson.client.handler.ConnectionWatchdog.channelInactive(ConnectionWatchdog.java:82) ~[redisson-3.15.0.jar!/:3.15.0]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:260) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:246) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:239) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:260) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:246) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:818) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164) ~[netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472) ~[netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
Caused by: org.redisson.client.WriteRedisConnectionException: Channel has been closed! Can't write command: (BLPOP), params: [KEC:MESSAGE:MIGRATE_VM_TO_DEDICATED_QUEUE:cn-shanghai-fin, 14] to channel: [id: 0x5fdf22a7, L:/10.65.140.249:11565 ! R:/10.111.17.89:6379]
at org.redisson.client.handler.CommandsQueue.channelInactive(CommandsQueue.java:76) ~[redisson-3.15.0.jar!/:3.15.0]
Actual behavior
个人分析的结果就是在阻塞连接的断开和发送PING的时候有并发问题引起。
为证实猜想我在每次阻塞获取到数据并在处理完之后，让程序休眠1s后，PingConnectionHandler这个类的异常消失了。但是会出现另外一个异常：
2021-02-07 00:25:10.759 [TID: N/A] ERROR 32018 --- [redisson-timer-4-1] o.r.c.h.PingConnectionHandler           :89 : {} Unable to send PING command over channel: [id: 0xdb83a2ad, L:/xxx9:37602 ! R:/1xxx9:6379]
org.redisson.client.WriteRedisConnectionException: Channel has been closed! Can't write command: (PING), params: [] to channel: [id: 0xaafedd5b, L:/10.111.xxx.xx:38828 ! R:/10.111.17.89:6379]
at org.redisson.client.handler.CommandsQueue.channelInactive(CommandsQueue.java:76) ~[redisson-3.15.0.jar!/:3.15.0]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:260) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:246) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:239) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at org.redisson.client.handler.ConnectionWatchdog.channelInactive(ConnectionWatchdog.java:82) ~[redisson-3.15.0.jar!/:3.15.0]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:260) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:246) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:239) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:260) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:246) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:818) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164) ~[netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472) ~[netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500) ~[netty-transport-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-common-4.1.45.Final.jar!/:4.1.45.Final]
at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
但是异常2
Steps to reproduce or test case
使用多个阻塞方式的Redisson队列，阻塞时间10s-20s，不停的循环阻塞获取队列元素，异常在一天之内就会出现
Redis version
2.8
Redisson version
3.15.0
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3406
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
no error log
Actual behavior
021-02-07 21:38:40.615  WARN 55104 --- [           main] i.n.r.d.DnsServerAddressStreamProviders  : Unable to load io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider, fallback to system defaults. This may result in incorrect DNS resolutions on MacOS.

java.lang.ClassNotFoundException: io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382) ~[na:1.8.0_271]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418) ~[na:1.8.0_271]
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:355) ~[na:1.8.0_271]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ~[na:1.8.0_271]
	at java.lang.Class.forName0(Native Method) ~[na:1.8.0_271]
	at java.lang.Class.forName(Class.java:348) ~[na:1.8.0_271]
	at io.netty.resolver.dns.DnsServerAddressStreamProviders$1.run(DnsServerAddressStreamProviders.java:50) ~[netty-resolver-dns-4.1.58.Final.jar:4.1.58.Final]
	at java.security.AccessController.doPrivileged(Native Method) ~[na:1.8.0_271]
	at io.netty.resolver.dns.DnsServerAddressStreamProviders.<clinit>(DnsServerAddressStreamProviders.java:46) ~[netty-resolver-dns-4.1.58.Final.jar:4.1.58.Final]
	at org.redisson.connection.MasterSlaveConnectionManager.<init>(MasterSlaveConnectionManager.java:203) [redisson-3.15.0.jar:3.15.0]
	at org.redisson.connection.MasterSlaveConnectionManager.<init>(MasterSlaveConnectionManager.java:155) [redisson-3.15.0.jar:3.15.0]
	at org.redisson.connection.SingleConnectionManager.<init>(SingleConnectionManager.java:34) [redisson-3.15.0.jar:3.15.0]
	at org.redisson.config.ConfigSupport.createConnectionManager(ConfigSupport.java:200) [redisson-3.15.0.jar:3.15.0]
	at org.redisson.Redisson.<init>(Redisson.java:64) [redisson-3.15.0.jar:3.15.0]
	at org.redisson.Redisson.create(Redisson.java:104) [redisson-3.15.0.jar:3.15.0]
	at org.redisson.spring.starter.RedissonAutoConfiguration.redisson(RedissonAutoConfiguration.java:186) [redisson-spring-boot-starter-3.15.0.jar:3.15.0]
	at org.redisson.spring.starter.RedissonAutoConfiguration$$EnhancerBySpringCGLIB$$1.CGLIB$redisson$0(<generated>) [redisson-spring-boot-starter-3.15.0.jar:3.15.0]
	at org.redisson.spring.starter.RedissonAutoConfiguration$$EnhancerBySpringCGLIB$$1$$FastClassBySpringCGLIB$$1.invoke(<generated>) [redisson-spring-boot-starter-3.15.0.jar:3.15.0]
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:244) [spring-core-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:331) [spring-context-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.redisson.spring.starter.RedissonAutoConfiguration$$EnhancerBySpringCGLIB$$1.redisson(<generated>) [redisson-spring-boot-starter-3.15.0.jar:3.15.0]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_271]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_271]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_271]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_271]
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:652) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:485) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1336) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1176) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:556) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:516) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:324) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1307) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1227) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:886) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:790) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:540) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1336) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1176) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:556) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:516) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:324) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1307) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1227) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:886) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:790) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:540) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1336) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1176) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:556) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:516) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:324) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1307) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1227) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:640) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1420) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:516) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:324) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1307) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1227) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:640) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1420) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:516) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:324) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:207) [spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.boot.web.servlet.ServletContextInitializerBeans.getOrderedBeansOfType(ServletContextInitializerBeans.java:211) ~[spring-boot-2.3.8.RELEASE.jar:2.3.8.RELEASE]
	at org.springframework.boot.web.servlet.ServletContextInitializerBeans.addAsRegistrationBean(ServletContextInitializerBeans.java:174) ~[spring-boot-2.3.8.RELEASE.jar:2.3.8.RELEASE]
	at org.springframework.boot.web.servlet.ServletContextInitializerBeans.addAsRegistrationBean(ServletContextInitializerBeans.java:169) ~[spring-boot-2.3.8.RELEASE.jar:2.3.8.RELEASE]
	at org.springframework.boot.web.servlet.ServletContextInitializerBeans.addAdaptableBeans(ServletContextInitializerBeans.java:154) ~[spring-boot-2.3.8.RELEASE.jar:2.3.8.RELEASE]
	at org.springframework.boot.web.servlet.ServletContextInitializerBeans.<init>(ServletContextInitializerBeans.java:86) ~[spring-boot-2.3.8.RELEASE.jar:2.3.8.RELEASE]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.getServletContextInitializerBeans(ServletWebServerApplicationContext.java:255) ~[spring-boot-2.3.8.RELEASE.jar:2.3.8.RELEASE]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.selfInitialize(ServletWebServerApplicationContext.java:229) ~[spring-boot-2.3.8.RELEASE.jar:2.3.8.RELEASE]
	at org.springframework.boot.web.embedded.tomcat.TomcatStarter.onStartup(TomcatStarter.java:53) ~[spring-boot-2.3.8.RELEASE.jar:2.3.8.RELEASE]
	at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5166) ~[tomcat-embed-core-9.0.41.jar:9.0.41]
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) ~[tomcat-embed-core-9.0.41.jar:9.0.41]
	at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1384) ~[tomcat-embed-core-9.0.41.jar:9.0.41]
	at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1374) ~[tomcat-embed-core-9.0.41.jar:9.0.41]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_271]
	at org.apache.tomcat.util.threads.InlineExecutorService.execute(InlineExecutorService.java:75) ~[tomcat-embed-core-9.0.41.jar:9.0.41]
	at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:134) ~[na:1.8.0_271]
	at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:909) ~[tomcat-embed-core-9.0.41.jar:9.0.41]
	at org.apache.catalina.core.StandardHost.startInternal(StandardHost.java:843) ~[tomcat-embed-core-9.0.41.jar:9.0.41]
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) ~[tomcat-embed-core-9.0.41.jar:9.0.41]
	at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1384) ~[tomcat-embed-core-9.0.41.jar:9.0.41]
	at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1374) ~[tomcat-embed-core-9.0.41.jar:9.0.41]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_271]
	at org.apache.tomcat.util.threads.InlineExecutorService.execute(InlineExecutorService.java:75) ~[tomcat-embed-core-9.0.41.jar:9.0.41]
	at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:134) ~[na:1.8.0_271]
	at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:909) ~[tomcat-embed-core-9.0.41.jar:9.0.41]
	at org.apache.catalina.core.StandardEngine.startInternal(StandardEngine.java:262) ~[tomcat-embed-core-9.0.41.jar:9.0.41]
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) ~[tomcat-embed-core-9.0.41.jar:9.0.41]
	at org.apache.catalina.core.StandardService.startInternal(StandardService.java:434) ~[tomcat-embed-core-9.0.41.jar:9.0.41]
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) ~[tomcat-embed-core-9.0.41.jar:9.0.41]
	at org.apache.catalina.core.StandardServer.startInternal(StandardServer.java:930) ~[tomcat-embed-core-9.0.41.jar:9.0.41]
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) ~[tomcat-embed-core-9.0.41.jar:9.0.41]
	at org.apache.catalina.startup.Tomcat.start(Tomcat.java:486) ~[tomcat-embed-core-9.0.41.jar:9.0.41]
	at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize(TomcatWebServer.java:123) ~[spring-boot-2.3.8.RELEASE.jar:2.3.8.RELEASE]
	at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.<init>(TomcatWebServer.java:104) ~[spring-boot-2.3.8.RELEASE.jar:2.3.8.RELEASE]
	at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getTomcatWebServer(TomcatServletWebServerFactory.java:440) ~[spring-boot-2.3.8.RELEASE.jar:2.3.8.RELEASE]
	at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getWebServer(TomcatServletWebServerFactory.java:193) ~[spring-boot-2.3.8.RELEASE.jar:2.3.8.RELEASE]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.createWebServer(ServletWebServerApplicationContext.java:178) ~[spring-boot-2.3.8.RELEASE.jar:2.3.8.RELEASE]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:158) ~[spring-boot-2.3.8.RELEASE.jar:2.3.8.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.__refresh(AbstractApplicationContext.java:545) ~[spring-context-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.jrLockAndRefresh(AbstractApplicationContext.java:40002) ~[spring-context-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:41008) ~[spring-context-5.2.12.RELEASE.jar:5.2.12.RELEASE]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:143) ~[spring-boot-2.3.8.RELEASE.jar:2.3.8.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:758) ~[spring-boot-2.3.8.RELEASE.jar:2.3.8.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:750) ~[spring-boot-2.3.8.RELEASE.jar:2.3.8.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:405) ~[spring-boot-2.3.8.RELEASE.jar:2.3.8.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:315) ~[spring-boot-2.3.8.RELEASE.jar:2.3.8.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1237) ~[spring-boot-2.3.8.RELEASE.jar:2.3.8.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1226) ~[spring-boot-2.3.8.RELEASE.jar:2.3.8.RELEASE]
	at cn.exrick.xboot.XbootApplication.main(XbootApplication.java:30) ~[classes/:na]

Steps to reproduce or test case

Spring Boot 2.3.8

Redis version

5.0.7
Redisson version


3.14.1
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3407
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Redis cluster master down, redisson client update cluster state, and tps come down.  After a period of time, restart master node,  tps come back to normal.
Actual behavior
restart master node,  tps  can't recover , just come back a little.  And server no error.
Steps to reproduce or test case
5 master and 5 slave
master 1 down and wait for slave become master
restart master 1,  observe tps
config
    readMode: "MASTER"
    subscriptionMode: "MASTER"
    nodeAddresses:
        - "redis://127.0.0.1:7001"
        - "redis://127.0.0.1:7002"
        - "redis://127.0.0.1:7003"
        - "redis://127.0.0.1:7004"
        - "redis://127.0.0.1:7005"
        - "redis://127.0.0.1:7006"
        - "redis://127.0.0.1:7007"
        - "redis://127.0.0.1:7008"
        - "redis://127.0.0.1:7009"
        - "redis://127.0.0.1:7010"
    scanInterval: 1000
    failedSlaveReconnectionInterval: 3000
    failedSlaveCheckInterval: 3000
    pingConnectionInterval: 5000

version
redisson version : 3.14.1
Looking forward for your response, Thank you!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3408
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
如何使用redisson实现redis list的rpoplpush功能
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3409
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi guys!
thanks a lot for your brilliant product it helped us tremendously. However I believe that we are facing a bug there.
redissonClient.getCommandExecutor().read(name, RedisCommands.XRANGE, name, "-", "+")
returns LinkedHashMap
while
redissonClient.getStream(name).read(10, new StreamMessageId(0L, 0L));
return HashMap, which is imo wrong.
When using redis streams and XRANGE command, one wants to rely on ordering being exactly the same as ordering on StreamMessageId's.
Would you have some time to check this?
Thanks,
T
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3410
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3411
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
So i suggest. There is a way to do FST codec on Topic (PUB\SUB). When i tried to use it. It didnt work. Then i though that im choose a wrong way. And then i Make log of redisson to debug "logging.level.org.redisson=debug".
So what i see when i use publish method :

org.redisson.command.RedisExecutor       : connection released for command (PUBLISH) and params [SERVICES, PooledUnsafeDirectByteBuf(ridx: 0, widx: 48, cap: 256)] from slot NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null] using connection RedisConnection@1597660839 [redisClient=[addr=redis://db.test.me:6379], channel=[id: 0xc125e7d4, L:/192.168.126.1:59815 - R:db.test.me/192.168.126.142:6379], currentCommand=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@75ecf0f1(success: 1)], command=(PUBLISH), params=[SERVICES, PooledUnsafeDirectByteBuf(ridx: 0, widx: 48, cap: 256)], codec=org.redisson.client.codec.StringCodec]]

As we see there is using still StringCodec.  Then i tried to use FST codec not for PUB\SUB. Just for save info to redisson. And then it works. My configuration of FST is simple :

    FSTConfiguration fstConfiguration = FSTConfiguration.createDefaultConfiguration();
    fstConfiguration.setForceSerializable(true);


There is a way to use FSTCodec for Pub\Sub, not only for store data? Version of redisson 3.14
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3412
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When a blockQueue executed with TIMEOUT, it will always trigger reconnecting via one connection.  PING will trigger again when connection reconnected, but previous PING will still ongoing.
ps: 3302 fix will reduce the possibility of reconnecting,  but whenever reconnecting happen, duplication ping will happen.
Expected behavior
Redis PING performed one time per interval per connection
Actual behavior
Redis PING performed mutiple times per interval per connection when this connection got reconnected
Steps to reproduce or test case
public class BlockingOperationTest {
    public static void main(String[] args) throws InterruptedException {
        Config config = new Config();
        config.setCodec(StringCodec.INSTANCE).useSingleServer().setAddress("redis://localhost:6379")
                .setPingConnectionInterval(1000)
                .setTimeout(200)
                .setConnectionMinimumIdleSize(1);
        RedissonClient redisson = Redisson.create(config);

        RBlockingQueue<String> queue = redisson.getBlockingQueue("testQueue");
        for(;;){
            try {
//                System.out.println("start poll");
                queue.poll(3, TimeUnit.SECONDS);
                //reconnect every time
//                System.out.println("end poll");
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }
}

Redis version
ANY
Redisson version
3.13.6
Redisson configuration
ANY
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3413
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The Chinese wiki mentions that the default codec is JsonJacksonCodec, but in fact the default codec is FstCodec,  please correct it, thank you
https://github.com/redisson/redisson/wiki/2.-%E9%85%8D%E7%BD%AE%E6%96%B9%E6%B3%95#codec%E7%BC%96%E7%A0%81
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3414
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
when i want to use the addandget API,i found the number convert throw a ClassCastException.
source code:BaseTransactionalMap.java
BigDecimal currentValue = BigDecimal.ZERO; 
if (entry != MapEntry.NULL) { 
currentValue = (BigDecimal) entry.getValue(); 
} 
BigDecimal res = currentValue.add(new BigDecimal(value.toString())); 

the error is on third line
Can I use new BigDecimal(entry.getValue()) instead?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3415
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3416
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Can we avoid to use separate module?
There are no changes in RedissonLiveObjectService. Does it mean that following to the rules is enough?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3417
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3418
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3419
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
Redisson version
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3420
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RedissonBaseLock.java:312
opStatus is always null:
RedissonPromise.java:183  (status of netty's Future is canceled due to Exception thrown from the same thread)
I'm experience it permanently.
At a first glance (if i'm not mistaken) this is a Blocker  level issue.
RedissonPromise.java:187:
Same behavior if Exception got thrown too early, such that f.getNow() results null
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3421
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redis version：5.0.9
redisson version：3.15.0
Instance code：
`@RestController
public class TestController {
@Resource(name = "redisson")
private RedissonClient redisson;


@GetMapping("/atomicDouble")
public void atomicDouble() {
    RAtomicDouble atomicDouble = redisson.getAtomicDouble("test:atomicDouble");
    atomicDouble.set(10.89);
}


@GetMapping("/addAtomicDouble")
public double addAtomicDouble() {
    RAtomicDouble atomicDouble = redisson.getAtomicDouble("test:atomicDouble");
    // 多线程调用该方法，不会造成数据不一致
    return atomicDouble.addAndGet(20.00);
}

}`
Running results：
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3422
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In my scenario, I invoke RStream.claim(groupName, consumerName, idleTime, idleTimeUnit, ids)
where some ids may already be removed from a stream.
I would expect this method to claim and return whatever records exist.
Instead, it fails with NPE
Caused by: java.lang.NullPointerException at org.redisson.client.protocol.decoder.ObjectMapReplayDecoder2.decode(ObjectMapReplayDecoder2.java:37) at org.redisson.client.protocol.decoder.ObjectMapReplayDecoder2.decode(ObjectMapReplayDecoder2.java:30) at org.redisson.client.protocol.decoder.ListMultiDecoder2.decode(ListMultiDecoder2.java:46) at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:412) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:368) at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:178) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:117) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:102) at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:508) at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.base/java.lang.Thread.run(Thread.java:834)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3423
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is your feature request related to a problem? Please describe.
Trying to implement a sliding-expiration..........in a performant manner.
the specific request is for RMapCache to add an expire "by key" functionality
Current "expire" (below) does not have a "by-key" parameter.
package org.redisson.api;

public interface RExpirab

    /**
     * Set a timeout for object. After the timeout has expired,
     * the key will automatically be deleted.
     *
     * @param timeToLive - timeout before object will be deleted
     * @param timeUnit - timeout time unit
     * @return <code>true</code> if the timeout was set and <code>false</code> if not
     */
    boolean expire(long timeToLive, TimeUnit timeUnit);

Describe the solution you'd like
Consider adding "expire by KEY" functionality to
package org.redisson.api;
public interface RMapCache<K, V>

similar to how it exists here
https://github.com/redisson/redisson/blob/master/redisson/src/main/java/org/redisson/api/RMultimapCache.java#L39
public interface RMultimapCache<K, V>
Describe alternatives you've considered
Currently , we are "re-putting" in the item.
    private Optional<V> internalGet(String cacheMapName, K key, boolean runSlide, long cacheItemLiveTtl, TimeUnit cacheItemLiveTimeUnit) {
        Optional<V> returnItem = Optional.empty();
        RMapCache<K, V> map = this.getCache(cacheMapName);
        //Collection<V> allKeys = map.values();
        V foundItem = map.get(key);
        if (null != foundItem) {
            if (runSlide) {
                /* Redisson , not sure if an explicit "expire-by-key" exists on RMapCache<K, V> */
                /* so here we re-put the item */
                foundItem = map.put(key, foundItem, cacheItemLiveTtl, cacheItemLiveTimeUnit);

            }
            returnItem = Optional.of(foundItem);
        }
        return returnItem;
    }

===========
We're doing this to get "sliding expiration" to work.
Other Project FYI's:
Lettuce and Jedis have this "expire by key" functionality.
LETTUCE
package io.lettuce.core.api.sync;
public interface RedisKeyCommands<K, V> {

    /**
     * Set a key's time to live in seconds.
     *
     * @param key the key
     * @param seconds the seconds type: long
     * @return Boolean integer-reply specifically:
     *
     *         {@code true} if the timeout was set. {@code false} if {@code key} does not exist or the timeout could not
     *         be set.
     */
    Boolean expire(**K key,** long seconds);


JEDIS
package redis.clients.jedis;


public class Jedis

  @Override
  public Long expire(final **String key,** final int seconds) {

  }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3424
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Cache should respect configured TTL no matter how entry was put in it.
Actual behavior
For now if cache loader is configured RedissonMap puts loaded entries into cache ignoring specified TTL.
Steps to reproduce or test case
Create map cache with some TTL and cache loader, let loader to provide value for some key, wait for TTL and then try to get value from cache again - cache loader won't be used.
Redis version
5.0.9
Redisson version
3.12.3
Redisson configuration
Single Redis instance
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3425
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Normal mission cancellation
Actual behavior
Failed to cancel the task and blocked the thread
Steps to reproduce or test case
public class SchedulerServiceExamples {
    private static final Logger LOG = LoggerFactory.getLogger(SchedulerServiceExamples.class);

    public static void main(String[] args) throws InterruptedException {
        Config config = new Config();
        config.useSingleServer().setAddress("redis://127.0.0.1:6379");

        RedissonClient redisson = Redisson.create(config);

        RedissonNodeConfig nodeConfig = new RedissonNodeConfig(config);
        nodeConfig.setExecutorServiceWorkers(Collections.singletonMap("myExecutor", 5));
        RedissonNode node = RedissonNode.create(nodeConfig);
        node.start();

        RScheduledExecutorService e = redisson.getExecutorService("myExecutor");
        String taskId = redisson.getExecutorService("myExecutor").schedule(new RunnableTask(), 2000, TimeUnit.MILLISECONDS).getTaskId();
        Thread.sleep(5500);

        LOG.info("xxxx start cancel task");
        e.cancelTask(taskId);
        LOG.info("yyyy end cancel task");

        e.shutdown();
        node.shutdown();
    }

    public static class RunnableTask implements Runnable, Serializable {

        private static final Logger LOG = LoggerFactory.getLogger(RunnableTask.class);

        @Override
        public void run() {
            LOG.info("Task start...");
            try {
                Thread.sleep(1000);
                LOG.info("Task running 1 ...");
                Thread.sleep(1000);
                LOG.info("Task running 2 ...");
                Thread.sleep(1000);
                LOG.info("Task running 3 ...");
                Thread.sleep(1000);
                LOG.info("Task running 4 ...");
            } catch (InterruptedException interruptedException) {
                LOG.info("Task interruptedException");
            }
        }

    }
}

Redis version
docker redis:3.2.11
Redisson version
3.13.0, 3.15.0
Redisson configuration
Default configuration
When canceling a timed task, if the task is running, there is a chance that the task will not be canceled. If we use synchronous method to cancel the task, it will cause the current thread to block permanently, and the actual analysis shows that it will be in the scheduleCheck method.
Related Logs
log.log
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3426
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi mrniko,
When will redisson 3.15.1 be released? Will you update netty to the latest version?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3427
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We are developing a micro-service in spring-boot, which would be deployed in cloud foundry , we want to use redisson as l2 hibernate cache, problem is RedissonRegionFactory expects Config from redisson.json/yaml file,  and
we cannot have file in class path, is it possible read credential from vcap services ? or make redisson-hibernate spring compatible so that we can inject properties to RedissonRegionFactory.
we planning to use redisson as regular cache as well hibernernate l2 cache, please let me know is redisson is suitable for my use-case.
i tried extending the class RedissonRegionFactory and overrite createRedissonClient method to inject vcap peroperties in Config object but before spring creates beans hibernate trying to instantiate RedissonRegionFactory (i could be wrong).
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3428
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redis version 4.0.8
Redisson version 3.9.1
Redisson configuration singleServerConfig <org.redisson.codec.JsonJacksonCodec>
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3429
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3430
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3431
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3432
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3433
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3434
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3435
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3436
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3437
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3438
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3439
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3440
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3441
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3442
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3443
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3444
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3445
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3446
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3447
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3448
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3449
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3450
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3451
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3452
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3453
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3454
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3455
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3456
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3457
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3458
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3459
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3460
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3461
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3462
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3463
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3464
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3465
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3466
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3467
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3468
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3469
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3470
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3471
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3472
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3473
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3474
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3475
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3476
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3477
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3478
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3479
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3480
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3481
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3482
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3483
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3484
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3485
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3486
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3487
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3488
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3489
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3490
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3491
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3492
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3493
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3494
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3495
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3496
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3497
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3498
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3499
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3500
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3501
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3502
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3503
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3504
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3505
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3506
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3507
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3508
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3509
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3510
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3511
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3512
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3513
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3514
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3515
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3516
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3517
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3518
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3519
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3520
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3521
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I wrote a test case like this:
    @Test
    public void testLock() {
        new Thread() {
            @Override
            public void run() {
                Lock lock = redisson.getLock("lock1");
                if (lock.tryLock()) {
                    System.out.println(new Date() + " - locked");
                }
                try {
                    Thread.sleep(11000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(new Date() + " - throw error ");
                throw new RuntimeException();
            }
        }.start();
        try {
            Thread.sleep(60000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
and here is the result

Thread crashed and renew task is still going on.
I think it's necessary to check thread when renewing.
any idea? :)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3522
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Use method Config.setConnectionListener() for listener registration.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3523
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3524
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@mrniko do you like the changes, or I can close the MR?
I ask it because has no experience with open source and I don't understood that should i resolve conflicts or no ;/
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3525
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Batch response include result of two operations:
 RBatchReactive batch = redissonClient.createBatch();
 batch.getSetCache("setKey"), StringCodec.INSTANCE).contains("setEntryKey");
 batch.getBucket("bucketKey").isExists();
 return batch.execute()
           .flatMap(r -> {
                List<?> res = r.getResponses();
                boolean isExists = (Boolean) res.get(0);
                boolean contains = (Boolean) res.get(1);
                logger.info("batch result: isExists = {}, contains = {}", isExists, contains);
                return Mono.just(isExists && contains);
           })
           .subscribe();
Actual behavior
Batch response include result only for  batch.getBucket("bucketKey").isExists(); operation. During debugging i see that
executeAsync() method of CommandBatchService have only one command.
Redis version
5.0.7
Redisson version
3.13.5
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3526
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
method call should return without exception
Actual behavior
A RedisException is thrown:
org.redisson.client.RedisException: ERR Error running script (call to f_d66032e767a3ea7814ca959c0a81ae0baa165f75): @user_script:1: user_script:1: too many results to unpack . channel: [id: 0xf4ad5dc9, L:/<address> - R:<address>] command: (EVAL), params: [local rate = redis.call('hget', KEYS[1], 'rate');local interval = redis.call('hget', KEYS[1], 'inter..., 5, MyRateLimiter_107728585506707301, {MyRateLimiter_107728585506707301}:value, {MyRateLimiter_107728585506707301}:value:b3c4bb40-b4ac-46f8-a6f7-4f8161b4842..., {MyRateLimiter_107728585506707301}:permits, {MyRateLimiter_107728585506707301}:permits:b3c4bb40-b4ac-46f8-a6f7-4f8161b48..., 1, 1617010579119, 606081525...
Steps to reproduce or test case

Add more than 8k entries to rate limiter.
Wait for all of them to expire.
call availablePermits/tryAcquire.

RRateLimiter rateLimiter = redissonClient.getRateLimiter("test");
rateLimiter.setRate(RateType.OVERALL, 10_000, 2, RateIntervalUnit.MINUTES);
for (int i = 0; i < 8_001; i++) {
    rateLimiter.tryAcquire();
}
try {
    Thread.sleep(2*60*1000);
} catch (InterruptedException e) {
    e.printStackTrace();
}
long check = rateLimiter.availablePermits(); //throws the unwanted exception ...
// boolean check = rateLimiter.tryAcquire();  //would also throw the unwanted exception ...
System.out.println("result=" + check);


Redis version
6.2.1
Redisson version
3.14.1
Redisson configuration
singleServerConfig:
idleConnectionTimeout: 10000
connectTimeout: 10000
timeout: 3000
retryAttempts: 3
retryInterval: 1500
subscriptionsPerConnection: 5
sslEnableEndpointIdentification: true
sslProvider: "JDK"
pingConnectionInterval: 20000
keepAlive: true
tcpNoDelay: false
address: "redis://localhost:6379"
subscriptionConnectionMinimumIdleSize: 1
subscriptionConnectionPoolSize: 50
connectionMinimumIdleSize: 2
connectionPoolSize: 8
database: 4
dnsMonitoringInterval: 5000
threads: 16
nettyThreads: 32
codec: !<org.redisson.codec.JsonJacksonCodec> {}
referenceEnabled: true
transportMode: "NIO"
lockWatchdogTimeout: 30000
reliableTopicWatchdogTimeout: 600000
keepPubSubOrder: true
useScriptCache: false
minCleanUpDelay: 5
maxCleanUpDelay: 1800
cleanUpKeysAmount: 100
nettyHook: !<org.redisson.client.DefaultNettyHook> {}
useThreadClassLoader: true
addressResolverGroupFactory: !<org.redisson.connection.DnsAddressResolverGroupFactory> {}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3527
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Any alternative solution to create a SQL table structure in Redis using Redisson in java app. For example a table of say Products.
The standard flow would be to instantiate a RMapCache and add the products to that - something like this
  // save the prod to ProdTableCache
    final RMapCache<String, Product> prodMap;
    String prodMapKey = "ProductTable";
    final TypedJsonJacksonCodec prodCodec = new TypedJsonJacksonCodec(String.class, Product.class, new ObjectMapper());
    prodMap = redisson.getMapCache(prodMapKey, prodCodec);

    Product prod1 = new Product("Prod101", "Mobile", 1000);
    Product prod2 = new Product("Prod102", "Tablet", 2000);
    
    prodMap.put(prod1.id, prod1, 2, TimeUnit.DAYS);
    prodMap.put(prod2.id, prod2, 2, TimeUnit.DAYS);


and this in Redis would result in something like this
hscan "ProductTable" 0
1) "0"
2) 1) "\"Prod101\""
   2) "\x00\x00\x00\x00\x00\x00\x00\x00-\x00\x00\x00\x00\x00\x00\x00{\"id\":\"Prod101\",\"name\":\"Mobile\",\"price\":1000}"
   3) "\"Prod102\""
   4) "\x00\x00\x00\x00\x00\x00\x00\x00-\x00\x00\x00\x00\x00\x00\x00{\"id\":\"Prod102\",\"name\":\"Tablet\",\"price\":2000}"


While this solves the immediate problem, 2 or 3 questions arise


when doing the get command - prodRet = prodMap.get("Prod101"); - does Redis need to do a 2 step lookup - first to find the "ProductTable" and then to find the prod key within that ? is this not expensive?


in a Redis cluster environment the whole "ProductTable" will end up in 1 SLOT in 1 node. So whats the use of sharding across cluster ? Yes there may be other tables that may go to other nodes but no guarantees.


If someone has a better solution or better insight into this can you please share. Or am i missing something here?
appreciate your help...
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3528
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
This is a very simple java program using Redisson adding products to a productTableCache
        // save the prod to ProdTableCache
        Product prod1 = new Product("DirectProd102", "Mobile", 1000);
        Product prod2 = new Product("LocalProd102", "Mobile", 1000);
        String prodMapKey = "ProductTable";
        final TypedJsonJacksonCodec prodCodec = new TypedJsonJacksonCodec(String.class, Product.class, new ObjectMapper());
        RMapCache<String, Product> prodDirectMap = redisson.getMapCache(prodMapKey, prodCodec);
        prodDirectMap.put(prod1.id, prod1);


When i look from redis-cli , i see these extra bytes added to the product value in redis - what are these additional bytes ?
127.0.0.1:6001> hscan ProductTable 0
1) "0"
    3) "\"DirectProd102\""
    4) "\x00\x00\x00\x00\x00\x00\x00\x00-\x00\x00\x00\x00\x00\x00\x00{\"id\":\"Prod102\",\"name\":\" Mobile  \",\"price\":1000}"


Now if i insert another product using Redisson getLocalMapedCache i dont see these additional bytes
        Product prod2 = new Product("LocalProd102", "Mobile", 1000);
        RLocalCachedMap<String, Product> prodLocalMap = redisson.getLocalCachedMap(prodMapKey, prodCodec, options);
        prodLocalMap.put(prod2.id, prod2);


127.0.0.1:6001> hscan ProductTable 0
1) "0"
2)  1) "\"LocalProd102\""
    2) "{\"id\":\"LocalProd102\",\"name\":\"Mobile\",\"price\":1000}"


But now if i refer to LocalProd102 in an EVALSHA script , it gives exception possibly because the additional bytes are not found.
Any help or prior experience in this regards ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3529
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
when I use it in Distribute Schedule  ,Runnable method  depencies on spring context(i.e @Service UserService.class and @Mapper UserMapper.class include more indirection depencies )   each other must implemnts Serializable ,This way is unfriendly,so I suggest ...
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3530
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
There isn't any standard way or sample to basic Redisson with Quarkus Integration!
I actually, looking to find a way to handle distributed cache with Redisson. Could you please inform me in this way?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3531
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for suggested pr. According to your changes old values are sent for any listener even if old value wasn't requested. This may increase pub/sub traffic for customers who don't need it. I think we need to maintain counter of listeners requested old value and don't send it if counter == 0.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3532
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I'm trying to configure the Reddisson client to connect over TLS1.3. Has anyone had success with this? I've been setting the ssl* configuration parameters with the correct keystore file and sslProvider but I keep getting handshake failures.
io.netty.handler.codec.DecoderException: javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure\n\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:478)\n\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.base/java.lang.Thread.run(Thread.java:832)\nCaused by: javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure\n\tat java.base/sun.security.ssl.Alert.createSSLException(Alert.java:131)\n\tat java.base/sun.security.ssl.Alert.createSSLException(Alert.java:117)\n\tat java.base/sun.security.ssl.TransportContext.fatal(TransportContext.java:356)\n\tat java.base/sun.security.ssl.Alert$AlertConsumer.consume(Alert.java:293)\n\tat java.base/sun.security.ssl.TransportContext.dispatch(TransportContext.java:202)\n\tat java.base/sun.security.ssl.SSLTransport.decode(SSLTransport.java:171)\n\tat java.base/sun.security.ssl.SSLEngineImpl.decode(SSLEngineImpl.java:736)\n\tat java.base/sun.security.ssl.SSLEngineImpl.readRecord(SSLEngineImpl.java:691)\n\tat java.base/sun.security.ssl.SSLEngineImpl.unwrap(SSLEngineImpl.java:506)\n\tat java.base/sun.security.ssl.SSLEngineImpl.unwrap(SSLEngineImpl.java:482)\n\tat java.base/javax.net.ssl.SSLEngine.unwrap(SSLEngine.java:637)\n\tat io.netty.handler.ssl.SslHandler$SslEngineType$3.unwrap(SslHandler.java:283)\n\tat io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1388)\n\tat io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1283)\n\tat io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1330)\n\tat io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:508)\n\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:447)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3533
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3534
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I using:

Hibernate 5.4.21.Final
redisson-hibernate-53 3.13.4

Codec: org.redisson.codec.Kryo5Codec
Expected behavior
deserialization should work with org.redisson.codec.Kryo5Codec too.
Actual behavior
TestEntity testEntity = session.bySimpleNaturalId(TestEntity.class).load("erik"); (READ_WRITE)
Loading entity causing an error:
https://ghostbin.co/paste/gwjgdn/edit
Steps to reproduce or test case
Use Hibernate with redisson second level cache and load an entity with a READ_WRITE as strategy.
Redisson version
3.13.4
Redisson configuration
singleServerConfig:
idleConnectionTimeout: 10000
connectTimeout: 10000
timeout: 8000
retryAttempts: 3
retryInterval: 1500
password: ""
subscriptionsPerConnection: 5
clientName: null
address: "redis://192.168.100.90:6379"
subscriptionConnectionMinimumIdleSize: 1
subscriptionConnectionPoolSize: 16
connectionMinimumIdleSize: 10
connectionPoolSize: 32
database: 0
dnsMonitoringInterval: 5000
threads: 32
nettyThreads: 32
codec: !<org.redisson.codec.Kryo5Codec> {}
useThreadClassLoader: false
NOTE: If it is not a redisson error, where should I create an issue?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3535
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Set up:
public final CompletionStage<Long> foo(
        String sha,
        String key,
        long expirationSeconds,
        String... elements) {
    String[] keys = {key};
    String[] arguments = new String[elements.length + 1];
    arguments[0] = String.valueOf(expirationSeconds);
    System.arraycopy(elements, 0, arguments, 1, elements.length);

    // calls inside this function are simplified. please ignore redundant allocations / casts.
    Object[] vals = Arrays.copyOf(arguments, arguments.length, Object[].class);

    // RedissonClient client;
    return client
            .getScript()
            .evalShaAsync(RScript.Mode.READ_WRITE, sha, RScript.ReturnType.INTEGER, Arrays.asList(keys), vals);
}

where:

sha is the hash of a loaded script (via SCRIPT LOAD) command.
key is an alphanumeric string. e.g. "123456789"
expirationSeconds is 3600
elements is a single alphanumeric string. e.g. "foobar1234"

the loaded Lua script contains the following lines:
if not tonumber(ARGV[1]) then
  return {err="invalid expiration. ARGV[1]="..ARGV[1]}
end

in order to parse the expiration.
Expected behavior
the if check in LUA script should not trigger an error.
Actual behavior
script returned error and from the error message ARGV[1] is set to > 3600 with possible whitespace characters (stripped from console output)
Steps to reproduce or test case

load a script (statically or programmatically) contains the argument parse lines above
invoke the method above
observe the application output

Redis version
6.0.5 (AWS ElastiCache, cluster mode)
Redisson version
3.15.3
Redisson configuration
Config cfg = new Config();
RedisURI uri = new RedisURI("redis", "aws-ec-redis-cluster-endpoint", 6379);
cfg.useClusterServers().addNodeAddress(uri.toString());
cfg.setThreads(4);
cfg.setNettyThreads(8);
RedissonClient client = Redisson.create(cfg);

Note on the script:
the same script (without modification) worked with lettuce-core in the same application in a production environment (with thousands of calls per minute running 24/7) and has been proven stable.
for some reason the arguments received on Redis server (from redisson) contains extra characters for the first argument.
Update
I tested a non-default Codec:
cfg.setCodec(StringCodec.INSTANCE);
and the issue is addressed. Not sure if this is expected behavior for the default Codec
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3536
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi Team,
while we are using Redisson 2.15.1.
Java 1.7.80
With 3 redis clusters and 3 application instances
with below redisson.conf
`{
"clusterServersConfig":{
"idleConnectionTimeout":10000,
"connectTimeout":10000,
"timeout":3000,
"retryAttempts":3,
"retryInterval":1500,
"failedSlaveReconnectionInterval":3000,
"failedSlaveCheckInterval":60000,
"password":null,
"subscriptionsPerConnection":10,
"clientName":null,
"loadBalancer":{
"class":"org.redisson.connection.balancer.RoundRobinLoadBalancer"
},
"subscriptionConnectionMinimumIdleSize":1,
"subscriptionConnectionPoolSize":50,
"slaveConnectionMinimumIdleSize":1,
"slaveConnectionPoolSize":2,
"masterConnectionMinimumIdleSize":1,
"masterConnectionPoolSize":2,
"readMode":"MASTER",
"subscriptionMode":"MASTER",
"nodeAddresses":[
"master1",
"master2”,
"master3”,
"master1-slave1”,
"master1-slave2”,
"master1-slave3”,
"master2-slave1”,
"master2-slave2”,
"master2-slave3”,
"master3-slave1”,
"master3-slave2”,
"master3-slave3”,
  ],
  "scanInterval":1000,
  "pingConnectionInterval": 0,
  "keepAlive": false,
  "tcpNoDelay": false,

},
"threads":0,
"nettyThreads": 0,
"codec":{
"class":"org.redisson.codec.SerializationCodec"
},
"transportMode":"NIO"
}`
And getting below error.
org.redisson.client.RedisException: Unexpected exception while processing command
at org.redisson.command.CommandAsyncService.convertException(CommandAsyncService.java:414)
at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:211)
at org.redisson.RedissonObject.get(RedissonObject.java:75)
at org.redisson.RedissonMap.putAll(RedissonMap.java:296)
at org.redisson.tomcat.RedissonSession.access(RedissonSession.java:117)
at org.redisson.tomcat.RedissonSessionManager.findSession(RedissonSessionManager.java:176)
at org.apache.catalina.connector.Request.doGetSession(Request.java:2855)
at org.apache.catalina.connector.Request.getSession(Request.java:2254)
at org.redisson.tomcat.UpdateValve.invoke(UpdateValve.java:60)
at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:518)
at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1091)
at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:668)
at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1527)
at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1484)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NullPointerException
at org.redisson.codec.CompositeCodec.getValueDecoder(CompositeCodec.java:74)
at org.redisson.client.handler.CommandDecoder.selectDecoder(CommandDecoder.java:464)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:329)
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:130)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:110)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:591)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:508)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470)
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
... 1 more
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3537
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We are trying the below approach to get the data from Redis with TTL.
RMap<String, Object> rMap = this.client.getMap(this.getEnvCacheKey(cacheKey));
rMap.expire(this.defaultTTL, TimeUnit.SECONDS);
//Fetch the object
Object object = rMap.get("id");
//Putting the same in list
List list = new ArrayList<>();
list.add(object);
//Now TTL expires of key and object deleted.
Now list.size == 0 and my application failing due to this since the object fetched in removed from memory.
Please any approach to mitigate this issue.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3538
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi
Does Redisson has any logic for intelligently handling a scenario where a particular shard is down in Redis. Possible 'intelligent' solutions could be to-

Avoid calling Redis cluster for keys located over that shard
Not keep retrying for keys which are continuously failing

All these solutions may enable it to keep serving the traffic for which ever keys it can from other shards.
This is possible only with some built in knowledge of key distribution across shards, I am not aware if redisson has that context ?
Thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3539
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
hi,im use redisson collection ,and this is my code
t6 put kv to localCachedMap,
then concurrent requests t5, found   duplicate records
    @GetMapping("/t5")
    public String t5() {
        RLocalCachedMap<Long, Map<Long, String>> rcount = redisson.getLocalCachedMap("tt2", LocalCachedMapOptions.defaults());
        Iterator<Map.Entry<Long, Map<Long, String>>> iterator = rcount.entrySet().iterator();
        int i = 0;
        while (iterator.hasNext()) {
            Map.Entry<Long, Map<Long, String>> item = iterator.next();
            if (i >= 10) {
                break;
            }
            Long key = item.getKey();
            Map<Long, String> pair = item.getValue();
            log.info("left---- : " + item.getKey() + "val---- : " + pair.get(key));
            rcount.remove(key);
            log.info("size : ",rcount.size());
            i++;
            log.info("---------------------------------------------------------");

        }
        rcount.destroy();
        return "ok!";
    }

    @GetMapping("/t6")
    public String t6() {
        RLocalCachedMap<Long, Map<Long, String>> rcount = redisson.getLocalCachedMap("tt2", LocalCachedMapOptions.defaults());
        for (int i = 100; i < 1000; i++) {
            HashMap hashMap = Maps.newHashMap();
            hashMap.put(Long.valueOf(i), "val" + i);
            rcount.put(Long.valueOf(i), hashMap);
        }
        return "ok!";
    }
request  log
2021-04-07 15:05:36.532  INFO 1860 --- [io-8082-exec-10] com.test.controller.TController      : ---------------------------------------------------------
2021-04-07 15:05:36.532  INFO 1860 --- [io-8082-exec-10] com.test.controller.TController      : left---- : 972val---- : val972
2021-04-07 15:05:36.534  INFO 1860 --- [nio-8082-exec-9] com.test.controller.TController      : ---------------------------------------------------------
2021-04-07 15:05:36.534  INFO 1860 --- [nio-8082-exec-9] com.test.controller.TController      : left---- : 972val---- : val972
2021-04-07 15:05:36.536  INFO 1860 --- [io-8082-exec-10] com.test.controller.TController      : size : 
2021-04-07 15:05:36.537  INFO 1860 --- [nio-8082-exec-9] com.test.controller.TController      : size : 
2021-04-07 15:05:36.537  INFO 1860 --- [io-8082-exec-10] com.test.controller.TController      : ---------------------------------------------------------
2021-04-07 15:05:36.537  INFO 1860 --- [io-8082-exec-10] com.test.controller.TController      : left---- : 875val---- : val875
2021-04-07 15:05:36.539  INFO 1860 --- [nio-8082-exec-9] com.test.controller.TController      : ---------------------------------------------------------
2021-04-07 15:05:36.539  INFO 1860 --- [nio-8082-exec-9] com.test.controller.TController      : left---- : 875val---- : val875
2021-04-07 15:05:36.540  INFO 1860 --- [io-8082-exec-10] com.test.controller.TController      : size : 
2021-04-07 15:05:36.542  INFO 1860 --- [io-8082-exec-10] com.test.controller.TController      : ---------------------------------------------------------
2021-04-07 15:05:36.542  INFO 1860 --- [nio-8082-exec-9] com.test.controller.TController      : size : 
2021-04-07 15:05:36.542  INFO 1860 --- [io-8082-exec-10] com.test.controller.TController      : left---- : 561val---- : val561
2021-04-07 15:05:36.544  INFO 1860 --- [nio-8082-exec-9] com.test.controller.TController      : ---------------------------------------------------------
2021-04-07 15:05:36.544  INFO 1860 --- [nio-8082-exec-9] com.test.controller.TController      : left---- : 561val---- : val561
2021-04-07 15:05:36.545  INFO 1860 --- [io-8082-exec-10] com.test.controller.TController      : size : 
2021-04-07 15:05:36.547  INFO 1860 --- [io-8082-exec-10] com.test.controller.TController      : ---------------------------------------------------------
2021-04-07 15:05:36.547  INFO 1860 --- [nio-8082-exec-9] com.test.controller.TController      : size : 
2021-04-07 15:05:36.550  INFO 1860 --- [nio-8082-exec-9] com.test.controller.TController      : ---------------------------------------------------------
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3540
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
example:
BITFIELD key get u5 0
can I use redisson client to execute command like this?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3541
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We are using Redisson to connect to an AWS ElastiCache Redis cluster. We are seeing an elevated number of exceptions after we scale the cluster up or down and redistribute the slots.
Expected behavior
Redisson will pick up the new topology and slot distribution after the re-sharding is done.
Actual behavior
We are seeing these exceptions:
org.redisson.client.RedisNodeNotFoundException: Node: NodeSource [slot=XXXXX, addr=redis://XXXX:XXXX, redisClient=null, redirect=MOVED, entry=null] hasn't been discovered yet. Increase value of retryAttempts and/or retryInterval settings.

The exceptions persist for hours after the re-sharding is done. We don't see these exceptions if we restart our service.
Steps to reproduce or test case

Initialize Redisson client and connect to AWS ElastiCache cluster
Add or remove shards
Wait until cluster is in active state and slot redistribution is done
Try to read from the cluster

Redis version
AWS ElastiCache Redis
Engine: Clustered Redis
Encryption-in-Transit: No
Redis Version 6.0.5
Redisson version
3.15.0
Redisson configuration
...
.useClusterServers()
.addNodeAddress(###)
.setScanInterval(100)
.setRetryInterval(50)
.setRetryAttempts(2)
.setPingConnectionInterval(1000)
.setTimeout(30000);
...

All other values are default
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3542
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
not error
Actual behavior
got java.lang.ClassCastException: java.lang.String cannot be cast to com.example.entities.MyLiveObject2
Steps to reproduce or test case
@REntity @Data @NoArgsConstructor public class MyLiveObject2 { @RId private String id; @RIndex private String name; private String remark; }
`@Test
public void test() throws IOException {
RMap<Integer, MyLiveObject2> map = redisson.getMap("map");
    RLiveObjectService service = redisson.getLiveObjectService();

    MyLiveObject2 obj1 = new MyLiveObject2();
    obj1.setId("1");
    obj1.setName("username1");
    obj1.setRemark("remark1");
    obj1 = service.persist(obj1);
    
    System.out.println(obj1);

    map.put(1, obj1);
}`

`@Test
public void test()2 throws IOException {
RMap<Integer, MyLiveObject2> map = redisson.getMap("map");
    MyLiveObject2 obj1 = map.get(1);   // java.lang.ClassCastException: java.lang.String cannot be cast to com.example.entities.MyLiveObject2
    System.out.println(obj1);
}`

Redis version
3.2.100
Redisson version
2.15.2 or 3.15.3
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3543
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We have a 3 node redis cluster and redis clients running as java servers.
on some redis clients we see Redisson continuously keeps doing connections initialized - sometimes for more than 2 min or so.
Same program is runing on other servers connected to the same redis cluster but there we dont see this issue.
What could be triggering this reconnections? Anything we need to change in the config ?
2021-04-08T10:57:47,231 [redisson-netty-2-4] INFO  (ConnectionPool.java:167) - 1 connections initialized for /xxx.18.251.2:6379
2021-04-08T10:57:47,237 [redisson-netty-2-24] INFO  (ClusterConnectionManager.java:254) - /xxx.81.23.45:6379 master and related slaves:  removed
2021-04-08T10:57:47,240 [redisson-netty-2-24] INFO  (ConnectionPool.java:167) - 24 connections initialized for /xxx.18.251.2:6379
2021-04-08T10:57:47,241 [redisson-netty-2-15] INFO  (ConnectionPool.java:167) - 24 connections initialized for /xxx.18.251.2:6379
2021-04-08T10:57:47,241 [redisson-netty-2-24] INFO  (ClusterConnectionManager.java:332) - master: redis://xxx.18.251.2:6379 added for slot ranges: [[0-5460]]
2021-04-08T10:57:47,245 [redisson-netty-2-24] INFO  (ConnectionPool.java:167) - 1 connections initialized for /xxx.18.251.2:6379
2021-04-08T10:57:52,245 [redisson-netty-2-6] INFO  (ConnectionPool.java:167) - 1 connections initialized for /xxx.81.23.45:6379
2021-04-08T10:57:52,249 [redisson-netty-2-29] INFO  (ClusterConnectionManager.java:254) - /xxx.18.251.2:6379 master and related slaves:  removed
2021-04-08T10:57:52,249 [redisson-netty-2-29] INFO  (ConnectionPool.java:167) - 24 connections initialized for /xxx.81.23.45:6379
2021-04-08T10:57:52,251 [redisson-netty-2-22] INFO  (ConnectionPool.java:167) - 1 connections initialized for /xxx.81.23.45:6379


Below is the config passed to redisson
creating with this config = {"clusterServersConfig":{"idleConnectionTimeout":10000,"connectTimeout":5000,"timeout":3000,"retryAttempts":10,"retryInterval":1500,"subscriptionsPerConnection":5,"sslEnableEndpointIdentification":true,"sslProvider":"JDK","pingConnectionInterval":0,"keepAlive":false,"tcpNoDelay":false,"loadBalancer":{"class":"org.redisson.connection.balancer.RoundRobinLoadBalancer"},"slaveConnectionMinimumIdleSize":24,"slaveConnectionPoolSize":64,"failedSlaveReconnectionInterval":3000,"failedSlaveCheckInterval":180000,"masterConnectionMinimumIdleSize":24,"masterConnectionPoolSize":64,"readMode":"SLAVE","subscriptionMode":"MASTER","subscriptionConnectionMinimumIdleSize":1,"subscriptionConnectionPoolSize":50,"dnsMonitoringInterval":5000,"natMapper":{"class":"org.redisson.api.DefaultNatMapper"},"nodeAddresses":["redis://xxx.81.23.45:6379","redis://xxx.81.23.47:6379","redis://xxx.81.23.48:6379"],"scanInterval":5000,"checkSlotsCoverage":true},"threads":16,"nettyThreads":32,"referenceEnabled":true,"transportMode":"NIO","lockWatchdogTimeout":30000,"keepPubSubOrder":true,"decodeInExecutor":false,"useScriptCache":false,"minCleanUpDelay":5,"maxCleanUpDelay":1800,"cleanUpKeysAmount":100,"nettyHook":{"class":"org.redisson.client.DefaultNettyHook"},"useThreadClassLoader":true,"addressResolverGroupFactory":{"class":"org.redisson.connection.DnsAddressResolverGroupFactory"}}
appreciate any help.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3544
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Reddison watchDog strategy use timerTask to increase key expiration time while set the lock success
private void renewExpiration() {
    ExpirationEntry ee = EXPIRATION_RENEWAL_MAP.get(getEntryName());
    if (ee == null) {
        return;
    }
    
    Timeout task = commandExecutor.getConnectionManager().newTimeout(new TimerTask() {
        @Override
        public void run(Timeout timeout) throws Exception {
            ExpirationEntry ent = EXPIRATION_RENEWAL_MAP.get(getEntryName());
            if (ent == null) {
                return;
            }
            Long threadId = ent.getFirstThreadId();
            if (threadId == null) {
                return;
            }
            
            RFuture<Boolean> future = renewExpirationAsync(threadId);
            ......
   }

}
First use entryName to get ExpirationEntry object. For the same entryName, other threads can't get the key because locked(ps: same thread can get and counter++)，so why use LinkedHashMap to save thread if there only have one thread?
`public static class ExpirationEntry {
    private final Map<Long, Integer> threadIds = new LinkedHashMap<>();
    private volatile Timeout timeout;

    public ExpirationEntry() {
        super();
    }

    public synchronized void addThreadId(long threadId) {
        Integer counter = threadIds.get(threadId);
        if (counter == null) {
            counter = 1;
        } else {
            counter++;
        }
        threadIds.put(threadId, counter);
    }

}`
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3545
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Some time getting following exception in unit tests but not always
org.redisson.client.WriteRedisConnectionException: Unable to write command into connection! 
Node source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null],
 connection: RedisConnection@1405217801 [redisClient=[addr=redis://localhost:6333], 
channel=[id: 0xec022dc7, L:0.0.0.0/0.0.0.0:38200], currentCommand=null], command: (EVAL), 
params: [local v = redis.call('hget', KEYS[1], ARGV[1]); 
redis.call('hset', KEYS[1], ARGV[1], ARGV[2]); retur..., 1,  
RequestCache, PooledUnsafeDirectByteBuf(ridx: 0, widx: 42, cap: 256), 
PooledUnsafeDirectByteBuf(ridx: 0, widx: 103, cap: 256)] after 3 retry attempts
Caused by: io.netty.channel.StacklessClosedChannelException
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3546
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In the below code, we are facing intermittent issues where System.out.println("Your Ids: "+ids1) is not printed when we add something and RedissionSet reference doesn't contain anything even after adding objects to it.
final Set<String> homeIds = platformCache.getSet(Home.fetchProductCacheKey(productId));

List<String> getIds = callToDb.getProductId(productId);

for(String ids : getIds) {
homeIds.add(ids);
}

for(String ids1: homeIds) { // This for loop is not run since homeids were empty sometimes.
System.out.println("Your Ids: "+ids1);
}


Are we doing anything wrong? Any help will be appreciated.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3547
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
our server sometimes throw a exception ,the flow ,then the sytem is unavailable，how to solve this problem,thinks
09:44:13.798 [http-nio-8080-exec-10] ERROR com.yonyoucloud.fi.ml.matctr.controller.MatCtrController 223 excute - Redis server response timeout (3000 ms) occured after 3 retry attempts. Command: (SCAN), params: [0, MATCH, LOCK:FI:PCM:ML_ROLL_CALC:2178455676211456_2186231617491200, COUNT, 10], channel: [id: 0xe84efdef, L:/172.21.178.133:58668 - R:172.20.49.236/172.20.49.236:6352]
org.redisson.client.RedisResponseTimeoutException: Redis server response timeout (3000 ms) occured after 3 retry attempts. Command: (SCAN), params: [0, MATCH, LOCK:FI:PCM:ML_ROLL_CALC:2178455676211456_2186231617491200, COUNT, 10], channel: [id: 0xe84efdef, L:/172.21.178.133:58668 - R:172.20.49.236/172.20.49.236:6352]
at org.redisson.command.CommandAsyncService$8.run(CommandAsyncService.java:935)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:672)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:747)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:472)
at java.lang.Thread.run(Thread.java:748)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3548
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
hi,
we see some time following exception at the log , we don't know the reason for it
2021-04-12 06:15:11.452 ERROR [redisson-netty-2-15] [UID:, MSG_ID:] [org.redisson.connection.DNSMonitor] <Unable to resolve **********.amazonaws.com>
java.lang.IndexOutOfBoundsException: Index: 0, Size: 0
at java.util.ArrayList.rangeCheck(ArrayList.java:659) ~[na:1.8.0_261]
at java.util.ArrayList.get(ArrayList.java:435) ~[na:1.8.0_261]
at io.netty.resolver.dns.DnsNameResolver.doResolveCached(DnsNameResolver.java:613) ~[netty-all-4.1.15.Final.jar:4.1.15.Final]
at io.netty.resolver.dns.DnsNameResolver.doResolve(DnsNameResolver.java:593) ~[netty-all-4.1.15.Final.jar:4.1.15.Final]
at io.netty.resolver.dns.DnsNameResolver.doResolve(DnsNameResolver.java:527) ~[netty-all-4.1.15.Final.jar:4.1.15.Final]
at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:63) ~[netty-all-4.1.15.Final.jar:4.1.15.Final]
at io.netty.resolver.dns.InflightNameResolver.resolve(InflightNameResolver.java:100) ~[netty-all-4.1.15.Final.jar:4.1.15.Final]
at io.netty.resolver.dns.InflightNameResolver.resolve(InflightNameResolver.java:66) ~[netty-all-4.1.15.Final.jar:4.1.15.Final]
at io.netty.resolver.dns.InflightNameResolver.resolve(InflightNameResolver.java:51) ~[netty-all-4.1.15.Final.jar:4.1.15.Final]
at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:57) ~[netty-all-4.1.15.Final.jar:4.1.15.Final]
at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:32) ~[netty-all-4.1.15.Final.jar:4.1.15.Final]
at io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:108) ~[netty-all-4.1.15.Final.jar:4.1.15.Final]
at org.redisson.connection.DNSMonitor.monitorMasters(DNSMonitor.java:103) ~[redisson-3.14.0.jar:3.14.0]
at org.redisson.connection.DNSMonitor.access$300(DNSMonitor.java:45) ~[redisson-3.14.0.jar:3.14.0]
at org.redisson.connection.DNSMonitor$1.run(DNSMonitor.java:92) ~[redisson-3.14.0.jar:3.14.0]
at io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38) ~[netty-all-4.1.15.Final.jar:4.1.15.Final]
at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:120) ~[netty-all-4.1.15.Final.jar:4.1.15.Final]
at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163) [netty-all-4.1.15.Final.jar:4.1.15.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403) [netty-all-4.1.15.Final.jar:4.1.15.Final]
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463) [netty-all-4.1.15.Final.jar:4.1.15.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) [netty-all-4.1.15.Final.jar:4.1.15.Final]
at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138) [netty-all-4.1.15.Final.jar:4.1.15.Final]
at java.lang.Thread.run(Thread.java:748) [na:1.8.0_261]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3549
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I use both sync and reactive redisson clients in one project. Reactive one for business logic and sync one for third party library.
Calling sync client methods in reactive client map/subscription lambda/callback will throw the exception:
java.lang.IllegalStateException: Sync methods can't be invoked from async/rx/reactive listeners
		at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:135)
		at org.redisson.RedissonObject.get(RedissonObject.java:81)
		at org.redisson.RedissonBucket.get(RedissonBucket.java:104)

The exception is thrown by a method checks name of current thread starts with "redisson-netty"(introduced in version 3.15.1?). However, all reactive operator will run in the thread that named "redisson-netty-x" in downstream of reactive redisson client operation.
Steps to reproduce or test case
RedissonClient client = Redisson.create(); 
RedissonReactiveClient reactiveClient = Redisson.createReactive();

reactiveClient.getBucket("key").get() 
        .map(ignored -> client.getBucket("key").get())  // Throws exception
        .block();

Redisson version
3.15.3
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3550
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Calling sync methods in async/rx/reactive callback lead to timeout exceptions, since they called in netty-threads. Use separate ExecutorService.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3551
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case
5.X*
3.14.1
Redisson configuration
An exception was thrown by org.redisson.misc.RedissonPromise$$Lambda$477/641664202.operationComplete()
java.lang.NullPointerException: null
at java.util.concurrent.ConcurrentHashMap.get(ConcurrentHashMap.java:936)
at java.util.concurrent.ConcurrentHashMap.getOrDefault(ConcurrentHashMap.java:1588)
at org.redisson.pubsub.PublishSubscribeService.getConnectionsQueue(PublishSubscribeService.java:222)
at org.redisson.pubsub.PublishSubscribeService.access$100(PublishSubscribeService.java:55)
at org.redisson.pubsub.PublishSubscribeService$5$1.run(PublishSubscribeService.java:410)
at org.redisson.pubsub.AsyncSemaphore.tryRun(AsyncSemaphore.java:86)
at org.redisson.pubsub.AsyncSemaphore.acquire(AsyncSemaphore.java:66)
at org.redisson.pubsub.PublishSubscribeService$5.run(PublishSubscribeService.java:407)
at org.redisson.pubsub.AsyncSemaphore.tryRun(AsyncSemaphore.java:86)
at org.redisson.pubsub.AsyncSemaphore.acquire(AsyncSemaphore.java:66)
at org.redisson.pubsub.PublishSubscribeService.unsubscribe(PublishSubscribeService.java:397)
at org.redisson.pubsub.PublishSubscribeService.lambda$reattachPubSub$6(PublishSubscribeService.java:512)
at org.redisson.pubsub.PublishSubscribeService$$Lambda$1307/1783130940.accept(Unknown Source)
at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175)
at java.util.concurrent.ConcurrentHashMap$EntrySpliterator.forEachRemaining(ConcurrentHashMap.java:3606)
at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512)
at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502)
at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
at org.redisson.pubsub.PublishSubscribeService.reattachPubSub(PublishSubscribeService.java:507)
at org.redisson.cluster.ClusterConnectionManager$$Lambda$625/1213684246.accept(Unknown Source)
at java.lang.Iterable.forEach(Iterable.java:75)
at org.redisson.cluster.ClusterConnectionManager.checkSlotsMigration(ClusterConnectionManager.java:707)
at org.redisson.cluster.ClusterConnectionManager.lambda$null$9(ClusterConnectionManager.java:463)
at org.redisson.cluster.ClusterConnectionManager$$Lambda$622/1202605701.accept(Unknown Source)
at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:187)
at org.redisson.misc.RedissonPromise$$Lambda$477/641664202.operationComplete(Unknown Source)
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)
at io.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:183)
at org.redisson.misc.RedissonPromise.onComplete(RedissonPromise.java:181)
at org.redisson.cluster.ClusterConnectionManager.lambda$updateClusterState$10(ClusterConnectionManager.java:462)
at org.redisson.cluster.ClusterConnectionManager$$Lambda$621/1480608532.accept(Unknown Source)
at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:187)
at org.redisson.misc.RedissonPromise$$Lambda$477/641664202.operationComplete(Unknown Source)
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)
at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:570)
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:549)
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)
at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)
at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)
at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)
at org.redisson.misc.RedissonPromise.trySuccess(RedissonPromise.java:82)
at org.redisson.client.handler.CommandDecoder.completeResponse(CommandDecoder.java:433)
at org.redisson.client.handler.CommandDecoder.handleResult(CommandDecoder.java:427)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:358)
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:178)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:117)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:102)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:498)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:745)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3552
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
hi,
is following exception is also related to netty version or there is other problem , by the way wasn't happen to us before production :)
2021-04-13 00:56:32.886 ERROR [redisson-netty-5-6] [UID:, MSG_ID:] [org.redisson.client.handler.CommandDecoder] <Unable to decode data. channel: [id: 0x7cf299d2, L:/10.20.30.46:60492 - R*amazonaws.com/], reply: ReplayingDecoderByteBuf(ridx=731, widx=16046), command: (HGETALL), params: [redisson:tomcat_session:FC5EA1D579A23B0EABBE7309D03486F2.APP_EMEA_2103]>
java.io.IOException: java.lang.ClassNotFoundException: com.panaya.as.blexecuter.imp.BaseBLContext
at org.redisson.codec.MarshallingCodec$3.decode(MarshallingCodec.java:153) ~[redisson-all-3.14.0.jar:3.14.0]
at org.redisson.codec.SnappyCodec$3.decode(SnappyCodec.java:84) ~[redisson-all-3.14.0.jar:3.14.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:356) [redisson-all-3.14.0.jar:3.14.0]
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:400) [redisson-all-3.14.0.jar:3.14.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:365) [redisson-all-3.14.0.jar:3.14.0]
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:178) [redisson-all-3.14.0.jar:3.14.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:117) [redisson-all-3.14.0.jar:3.14.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:102) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:501) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [redisson-all-3.14.0.jar:3.14.0]
at java.lang.Thread.run(Thread.java:748) [na:1.8.0_261]
Caused by: java.lang.ClassNotFoundException: com.panaya.as.blexecuter.imp.BaseBLContext
at java.net.URLClassLoader.findClass(URLClassLoader.java:382) ~[na:1.8.0_261]
at java.lang.ClassLoader.loadClass(ClassLoader.java:418) ~[na:1.8.0_261]
at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ~[na:1.8.0_261]
at java.lang.Class.forName0(Native Method) ~[na:1.8.0_261]
at java.lang.Class.forName(Class.java:348) ~[na:1.8.0_261]
at org.jboss.marshalling.AbstractClassResolver.loadClass(AbstractClassResolver.java:129) ~[redisson-all-3.14.0.jar:3.14.0]
at org.jboss.marshalling.AbstractClassResolver.resolveClass(AbstractClassResolver.java:110) ~[redisson-all-3.14.0.jar:3.14.0]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadClassDescriptor(RiverUnmarshaller.java:1033) ~[redisson-all-3.14.0.jar:3.14.0]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadNewObject(RiverUnmarshaller.java:1366) ~[redisson-all-3.14.0.jar:3.14.0]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadObject(RiverUnmarshaller.java:283) ~[redisson-all-3.14.0.jar:3.14.0]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadObject(RiverUnmarshaller.java:216) ~[redisson-all-3.14.0.jar:3.14.0]
at org.jboss.marshalling.AbstractObjectInput.readObject(AbstractObjectInput.java:41) ~[redisson-all-3.14.0.jar:3.14.0]
at org.redisson.codec.MarshallingCodec$3.decode(MarshallingCodec.java:151) ~[redisson-all-3.14.0.jar:3.14.0]
... 26 common frames omitted
2021-04-13 00:56:32.887 ERROR [redisson-netty-5-6] [UID:, MSG_ID:] [org.redisson.client.handler.ErrorsLoggingHandler] <Exception occured. Channel: [id: 0x7cf299d2, L:/10.20.30.46:60492 - R:emea-redis.mugo7l.ng.0001.euw1.cache.amazonaws.com/10.20.100.149:6379]>
io.netty.handler.codec.DecoderException: java.io.IOException: java.lang.ClassNotFoundException: com.panaya.as.blexecuter.imp.BaseBLContext
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:421) ~[redisson-all-3.14.0.jar:3.14.0]
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276) ~[redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [redisson-all-3.14.0.jar:3.14.0]
at java.lang.Thread.run(Thread.java:748) [na:1.8.0_261]
Caused by: java.io.IOException: java.lang.ClassNotFoundException: com.panaya.as.blexecuter.imp.BaseBLContext
at org.redisson.codec.MarshallingCodec$3.decode(MarshallingCodec.java:153) ~[redisson-all-3.14.0.jar:3.14.0]
at org.redisson.codec.SnappyCodec$3.decode(SnappyCodec.java:84) ~[redisson-all-3.14.0.jar:3.14.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:356) ~[redisson-all-3.14.0.jar:3.14.0]
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:400) ~[redisson-all-3.14.0.jar:3.14.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:365) ~[redisson-all-3.14.0.jar:3.14.0]
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:178) ~[redisson-all-3.14.0.jar:3.14.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:117) ~[redisson-all-3.14.0.jar:3.14.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:102) ~[redisson-all-3.14.0.jar:3.14.0]
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:501) ~[redisson-all-3.14.0.jar:3.14.0]
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) ~[redisson-all-3.14.0.jar:3.14.0]
... 17 common frames omitted
Caused by: java.lang.ClassNotFoundException: com.panaya.as.blexecuter.imp.BaseBLContext
at java.net.URLClassLoader.findClass(URLClassLoader.java:382) ~[na:1.8.0_261]
at java.lang.ClassLoader.loadClass(ClassLoader.java:418) ~[na:1.8.0_261]
at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ~[na:1.8.0_261]
at java.lang.Class.forName0(Native Method) ~[na:1.8.0_261]
at java.lang.Class.forName(Class.java:348) ~[na:1.8.0_261]
at org.jboss.marshalling.AbstractClassResolver.loadClass(AbstractClassResolver.java:129) ~[redisson-all-3.14.0.jar:3.14.0]
at org.jboss.marshalling.AbstractClassResolver.resolveClass(AbstractClassResolver.java:110) ~[redisson-all-3.14.0.jar:3.14.0]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadClassDescriptor(RiverUnmarshaller.java:1033) ~[redisson-all-3.14.0.jar:3.14.0]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadNewObject(RiverUnmarshaller.java:1366) ~[redisson-all-3.14.0.jar:3.14.0]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadObject(RiverUnmarshaller.java:283) ~[redisson-all-3.14.0.jar:3.14.0]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadObject(RiverUnmarshaller.java:216) ~[redisson-all-3.14.0.jar:3.14.0]
at org.jboss.marshalling.AbstractObjectInput.readObject(AbstractObjectInput.java:41) ~[redisson-all-3.14.0.jar:3.14.0]
at org.redisson.codec.MarshallingCodec$3.decode(MarshallingCodec.java:151) ~[redisson-all-3.14.0.jar:3.14.0]
... 26 common frames omitted
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3553
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello
We're using Azure Redis for Cache which has Redis 4.0.14 under the hood with cluster configuration (number of master nodes is configurable, can be less than 3):
                                   --------- 10.x.x.x:15000 (master 1) ------- 10.x.x.x:15001/2 (slave 1)
10.x.x.x:6380 (LB) -| 
                                  --------- 10.x.x.x:15003 (master 2) ------- 10.x.x.x:15001/2 (slave 2)
There is scheduled maintenance on Azure which doing the following:

Terminate all slave nodes
Pause ~10 min
Terminate all master nodes and load balancer

We have multiple components connected to redis (9 instances) and all of them are not able to execute commands after redis outage.
While redis is out of service we see following exceptions (which is okay):
"org.redisson.client.RedisTimeoutException: Command execution timeout for command: (PING), params: [], Redis client: [addr=rediss://10.10.20.4:15003]"
There is a timer (not redis-based) which every 10 secords extracts value for particular redis key.  When there are no more exceptions which looks like above, we have a lot following exceptions (as a result of GET command sent by the timer):
org.redisson.client.WriteRedisConnectionException: Unable to write command into connection! Node source: NodeSource [slot=1697, addr=null, redisClient=null, redirect=null, entry=null], connection: RedisConnection@1647044099 [redisClient=[addr=rediss://10.10.20.4:15000], channel=[id: 0x25772886, L:/10.10.9.179:35752 ! R:10.10.20.4/10.10.20.4:15000], currentCommand=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@11673588(failure: org.redisson.client.RedisTimeoutException: Command execution timeout for command: (PING), params: [], Redis client: [addr=rediss://10.10.20.4:15000])], command=(PING), params=[], codec=org.redisson.client.codec.StringCodec]], command: (GET), params: [metric.oos] after 3 retry attempts at org.redisson.command.RedisExecutor.checkWriteFuture(RedisExecutor.java:278) at org.redisson.command.RedisExecutor.access$100(RedisExecutor.java:60) at org.redisson.command.RedisExecutor$1.operationComplete(RedisExecutor.java:161) at org.redisson.command.RedisExecutor$1.operationComplete(RedisExecutor.java:158) at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577) at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551) at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490) at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615) at io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:608) at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117) at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:993) at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:865) at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367) at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717) at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764) at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071) at io.netty.util.concurrent.PromiseTask.runTask(PromiseTask.java:98) at io.netty.util.concurrent.PromiseTask.run(PromiseTask.java:106) at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164) at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.base/java.lang.Thread.run(Unknown Source) Caused by: java.nio.channels.ClosedChannelException: null at io.netty.channel.AbstractChannel$AbstractUnsafe.newClosedChannelException(AbstractChannel.java:957) ... 14 common frames omitted 
And in a few minutes after previous exceptions operation to extract value in timer fails all the time with a little bit another exception:
org.redisson.client.RedisTimeoutException: Unable to acquire connection! RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@7850d27b(failure: java.util.concurrent.CancellationException)]Increase connection pool size. Node source: NodeSource [slot=11951, addr=rediss://10.10.20.4:15002, redisClient=null, redirect=MOVED, entry=null], command: (GET), params: [metric.oos] after 0 retry attempts at org.redisson.command.RedisExecutor$2.run(RedisExecutor.java:187) at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:672) at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:747) at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:472) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.base/java.lang.Thread.run(Unknown Source)
In the beginning we also observed following WARN which also may cause issues:
java.util.ConcurrentModificationException: null at java.base/java.util.HashMap$KeySpliterator.forEachRemaining(Unknown Source) at java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source) at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(Unknown Source) at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(Unknown Source) at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(Unknown Source) at java.base/java.util.stream.AbstractPipeline.evaluate(Unknown Source) at java.base/java.util.stream.ReferencePipeline.forEach(Unknown Source) at org.redisson.cluster.ClusterConnectionManager.upDownSlaves(ClusterConnectionManager.java:499) at org.redisson.cluster.ClusterConnectionManager.checkSlaveNodesChange(ClusterConnectionManager.java:489) at org.redisson.cluster.ClusterConnectionManager.lambda$updateClusterState$10(ClusterConnectionManager.java:467) at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:187) at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577) at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:570) at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:549) at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490) at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615) at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604) at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104) at org.redisson.misc.RedissonPromise.trySuccess(RedissonPromise.java:82) at org.redisson.client.handler.CommandDecoder.completeResponse(CommandDecoder.java:435) at org.redisson.client.handler.CommandDecoder.handleResult(CommandDecoder.java:429) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:360) at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:177) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:116) at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:101) at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:501) at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1526) at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1275) at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1322) at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:501) at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:440) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650) at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.base/java.lang.Thread.run(Unknown Source) 
Expected behavior
Connections to redis successfully restored after outage
Actual behavior
Some redis connections have closed channel and associated to particular slots. Unable to execute redis commands
Steps to reproduce or test case
Terminate slaves/masters in redis cluster configuration multiple times. Check that in connection pool all channels are not closed when redis instances will be restored
Redis version
Azure Redis for Cache (Redis 4.0.14)
Redisson version
3.15.3
Redisson configuration
clusterServersConfig:
idleConnectionTimeout: 10000
connectTimeout: 10000
timeout: 3000
retryAttempts: 3
retryInterval: 1500
failedSlaveReconnectionInterval: 3000
failedSlaveCheckInterval: 60000
password: ********
subscriptionsPerConnection: 5
clientName: null
subscriptionConnectionMinimumIdleSize: 1
subscriptionConnectionPoolSize: 50
slaveConnectionMinimumIdleSize: 24
slaveConnectionPoolSize: 64
masterConnectionMinimumIdleSize: 24
masterConnectionPoolSize: 64
readMode: "MASTER"
subscriptionMode: "SLAVE"
nodeAddresses:
- "rediss://........"
threads: 16
nettyThreads: 32
codec: !<org.redisson.codec.FstCodec> {}
transportMode: "NIO"
Thank you for help
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3554
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3555
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
My entities are annotated with Regions following Redis hierarchy, using colons:
@Cache(region = "jpa:entity:Product", usage = CacheConcurrencyStrategy.READ_WRITE)
How could I set the eviction times for these Entities, on our application.properties?
We try:
spring.jpa.properties.hibernate.cache.redisson.*.expiration.time_to_live=1000
spring.jpa.properties.hibernate.cache.redisson.jpa:entity:Product.expiration.time_to_live=1000
spring.jpa.properties.hibernate.cache.redisson.jpa\:entity\:Product.expiration.time_to_live=1000

But none of them worked.
Replacing the region to string that is not colon delimiter, works as a charm.
Any advice?
Thanks!!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3556
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We have a use case whereby when we first create objects in our Redis Hashmap, we set a long TTL (e.g. 1 month) to ensure that the data will be cleared out at some point in the future.
However, in general this data is only required for a few days, and for optimization we would like to clear this data out sooner when possible. When our application is made aware that it is safe to clean up this data earlier, we would like to set a new TTL on the entries (e.g. 1 day).
Unfortunately, I can't see any way to alter the TTL on an existing entry (other than doing a read, followed by a write with the new TTL).
What I was looking for in the API was something similar to:
public void setTimeToLive(K key, long ttl, TimeUnit ttlUnit);
or even better, a method which accepts a batch of keys
public void setTimeToLive(List<K> keys, long ttl, TimeUnit ttlUnit);
Does anything like this already exist already in Redisson? (or is there some other workaround I can use?)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3557
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
in redis in action https://redislabs.com/ebook/part-2-core-concepts/01chapter-9-reducing-memory-use/9-2-sharded-structures/9-2-2-sets/
They have API such as
conn.hget(shard, key)
conn.hset(shard, key, value)
does Redisson has similar API to help Shard automatically?
of course I can handle shard myself as
conn.hget("key:shard")
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3558
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3559
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When creating a MapCache object within a transaction, I noticed that the create methods don't support the passing of MapOptions to configure the instance.
When creating from the client itself, the option is there to pass options to the method.
Are the fields in the MapOptions object that are not needed in a transactional context? It looks like at least for RMapCache objects, the options field is null when it calls the superclass.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3560
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We using redisson for our tomcat session cache in Kubernetes cluster. We have setup a sentinel cluster with 3 redis instance.
We have some issue when one of our redis pod changes. This can happen when maintaining a node. In this case the redis pod is recreated on another node but with a new IP.
For connect to sentinel we use a statefulset headless service.
Expected behavior
Redisson reconnect to the new redis node and stop communicating with the old pod
Actual behavior
Redisson reconnect to the new redis node BUT continue to try reconnect on old node indefinitely.
Steps to reproduce or test case

Setup redis sentinel cluster in Kubernetes (with statefulset). Our pod have 2 container, one for redis (port 6379), and one for is sentinel (port 26379).
Start tomcat pod with redisson config for session.
kubectl delete pod <redis slave pod>

Redis version
6.0.12
Redisson version
3.15.3
Redisson configuration
sentinelServersConfig:
  password: ${REDIS_PASSWORD}
  subscriptionConnectionMinimumIdleSize: 1
  subscriptionConnectionPoolSize: 10
  slaveConnectionMinimumIdleSize: 2
  slaveConnectionPoolSize: 10
  masterConnectionMinimumIdleSize: 5
  masterConnectionPoolSize: 10
  idleConnectionTimeout: 5000
  pingConnectionInterval: 0
  dnsMonitoringInterval: 5000
  checkSentinelsList: true
  clientName: ${HOSTNAME}
  sentinelAddresses:
  - "redis://redis-${ENV}-rds01-0.redis-${ENV}-rds01-headless.infra.svc.cluster.local:26379"
  - "redis://redis-${ENV}-rds01-1.redis-${ENV}-rds01-headless.infra.svc.cluster.local:26379"
  - "redis://redis-${ENV}-rds01-2.redis-${ENV}-rds01-headless.infra.svc.cluster.local:26379"
  masterName: "redisk8s"
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3561
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In #3511 I introduced a ByteBuf leak because the buffer copy is never released: https://github.com/redisson/redisson/blob/master/redisson/src/main/java/org/redisson/jcache/JCacheEventCodec.java#L50
I can create a PR to fix this shortly.
"LEAK: ByteBuf.release() was not called before it's garbage-collected. See https://netty.io/wiki/reference-counted-objects.html for more information.
Recent access records: 
Created at:
	io.netty.buffer.PooledByteBufAllocator.newDirectBuffer(PooledByteBufAllocator.java:385)
	io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:187)
	io.netty.buffer.UnsafeByteBufUtil.copy(UnsafeByteBufUtil.java:436)
	io.netty.buffer.PooledUnsafeDirectByteBuf.copy(PooledUnsafeDirectByteBuf.java:216)
	io.netty.buffer.AbstractUnpooledSlicedByteBuf.copy(AbstractUnpooledSlicedByteBuf.java:224)
	io.netty.buffer.AbstractByteBuf.copy(AbstractByteBuf.java:1196)
	org.redisson.jcache.JCacheEventCodec$1.decode(JCacheEventCodec.java:50)
	org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:358)
	org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:402)
	org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:367)
	org.redisson.client.handler.CommandPubSubDecoder.decodeCommand(CommandPubSubDecoder.java:84)
	org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:116)
	org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:101)
	io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:508)
	io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
	io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
	io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)
	io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)
	io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)
	io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
	io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	java.base/java.lang.Thread.run(Unknown Source)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3562
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3563
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior:  Redisson Client should throw checked exception or return bool value when operation on RBucket can not be performed because server is down
Actual behavior When single server will be shut down during application work and some operation on RBucket will be performed, then NullPointer exception exception is thrown. Also redisson treats RBucket object as not null one.
An exception was thrown by org.redisson.misc.RedissonPromise$$Lambda$731/0x0000000840e3b040.operationComplete()
java.lang.NullPointerException: null
at org.redisson.client.RedisConnection.send(RedisConnection.java:169) ~[redisson-3.15.0.jar:3.15.0]
at org.redisson.command.RedisExecutor.sendCommand(RedisExecutor.java:622) ~[redisson-3.15.0.jar:3.15.0]
at org.redisson.command.RedisExecutor.lambda$execute$2(RedisExecutor.java:151) ~[redisson-3.15.0.jar:3.15.0]
at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:187) ~[redisson-3.15.0.jar:3.15.0]
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578) ~[netty-common-4.1.58.Final.jar:4.1.58.Final]
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552) ~[netty-common-4.1.58.Final.jar:4.1.58.Final]
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491) ~[netty-common-4.1.58.Final.jar:4.1.58.Final]
at io.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:184) ~[netty-common-4.1.58.Final.jar:4.1.58.Final]
at org.redisson.misc.RedissonPromise.onComplete(RedissonPromise.java:181) ~[redisson-3.15.0.jar:3.15.0]
at org.redisson.command.RedisExecutor.execute(RedisExecutor.java:139) ~[redisson-3.15.0.jar:3.15.0]
at org.redisson.command.CommandAsyncService.async(CommandAsyncService.java:606) ~[redisson-3.15.0.jar:3.15.0]
at org.redisson.command.CommandAsyncService.writeAsync(CommandAsyncService.java:591) ~[redisson-3.15.0.jar:3.15.0]
at org.redisson.RedissonObject.deleteAsync(RedissonObject.java:202) ~[redisson-3.15.0.jar:3.15.0]
at org.redisson.RedissonObject.delete(RedissonObject.java:197) ~[redisson-3.15.0.jar:3.15.0]
Steps to reproduce or test case

Turn on redis and redisson with single server mode
Save some value by using RBucket
Shut down redis server
Try to save / remove another value by using RedissonClient (by using RBucket)

Redis version  6.2.0
Redisson version 3.15.0
Redisson configuration

single server
REDIS_MIN_CONNECTION_POOL_SIZE: 24
REDIS_MAX_CONNECTION_POOL_SIZE: 64
REDIS_IDLE_CONNECTION_TIMEOUT=300000
REDIS_RETRY_ATTEMPTS=0
REDIS_TIMEOUT=500
REDIS_CONNECT_TIMEOUT=1000

Setting pingConnectionInterval does not do the work. I think that send method from RedisConnection class is culprit, it does not check whether channel has null value.
    public <T, R> ChannelFuture send(CommandData<T, R> data) {
        return channel.writeAndFlush(data);
    }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3564
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redis version 4.0.7
Redisson version redisson-spring-data-22:3.12.5
In ReactiveKeyCommands the method expire was defined as a write operation, but in the RedissonReactiveKeyCommands
the method expire was implement as a read operation.
ReactiveKeyCommands :
/**
 * Set time to live for given {@code key} in seconds.
 *
 * @param key must not be {@literal null}.
 * @param timeout must not be {@literal null}.
 * @return
 * @see <a href="https://redis.io/commands/expire">Redis Documentation: EXPIRE</a>
 */
default Mono<Boolean> expire(ByteBuffer key, Duration timeout) {

	Assert.notNull(key, "Key must not be null!");
	Assert.notNull(timeout, "Timeout must not be null!");

	return expire(Mono.just(new ExpireCommand(key, timeout))).next().map(BooleanResponse::getOutput);
}

RedissonReactiveKeyCommands :
@Override
public Flux<BooleanResponse<ExpireCommand>> expire(Publisher<ExpireCommand> commands) {
    return execute(commands, command -> {

        Assert.notNull(command.getKey(), "Key must not be null!");

        byte[] keyBuf = toByteArray(command.getKey());
        Mono<Boolean> m = read(keyBuf, StringCodec.INSTANCE, EXPIRE, keyBuf, command.getTimeout().getSeconds());
        return m.map(v -> new BooleanResponse<>(command, v));
    });
}

When using the reactive redisson to work on Sentinel mode and executing expire command will cause the exception which tips that should not execute write command in a slave instance, because the RedisExecutor was set as readOnlyMode.
When RedisExecutor was set as readOnlyMode, the connectionManager will return a slave connection.
protected RFuture<RedisConnection> getConnection() {
    RFuture<RedisConnection> connectionFuture;
    if (readOnlyMode) {
        connectionFuture = connectionManager.connectionReadOp(source, command);
    } else {
        connectionFuture = connectionManager.connectionWriteOp(source, command);
    }
    return connectionFuture;
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3565
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am trying to tune redisson client connection pool configuration and I am using cluster mode to connect to ElastiCache. I am trying to analyse what is current connections utilised and other connection pool details.
Can anyone please help me how to print the information?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3566
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3567
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Remapping function result is written to redis and returned.
Actual behavior
Remapping function result is only returned, but not saved if object instance remains the same.
Steps to reproduce or test case
        data class Test(var s1: String, var l1: Long): Serializable
 
        val map = redisson.getMap<String,Test>("test-map-1")
        logger.info {map.getOrPut("test-map-1") { Test("t", 0) }  }
        logger.info { map.computeIfPresent("test-map-1", BiFunction { _, u -> u.l1++; u }) }
        logger.info { map.get("test-map-1") }

This snippet prints
Test(s1=t, l1=0)
Test(s1=t, l1=1)
Test(s1=t, l1=0)

Redis version
6.0.11
Redisson version
3.15.4
Redisson configuration
Empty configuration, with local redis.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3568
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Using 3.15.4 and sentinel connections, when I set the config connection listener, i don't get a connect or disconnect when (all) nodes have failed (e.g. dropping the Redis traffic from firewall to simulate network issues).
When this happens, a .getBucket command is blocking and remains blocked no matter if the connection is restored or not
The config i'm using:
sentinelServersConfig:
pingConnectionInterval: 500
idleConnectionTimeout: 10000
connectTimeout: 10000
timeout: 500
retryAttempts: 3
retryInterval: 500
failedSlaveReconnectionInterval: 3000
failedSlaveCheckInterval: 5000
password: null
subscriptionsPerConnection: 5
clientName: null
loadBalancer: !<org.redisson.connection.balancer.RoundRobinLoadBalancer> {}
subscriptionConnectionMinimumIdleSize: 1
subscriptionConnectionPoolSize: 50
slaveConnectionMinimumIdleSize: 1
slaveConnectionPoolSize: 64
masterConnectionMinimumIdleSize: 1
masterConnectionPoolSize: 64
readMode: "SLAVE"
subscriptionMode: "SLAVE"
sentinelAddresses:

"redis://xxx:16379"
"redis://yyy:16379"
"redis://zzzz:16379"
masterName: "redis-cluster"
database: 0
threads: 0
nettyThreads: 0
codec: !<org.redisson.client.codec.ByteArrayCodec> {}
transportMode: "NIO"

The question i have is how to figure out when the connection is broken ? What am i missing ?
Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3569
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi Team,
Can you share a sample on how to read/write a simple key value  using RedissonReactiveClient
key: String
value:  java object
Reactive way of writing and reading will be great help.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3570
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3571
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
// src/main/java/org/redisson/cluster/ClusterConnectionManager.java

private void checkSlaveNodesChange(Collection<ClusterPartition> newPartitions) {
        Set<ClusterPartition> lastPartitions = getLastPartitions();
        for (ClusterPartition newPart : newPartitions) {
            for (ClusterPartition currentPart : lastPartitions) {

                /***** this will always be true if all cluster nodes have same ip & port*****/

                if (!newPart.getMasterAddress().equals(currentPart.getMasterAddress())) {
                    continue;
                }

                MasterSlaveEntry entry = getEntry(currentPart.slots().nextSetBit(0));
                // should be invoked first in order to remove stale failedSlaveAddresses

                /*******  more and more slaves will be added if some master don't have any slave  ******/

                Set<RedisURI> addedSlaves = addRemoveSlaves(entry, currentPart, newPart);
                // Do some slaves have changed state from failed to alive?
                upDownSlaves(entry, currentPart, newPart, addedSlaves);

                break;
            }
        }
    }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3572
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hey guys! We're using Redisson in our app and instantiating it as a Singleton. But faced some weird behavior when the Redis cluster was rebooted. We're calling the method RMap.getAll(Set<K> keys) and this time got incorrect data from Redis. Seems like some of the Redisson workers returned the requested data and other ones not.
Now we're trying to create the Redisson client for each request to avoid the mentioned issue. Is it a good idea or will be better to create it one time along with the application?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3573
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We (@cstamas and me) are currently trying to integrate Redisson into Apache Maven Resolver. The purpose is to synchronize access to the Maven local repository across multiple processes. In our tests we experience a constant thread stravation where a write lock cannot be obtained in time, but tens of other threads are given access with RSemaphore. I assumed that we are having the same problem as in #1763, but the fiddling with config options did not work out. The lock is a hot path in dependency resolution.
Env:

Redis 6.0.12 and 6.2.1 from FreeBSD ports
Java "1.8.0_282"
Redisson 3.15.3
Maven from master, Maven Resolver from master

Config: default as well as
singleServerConfig:
  address: "redis://localhost:6379"
  subscriptionConnectionMinimumIdleSize: 25
  subscriptionConnectionPoolSize: 100
  subscriptionsPerConnection: 10
  connectionPoolSize: 100

The amount of locks is around 500 accessed by around 100 Maven modules from 48 threads (T4C on a 12-core Xeon processor).
Here is a sample condensed overview of semaphore permit acquisition and release:
lock_held	start_timestamp	end_timestamp	thread	start_message	end_message
243	35276	35519	mvn-builder-org.example:module001:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
259	35276	35535	mvn-builder-org.example:module021:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
215	35276	35491	mvn-builder-org.example:module023:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
264	35287	35551	mvn-builder-org.example:module013:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
269	35297	35566	mvn-builder-org.example:module008:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
286	35297	35583	mvn-builder-org.example:module009:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
273	35326	35599	mvn-builder-org.example:module014:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
296	35335	35631	mvn-builder-org.example:module005:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
324	35339	35663	mvn-builder-org.example:module017:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
274	35340	35614	mvn-builder-org.example:module004:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
298	35349	35647	mvn-builder-org.example:module012:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
326	35358	35684	mvn-builder-org.example:module006:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
336	35364	35700	mvn-builder-org.example:module003:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
331	35385	35716	mvn-builder-org.example:module015:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
343	35389	35732	mvn-builder-org.example:module016:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
365	35399	35764	mvn-builder-org.example:module010:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
344	35404	35748	mvn-builder-org.example:module007:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
356	35424	35780	mvn-builder-org.example:module022:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
358	35438	35796	mvn-builder-org.example:module002:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
363	35449	35812	mvn-builder-org.example:module011:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
369	35460	35829	mvn-builder-org.example:module024:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
377	35467	35844	mvn-builder-org.example:module019:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
384	35476	35860	mvn-builder-org.example:module020:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
396	35480	35876	mvn-builder-org.example:module018:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
431	35494	35925	mvn-builder-org.example:module023:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
400	35523	35923	mvn-builder-org.example:module001:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
384	35538	35922	mvn-builder-org.example:module021:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
368	35554	35922	mvn-builder-org.example:module013:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
352	35570	35922	mvn-builder-org.example:module008:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
336	35586	35922	mvn-builder-org.example:module009:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
320	35602	35922	mvn-builder-org.example:module014:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
310	35618	35928	mvn-builder-org.example:module004:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
292	35634	35926	mvn-builder-org.example:module005:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
272	35650	35922	mvn-builder-org.example:module012:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
255	35667	35922	mvn-builder-org.example:module017:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
236	35688	35924	mvn-builder-org.example:module006:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
217	35704	35921	mvn-builder-org.example:module003:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
208	35720	35928	mvn-builder-org.example:module015:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
185	35736	35921	mvn-builder-org.example:module016:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
175	35751	35926	mvn-builder-org.example:module007:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
163	35767	35930	mvn-builder-org.example:module010:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
136	35784	35920	mvn-builder-org.example:module022:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
118	35800	35918	mvn-builder-org.example:module002:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
102	35816	35918	mvn-builder-org.example:module011:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
86	35832	35918	mvn-builder-org.example:module024:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
69	35848	35917	mvn-builder-org.example:module019:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
52	35864	35916	mvn-builder-org.example:module020:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
70	35930	36000	mvn-builder-org.example:module018:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
41	35957	35998	mvn-builder-org.example:module022:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
36	35966	36002	mvn-builder-org.example:module019:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
92	35974	36066	mvn-builder-org.example:module013:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
41	35976	36017	mvn-builder-org.example:module008:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
41	35976	36017	mvn-builder-org.example:module009:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
41	35976	36017	mvn-builder-org.example:module012:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
41	35976	36017	mvn-builder-org.example:module014:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
42	35976	36018	mvn-builder-org.example:module017:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
33	35977	36010	mvn-builder-org.example:module016:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
45	35978	36023	mvn-builder-org.example:module002:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
45	35978	36023	mvn-builder-org.example:module011:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
44	35979	36023	mvn-builder-org.example:module024:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
96	35982	36078	mvn-builder-org.example:module003:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
46	35982	36028	mvn-builder-org.example:module020:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
40	35984	36024	mvn-builder-org.example:module015:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
47	35987	36034	mvn-builder-org.example:module001:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
47	35987	36034	mvn-builder-org.example:module005:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
47	35987	36034	mvn-builder-org.example:module007:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
48	35987	36035	mvn-builder-org.example:module023:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
46	35988	36034	mvn-builder-org.example:module006:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
48	35990	36038	mvn-builder-org.example:module021:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
67	35999	36066	mvn-builder-org.example:module004:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
48	35999	36047	mvn-builder-org.example:module010:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
44	36077	36121	mvn-builder-org.example:module018:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
190	97706	97896	mvn-builder-org.example:module026:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
205	97706	97911	mvn-builder-org.example:module038:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
174	97706	97880	mvn-builder-org.example:module039:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
221	97706	97927	mvn-builder-org.example:module044:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
227	97716	97943	mvn-builder-org.example:module034:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
257	97734	97991	mvn-builder-org.example:module042:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
239	97737	97976	mvn-builder-org.example:module043:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
221	97738	97959	mvn-builder-org.example:module030:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
299	97756	98055	mvn-builder-org.example:module025:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
309	97762	98071	mvn-builder-org.example:module029:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
273	97766	98039	mvn-builder-org.example:module046:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
239	97768	98007	mvn-builder-org.example:module028:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
255	97768	98023	mvn-builder-org.example:module033:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
302	97785	98087	mvn-builder-org.example:module037:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
309	97794	98103	mvn-builder-org.example:module027:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
315	97804	98119	mvn-builder-org.example:module045:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
326	97809	98135	mvn-builder-org.example:module032:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
343	97824	98167	mvn-builder-org.example:module035:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
319	97832	98151	mvn-builder-org.example:module031:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
347	97836	98183	mvn-builder-org.example:module040:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
352	97847	98199	mvn-builder-org.example:module048:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
363	97852	98215	mvn-builder-org.example:module041:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
372	97859	98231	mvn-builder-org.example:module036:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
377	97870	98247	mvn-builder-org.example:module047:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
429	97883	98312	mvn-builder-org.example:module039:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
392	97899	98291	mvn-builder-org.example:module026:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
379	97915	98294	mvn-builder-org.example:module038:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
360	97931	98291	mvn-builder-org.example:module044:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
344	97947	98291	mvn-builder-org.example:module034:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
331	97963	98294	mvn-builder-org.example:module030:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
317	97979	98296	mvn-builder-org.example:module043:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
300	97995	98295	mvn-builder-org.example:module042:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
287	98011	98298	mvn-builder-org.example:module028:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
264	98027	98291	mvn-builder-org.example:module033:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
248	98043	98291	mvn-builder-org.example:module046:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
232	98059	98291	mvn-builder-org.example:module025:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
222	98074	98296	mvn-builder-org.example:module029:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
201	98090	98291	mvn-builder-org.example:module037:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
184	98106	98290	mvn-builder-org.example:module027:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
166	98123	98289	mvn-builder-org.example:module045:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
150	98138	98288	mvn-builder-org.example:module032:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
134	98154	98288	mvn-builder-org.example:module031:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
125	98170	98295	mvn-builder-org.example:module035:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
101	98186	98287	mvn-builder-org.example:module040:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
83	98202	98285	mvn-builder-org.example:module048:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
66	98218	98284	mvn-builder-org.example:module041:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
49	98235	98284	mvn-builder-org.example:module036:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
100	98298	98398	mvn-builder-org.example:module047:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
38	98338	98376	mvn-builder-org.example:module040:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
43	98345	98388	mvn-builder-org.example:module033:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
43	98345	98388	mvn-builder-org.example:module034:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
53	98345	98398	mvn-builder-org.example:module044:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
44	98346	98390	mvn-builder-org.example:module025:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
45	98346	98391	mvn-builder-org.example:module027:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
44	98346	98390	mvn-builder-org.example:module037:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
47	98346	98393	mvn-builder-org.example:module045:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
42	98346	98388	mvn-builder-org.example:module046:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
47	98347	98394	mvn-builder-org.example:module031:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
55	98347	98402	mvn-builder-org.example:module032:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
46	98348	98394	mvn-builder-org.example:module035:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
47	98348	98395	mvn-builder-org.example:module041:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
46	98348	98394	mvn-builder-org.example:module048:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
47	98349	98396	mvn-builder-org.example:module036:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
48	98351	98399	mvn-builder-org.example:module029:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
51	98351	98402	mvn-builder-org.example:module043:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
50	98352	98402	mvn-builder-org.example:module042:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
50	98353	98403	mvn-builder-org.example:module030:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
49	98353	98402	mvn-builder-org.example:module038:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
52	98367	98419	mvn-builder-org.example:module028:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
80	98388	98468	mvn-builder-org.example:module026:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
51	98388	98439	mvn-builder-org.example:module039:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
33	98451	98484	mvn-builder-org.example:module047:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
45032	126932	171964	mvn-builder-org.example:module049:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Failed to acquire write lock for 'metadata:org.webjars.bower:datatables.net'
201	126932	127133	mvn-builder-org.example:module056:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
212	126937	127149	mvn-builder-org.example:module053:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
227	126938	127165	mvn-builder-org.example:module054:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
7569	126941	134510	mvn-builder-org.example:module062:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
228	126959	127187	mvn-builder-org.example:module063:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
242	126974	127216	mvn-builder-org.example:module068:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
254	126979	127233	mvn-builder-org.example:module061:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
261	126989	127250	mvn-builder-org.example:module058:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
286	126999	127285	mvn-builder-org.example:module052:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
263	127004	127267	mvn-builder-org.example:module060:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
354	127017	127371	mvn-builder-org.example:module067:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
280	127023	127303	mvn-builder-org.example:module050:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
297	127023	127320	mvn-builder-org.example:module055:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
305	127032	127337	mvn-builder-org.example:module057:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
315	127039	127354	mvn-builder-org.example:module070:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
374	127049	127423	mvn-builder-org.example:module066:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
328	127060	127388	mvn-builder-org.example:module069:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
339	127067	127406	mvn-builder-org.example:module065:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
363	127077	127440	mvn-builder-org.example:module071:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
368	127089	127457	mvn-builder-org.example:module051:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
383	127096	127479	mvn-builder-org.example:module072:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
397	127103	127500	mvn-builder-org.example:module064:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
438	127136	127574	mvn-builder-org.example:module056:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
392	127154	127546	mvn-builder-org.example:module053:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
2	127169	127171	mvn-builder-org.example:module054:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
371	127175	127546	mvn-builder-org.example:module054:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
2	127191	127193	mvn-builder-org.example:module063:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
347	127202	127549	mvn-builder-org.example:module063:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
326	127220	127546	mvn-builder-org.example:module068:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
318	127236	127554	mvn-builder-org.example:module061:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
315	127254	127569	mvn-builder-org.example:module058:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
271	127274	127545	mvn-builder-org.example:module060:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
259	127291	127550	mvn-builder-org.example:module052:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
245	127307	127552	mvn-builder-org.example:module050:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
219	127325	127544	mvn-builder-org.example:module055:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
202	127342	127544	mvn-builder-org.example:module057:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
186	127358	127544	mvn-builder-org.example:module070:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
167	127376	127543	mvn-builder-org.example:module067:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
151	127392	127543	mvn-builder-org.example:module069:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
133	127410	127543	mvn-builder-org.example:module065:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
116	127427	127543	mvn-builder-org.example:module066:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
98	127444	127542	mvn-builder-org.example:module071:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
78	127463	127541	mvn-builder-org.example:module051:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
54	127487	127541	mvn-builder-org.example:module072:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
127	127554	127681	mvn-builder-org.example:module064:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
38	127610	127648	mvn-builder-org.example:module057:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
40	127615	127655	mvn-builder-org.example:module055:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
40	127615	127655	mvn-builder-org.example:module060:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
40	127615	127655	mvn-builder-org.example:module068:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
42	127616	127658	mvn-builder-org.example:module065:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
39	127616	127655	mvn-builder-org.example:module067:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
42	127616	127658	mvn-builder-org.example:module069:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
48	127616	127664	mvn-builder-org.example:module070:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
46	127617	127663	mvn-builder-org.example:module066:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
42	127617	127659	mvn-builder-org.example:module071:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
52	127617	127669	mvn-builder-org.example:module072:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
43	127619	127662	mvn-builder-org.example:module050:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
42	127619	127661	mvn-builder-org.example:module051:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
57	127619	127676	mvn-builder-org.example:module061:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
62	127620	127682	mvn-builder-org.example:module052:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
43	127620	127663	mvn-builder-org.example:module053:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
68	127626	127694	mvn-builder-org.example:module058:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
42	127694	127736	mvn-builder-org.example:module056:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
36	127791	127827	mvn-builder-org.example:module064:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
45101	129487	174588	mvn-builder-org.example:module059:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Failed to acquire write lock for 'metadata:org.webjars.bower:datatables.net'
3	134512	134515	mvn-builder-org.example:module062:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
5	134517	134522	mvn-builder-org.example:module062:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
40	136548	136588	mvn-builder-org.example:module075:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
45009	136550	181559	mvn-builder-org.example:module076:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Failed to acquire write lock for 'metadata:org.webjars.bower:datatables.net'
45003	136556	181559	mvn-builder-org.example:module077:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Failed to acquire write lock for 'metadata:org.webjars.bower:datatables.net'
45001	136558	181559	mvn-builder-org.example:module073:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Failed to acquire write lock for 'metadata:org.webjars.bower:datatables.net'
45002	136573	181575	mvn-builder-org.example:module093:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Failed to acquire write lock for 'metadata:org.webjars.bower:datatables.net'
45002	136578	181580	mvn-builder-org.example:module074:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Failed to acquire write lock for 'metadata:org.webjars.bower:datatables.net'
2	136591	136593	mvn-builder-org.example:module075:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
2	136596	136598	mvn-builder-org.example:module075:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
9	136774	136783	mvn-builder-org.example:module095:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
2	136785	136787	mvn-builder-org.example:module095:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
2	136789	136791	mvn-builder-org.example:module095:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
8	136945	136953	mvn-builder-org.example:module096:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
2	136955	136957	mvn-builder-org.example:module096:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
2	136959	136961	mvn-builder-org.example:module096:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
8	137114	137122	mvn-builder-org.example:module097:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
2	137124	137126	mvn-builder-org.example:module097:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
2	137129	137131	mvn-builder-org.example:module097:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
9	137284	137293	mvn-builder-org.example:module098:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
2	137295	137297	mvn-builder-org.example:module098:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
2	137299	137301	mvn-builder-org.example:module098:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
7	137452	137459	mvn-builder-org.example:module099:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
1	137462	137463	mvn-builder-org.example:module099:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
2	137465	137467	mvn-builder-org.example:module099:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
9	140619	140628	mvn-builder-org.example:module100:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
3	140630	140633	mvn-builder-org.example:module100:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
2	140635	140637	mvn-builder-org.example:module100:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
45016	181404	226420	mvn-builder-org.example:module086:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Failed to acquire write lock for 'metadata:org.webjars.bower:datatables.net'
45016	181404	226420	mvn-builder-org.example:module089:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Failed to acquire write lock for 'metadata:org.webjars.bower:datatables.net'
45014	181406	226420	mvn-builder-org.example:module081:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Failed to acquire write lock for 'metadata:org.webjars.bower:datatables.net'
45014	181406	226420	mvn-builder-org.example:module092:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Failed to acquire write lock for 'metadata:org.webjars.bower:datatables.net'
45020	181407	226427	mvn-builder-org.example:module079:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Failed to acquire write lock for 'metadata:org.webjars.bower:datatables.net'
45013	181407	226420	mvn-builder-org.example:module085:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Failed to acquire write lock for 'metadata:org.webjars.bower:datatables.net'
45013	181407	226420	mvn-builder-org.example:module088:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Failed to acquire write lock for 'metadata:org.webjars.bower:datatables.net'
92	181408	181500	mvn-builder-org.example:module082:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Releasing write lock for 'metadata:org.webjars.bower:datatables.net'
45019	181408	226427	mvn-builder-org.example:module083:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Failed to acquire write lock for 'metadata:org.webjars.bower:datatables.net'
45015	181412	226427	mvn-builder-org.example:module087:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Failed to acquire write lock for 'metadata:org.webjars.bower:datatables.net'
45013	181414	226427	mvn-builder-org.example:module090:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Failed to acquire write lock for 'metadata:org.webjars.bower:datatables.net'
45002	181425	226427	mvn-builder-org.example:module084:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Failed to acquire write lock for 'metadata:org.webjars.bower:datatables.net'
45003	181464	226467	mvn-builder-org.example:module080:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Failed to acquire write lock for 'metadata:org.webjars.bower:datatables.net'
45002	181465	226467	mvn-builder-org.example:module091:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Failed to acquire write lock for 'metadata:org.webjars.bower:datatables.net'
45004	181494	226498	mvn-builder-org.example:module078:jar:1.0.0-snapshot	Acquiring write lock for 'metadata:org.webjars.bower:datatables.net'	Failed to acquire write lock for 'metadata:org.webjars.bower:datatables.net'
2	181503	181505	mvn-builder-org.example:module082:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'
3	181508	181511	mvn-builder-org.example:module082:jar:1.0.0-snapshot	Acquiring read lock for 'metadata:org.webjars.bower:datatables.net'	Releasing read lock for 'metadata:org.webjars.bower:datatables.net'

I can provide full debug output, actual source code (see PR), pre-compiled Maven distro and the sample project which almost always fails for me. Help would be very appreciated because I am at my wit's end.
Note: The following lock types work flawlessly with the same project: rwlock-redisson (RReadWriteLock), semaphore-local (Semaphore) and rwlock-local (ReentrantReadWriteLock).
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3574
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Good morning:
I have been working in the implementation of a Redisson client to connect a Java application to Redis cluster defined by a YAML config file (loaded from the Config class) and by using RBucket as a class to put and get key-value pairs.
The connection is primary established by calling Redisson.create(config) method. Sometimes, even if a master is up after an outage, a RedisNodeNotFoundException exception happen saying that we need to increase the value of retryAttempts and/or retryInterval settings.
I really appreciate if you can give me some advices, recommendations about some configuration fields I could have missed, or something about the uses of RBucket or Redisson.create method in order to make it more resilient and to solve that issue.
Thank you so much in advance.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3575
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
中文文档和英文文档不一致, 是不是中文文档好久没跟新了
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3576
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I am trying to execute few commands on several maps as part of an rbatch.
There are both putAllAsync commands and removeAsync commands.
All the put commands works fine but it seems that nothing is getting deleted.
The key type for each of the following maps is Long
   public void removeInactiveReportersFromRedis(long siteId) {
        List<Long>  inactiveReporterIdsList = new ArrayList<>(getInactiveReporterIdsPerSite(siteId));
        if (!CollectionUtils.isEmpty(inactiveReporterIdsList)) {
            reportersMap.fastRemoveAsync(inactiveReporterIdsList);
            panelsMap.fastRemoveAsync(inactiveReporterIdsList);
            parentsMap.fastRemoveAsync(inactiveReporterIdsList);
        }
    }

These maps are of type RMapAsync ( and are part of the batch).
At the end of the batch I execute it using redisBatch.executeAsync()
Is there an issue with removing from a map and adding values to map in the same batch? Is there any other issue? How can I solve this?
Thanks.
******** EDIT *******
It doesn't happen only in batch operations but also in calling fastRemoveAsync for RedissonLocalCachedMap
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3577
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
使用RedissonLock加锁如果对应的资源已经被锁定，需要等待的时候，使用pubsub订阅消息来等待锁资源。当同时等待锁订阅消息达到subscriptionConnectionPoolSize*subscriptionsPerConnection个时，再多来一个锁等待订阅消息，
org.redisson.pubsub.PublishSubscribeService#connect 方法向连接池获取新的分发订阅连接，最终调用到
org.redisson.connection.ClientConnectionsEntry#acquireSubscribeConnection方法的
freeSubscribeConnectionsCounter.acquire(runnable)
由于freeSubscribeConnectionsCounter信号量已用完（到到了subscriptionConnectionPoolSize），连接一直无法获取导致PublishSubscribeService中的freePubSubLock没有释放。   另外由于PublishSubscribeService向连接池获取连接后是直接缓存下来，不把分发订阅链接释返回给连接池的，因此导致freeSubscribeConnectionsCounter一直等待，出现死锁情况。
最终由于PublishSubscribe.entries不断的积压会导致内存异常
异常堆栈信息：
org.redisson.client.RedisTimeoutException: Subscribe timeout: (5000ms). Increase 'subscriptionsPerConnection' and/or 'subscriptionConnectionPoolSize' parameters.
at org.redisson.command.CommandAsyncService.syncSubscription(CommandAsyncService.java:171)
at org.redisson.RedissonLock.lockInterruptibly(RedissonLock.java:149)
at org.redisson.RedissonLock.lock(RedissonLock.java:127)
内存泄漏截图：
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3578
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Please remain only changes related to the issue.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3579
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I'm using Redisson 3.15.3
In my attached example you see that i try to create (or get an existing) RAtomicLong with a given name and expiration. Everything works apart from the yellow marked line where i try to set the expiration. In this concrete case expiration is 15 and unit is TimeUnit.MINUTES. But the expire() call always returns false.
I'm wondering if i do something wrong or what might be common causes for expire to return false (so i could investigate those further)?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3580
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I'm working on a kotlin micronaut web app which is attempting to be fully async and we're using redisson for distributed locks.
I'm somewhat unclear on how to exactly use it correctly.
The official documentation says RLock object behaves according to the Java Lock specification. It means only lock owner thread can unlock it otherwise IllegalMonitorStateException would be thrown. Otherwise consider to use RSemaphore object. which sounds weird as in an async context, executing on a specific threads is never guaranteed.
The code I'm using for now, in a kotlin suspendable func, is like this:
val lock = rediClinet.getLock("lock_name)
try {
    (lock.lockAsync(50, TimeUnit.SECONDS) as CompletionStage<Void>).await()
    //fancy kotlin async code here.
}
finally {
    (lock.unlockAsync() as CompletionStage<Void>).await()
}
The unlock line is not guaranteed to execute on the same thread as the lockAsync line.
Thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3581
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hey,
I have a production environment which uses a load balancer over several master Redis instances, so the actual IPs of the Redis instances switch with every request.
I update Redisson from some 3.3.* version to 3.15.3 and started to notice odd memory consumption: something keeps piling up in the Old Generation and never gets garbage-collected. Normally, it would take about a day to reach Old Gen mem cap and in a few days, so when other objects make it to Old Gen, the app just dies with OOM.
I dumped the memory, it looks like when IPs change, new ClientConnectionsEntry items are allocated and attached the linked queue in the IdleConnectionWatcher which is never pruned, unless the client is shut down. I can't tell how many nodes are in those queues, probably too many, because IdleConnectionWatcher is about 30Mb big.
Unfortunately, I cannot change the infrastructure I use. Any chance there's any config that could just mitigate it for now?
Expected behavior
Application does not run out of memory if connection entries are re-created frequently and dangling objects are cleaned up.
Actual behavior
Strong references to previously created objects are retained and keep piling up until the app gets OOM-killed.
Steps to reproduce or test case
Tricky: Redis instances should be behind a load balancer, which should have a resolvable hostname. The idea is to make Redisson try to rebuild the connection pool every time it makes a request.
Redis version
Idk, because I don't have access to the infrastructure.
Redisson version
3.15.3
Redisson configuration

Clients connect to Master nodes.
Clients are single-threaded.
Clients attempt to resolve hostname to connect to actual Redis instances.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3582
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
在redisson-spring-data包中，RedissonConnection在集群模式中调用RedissonConnection.mGet和mSet方法时，如果key不在同一个slot中，会抛出CROSSSLOT异常。同样的操作在spring的另外两个实现中JedisClusterConnection和LettuceConnection中并不会报错（内部自动按slot进行调用），所以想咨询下redisson的mGet和mSet实现出于什么考虑，实现方式与spring的不同，还是说这是一个bug？

代码

public class RedisTemplateTest {
    @Autowired
    private RedisTemplate<String, String> redisTemplate;

    @Test
    public void testMGet() {
        Map<String, String> of = Maps.of("TestA", "b", "TestC", "d", "efg", "db");
        redisTemplate.opsForValue().multiSet(of);
    }
}

依赖版本
redisson: 3.15.4
redisson-spring-boot-starter: 3.15.4
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3583
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We are seeing leaked Netty buffers like this quite frequently in production. In some deployments it causes out of memory errors on our container instances.
Seen both in Redisson 3.15.2 and 3.13.1. The codec is JsonJacksonCodec as you can see from the allocation call stack. So far I have only seen it with pipelined write operations (RBatch, in memory atomic). No other exceptions or errors during the write operation was seen.
My question is, is there something we should be doing differently to avoid such leaks, or is this a possible bug? Any hints on where to look would be helpful. I have not been able to create a local minimal repro to share unfortunately.
2021-04-16 06:09:56.447 ERROR 28 --- [sson-netty-2-10] io.netty.util.ResourceLeakDetector       : LEAK: ByteBuf.release() was not called before it's garbage-collected. See https://netty.io/wiki/reference-counted-objects.html for more information.
Recent access records:
Created at:
io.netty.buffer.PooledByteBufAllocator.newDirectBuffer(PooledByteBufAllocator.java:363)
io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:187)
io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:173)
io.netty.buffer.AbstractByteBufAllocator.buffer(AbstractByteBufAllocator.java:107)
org.redisson.codec.JsonJacksonCodec$1.encode(JsonJacksonCodec.java:77)
org.redisson.RedissonObject.encodeMapValue(RedissonObject.java:336)
org.redisson.RedissonMap.putOperationAsync(RedissonMap.java:894)
org.redisson.RedissonMap.putAsync(RedissonMap.java:881)
...
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3584
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi, In our test case, we store three keys that start with  test  in redis cluster, two of which are in the same node, one in the other node, and then using  RedissonConnection#scan  method to query   test*. we can only query keys on a node, not all nodes.
Expected behavior
In Redis cluster mode，when we use RedissonConnection#scan to  get the keys with a pattern mode like (test*), we want to get the keys that can be matched by the pattern on all redis cluster nodes
Actual behavior
In Redis cluster mode，when we use RedissonConnection#scan to get the keys with a pattern mode like (test*) in redis instance，we can only get the keys matched by the pattern on a certain redis node
Steps to reproduce or test case

a redis cluster with 3 master  and 3 slave
put key-value：

testa: b
testb: d
testadfdf: db

scan key in the following way

public class RedisTemplateTest {

    @Autowired
    private RedisTemplate<String, String> redisTemplate;

    @Test
    public void testScan() {
        Set<String>  expected = new HashSet<>(Arrays.asList("testa", "testb", "testadfdf"));
       
        Set<String> actual = new HashSet<>();
        try (Cursor<byte[]> test = redisTemplate.executeWithStickyConnection(e -> e.scan(ScanOptions.scanOptions()
                .match("test*").build()))) {
            while (test.hasNext()) {
                actual.add(StringUtils.toEncodedString(test.next(), StandardCharsets.UTF_8));
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
        assertThat(actual, equalTo(expected));
    }
}


the result we got it

testa
testa

or
testb
testadfdf
testb
testadfdf


position that may cause errors

RedissonConnection#scan



                RFuture<ListScanResult<byte[]>> f = executorService.readAsync(client, entry, ByteArrayCodec.INSTANCE, RedisCommands.SCAN, args.toArray());
                ListScanResult<byte[]> res = syncFuture(f);
                long pos = res.getPos();
                client = res.getRedisClient();
                if (pos == 0) {
                    if (entries.hasNext()) {
                        pos = -1;
                        // reset entry but not reset redisClient
                        entry = entries.next();
                    } else {
                        entry = null;
                    }
                }

Redis version
4.0.2
Redisson version

redisson: 3.15.4
redisson-spring-data-18: 3.15.4

Redisson configuration
spring:
  redis:
    cluster:
      nodes: ${nodes}
    password: ${password}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3585
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Good morning:
I hope you are doing well.
I would like to know which is the process or thread that is used by the ConnectionListener so that the RedissonClient reconnects to the Redis Server.
I mean we can get onConnect and onDisconnect events, but I would like to know how Redisson implements reconnection mechanisms so that the listener can trigger the onConnect event.
Could that mechanisms (process/thread) be configured by using the YAML config? Or have a behavioral properties set by default for all the implementations that use it?
I appreciate your attention and collaboration with the related details about this topic.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3586
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Background:
Redisson version: 3.15.0
Framework: Spring Boot
Redis instance type: Cluster mode ( Azure Cache Premium with 2 nodes )
I am using scheduleWithFixedDelay API of redisson to schedule two kinds of delayed jobs:

repeat every 2 mins with a initial delay of 5 mins and max execution count of 5 times
repeat every 2 mins with a initial delay of 15 mins and max execution count of 10 times

I have implemented the logic for the max execution count using RAtomicLong data type.
Issue
When I schedule using the executor.scheduleWithFixedDelay API, the job is not executed at the expected initial delay configured. To add some more context, I spawned multiple instances of both the delayed job types and NONE of them ran at the expected delay ( 5 mins or 15 mins). In fact, all of them ran the next day around the same time with a delay of ~8 hours from their initial creation time.
On the other hand, jobs that I schedule with executor.execute API are running fine without any issues immediately. The problem is happening only with scheduleWithFixedDelay API.
Below is some sample source code of roughly how the delayed jobs look like along with the redissonClient / redisson node creation code.
Highly appreciate any help with this :)
Code
DelayedJobCreator
@Service
public class DelayedJobCreator {
	@Autowired
	private final RedissonClient redissonClient;

	public void createTypeOne(DelayedJobData jobData) {
		Long initialDelay = 300 L;
		Long repeatedDelay = 120 L;
		RScheduledExecutorService executor = redissonClient
                             .getExecutorService("delayed-job-service");
		executor.scheduleWithFixedDelay(
                             new TypeOneDelayedJob(jobData), initialDelay, repeatedDelay, TimeUnit.SECONDS
                 );
	}

	public void createTypeTwo(DelayedJobData jobData) {
		Long initialDelay = 900 L;
		Long repeatedDelay = 120 L;
		RScheduledExecutorService executor = redissonClient
                             .getExecutorService("delayed-job-service");
		executor.scheduleWithFixedDelay(
                             new TypeTwoDelayedJob(jobData), initialDelay, repeatedDelay, TimeUnit.SECONDS
                 );
	}
}
TypeOneDelayedJob
@Slf4j
@Component
public class TypeOneDelayedJob implements Runnable, Serializable {
	private Long maxCount = 5;
	private Long maxDelay = 1800000; // 30 mins
	DelayedJobData jobData;

	@RInject
	RedissonClient redissonClient;

	@RInject
	String taskId;
	@Override
	public void run() {
		RAtomicLong count = redissonClient.getAtomicLong("countTypeOne:" + taskId);
		Long newValue = count.incrementAndGet();
		Long createdEpoch = jobData.getEpoch();
		Long currentEpoch = System.currentTimeMillis();

		RScheduledExecutorService executor = redissonClient.getExecutorService("delayed-job-service");
		if (newValue > maxCount) {
			log.info("Maximum retries hit for TypeOneDelayedJob with taskId: {}", taskId);
			executor.cancelTask(taskId);
		} else if (currentEpoch - createdEpoch > maxDelay) {
			log.info("Maximum delay TypeOneDelayedJob with taskId: {}", taskId);
			executor.cancelTask(taskId);
		} else {
			// Job logic
		}
	}
}
TypeTwoDelayedJob
@Slf4j
@Component
public class TypeTwoDelayedJob implements Runnable, Serializable {
	private Long maxCount = 10;
	private Long maxDelay = 1800000; // 30 mins
	DelayedJobData jobData;

	@RInject
	RedissonClient redissonClient;

	@RInject
	String taskId;
	@Override
	public void run() {
		RAtomicLong count = redissonClient.getAtomicLong("countTypeOne:" + taskId);
		Long newValue = count.incrementAndGet();
		Long createdEpoch = jobData.getEpoch();
		Long currentEpoch = System.currentTimeMillis();

		RScheduledExecutorService executor = redissonClient.getExecutorService("delayed-job-service");
		if (newValue > maxCount) {
			log.info("Maximum retries hit for TypeTwoDelayedJob with taskId: {}", taskId);
			executor.cancelTask(taskId);
		} else if (currentEpoch - createdEpoch > maxDelay) {
			log.info("Maximum delay TypeTwoDelayedJob with taskId: {}", taskId);
			executor.cancelTask(taskId);
		} else {
			// Job logic
		}
	}
}
Spring bean creation - Configuration class
@Bean
public Config redissonConfig() {
    Config config = new Config();
    config.useClusterServers()
        .addNodeAddress(host)
        .setPassword(password);
    return config;
}

@SneakyThrows
@Bean(destroyMethod = "shutdown")
public RedissonClient redissonClient(Config config) {
    return Redisson.create(config);
}

@Bean(destroyMethod = "shutdown")
public RedissonNode redissonNode(Config config) {
    RedissonNodeConfig nodeConfig = new RedissonNodeConfig(config);
    nodeConfig.setBeanFactory(beanFactory);
    nodeConfig.setExecutorServiceWorkers(Collections.singletonMap("delayed-job-service", 2));
    RedissonNode node = RedissonNode.create(nodeConfig);
    node.start();
    return node;
}
Update
An update to the issue, we noticed few redisson errors in the logs related to Redisson connection timeouts i,e
ERROR 6 --- [isson-timer-4-1] o.r.c.handler.PingConnectionHandler      : Unable to send PING command over channel: [id: 0x6f24e6ea, L:/10.114.48.173:57092 - R:euw-prod-052-fps-ctwr-redis-cluster.redis.cache.windows.net/10.114.49.200:6380]

org.redisson.client.RedisTimeoutException: Command execution timeout for command: (PING), params: [], Redis client: [addr=rediss://euw-prod-052-fps-ctwr-redis-cluster.redis.cache.windows.net:6380]
at org.redisson.client.RedisConnection.lambda$async$1(RedisConnection.java:207) ~[redisson-3.15.0.jar!/:3.15.0]
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:672) [netty-common-4.1.58.Final.jar!/:4.1.58.Final]
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:747) [netty-common-4.1.58.Final.jar!/:4.1.58.Final]
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:472) [netty-common-4.1.58.Final.jar!/:4.1.58.Final]
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-common-4.1.58.Final.jar!/:4.1.58.Final]
at java.lang.Thread.run(Thread.java:748) [na:1.8.0_212]

We felt these errors were causing the scheduleWithFixedDelay to not to work properly, so to fix these connection timeouts, we set the following params to the redisson client:
pingConnectionInterval: 10000
keepAlive: true 

Post doing these configuration changes, we did not notice these timeouts for 2 days and the scheduleWithFixedDelay API did work as expected. However, we started receiving these timeouts after 2 days.
I wanted to know what is a right way to deal with this situation. Also, as mentioned before, this is ONLY happening for scheduleWithFixedDelay usecase and not the execute API. Why is this happening ONLY for the schedule API and not the execute API ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3587
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
A test program is pushing a bunch of requests (evalSha for lock-free evaluation) repeatedly. Then bounced Redis Cluster in the middle of it. The connections were lost, then discovered within seconds, as expected. However, Redisson is stuck unable to recover from this condition:
org.redisson.client.RedisNodeNotFoundException: Node for slot: 13907 hasn't been discovered yet. Check cluster slots coverage using CLUSTER NODES command. Increase value of retryAttempts and/or retryInterval settings.
	at org.redisson.connection.MasterSlaveConnectionManager.createNodeNotFoundException(MasterSlaveConnectionManager.java:554)
	at org.redisson.connection.MasterSlaveConnectionManager.connectionWriteOp(MasterSlaveConnectionManager.java:508)
	at org.redisson.command.RedisExecutor.getConnection(RedisExecutor.java:534)
	at org.redisson.command.RedisExecutor.execute(RedisExecutor.java:121)
	at org.redisson.command.RedisExecutor$2.run(RedisExecutor.java:251)
	at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:672)
	at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:747)
	at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:472)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more

Redis cluster state is fine:
127.0.0.1:6379> cluster nodes
fe0223c0b542837bd94699d1af3c19e4ac31178f 172.28.1.2:6379@16379 master - 0 1619718045643 2 connected 5461-10922
5d8b390298d2962cf69385d3e15b71dc432d5280 172.28.1.5:6379@16379 slave af2498fa4bb5ad08751bfb52a954a36964510e59 0 1619718045000 1 connected
af2498fa4bb5ad08751bfb52a954a36964510e59 172.28.1.1:6379@16379 myself,master - 0 1619718043000 1 connected 0-5460
9e3493660fd571eb3454de79fd85776bfe3f81e5 172.28.1.3:6379@16379 master - 0 1619718044000 3 connected 10923-16383
9e23832ccbefdd2d20a410848fecc092efd78b1e 172.28.1.4:6379@16379 slave 9e3493660fd571eb3454de79fd85776bfe3f81e5 0 1619718045000 3 connected
76585e6d75f61b98178df0c6aafcba6a0de0d8b3 172.28.1.6:6379@16379 slave fe0223c0b542837bd94699d1af3c19e4ac31178f 0 1619718044541 2 connected

Expected behavior
Eventually discover the hash slot is available.
Actual behavior
Retrying the same sequence of operations does not recover even after 5 minutes.
Steps to reproduce or test case

Start Redis cluster
Loop evalSha across all cluster nodes.
Bounce Redis cluster in the middle of the loop
Observe the failures

Observe that restarting the Redisson (bounce microservice in this case) recovers - so the issue is not in Redis cluster.
Redis version
127.0.0.1:6379> info
# Server
redis_version:6.2.1
redis_git_sha1:00000000
redis_git_dirty:0
redis_build_id:fa5dfffb0053744e
redis_mode:cluster
os:Linux 4.14.35-1902.3.1.el7uek.x86_64 x86_64
arch_bits:64
multiplexing_api:epoll
atomicvar_api:c11-builtin
gcc_version:8.3.0
process_id:1
process_supervised:no
run_id:84f6b708cd93f23cb33317537d55220e8bd94b61
tcp_port:6379
server_time_usec:1619718169208450
uptime_in_seconds:1922
uptime_in_days:0
hz:10
configured_hz:10
lru_clock:9105433
executable:/data/redis-server
config_file:/usr/local/etc/redis/redis.conf
io_threads_active:0

Redisson version
3.15.4
Redisson configuration
@ApplicationScoped
public class RedissonClientProvider {
   public RedissonClientProvider() {
   }

   @Produces
   @ApplicationScoped
   public RedissonClient cluster(@ConfigProperty(name = "jedis.cluster.addresses") String[] addresses) {
      Config config = new Config();
      config.useClusterServers()
            .addNodeAddress(Arrays.stream(addresses).map(a -> "redis://" + a).toArray(n -> new String[n]))
            .setRetryAttempts(3);
      return Redisson.create(config);
   }
}

Config: just a bunch of hostname:port, no password.
Cluster is the minimal set of nodes: 6 redis containers, dataset is tiny (100K 10Byte strings).
/usr/local/etc/redis/redis.conf:
port 6379
cluster-enabled yes
cluster-config-file nodes.conf
cluster-node-timeout 5000
appendonly yes
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3588
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Not exactly.  Redis becoming unavailable is an unexpected event.  We can't
anticipate when that would happen.  We can only react to it.  If our redis
instance is unavailable, our spring boot-based service can't start since it
will encounter an exception when Redisson.create() is invoked.  If my
service is set up to run in a Kubernetes cluster, I have no control over
when my service may get rescheduled to a different pod.  If that were to
happen, it would be in a state where my service would be down and I would
have a dependency on redis to start.

These changes allow for the application to start if the caching is just a
nice-to-have feature and not a hard requirement.
…
On Mon, May 3, 2021 at 2:10 AM Nikita Koksharov ***@***.***> wrote:
 Can't we solve this with annotation below on RedissonAutoConfiguration
 class?

 @ConditionalOnProperty(prefix = "spring.redis.redisson", name = "enabled", havingValue = "true",
 		matchIfMissing = true)

 —
 You are receiving this because you authored the thread.
 Reply to this email directly, view it on GitHub
 <#3588 (comment)>,
 or unsubscribe
 <https://github.com/notifications/unsubscribe-auth/AD3AEGBGD7WTPHCN6YMXPPDTLY46FANCNFSM435OKMXQ>
 .
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3589
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
RMap.put should succeed
Actual behavior
RMap.put throws io.netty.util.IllegalReferenceCountException: refCnt: 0 when a java bean is set as value in RMap
Steps to reproduce or test case
Redission Initialization
private RMap<String, Expression> expressionMap;
this.expressionMap = this.redissonClient.getMap("ExpressionMap");

Expression Class
@Data
@NoArgsConstructor
@AllArgsConstructor
@Builder
@JsonInclude(JsonInclude.Include.NON_NULL)
public class Expression {
private String expression;
private boolean custom;
}

setting key and value
Expression expression = new Expression();
expression.setExpression("a > 20");
expression.setCustom(false);
this.expressionMap.put(uuid, expression);

System Setup
My application is a spring-boot application. Tried Running on both Tomcat and Undertow embedded server but the result is the same.
My SpringBoot version is 2.4.3 but have tried updating it to 2.4.2 and similarly 3.15.3 but the result is the same.
Exception Trace
io.netty.util.IllegalReferenceCountException: refCnt: 0
	at io.netty.buffer.AbstractByteBuf.ensureAccessible(AbstractByteBuf.java:1456) ~[netty-buffer-4.1.59.Final.jar:4.1.59.Final]
	at io.netty.buffer.AbstractByteBuf.ensureWritable0(AbstractByteBuf.java:291) ~[netty-buffer-4.1.59.Final.jar:4.1.59.Final]
	at io.netty.buffer.AbstractByteBuf.ensureWritable(AbstractByteBuf.java:282) ~[netty-buffer-4.1.59.Final.jar:4.1.59.Final]
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1075) ~[netty-buffer-4.1.59.Final.jar:4.1.59.Final]
	at org.redisson.codec.MarshallingCodec$ByteOutputWrapper.write(MarshallingCodec.java:129) ~[redisson-3.15.3.jar:3.15.3]
	at org.jboss.marshalling.SimpleDataOutput.flush(SimpleDataOutput.java:336) ~[jboss-marshalling-2.0.11.Final.jar:2.0.11.Final]
	at org.jboss.marshalling.SimpleDataOutput.finish(SimpleDataOutput.java:378) ~[jboss-marshalling-2.0.11.Final.jar:2.0.11.Final]
	at org.jboss.marshalling.AbstractMarshaller.finish(AbstractMarshaller.java:126) ~[jboss-marshalling-2.0.11.Final.jar:2.0.11.Final]
	at org.redisson.codec.MarshallingCodec.lambda$new$1(MarshallingCodec.java:169) ~[redisson-3.15.3.jar:3.15.3]
	at org.redisson.command.CommandAsyncService.encodeMapValue(CommandAsyncService.java:715) ~[redisson-3.15.3.jar:3.15.3]
	at org.redisson.RedissonObject.encodeMapValue(RedissonObject.java:305) ~[redisson-3.15.3.jar:3.15.3]
	at org.redisson.RedissonMap.putOperationAsync(RedissonMap.java:1336) ~[redisson-3.15.3.jar:3.15.3]
	at org.redisson.RedissonMap.putAsync(RedissonMap.java:1322) ~[redisson-3.15.3.jar:3.15.3]
	at org.redisson.RedissonMap.put(RedissonMap.java:644) ~[redisson-3.15.3.jar:3.15.3]

Redis version
Docker Compose config for Redis Server
redis-server:
    image: 'bitnami/redis:5.0.9'
    mem_limit: 512M
    ports:
      - "6379:6379"
    environment:
      - ALLOW_EMPTY_PASSWORD=yes    
    volumes:
      - iot-redis-storage:/bitnami/redis/data

Redisson version

	<dependency>
		<groupId>org.redisson</groupId>
		<artifactId>redisson-spring-boot-starter</artifactId>
		<version>3.15.3</version>
	</dependency>

Redisson configuration
redis-local.yaml
singleServerConfig:
  idleConnectionTimeout: 10000
  connectTimeout: 10000
  timeout: 3000
  retryAttempts: 3
  retryInterval: 1500
  password: null
  subscriptionsPerConnection: 5
  clientName: null
  address: "redis://127.0.0.1:6379"
  subscriptionConnectionMinimumIdleSize: 1
  subscriptionConnectionPoolSize: 50
  connectionMinimumIdleSize: 10
  connectionPoolSize: 20
  database: 0
  dnsMonitoringInterval: 5000
threads: 16
nettyThreads: 32
codec: !<org.redisson.codec.MarshallingCodec> {}
transportMode: "NIO"
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3590
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
If I use Redisson LocalCachedMap to save into Redis and then refer it using the LocalCachedMap it all works OK.
But If i refer to that same object saved using LocalCachedMap in a EVALSHA Lua script i get this exception given below.
If i just use RMapCache to save the object and refer it in the same EVALSHA Lua script it works OK - so this means the script has no issue.
The issue seems to be when the script has to unpack an object saved using LocalCachedMap.
What is the workaround / solution for this ?
Exception in thread "main" org.redisson.client.RedisException: ERR Error running script (call to f_3ed22d9cfe2ba9d0d8b8f0a790d2ced8cb1ea564): @user_script:24: user_script:24: bad argument #2 to 'unpack' (data string too short) . channel: [id: 0x9310621e, L:/192.168.1.9:58359 - R:rdaws.a2omobile.com/18.206.117.202:6001] command: (EVALSHA), params: [3ed22d9cfe2ba9d0d8b8f0a790d2ced8cb1ea564, 2, VId_{NOCAChE7900c1c:5eee4437}_150998044, VPortCache_{NOCAChE7900c1c:5eee4437}, PooledUnsafeDirectByteBuf(ridx: 0, widx: 2, cap: 256)]
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:365)
	at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:196)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:134)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:104)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:501)
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Unknown Source)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3591
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Description
Hi team,
We're encountering an issue in production env that Redisson client keeps hit the maxmemory limit of Redis, we're using AWS Elasticache Redis with cluster mode disabled, have upgraded the node type from t2.small to cache.t3.medium, but it still too small.
We're wondering if it's an issue that others may also experience, are there any potential solutions for us to try?
Version:
redisson-all: 3.13.5
redisson Tomcat 9: 3.13.5
Error message from Tomcat log:
org.redisson.client.RedisOutOfMemoryException: command not allowed when used memory > 'maxmemory'

Redisson config:
{
    "singleServerConfig": {
        "idleConnectionTimeout": 10000,
        "connectTimeout": 10000,
        "timeout": 3000,
        "retryAttempts": 3,
        "retryInterval": 1500,
        "password": xxxxxx,
        "subscriptionsPerConnection": 5,
        "clientName": xxxxx,
        "address": "rediss://xxxxxxxxx:6379",
        "subscriptionConnectionMinimumIdleSize": 1,
        "subscriptionConnectionPoolSize": 50,
        "connectionMinimumIdleSize": 24,
        "connectionPoolSize": 64,
        "database": 0
    },
    "threads": 0,
    "nettyThreads": 0,
    "codec": {
         "class": "org.redisson.codec.FstCodec"
     },
     "transportMode": "NIO"
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3592
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
There is only one section 6.12 RateLimiter in the English version of the documentation.
Actual behavior
Section 6.12 RateLimiter is duplicated in the English version of the documentation.
Steps to reproduce or test case
https://github.com/redisson/redisson/wiki/6.-distributed-objects#612-ratelimiter
Redis version
N/A
Redisson version
N/A
Redisson configuration
N/A
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3593
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When using distributed locks, why not use the JVM locks first to reduce the pressure of redis?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3594
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We are using Jackson-based (de)serialization. Our DTOs are immutable and use Lombok's @Jacksonized @Builder (so no setters in those classes).
To our surprise, this does not work in all cases. When deserializing with a "pure" Jackson, everything works fine. But when using Redisson, Lombok's @Builder.Default breaks deserialization. In this case, the generated builder class does not have a matching field for the JSON property. For instance, a field String example in the DTO will result in two fields in the builder: String example$value and boolean example$set. None of them matches the JSON property example (serialized from the DTO). However, there is a matching setter method example(String), which is used by Jackson in that case.
After a bit of debugging, we found the reason why it works with Jackson directly, but not in Redisson: JsonJacksonCodec explicitly switches off the detection of setters, but only relies on fields (which is obviously not sufficient in this case). The solution is easy: We simply use our own codec that extends JsonJacksonCodec, switch on the setter detection and everything seems to work again.
However, the question remains: Why does Redisson explicitly deactivate the detection of setters (and getters, too)? Is there any drawback in allowing it, like we did?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3595
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
HI Team,
I had a doubt regarding redisson connection pooling management.
I have an application with a high volume of traffic and hence get a lot of concurrent requests.
Have optimised my connection pool accordingly.But i have the following query
What if a new request arrives and all the connections are busy in case of unprecedented volume.
How does redisson handle such scenarios.Is there a connection request time out , post which it tries to create a new connection if pool is exhausted OR the request is rejected in absence of a connection in the pool .
regards,
AC
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3596
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3597
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3598
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3599
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3600
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3601
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3602
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3603
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3604
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3605
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3606
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3607
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3608
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3609
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3610
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3611
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3612
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3613
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3614
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3615
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3616
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3617
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3618
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3619
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3620
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3621
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3622
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3623
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3624
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3625
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3626
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3627
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3628
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3629
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3630
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3631
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3632
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3633
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3634
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3635
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3636
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3637
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3638
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3639
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3640
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3641
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3642
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3643
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3644
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3645
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3646
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3647
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3648
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3649
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3650
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3651
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3652
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3653
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3654
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3655
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3656
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3657
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3658
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3659
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3660
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3661
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3662
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3663
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3664
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3665
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3666
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3667
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3668
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3669
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3670
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3671
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3672
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3673
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3674
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3675
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3676
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3677
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3678
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3679
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3680
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3681
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3682
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3683
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3684
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3685
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3686
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3687
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3688
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3689
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3690
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3691
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3692
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3693
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3694
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3695
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3696
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3697
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3698
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3699
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3700
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3701
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3702
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3703
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3704
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3705
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3706
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3707
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3708
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3709
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3710
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3711
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3712
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3713
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3714
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3715
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3716
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3717
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3718
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3719
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3720
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3721
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3722
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3723
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3724
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
If the thread ID is used as the key value for reentry, is there any problem if the thread pool is used for calling the sub method? Can the key value be specified externally? And if the thread number will be repeated
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3725
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
项目中引入三个redis相关的依赖，本次新增redisson 3.9.1。

org.redisson
redisson-spring-boot-starter
3.9.1

<dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-data-redis</artifactId>
            <version>2.3.0.RELEASE</version>

  
 <dependency>
            <groupId>redis.clients</groupId>
            <artifactId>jedis</artifactId>
            <version>2.9.1</version>
   </dependency>

没有重写redisson配置，使用默认的spring.redis配置
现在线上报有
org.redisson.client.RedisConnectionClosedException: Command (EVAL), params: [if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then redis.call('pexpire', KEYS[1], ARGV[1]); retu..., 1, * * :10, 30000, 961d0a00-de8f-4176-935d-c4b7a71b17e8:911] succesfully sent, but channel [id: 0x96383] has been closed! 异常。
并伴有jedis报错
Cannot get Jedis connection; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool
请问是否因为本次引入redisson 导致 无法正常使用jedis。
使用代码如下：
RLock lock = redissonClient.getLock(MessageFormat.format(ConstantRedis.BATCH_JOB_REDIS_KEY, shardingIndex));
boolean bool = false;
try {
bool = lock.tryLock();
if (bool) {
List batchJobList = tScrmBatchJobMapper.selectBatchTask(shardingIndex
, Lists.newArrayList(BatchJobStatusEnum.STATUS.WAIT.getCode(), BatchJobStatusEnum.STATUS.ING.getCode())
, maxSize, MAX_RETRY_COUNT);
if (CollUtil.isEmpty(batchJobList)) {
return;
} ...
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3726
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
你好，我们在压测过程中，发现在服务器cpu使用率为90左右%时，Redisson性能有不稳定问题，随着压测时间的增加，TPS会逐步下降，主要的耗时在redisTemplate.opsForValue().multiGet(keys)上，耗时最大可达7s以上，dump堆内存后，发现RedisConnection个数并没有增加，依旧保持最小连接数在运行，压测期间，我们尝试调整过threads、readMode、nettyThreads均没有明显效果，将驱动更换为Jedis后，该现象并没有出现。Redisson遇到这个问题需要调整什么参数解决？
下面是我们的测试场景，及结果：
    @Autowired
    private final RedisTemplate<String, Object> redisTemplate;


   /**
     * 部分代码已省略，仅保留核心代码
     *
     * @param keys
     * @param cacheLoader
     * @return
     */
    public List<Object> get(List<String> keys, CacheLoader<List<String>, List<Object>> cacheLoader) {

        // load from redis
        final List<Object> remoteCachedResult = redisTemplate.opsForValue().multiGet(keys);

        BitSet missIndex = new BitSet(keys.size());

        // find miss key
        List<String> missKey = new ArrayList<>();
        for (int i = 0; i < keys.size(); i++) {
            if (remoteCachedResult.get(i) == null) {
                missKey.add(keys.get(i));
                missIndex.set(i);
            }
        }

        // load miss key if necessary
        if (CollectionUtils.isNotEmpty(missKey)) {
            final List<Object> load = cacheLoader.load(missKey);

            int keyIndex = -1;
            for (Object t : load) {
                keyIndex = missIndex.nextSetBit(keyIndex + 1);
                if (t != null) {
                    redisTemplate.opsForValue().set(keys.get(keyIndex), t);
                    remoteCachedResult.set(keyIndex, t);
                }
            }
        }
        return remoteCachedResult;
    }




Redisson:



Jedis



版本

Redisson: 3.16.0
redisson-spring-data: 3.16.0
springboot: 1.5.22
redis: 4.0（集群部署，3主3从）



配置


    redisson:
      config: |
        clusterServersConfig:
          readMode: MASTER_SLAVE
          connectTimeout: 1000
          retryAttempts: 3
          retryInterval: 1500
          failedSlaveReconnectionInterval: 1500
          failedSlaveCheckInterval: 30000
          password: password
          slaveConnectionMinimumIdleSize: 64
          slaveConnectionPoolSize: 256
          masterConnectionMinimumIdleSize: 64
          masterConnectionPoolSize: 256
          nodeAddresses:
          - "redis://ip:port"
          - "redis://ip:port"
          - "redis://ip:port"
          - "redis://ip:port"
          - "redis://ip:port"
          - "redis://ip:port"
        threads: 256
        nettyThreads: 0
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3727
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
hi,
We use RMapCache object to save our data, but we can see that the redisson client gets all the map when we need data and not a specific key on the map.
is there a better way or map to prevent this behaviour and get the key we want instead of all the map and continue having TTL leave map ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3728
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
This is a followup to #3573. We have now received the first user feedback from @jebeaudet which exhibits the same behavior as in the previous issue.
We have tried with Maven 3.8.x from the maven-3.8.x and Resolver 1.7.1 with Redisson's RSemaphore. Several runs observe the same behavior. One thread tries to acquire a lock which is not held by anyone else and after the time is up (30 s) no lock is obtained. @jebeaudet privately provided me log files of those builds and I have distilled the lock workflows from it. Here is a sample:
lock_held	start_timestamp	end_timestamp	thread	lock_workflow	lock_type	lock_name
6	3017	3023	main	acquire => release	write	artifact:com.coveo:coveo-cloud-base-service-pom:40.123.0
12	3052	3064	main	acquire => release	write	artifact:com.amazonaws:aws-java-sdk-bom:1.12.9
4	3093	3097	main	acquire => release	write	artifact:com.amazonaws:aws-java-sdk-pom:1.12.9
3	3117	3120	main	acquire => release	write	artifact:com.fasterxml.jackson:jackson-bom:2.12.3
4	3130	3134	main	acquire => release	write	artifact:com.fasterxml.jackson:jackson-parent:2.12
3	3141	3144	main	acquire => release	write	artifact:com.fasterxml:oss-parent:41
6	3163	3169	main	acquire => release	write	artifact:org.eclipse.jetty:jetty-bom:9.4.42.v20210604
5	3180	3185	main	acquire => release	write	artifact:org.springframework.boot:spring-boot-dependencies:2.3.12.RELEASE
2	3209	3211	main	acquire => release	write	artifact:com.datastax.oss:java-driver-bom:4.6.1
6	3239	3245	main	acquire => release	write	artifact:io.dropwizard.metrics:metrics-bom:4.1.22
2	3266	3268	main	acquire => release	write	artifact:io.dropwizard.metrics:metrics-parent:4.1.22
2	3278	3280	main	acquire => release	write	artifact:org.codehaus.groovy:groovy-bom:2.5.14
14	3298	3312	main	acquire => release	write	artifact:com.fasterxml.jackson:jackson-bom:2.11.4
2	3360	3362	main	acquire => release	write	artifact:com.fasterxml.jackson:jackson-parent:2.11
2	3369	3371	main	acquire => release	write	artifact:com.fasterxml:oss-parent:38
4	3388	3392	main	acquire => release	write	artifact:org.glassfish.jersey:jersey-bom:2.30.1
2	3408	3410	main	acquire => release	write	artifact:org.eclipse.ee4j:project:1.0.5
2	3419	3421	main	acquire => release	write	artifact:org.junit:junit-bom:5.6.3
2	3431	3433	main	acquire => release	write	artifact:org.jetbrains.kotlin:kotlin-bom:1.3.72
5	3460	3465	main	acquire => release	write	artifact:org.jetbrains.kotlinx:kotlinx-coroutines-bom:1.3.8
3	3484	3487	main	acquire => release	write	artifact:org.apache.logging.log4j:log4j-bom:2.13.3
5	3496	3501	main	acquire => release	write	artifact:org.apache.logging:logging-parent:1
1	3516	3517	main	acquire => release	write	artifact:org.apache:apache:18
2	3530	3532	main	acquire => release	write	artifact:io.micrometer:micrometer-bom:1.5.14
3	3539	3542	main	acquire => release	write	artifact:io.netty:netty-bom:4.1.65.Final
2	3546	3548	main	acquire => release	write	artifact:org.sonatype.oss:oss-parent:7
2	3555	3557	main	acquire => release	write	artifact:io.r2dbc:r2dbc-bom:Arabba-SR10
2	3563	3565	main	acquire => release	write	artifact:io.projectreactor:reactor-bom:Dysprosium-SR20
1	3577	3578	main	acquire => release	write	artifact:io.rsocket:rsocket-bom:1.0.5
2	3591	3593	main	acquire => release	write	artifact:org.springframework.data:spring-data-releasetrain:Neumann-SR9
2	3605	3607	main	acquire => release	write	artifact:org.springframework.data.build:spring-data-build:2.3.9.RELEASE
2	3614	3616	main	acquire => release	write	artifact:org.springframework:spring-framework-bom:5.2.15.RELEASE
2	3623	3625	main	acquire => release	write	artifact:org.springframework.integration:spring-integration-bom:5.3.8.RELEASE
1	3631	3632	main	acquire => release	write	artifact:org.springframework.security:spring-security-bom:5.3.9.RELEASE
2	3640	3642	main	acquire => release	write	artifact:org.springframework.session:spring-session-bom:Dragonfruit-SR3
1	3653	3654	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-dependencies:Hoxton.SR11
4	3659	3663	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-dependencies-parent:2.3.4.RELEASE
1	3670	3671	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-commons-dependencies:2.2.8.RELEASE
2	3675	3677	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-netflix-dependencies:2.2.8.RELEASE
1	3681	3682	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-stream-dependencies:Horsham.SR12
2	3686	3688	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-task-dependencies:2.2.5.RELEASE
2	3691	3693	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-dependencies-parent:2.2.3.RELEASE
1	3697	3698	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-circuitbreaker-dependencies:1.0.5.RELEASE
1	3703	3704	main	acquire => release	write	artifact:io.github.resilience4j:resilience4j-bom:1.7.0
2	3708	3710	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-config-dependencies:2.2.8.RELEASE
1	3714	3715	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-function-dependencies:3.0.14.RELEASE
2	3719	3721	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-gateway-dependencies:2.2.8.RELEASE
2	3724	3726	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-consul-dependencies:2.2.7.RELEASE
1	3730	3731	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-sleuth-dependencies:2.2.8.RELEASE
1	3736	3737	main	acquire => release	write	artifact:io.zipkin.brave:brave-bom:5.12.7
2	3741	3743	main	acquire => release	write	artifact:io.zipkin.reporter2:zipkin-reporter-bom:2.15.2
1	3748	3749	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-vault-dependencies:2.2.7.RELEASE
2	3753	3755	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-dependencies-parent:2.3.2.RELEASE
1	3760	3761	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-zookeeper-dependencies:2.2.5.RELEASE
2	3765	3767	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-security-dependencies:2.2.5.RELEASE
2	3771	3773	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-cloudfoundry-dependencies:2.2.3.RELEASE
1	3776	3777	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-dependencies-parent:2.3.1.RELEASE
1	3782	3783	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-bus-dependencies:2.2.4.RELEASE
1	3788	3789	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-contract-dependencies:2.2.7.RELEASE
1	3794	3795	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-aws-dependencies:2.2.6.RELEASE
1	3798	3799	main	acquire => release	write	artifact:com.amazonaws:aws-java-sdk-bom:1.11.792
1	3802	3803	main	acquire => release	write	artifact:com.amazonaws:aws-java-sdk-pom:1.11.792
1	3809	3810	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-openfeign-dependencies:2.2.8.RELEASE
1	3813	3814	main	acquire => release	write	artifact:io.github.openfeign:feign-bom:10.12
1	3819	3820	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-kubernetes-dependencies:1.1.9.RELEASE
2	3824	3826	main	acquire => release	write	artifact:io.fabric8:kubernetes-client-bom:4.13.2
2	3834	3836	main	acquire => release	write	artifact:org.springframework.cloud:spring-cloud-gcp-dependencies:1.2.8.RELEASE
1	3841	3842	main	acquire => release	write	artifact:com.google.guava:guava-bom:30.0-jre
2	3845	3847	main	acquire => release	write	artifact:org.sonatype.oss:oss-parent:9
1	3851	3852	main	acquire => release	write	artifact:com.google.cloud:libraries-bom:16.2.0
2	3856	3858	main	acquire => release	write	artifact:com.google.guava:guava-bom:30.1-android
2	3861	3863	main	acquire => release	write	artifact:com.google.protobuf:protobuf-bom:3.14.0
1	3866	3867	main	acquire => release	write	artifact:com.google.cloud:google-cloud-bom:0.146.0
2	3871	3873	main	acquire => release	write	artifact:com.google.cloud:google-cloud-accessapproval-bom:1.0.7
1	3877	3878	main	acquire => release	write	artifact:com.google.cloud:google-cloud-shared-config:0.9.4
1	3885	3886	main	acquire => release	write	artifact:com.google.cloud:google-cloud-asset-bom:2.2.0
1	3891	3892	main	acquire => release	write	artifact:com.google.cloud:google-cloud-automl-bom:1.3.2
1	3897	3898	main	acquire => release	write	artifact:com.google.cloud:google-cloud-bigquerydatatransfer-bom:1.0.22
11	3904	3915	main	acquire => release	write	artifact:com.google.cloud:google-cloud-bigquerystorage-bom:1.7.0
1	3920	3921	main	acquire => release	write	artifact:com.google.cloud:google-cloud-bigqueryconnection-bom:1.0.4
2	3927	3929	main	acquire => release	write	artifact:com.google.cloud:google-cloud-bigqueryreservation-bom:1.0.4
1	3934	3935	main	acquire => release	write	artifact:com.google.cloud:google-cloud-bigtable-bom:1.19.0
1	3940	3941	main	acquire => release	write	artifact:com.google.cloud:google-cloud-billing-bom:1.1.9
2	3946	3948	main	acquire => release	write	artifact:com.google.cloud:google-cloud-billingbudgets-bom:1.0.1
1	3952	3953	main	acquire => release	write	artifact:com.google.cloud:google-cloud-build-bom:2.1.7
1	3959	3960	main	acquire => release	write	artifact:com.google.cloud:google-cloud-container-bom:1.2.1
1	3965	3966	main	acquire => release	write	artifact:com.google.cloud:google-cloud-containeranalysis-bom:1.2.7
1	3971	3972	main	acquire => release	write	artifact:com.google.cloud:google-cloud-datacatalog-bom:1.0.10
1	3977	3978	main	acquire => release	write	artifact:com.google.cloud:google-cloud-datalabeling-bom:0.119.7
1	3984	3985	main	acquire => release	write	artifact:com.google.cloud:google-cloud-dataproc-bom:1.1.8
1	3990	3991	main	acquire => release	write	artifact:com.google.cloud:google-cloud-datastore-bom:1.105.3
1	3995	3996	main	acquire => release	write	artifact:com.google.cloud:google-cloud-dlp-bom:2.2.3
1	4001	4002	main	acquire => release	write	artifact:com.google.cloud:google-cloud-dialogflow-bom:2.4.3
2	4006	4008	main	acquire => release	write	artifact:com.google.cloud:google-cloud-document-ai-bom:0.3.6
1	4012	4013	main	acquire => release	write	artifact:com.google.cloud:google-cloud-errorreporting-bom:0.120.9-beta
1	4017	4018	main	acquire => release	write	artifact:com.google.cloud:google-cloud-firestore-bom:2.1.0
1	4022	4023	main	acquire => release	write	artifact:com.google.cloud:google-cloud-shared-config:0.9.2
1	4029	4030	main	acquire => release	write	artifact:com.google.cloud:google-cloud-functions-bom:1.0.3
1	4035	4036	main	acquire => release	write	artifact:com.google.cloud:google-cloud-game-servers-bom:1.0.3
2	4041	4043	main	acquire => release	write	artifact:com.google.cloud:google-cloud-iamcredentials-bom:1.1.7
1	4047	4048	main	acquire => release	write	artifact:com.google.cloud:google-cloud-iot-bom:1.1.8
2	4052	4054	main	acquire => release	write	artifact:com.google.cloud:google-cloud-kms-bom:1.40.3
1	4058	4059	main	acquire => release	write	artifact:com.google.cloud:google-cloud-language-bom:1.101.7
1	4063	4064	main	acquire => release	write	artifact:com.google.cloud:google-cloud-logging-bom:2.1.0
1	4068	4069	main	acquire => release	write	artifact:com.google.cloud:google-cloud-mediatranslation-bom:0.2.7
1	4072	4073	main	acquire => release	write	artifact:com.google.cloud:google-cloud-memcache-bom:0.2.8
1	4077	4078	main	acquire => release	write	artifact:com.google.cloud:google-cloud-monitoring-bom:2.0.9
1	4083	4084	main	acquire => release	write	artifact:com.google.cloud:google-cloud-monitoring-dashboard-bom:1.0.5
1	4089	4090	main	acquire => release	write	artifact:com.google.cloud:google-cloud-os-config-bom:1.1.1
2	4094	4096	main	acquire => release	write	artifact:com.google.cloud:google-cloud-os-login-bom:1.1.4
1	4101	4102	main	acquire => release	write	artifact:com.google.cloud:google-cloud-phishingprotection-bom:0.29.9
1	4106	4107	main	acquire => release	write	artifact:com.google.cloud:google-cloud-pubsub-bom:1.110.1
1	4111	4112	main	acquire => release	write	artifact:com.google.cloud:google-cloud-recaptchaenterprise-bom:1.0.7
1	4117	4118	main	acquire => release	write	artifact:com.google.cloud:google-cloud-recommender-bom:1.2.7
1	4123	4124	main	acquire => release	write	artifact:com.google.cloud:google-cloud-redis-bom:1.1.6
1	4128	4129	main	acquire => release	write	artifact:com.google.cloud:google-cloud-scheduler-bom:1.23.4
1	4133	4134	main	acquire => release	write	artifact:com.google.cloud:google-cloud-secretmanager-bom:1.2.6
1	4138	4139	main	acquire => release	write	artifact:com.google.cloud:google-cloud-securitycenter-bom:1.3.3
1	4142	4143	main	acquire => release	write	artifact:com.google.cloud:google-cloud-servicedirectory-bom:1.0.0
1	4148	4149	main	acquire => release	write	artifact:com.google.cloud:google-cloud-spanner-bom:3.1.1
2	4153	4155	main	acquire => release	write	artifact:com.google.cloud:google-cloud-speech-bom:1.24.8
1	4159	4160	main	acquire => release	write	artifact:com.google.cloud:google-cloud-talent-bom:1.0.3
1	4166	4167	main	acquire => release	write	artifact:com.google.cloud:google-cloud-tasks-bom:1.30.9
1	4172	4173	main	acquire => release	write	artifact:com.google.cloud:google-cloud-texttospeech-bom:1.2.5
2	4178	4180	main	acquire => release	write	artifact:com.google.cloud:google-cloud-trace-bom:1.2.8
1	4184	4185	main	acquire => release	write	artifact:com.google.cloud:google-cloud-translate-bom:1.95.5
1	4191	4192	main	acquire => release	write	artifact:com.google.cloud:google-cloud-video-intelligence-bom:1.5.6
2	4197	4199	main	acquire => release	write	artifact:com.google.cloud:google-cloud-vision-bom:1.100.8
1	4206	4207	main	acquire => release	write	artifact:com.google.cloud:google-cloud-websecurityscanner-bom:1.0.7
1	4215	4216	main	acquire => release	write	artifact:com.google.cloud:google-cloud-webrisk-bom:1.1.5
1	4221	4222	main	acquire => release	write	artifact:com.google.auth:google-auth-library-bom:0.22.1
2	4225	4227	main	acquire => release	write	artifact:com.google.cloud:google-cloud-core-bom:1.94.0
1	4296	4297	BuilderThread 0	acquire => release	write	artifact:org.apache.maven.plugins:maven-enforcer-plugin:3.0.0-M3
1	4307	4308	BuilderThread 0	acquire => release	write	artifact:org.apache.maven.enforcer:enforcer:3.0.0-M3
1	4312	4313	BuilderThread 0	acquire => release	write	artifact:org.apache.maven:maven-parent:33
1	4319	4320	BuilderThread 0	acquire => release	write	artifact:org.apache:apache:21
1	4331	4332	BuilderThread 0	acquire => release	write	artifact:org.apache.maven.plugins:maven-enforcer-plugin:3.0.0-M3
1	4343	4344	BuilderThread 0	acquire => release	write	artifact:net.revelc.code.formatter:formatter-maven-plugin:2.15.0
2	4348	4350	BuilderThread 0	acquire => release	write	artifact:com.fasterxml.jackson:jackson-bom:2.12.2
3	4353	4356	BuilderThread 0	acquire => release	write	artifact:com.fasterxml.jackson:jackson-parent:2.12
1	4359	4360	BuilderThread 0	acquire => release	write	artifact:com.fasterxml:oss-parent:41
2	4367	4369	BuilderThread 0	acquire => release	write	artifact:net.revelc.code.formatter:formatter-maven-plugin:2.15.0
2	4375	4377	BuilderThread 0	acquire => release	write	artifact:org.apache.maven.plugins:maven-jar-plugin:3.2.0
1	4380	4381	BuilderThread 0	acquire => release	write	artifact:org.apache.maven.plugins:maven-plugins:33
1	4386	4387	BuilderThread 0	acquire => release	write	artifact:org.apache.maven.plugins:maven-jar-plugin:3.2.0
1	4392	4393	BuilderThread 0	acquire => release	write	artifact:org.apache.maven.plugins:maven-source-plugin:3.2.1
2	4399	4401	BuilderThread 0	acquire => release	write	artifact:org.apache.maven.plugins:maven-source-plugin:3.2.1
2	4408	4410	BuilderThread 0	acquire => release	write	artifact:pl.project13.maven:git-commit-id-plugin:4.0.5
1	4414	4415	BuilderThread 0	acquire => release	write	artifact:pl.project13.maven:git-commit-id-plugin-parent:4.0.5
2	4419	4421	BuilderThread 0	acquire => release	write	artifact:org.sonatype.oss:oss-parent:9
1	4425	4426	BuilderThread 0	acquire => release	write	artifact:pl.project13.maven:git-commit-id-plugin:4.0.5
1	4430	4431	BuilderThread 0	acquire => release	write	artifact:io.github.jebeaudet:flyway-validator-maven-plugin:0.4.1
1	4434	4435	BuilderThread 0	acquire => release	write	artifact:io.github.jebeaudet:flyway-validator-maven-plugin:0.4.1
1	4440	4441	BuilderThread 0	acquire => release	write	artifact:org.apache.maven.plugins:maven-clean-plugin:2.5
1	4444	4445	BuilderThread 0	acquire => release	write	artifact:org.apache.maven.plugins:maven-plugins:22
1	4450	4451	BuilderThread 0	acquire => release	write	artifact:org.apache.maven:maven-parent:21
1	4455	4456	BuilderThread 0	acquire => release	write	artifact:org.apache:apache:10
2	4459	4461	BuilderThread 0	acquire => release	write	artifact:org.apache.maven.plugins:maven-clean-plugin:2.5
1	4467	4468	BuilderThread 0	acquire => release	write	artifact:com.mycila:license-maven-plugin:4.1
1	4471	4472	BuilderThread 0	acquire => release	write	artifact:com.mycila:license-maven-plugin-parent:4.1
2	4475	4477	BuilderThread 0	acquire => release	write	artifact:com.mycila:mycila-pom:9
1	4482	4483	BuilderThread 0	acquire => release	write	artifact:com.mycila:license-maven-plugin:4.1
2	4490	4492	BuilderThread 0	acquire => release	write	artifact:org.apache.maven.plugins:maven-install-plugin:2.4
1	4495	4496	BuilderThread 0	acquire => release	write	artifact:org.apache.maven.plugins:maven-plugins:23
1	4499	4500	BuilderThread 0	acquire => release	write	artifact:org.apache.maven:maven-parent:22
1	4503	4504	BuilderThread 0	acquire => release	write	artifact:org.apache:apache:11
2	4509	4511	BuilderThread 0	acquire => release	write	artifact:org.apache.maven.plugins:maven-install-plugin:2.4
1	4541	4542	BuilderThread 0	acquire => release	write	artifact:ch.qos.logback:logback-classic:1.2.3
1	4546	4547	BuilderThread 0	acquire => release	write	artifact:ch.qos.logback:logback-parent:1.2.3
1	4556	4557	BuilderThread 0	acquire => release	write	artifact:ch.qos.logback:logback-core:1.2.3
1	4562	4563	BuilderThread 0	acquire => release	write	artifact:org.slf4j:slf4j-api:1.7.30
1	4565	4566	BuilderThread 0	acquire => release	write	artifact:org.slf4j:slf4j-parent:1.7.30
1	4577	4578	BuilderThread 0	acquire => release	write	artifact:org.slf4j:jcl-over-slf4j:1.7.30
2	4583	4585	BuilderThread 0	acquire => release	write	artifact:org.springframework.boot:spring-boot-starter-test:2.3.12.RELEASE
2	4591	4593	BuilderThread 0	acquire => release	write	artifact:org.springframework.boot:spring-boot-starter:2.3.12.RELEASE
2	4596	4598	BuilderThread 0	acquire => release	write	artifact:org.springframework.boot:spring-boot:2.3.12.RELEASE
1	4601	4602	BuilderThread 0	acquire => release	write	artifact:org.springframework:spring-core:5.2.15.RELEASE
1	4606	4607	BuilderThread 0	acquire => release	write	artifact:org.springframework:spring-jcl:5.2.15.RELEASE
1	4611	4612	BuilderThread 0	acquire => release	write	artifact:org.springframework:spring-context:5.2.15.RELEASE
1	4616	4617	BuilderThread 0	acquire => release	write	artifact:org.springframework:spring-aop:5.2.15.RELEASE
1	4621	4622	BuilderThread 0	acquire => release	write	artifact:org.springframework:spring-beans:5.2.15.RELEASE
2	4626	4628	BuilderThread 0	acquire => release	write	artifact:org.springframework:spring-expression:5.2.15.RELEASE
1	4631	4632	BuilderThread 0	acquire => release	write	artifact:org.springframework.boot:spring-boot-autoconfigure:2.3.12.RELEASE
1	4635	4636	BuilderThread 0	acquire => release	write	artifact:org.springframework.boot:spring-boot-starter-logging:2.3.12.RELEASE
3	4639	4642	BuilderThread 0	acquire => release	write	artifact:org.apache.logging.log4j:log4j-to-slf4j:2.13.3
1	4645	4646	BuilderThread 0	acquire => release	write	artifact:org.apache.logging.log4j:log4j:2.13.3
1	4653	4654	BuilderThread 0	acquire => release	write	artifact:org.apache.logging.log4j:log4j-api:2.13.3
1	4659	4660	BuilderThread 0	acquire => release	write	artifact:org.slf4j:jul-to-slf4j:1.7.30
1	4665	4666	BuilderThread 0	acquire => release	write	artifact:jakarta.annotation:jakarta.annotation-api:1.3.5
1	4669	4670	BuilderThread 0	acquire => release	write	artifact:jakarta.annotation:ca-parent:1.3.5
1	4673	4674	BuilderThread 0	acquire => release	write	artifact:org.eclipse.ee4j:project:1.0.5
1	4679	4680	BuilderThread 0	acquire => release	write	artifact:org.yaml:snakeyaml:1.26
2	4685	4687	BuilderThread 0	acquire => release	write	artifact:org.springframework.boot:spring-boot-test:2.3.12.RELEASE
1	4690	4691	BuilderThread 0	acquire => release	write	artifact:org.springframework.boot:spring-boot-test-autoconfigure:2.3.12.RELEASE
1	4695	4696	BuilderThread 0	acquire => release	write	artifact:com.jayway.jsonpath:json-path:2.4.0
1	4699	4700	BuilderThread 0	acquire => release	write	artifact:net.minidev:json-smart:2.3.1
1	4703	4704	BuilderThread 0	acquire => release	write	artifact:net.minidev:minidev-parent:2.3.1
1	4708	4709	BuilderThread 0	acquire => release	write	artifact:net.minidev:accessors-smart:2.3.1
1	4712	4713	BuilderThread 0	acquire => release	write	artifact:org.ow2.asm:asm:5.0.4
1	4715	4716	BuilderThread 0	acquire => release	write	artifact:org.ow2.asm:asm-parent:5.0.4
1	4718	4719	BuilderThread 0	acquire => release	write	artifact:org.ow2:ow2:1.3
1	4723	4724	BuilderThread 0	acquire => release	write	artifact:jakarta.xml.bind:jakarta.xml.bind-api:2.3.3
1	4728	4729	BuilderThread 0	acquire => release	write	artifact:jakarta.xml.bind:jakarta.xml.bind-api-parent:2.3.3
2	4732	4734	BuilderThread 0	acquire => release	write	artifact:org.eclipse.ee4j:project:1.0.6
1	4738	4739	BuilderThread 0	acquire => release	write	artifact:jakarta.activation:jakarta.activation-api:1.2.2
1	4743	4744	BuilderThread 0	acquire => release	write	artifact:com.sun.activation:all:1.2.2
1	4750	4751	BuilderThread 0	acquire => release	write	artifact:org.assertj:assertj-core:3.16.1
1	4755	4756	BuilderThread 0	acquire => release	write	artifact:org.assertj:assertj-parent-pom:2.2.7
1	4760	4761	BuilderThread 0	acquire => release	write	artifact:org.junit:junit-bom:5.6.2
1	4765	4766	BuilderThread 0	acquire => release	write	artifact:org.hamcrest:hamcrest:2.2
2	4769	4771	BuilderThread 0	acquire => release	write	artifact:org.junit.jupiter:junit-jupiter:5.6.3
2	4775	4777	BuilderThread 0	acquire => release	write	artifact:org.junit:junit-bom:5.6.3
1	4780	4781	BuilderThread 0	acquire => release	write	artifact:org.junit.jupiter:junit-jupiter-api:5.6.3
1	4785	4786	BuilderThread 0	acquire => release	write	artifact:org.apiguardian:apiguardian-api:1.1.0
1	4789	4790	BuilderThread 0	acquire => release	write	artifact:org.opentest4j:opentest4j:1.2.0
1	4793	4794	BuilderThread 0	acquire => release	write	artifact:org.junit.platform:junit-platform-commons:1.6.3
1	4797	4798	BuilderThread 0	acquire => release	write	artifact:org.junit.jupiter:junit-jupiter-params:5.6.3
1	4802	4803	BuilderThread 0	acquire => release	write	artifact:org.junit.jupiter:junit-jupiter-engine:5.6.3
1	4806	4807	BuilderThread 0	acquire => release	write	artifact:org.junit.platform:junit-platform-engine:1.6.3
1	4811	4812	BuilderThread 0	acquire => release	write	artifact:org.junit.vintage:junit-vintage-engine:5.6.3
1	4816	4817	BuilderThread 0	acquire => release	write	artifact:junit:junit:4.13.1
1	4823	4824	BuilderThread 0	acquire => release	write	artifact:org.mockito:mockito-core:3.3.3
1	4828	4829	BuilderThread 0	acquire => release	write	artifact:net.bytebuddy:byte-buddy:1.10.22
1	4832	4833	BuilderThread 0	acquire => release	write	artifact:net.bytebuddy:byte-buddy-parent:1.10.22
2	4839	4841	BuilderThread 0	acquire => release	write	artifact:net.bytebuddy:byte-buddy-agent:1.10.22
1	4846	4847	BuilderThread 0	acquire => release	write	artifact:org.objenesis:objenesis:2.6
1	4849	4850	BuilderThread 0	acquire => release	write	artifact:org.objenesis:objenesis-parent:2.6
1	4854	4855	BuilderThread 0	acquire => release	write	artifact:org.mockito:mockito-junit-jupiter:3.3.3
1	4860	4861	BuilderThread 0	acquire => release	write	artifact:org.skyscreamer:jsonassert:1.5.0
1	4864	4865	BuilderThread 0	acquire => release	write	artifact:org.sonatype.oss:oss-parent:7
1	4868	4869	BuilderThread 0	acquire => release	write	artifact:com.vaadin.external.google:android-json:0.0.20131108.vaadin1
1	4872	4873	BuilderThread 0	acquire => release	write	artifact:org.springframework:spring-test:5.2.15.RELEASE
1	4875	4876	BuilderThread 0	acquire => release	write	artifact:org.xmlunit:xmlunit-core:2.7.0
1	4878	4879	BuilderThread 0	acquire => release	write	artifact:org.xmlunit:xmlunit-parent:2.7.0
1	4883	4884	BuilderThread 0	acquire => release	write	artifact:org.hamcrest:java-hamcrest:2.0.0.0
1	4888	4889	BuilderThread 0	acquire => release	write	artifact:pl.pragmatists:JUnitParams:1.1.1
1	4895	4896	BuilderThread 0	acquire => release	write	artifact:org.hamcrest:hamcrest-core:2.2
1	4898	4899	BuilderThread 0	acquire => release	write	artifact:com.github.npathai:hamcrest-optional:2.0.0
1	4904	4905	BuilderThread 0	acquire => release	write	artifact:uk.co.jemos.podam:podam:7.2.7.RELEASE
1	4911	4912	BuilderThread 0	acquire => release	write	artifact:net.jcip:jcip-annotations:1.0
1	4915	4916	BuilderThread 0	acquire => release	write	artifact:javax.annotation:javax.annotation-api:1.3.2
1	4919	4920	BuilderThread 0	acquire => release	write	artifact:net.java:jvnet-parent:3
1	4923	4924	BuilderThread 0	acquire => release	write	artifact:javax.validation:validation-api:2.0.1.Final
2	4929	4931	BuilderThread 0	acquire => release	write	artifact:org.apache.commons:commons-lang3:3.10
5	4934	4939	BuilderThread 0	acquire => release	write	artifact:org.apache.commons:commons-parent:50
1	4949	4950	BuilderThread 0	acquire => release	write	artifact:io.github.glytching:junit-extensions:2.4.0
1	4957	4958	BuilderThread 0	acquire => release	write	artifact:io.github.benas:random-beans:3.7.0
2	4961	4963	BuilderThread 0	acquire => release	write	artifact:io.github.benas:random-beans-parent:3.7.0
1	4966	4967	BuilderThread 0	acquire => release	write	artifact:org.objenesis:objenesis:2.5.1
2	4970	4972	BuilderThread 0	acquire => release	write	artifact:org.objenesis:objenesis-parent:2.5.1
2	4977	4979	BuilderThread 0	acquire => release	write	artifact:io.github.lukehutch:fast-classpath-scanner:2.2.1
2	4983	4985	BuilderThread 0	acquire => release	write	artifact:com.fasterxml.jackson.core:jackson-databind:2.12.3
2	4989	4991	BuilderThread 0	acquire => release	write	artifact:com.fasterxml.jackson:jackson-base:2.12.3
1	4994	4995	BuilderThread 0	acquire => release	write	artifact:com.fasterxml.jackson:jackson-bom:2.12.3
1	5001	5002	BuilderThread 0	acquire => release	write	artifact:com.fasterxml.jackson.core:jackson-annotations:2.12.3
1	5006	5007	BuilderThread 0	acquire => release	write	artifact:com.fasterxml.jackson.core:jackson-core:2.12.3
1	5012	5013	BuilderThread 0	acquire => release	write	artifact:com.h2database:h2:1.4.200
1	5016	5017	BuilderThread 0	acquire => release	write	artifact:com.google.guava:guava:30.1.1-jre
1	5019	5020	BuilderThread 0	acquire => release	write	artifact:com.google.guava:guava-parent:30.1.1-jre
2	5028	5030	BuilderThread 0	acquire => release	write	artifact:com.google.guava:failureaccess:1.0.1
1	5033	5034	BuilderThread 0	acquire => release	write	artifact:com.google.guava:guava-parent:26.0-android
1	5038	5039	BuilderThread 0	acquire => release	write	artifact:com.google.guava:listenablefuture:9999.0-empty-to-avoid-conflict-with-guava
1	5043	5044	BuilderThread 0	acquire => release	write	artifact:com.google.code.findbugs:jsr305:3.0.2
1	5047	5048	BuilderThread 0	acquire => release	write	artifact:org.checkerframework:checker-qual:3.8.0
2	5051	5053	BuilderThread 0	acquire => release	write	artifact:com.google.errorprone:error_prone_annotations:2.5.1
1	5055	5056	BuilderThread 0	acquire => release	write	artifact:com.google.errorprone:error_prone_parent:2.5.1
1	5061	5062	BuilderThread 0	acquire => release	write	artifact:com.google.j2objc:j2objc-annotations:1.3
1	5065	5066	BuilderThread 0	acquire => release	write	artifact:joda-time:joda-time:2.10.10
1	5076	5077	BuilderThread 0	acquire => release	write	artifact:org.apache.commons:commons-text:1.9
1	5082	5083	BuilderThread 0	acquire => release	write	artifact:org.apache.commons:commons-parent:51
1	5090	5091	BuilderThread 0	acquire => release	write	artifact:org.apache:apache:23
1	5097	5098	BuilderThread 0	acquire => release	write	artifact:commons-io:commons-io:2.10.0
1	5102	5103	BuilderThread 0	acquire => release	write	artifact:org.apache.commons:commons-parent:52
1	5112	5113	BuilderThread 0	acquire => release	write	artifact:org.junit:junit-bom:5.7.2
1	5119	5120	BuilderThread 0	acquire => release	write	artifact:com.google.truth:truth:1.1.3
1	5125	5126	BuilderThread 0	acquire => release	write	artifact:com.google.truth:truth-parent:1.1.3
1	5134	5135	BuilderThread 0	acquire => release	write	artifact:org.checkerframework:checker-qual:3.13.0
1	5139	5140	BuilderThread 0	acquire => release	write	artifact:com.google.auto.value:auto-value-annotations:1.7.4
1	5142	5143	BuilderThread 0	acquire => release	write	artifact:com.google.auto.value:auto-value-parent:1.7.4
1	5147	5148	BuilderThread 0	acquire => release	write	artifact:com.google.errorprone:error_prone_annotations:2.7.1
1	5151	5152	BuilderThread 0	acquire => release	write	artifact:com.google.errorprone:error_prone_parent:2.7.1
1	5155	5156	BuilderThread 0	acquire => release	write	artifact:org.ow2.asm:asm:9.1
1	5159	5160	BuilderThread 0	acquire => release	write	artifact:org.ow2:ow2:1.5
1	5164	5165	BuilderThread 0	acquire => release	write	artifact:com.google.truth.extensions:truth-java8-extension:1.1.3
1	5168	5169	BuilderThread 0	acquire => release	write	artifact:com.google.truth.extensions:truth-extensions-parent:1.1.3
30006	5207	35213	BuilderThread 0	acquire => acquire_failed	write	artifact:ch.qos.logback:logback-classic:1.2.3


The write lock artifact:ch.qos.logback:logback-classic:1.2.3 is not held by someone, yet it fails. I can provide several SQLite databases which contain raw imported data, prepared data as well as joined by lock workflows/transitions. The thread dump of a hanging build looks always the same:
"main" #1 prio=5 os_prio=0 cpu=2355.05ms elapsed=33.20s tid=0x00007f12e8028800 nid=0x3ad03e waiting on condition  [0x00007f12efa2f000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at jdk.internal.misc.Unsafe.park(java.base@11.0.11/Native Method)
	- parking to wait for  <0x0000000629cb6a28> (a java.util.concurrent.Semaphore$NonfairSync)
	at java.util.concurrent.locks.LockSupport.parkNanos(java.base@11.0.11/LockSupport.java:234)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(java.base@11.0.11/AbstractQueuedSynchronizer.java:1079)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(java.base@11.0.11/AbstractQueuedSynchronizer.java:1369)
	at java.util.concurrent.Semaphore.tryAcquire(java.base@11.0.11/Semaphore.java:415)
	at org.redisson.RedissonSemaphore.tryAcquire(RedissonSemaphore.java:320)
	at org.eclipse.aether.named.redisson.RedissonSemaphoreNamedLockFactory$RedissonSemaphore.tryAcquire(RedissonSemaphoreNamedLockFactory.java:83)
	at org.eclipse.aether.named.support.AdaptedSemaphoreNamedLock.lockExclusively(AdaptedSemaphoreNamedLock.java:107)
	at org.eclipse.aether.internal.impl.synccontext.named.NamedLockFactoryAdapter$AdaptedLockSyncContext.acquire(NamedLockFactoryAdapter.java:135)
	at org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolveArtifacts(DefaultArtifactResolver.java:229)
	at org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolveArtifact(DefaultArtifactResolver.java:209)
	at org.eclipse.aether.internal.impl.DefaultRepositorySystem.resolveArtifact(DefaultRepositorySystem.java:264)
	at org.apache.maven.project.ProjectModelResolver.resolveModel(ProjectModelResolver.java:192)
	at org.apache.maven.model.building.DefaultModelBuilder.importDependencyManagement(DefaultModelBuilder.java:1265)
	at org.apache.maven.model.building.DefaultModelBuilder.build(DefaultModelBuilder.java:474)
	at org.apache.maven.model.building.DefaultModelBuilder.build(DefaultModelBuilder.java:440)
	at org.apache.maven.project.DefaultProjectBuilder.build(DefaultProjectBuilder.java:618)
	at org.apache.maven.project.DefaultProjectBuilder.build(DefaultProjectBuilder.java:387)
	at org.apache.maven.graph.DefaultGraphBuilder.collectProjects(DefaultGraphBuilder.java:414)
	at org.apache.maven.graph.DefaultGraphBuilder.getProjectsForMavenReactor(DefaultGraphBuilder.java:405)
	at org.apache.maven.graph.DefaultGraphBuilder.build(DefaultGraphBuilder.java:82)
	at org.apache.maven.DefaultMaven.buildGraph(DefaultMaven.java:507)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:219)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:957)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:289)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:193)
	at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(java.base@11.0.11/Native Method)
	at jdk.internal.reflect.NativeMethodAccessorImpl.invoke(java.base@11.0.11/NativeMethodAccessorImpl.java:62)
	at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(java.base@11.0.11/DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(java.base@11.0.11/Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

Redis version
6.2.4
Redisson version
3.15.6 on Java 11.0.11
Redisson configuration
Nothing, but localhost....
PS: There is a similar issue with RReadWriteLock, but I will report this seperately.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3729
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
transactionOptions timeout option disable
Actual behavior
transactionOptions timeout option not disable
Steps to reproduce or test case
Hello
I use redisson with spring framework

create ReactiveRedissonTransactionManager bean

@Bean
fun transactionManager(redissonReactiveClient: RedissonReactiveClient): ReactiveRedissonTransactionManager {
    return ReactiveRedissonTransactionManager(redissonReactiveClient)
}

use @transactional Annotation

@Transactional(timeout = -1)
 fun create({some Arguments}): {
    val transaction = transactionManager.currentTransaction
    transactional.flatMap { tx -> 
        tx.getBucket(...)
    }
}
I set the timeout to -1 but it didn't set as desired. I think tunoff
so, I find ReactiveRedissonTransactionManagers doBegin` method
@Override
protected Mono<Void> doBegin(TransactionSynchronizationManager synchronizationManager, Object transaction, TransactionDefinition definition) throws TransactionException {
        ReactiveRedissonTransactionObject tObject = (ReactiveRedissonTransactionObject) transaction;

        TransactionOptions options = TransactionOptions.defaults();
        if (definition.getTimeout() != TransactionDefinition.TIMEOUT_DEFAULT) {
            options.timeout(definition.getTimeout(), TimeUnit.SECONDS);
        }

        RTransactionReactive trans = redissonClient.createTransaction(options);
        ReactiveRedissonResourceHolder holder = new ReactiveRedissonResourceHolder();
        holder.setTransaction(trans);
        tObject.setResourceHolder(holder);
        synchronizationManager.bindResource(redissonClient, holder);

        return Mono.empty();
}
inherit this class, and customize doBegin method set timeout -1
but didn`t not work well ( I set it up, but it was actually 30 seconds. )
how can I turn off timeout setting ?
ps. let me know if i can help you
Redis version
6.0.5
Redisson version
3.15.6
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3730
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
redisson_lock_queue and redisson_lock_timeout keys disappear once the lock that was taken by the first thread is timed out automatically after lock lease time, and then the second thread successfully takes the lock.
Actual behavior
Sometimes, even though the lock from the first thread is timed out and released automatically, the redisson_lock_queue and redisson_lock_timeout keys are stuck and the second thread can't acquire the lock, even though nobody is holding it. The second thread is stuck for full acquisition timeout. Then, it fails to get the lock eventually, and keys redisson_lock_queue and redisson_lock_timeout disappear, making the lock available again. Feels like lock expiry notification gets lost and Redisson waits for nothing. P.S. In this regard, would be great to have FairSpinLock not to rely on pubsub.
Related? #2883
Steps to reproduce or test case
1 redis, 1 sentinel
Create Redisson client with the following config:
    config.useSingleServer()
      .setClientName("my-lock")
      .setAddress("redis://redis:6379");

Start 2 threads, each taking Fair lock with:
lock.tryLock(20, 5, TimeUnit.SECONDS);
// Same reproduced with lock.lock(5, TimeUnit.SECONDS);


and then exit WITHOUT unlock.
Same reproduced with multiple Redisson instances.
Redis version
6.2.4
Redisson version
3.16.0
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3731
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I'm using Spring Cache as the abstract level for caching and Redisson as the client. Everything works fine, but recently I had a an issue with high cpu and memory when handle a lot of requests. Now i'm searching how to optimize or solve it. I read https://redis.io/topics/memory-optimization and see that Redis hash data type works well only when there is small number of entries in a hash.
This is how I'm using Redisson with Spring Cache.
@Bean
public CacheManager cacheManager(RedissonClient redissonClient, ApplicationProperties applicationProperties) {
        Map<String, CacheConfig> config = new HashMap<>();

        long ttlInMinutes = applicationProperties.getRedis().getExpiration();

        config.put("CacheA", getCacheConfig(ttlInMinutes));
        config.put("CacheB", getCacheConfig(ttlInMinutes));

        return new RedissonSpringCacheManager(redissonClient, config);
}

And I use spring Cacheable annotation in my method with the value as "CacheA" or "CacheB".
I checked the source code of RedissonSpringCacheManager, Redisson create a RMapCache instance for every cache names which are mapped to corresponding hash key in Redis. In my example there is two RMapCache instances, one for "CacheA", and one for "CacheB".
Now come to my issue, because my cache object (ex: CacheA) has thousands of entries. My idea is to split it into smaller hashes by altering the cache name dynamically. Example: CacheA-1, CacheA-2,....
But how can I do that in Redisson? Bellow is the code of createMapCache method in RedissonSpringCacheManager.java
private Cache createMapCache(String name, CacheConfig config) {
        RMapCache<Object, Object> map = getMapCache(name, config);
        
        Cache cache = new RedissonCache(map, config, allowNullValues);
        Cache oldCache = instanceMap.putIfAbsent(name, cache);
        if (oldCache != null) {
            cache = oldCache;
        } else {
            map.setMaxSize(config.getMaxSize());
        }
        return cache;
    }

Thanks,
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3732
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I experienced "The session manager failed to start due to previous errors". It looks "Can't parse json config /tomcat/redisson.conf".
I attached the redisson.conf here. If someone can review the conf file and provide suggestion solving the errors, it would be really appreciated.
SEVERE [main] org.redisson.tomcat.RedissonSessionManager.buildClient Can't parse json config /opt/tomcat/conf/redisson.conf
com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException: Unrecognized field "SingleServerConfig" (class org.redisson.config.Config), not marked as ignorable (23 known properties: "eventLoopGroup", "maxCleanUpDelay", "nettyHook", "keepPubSubOrder", "nettyThreads", "threads", "transportMode", "singleServerConfig", "sentinelServersConfig", "reliableTopicWatchdogTimeout", "useScriptCache", "minCleanUpDelay", "connectionListener", "executor", "codec", "replicatedServersConfig", "clusterServersConfig", "useThreadClassLoader", "masterSlaveServersConfig", "addressResolverGroupFactory", "lockWatchdogTimeout", "cleanUpKeysAmount", "referenceEnabled"])
at [Source: (StringReader); line: 2, column: 23] (through reference chain: org.redisson.config.Config["SingleServerConfig"])
catalina_error.log
redisson.conf.txt
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3733
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We faced an issue in following Azure Redis Cluster configuration:

master1 <-> slave1
master2 <-> slave2

Version of Redisson 3.15.4, Redis 4.0.14
Configuration:
clusterServersConfig:
idleConnectionTimeout: 10000
connectTimeout: 15000
timeout: 3000
retryAttempts: 3
retryInterval: 1500
failedSlaveReconnectionInterval: 3000
failedSlaveCheckInterval: 60000
subscriptionsPerConnection: 5
clientName: null
subscriptionConnectionMinimumIdleSize: 1
subscriptionConnectionPoolSize: 50
slaveConnectionMinimumIdleSize: 24
slaveConnectionPoolSize: 64
masterConnectionMinimumIdleSize: 24
masterConnectionPoolSize: 64
readMode: "MASTER"
subscriptionMode: "MASTER"
nodeAddresses:
- "rediss://...."
threads: 16
nettyThreads: 32
codec: !<org.redisson.codec.FstCodec> {}
transportMode: "NIO"
After few restarts of Redis we see following errors all the time:
org.redisson.client.RedisTimeoutException: Unable to acquire connection! RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@5123a990(failure: java.util.concurrent.CancellationException)]Increase connection pool size. Node source: NodeSource [slot=8616, addr=null, redisClient=null, redirect=null, entry=null], command: (BLPOP), params: [{job-scheduler-executor:org.redisson.executor.RemoteExecutorService}, 0] after 0 retry attempts","2":"at org.redisson.command.RedisExecutor$2.run(RedisExecutor.java:187)","3":"at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:672)","4":"at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:747)","5":"at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:472)","6":"at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","7":"at java.base/java.lang.Thread.run(Unknown Source)\n"}}
And we have a question:

When RedisExecutor executes its command and retryTimeout happened then:
1.1. Error message is assigning to exception variable
1.2. Then attemptPromise is cancelling
1.3. Then attemptPromise.onComplete happens which calls releaseConnection
1.4. There is a code

which do not release connection if connectionFuture.isSuccess() == false (and this condition always met in case of timeout or I am wrong?).
And looks like that its never releases this connection and free connection counter semaphore is not releasing at all here.
Is it expected behavior? Should we always have connectTimeout less than retryInterval?
And in case when 2nd attempt fails too, we still see in the logs "after 0 retry attempts" because we already have "exception" variable set on previous step.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3734
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
["B","B"]
Actual behavior
Returned array is non-deterministic way. Values that it can take:
["B"]
["B","B"]
["B","B","B"]
Steps to reproduce or test case
I use Redisson RedissonReactiveClient with Spring Boot 2.5.2. I wrote the following example code. When I hit refresh in the browser, I receive different array sizes in a non-deterministic way. The array is always deleted before the execution, so array should always contain the following 4 elements and filtering by "B" should return the two elements of the array, where the result  of the applied predicate is true.
Redis runs dockerized on localhost.
    @GetMapping("issue")
    public List<String> issue() {
        redissonReactiveClient.getList("testList").delete().block();
        RListReactive<String> testList = redissonReactiveClient.getList("testList");
        testList.add("A").block();
        testList.add("B").block();
        testList.add("A").block();
        testList.add("B").block();
        Predicate<String> lambdaPredicate = (String s) -> (s.equals("B"));
        Flux<String> ret = testList.iterator().filter(lambdaPredicate);
        return ret.collectList().block();
    }

Redis version
6.2.4
Redisson version
3.16.0
Redisson configuration
    @Bean
    public RedissonReactiveClient getRedissonClient() {
        Config config = new Config();
        config.useSingleServer()
                // use "rediss://" for SSL connection
                .setAddress("redis://localhost:6379").setPassword(redisPassword);
        RedissonClient redisson = Redisson.create(config);
        RedissonReactiveClient redissonReactive = redisson.reactive();
        return redissonReactive;
    }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3735
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
We are intermediately getting ClassNotFoundException exception while using redisson-spring-data-23:3.16.0. Could someone guide on the issue and its resolution please.
Using bare minimum config as below.
config.useClusterServers()
.addNodeAddress(host)
.setPassword(password)
.setPingConnectionInterval(pingConnectionInterval)
.setKeepAlive(keepAlive);
2021-07-19 15:52:53.763 ERROR 17 --- [sson-netty-2-31] o.r.client.handler.CommandDecoder        : Unable to decode data. channel: [id: 0x810739dd, L:/10.118.165.160:58932 - R:euw-dev-004-develop-redis.redis.cache.windows.net/10.118.221.36:6379], reply: ReplayingDecoderByteBuf(ridx=2003, widx=2003), command: (BLPOP), params: [{remote_response}:c99cdcb5-dc74-4ed0-8a21-b62e5d392436, 0]
java.io.IOException: java.lang.ClassNotFoundException: org.redisson.remote.RemoteServiceResponse
at org.redisson.codec.MarshallingCodec.lambda$new$0(MarshallingCodec.java:148) ~[redisson-3.16.0.jar!/:3.16.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:358) ~[redisson-3.16.0.jar!/:3.16.0]
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:402) ~[redisson-3.16.0.jar!/:3.16.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:367) ~[redisson-3.16.0.jar!/:3.16.0]
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:177) ~[redisson-3.16.0.jar!/:3.16.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:116) ~[redisson-3.16.0.jar!/:3.16.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:101) ~[redisson-3.16.0.jar!/:3.16.0]
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:507) ~[netty-codec-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) ~[netty-codec-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276) ~[netty-codec-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[netty-common-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.65.Final.jar!/:4.1.65.Final]
at java.base/java.lang.Thread.run(Unknown Source) ~[na:na]
Caused by: java.lang.ClassNotFoundException: org.redisson.remote.RemoteServiceResponse
at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(Unknown Source) ~[na:na]
at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(Unknown Source) ~[na:na]
at java.base/java.lang.ClassLoader.loadClass(Unknown Source) ~[na:na]
at java.base/java.lang.Class.forName0(Native Method) ~[na:na]
at java.base/java.lang.Class.forName(Unknown Source) ~[na:na]
at org.jboss.marshalling.AbstractClassResolver.loadClass(AbstractClassResolver.java:129) ~[jboss-marshalling-2.0.11.Final.jar!/:2.0.11.Final]
at org.jboss.marshalling.AbstractClassResolver.resolveClass(AbstractClassResolver.java:110) ~[jboss-marshalling-2.0.11.Final.jar!/:2.0.11.Final]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadClassDescriptor(RiverUnmarshaller.java:1048) ~[jboss-marshalling-river-2.0.11.Final.jar!/:2.0.11.Final]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadNewObject(RiverUnmarshaller.java:1381) ~[jboss-marshalling-river-2.0.11.Final.jar!/:2.0.11.Final]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadObject(RiverUnmarshaller.java:298) ~[jboss-marshalling-river-2.0.11.Final.jar!/:2.0.11.Final]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadObject(RiverUnmarshaller.java:231) ~[jboss-marshalling-river-2.0.11.Final.jar!/:2.0.11.Final]
at org.jboss.marshalling.AbstractObjectInput.readObject(AbstractObjectInput.java:41) ~[jboss-marshalling-2.0.11.Final.jar!/:2.0.11.Final]
at org.redisson.codec.MarshallingCodec.lambda$new$0(MarshallingCodec.java:146) ~[redisson-3.16.0.jar!/:3.16.0]
... 25 common frames omitted
2021-07-19 15:52:53.765 ERROR 17 --- [sson-netty-2-31] org.redisson.remote.AsyncRemoteProxy     : Can't get response from {remote_response}:c99cdcb5-dc74-4ed0-8a21-b62e5d392436
java.io.IOException: java.lang.ClassNotFoundException: org.redisson.remote.RemoteServiceResponse
at org.redisson.codec.MarshallingCodec.lambda$new$0(MarshallingCodec.java:148) ~[redisson-3.16.0.jar!/:3.16.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:358) ~[redisson-3.16.0.jar!/:3.16.0]
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:402) ~[redisson-3.16.0.jar!/:3.16.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:367) ~[redisson-3.16.0.jar!/:3.16.0]
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:177) ~[redisson-3.16.0.jar!/:3.16.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:116) ~[redisson-3.16.0.jar!/:3.16.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:101) ~[redisson-3.16.0.jar!/:3.16.0]
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:507) ~[netty-codec-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) ~[netty-codec-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276) ~[netty-codec-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[netty-common-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.65.Final.jar!/:4.1.65.Final]
at java.base/java.lang.Thread.run(Unknown Source) ~[na:na]
Caused by: java.lang.ClassNotFoundException: org.redisson.remote.RemoteServiceResponse
at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(Unknown Source) ~[na:na]
at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(Unknown Source) ~[na:na]
at java.base/java.lang.ClassLoader.loadClass(Unknown Source) ~[na:na]
at java.base/java.lang.Class.forName0(Native Method) ~[na:na]
at java.base/java.lang.Class.forName(Unknown Source) ~[na:na]
at org.jboss.marshalling.AbstractClassResolver.loadClass(AbstractClassResolver.java:129) ~[jboss-marshalling-2.0.11.Final.jar!/:2.0.11.Final]
at org.jboss.marshalling.AbstractClassResolver.resolveClass(AbstractClassResolver.java:110) ~[jboss-marshalling-2.0.11.Final.jar!/:2.0.11.Final]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadClassDescriptor(RiverUnmarshaller.java:1048) ~[jboss-marshalling-river-2.0.11.Final.jar!/:2.0.11.Final]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadNewObject(RiverUnmarshaller.java:1381) ~[jboss-marshalling-river-2.0.11.Final.jar!/:2.0.11.Final]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadObject(RiverUnmarshaller.java:298) ~[jboss-marshalling-river-2.0.11.Final.jar!/:2.0.11.Final]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadObject(RiverUnmarshaller.java:231) ~[jboss-marshalling-river-2.0.11.Final.jar!/:2.0.11.Final]
at org.jboss.marshalling.AbstractObjectInput.readObject(AbstractObjectInput.java:41) ~[jboss-marshalling-2.0.11.Final.jar!/:2.0.11.Final]
at org.redisson.codec.MarshallingCodec.lambda$new$0(MarshallingCodec.java:146) ~[redisson-3.16.0.jar!/:3.16.0]
... 25 common frames omitted
2021-07-19 15:52:53.767 ERROR 17 --- [sson-netty-2-31] o.r.client.handler.ErrorsLoggingHandler  : Exception occured. Channel: [id: 0x810739dd, L:/10.118.165.160:58932 - R:euw-dev-004-develop-redis.redis.cache.windows.net/10.118.221.36:6379]
io.netty.handler.codec.DecoderException: java.io.IOException: java.lang.ClassNotFoundException: org.redisson.remote.RemoteServiceResponse
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:421) ~[netty-codec-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276) ~[netty-codec-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[netty-transport-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[netty-common-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.65.Final.jar!/:4.1.65.Final]
at java.base/java.lang.Thread.run(Unknown Source) ~[na:na]
Caused by: java.io.IOException: java.lang.ClassNotFoundException: org.redisson.remote.RemoteServiceResponse
at org.redisson.codec.MarshallingCodec.lambda$new$0(MarshallingCodec.java:148) ~[redisson-3.16.0.jar!/:3.16.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:358) ~[redisson-3.16.0.jar!/:3.16.0]
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:402) ~[redisson-3.16.0.jar!/:3.16.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:367) ~[redisson-3.16.0.jar!/:3.16.0]
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:177) ~[redisson-3.16.0.jar!/:3.16.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:116) ~[redisson-3.16.0.jar!/:3.16.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:101) ~[redisson-3.16.0.jar!/:3.16.0]
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:507) ~[netty-codec-4.1.65.Final.jar!/:4.1.65.Final]
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) ~[netty-codec-4.1.65.Final.jar!/:4.1.65.Final]
... 17 common frames omitted
Caused by: java.lang.ClassNotFoundException: org.redisson.remote.RemoteServiceResponse
at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(Unknown Source) ~[na:na]
at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(Unknown Source) ~[na:na]
at java.base/java.lang.ClassLoader.loadClass(Unknown Source) ~[na:na]
at java.base/java.lang.Class.forName0(Native Method) ~[na:na]
at java.base/java.lang.Class.forName(Unknown Source) ~[na:na]
at org.jboss.marshalling.AbstractClassResolver.loadClass(AbstractClassResolver.java:129) ~[jboss-marshalling-2.0.11.Final.jar!/:2.0.11.Final]
at org.jboss.marshalling.AbstractClassResolver.resolveClass(AbstractClassResolver.java:110) ~[jboss-marshalling-2.0.11.Final.jar!/:2.0.11.Final]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadClassDescriptor(RiverUnmarshaller.java:1048) ~[jboss-marshalling-river-2.0.11.Final.jar!/:2.0.11.Final]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadNewObject(RiverUnmarshaller.java:1381) ~[jboss-marshalling-river-2.0.11.Final.jar!/:2.0.11.Final]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadObject(RiverUnmarshaller.java:298) ~[jboss-marshalling-river-2.0.11.Final.jar!/:2.0.11.Final]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadObject(RiverUnmarshaller.java:231) ~[jboss-marshalling-river-2.0.11.Final.jar!/:2.0.11.Final]
at org.jboss.marshalling.AbstractObjectInput.readObject(AbstractObjectInput.java:41) ~[jboss-marshalling-2.0.11.Final.jar!/:2.0.11.Final]
at org.redisson.codec.MarshallingCodec.lambda$new$0(MarshallingCodec.java:146) ~[redisson-3.16.0.jar!/:3.16.0]
... 25 common frames omitted
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3736
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello,
We are working through issues using Redisson with AWS Elasticache during switch between master/slave.
We currently have a replicated cluster of size 2: 1 master and 1 replicated node. AWS Elasticache provides two DNS endpoint: the primary one, and the reader.
Sometime on a failover, there is a switch between the master and the slave behind the DNS and redisson update his connexion. But it seem that the Redisson switch is incorrect and our service can't proceed command when this occurs.
Here is some log to help:
Jul 18, 2021 @ 08:57:42.757 ERROR redisson-netty-2-1 Can't process the remote service request.
org.redisson.client.RedisException: READONLY You can't write against a read only replica.. channel: [id: 0x7bdd858d, L:/X.X.2.68:37420 - R:READ_ONLY_DNS/X.X.1.13:6379] command: (BLPOP), params: [{redisson_mapreduce:org.redisson.executor.RemoteExecutorService}, 0]
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:365)
	at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:196)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:134)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:104)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:501)
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:830)
	
Jul 18, 2021 @ 08:57:42.759 INFO redisson-netty-2-1 24 connections initialized for PRIMARY_DNS/X.X.1.13:6379
Jul 18, 2021 @ 08:57:42.769 ERROR redisson-netty-2-1 Can't process the remote service request. 
Jul 18, 2021 @ 08:57:47.799 INFO redisson-netty-2-1 1 connections initialized for PRIMARY_DNS/X.X.2.27:6379 
Jul 18, 2021 @ 08:57:48.764 INFO redisson-netty-2-1 master PRIMARY_DNS/X.X.2.27:6379 has changed to READ_ONLY_DNS/X.X.1.13:6379 
Jul 18, 2021 @ 08:57:48.764 INFO redisson-netty-2-1 master READ_ONLY_DNS/X.X.1.13:6379 used as slave 
Jul 18, 2021 @ 08:57:48.764 INFO redisson-netty-2-1 24 connections initialized for READ_ONLY_DNS/X.X.1.13:6379 
Jul 18, 2021 @ 08:57:48.772 ERROR redisson-netty-2-1 Can't process the remote service request. 
Jul 18, 2021 @ 08:57:52.794 INFO redisson-netty-2-1 1 connections initialized for PRIMARY_DNS/X.X.1.13:6379 
Jul 18, 2021 @ 08:57:52.796 ERROR redisson-netty-2-1 Can't process the remote service request. 
Jul 18, 2021 @ 08:57:54.779 INFO redisson-netty-2-1 24 connections initialized for PRIMARY_DNS/X.X.1.13:6379 
Jul 18, 2021 @ 08:58:00.794 ERROR redisson-netty-2-1 Can't process the remote service request. 
Jul 18, 2021 @ 08:58:05.792 INFO redisson-netty-2-1 master PRIMARY_DNS/X.X.2.27:6379 used as slave 
Jul 18, 2021 @ 08:58:05.793 INFO redisson-netty-2-1 24 connections initialized for PRIMARY_DNS/X.X.2.27:6379 
Jul 18, 2021 @ 08:58:05.793 INFO redisson-netty-2-1 master READ_ONLY_DNS/X.X.1.13:6379 has changed to PRIMARY_DNS/X.X.2.27:6379 
Jul 18, 2021 @ 08:58:06.799 INFO redisson-netty-2-1 1 connections initialized for PRIMARY_DNS/X.X.1.13:6379 
Jul 18, 2021 @ 08:58:06.802 ERROR redisson-netty-2-1 Can't process the remote service request. 

Redisson config:
var config = new Config();
config.useReplicatedServers().addNodeAddress(props.getHosts().toArray(new String[0]));

var nodeConfig = new RedissonNodeConfig(config);
nodeConfig.setBeanFactory(factory);

var redissonClient = Redisson.create(config);
var node = RedissonNode.create(nodeConfig, redissonClient);
node.start();

return redissonClient;

Redisson version: 3.12
Redis version: 5.0.6
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3737
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
分布式锁，以redlock为例
客户端两台：客户端a，客户端b
客户端执行秒杀操作，直接操作redis，
1、首先客户端a，客户端b同时抢锁，
2、最终客户端a获取锁，然后执行业务处理（不需要网络）
3、这时客户端a 网络通信故障，致使客户端b获取到锁了，客户端b正常操作，修改状态数据（redis 数据）
4、之后接着客户端a网络正常了，也直接修改状态数据，（修正状态在lock 之后，但是显然此时客户端a处于无锁状态）
这样数据一致性不就没有保证了吗？
1、a.lock
2、业务逻辑
3、修正状态
4、a.unlock
走的第二步，第三步客户端处于无锁状态的，
一种想法1、后台watchdog 线程，检测到超时后阻塞业务线程 （但是好像没找到阻塞非当前线程的api)
另一种想法2、在unlock 时，假如redis 当前持锁线程非自己时，抛异常（貌似是这么处理的，不过，这样处理的话，那不是正确操作
应当捕获unlock 下的异常，然后对修改状态的操作做补偿了，也好像不太对）。
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3738
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is your feature request related to a problem? Please describe.
I am using RedissonMap to store ... a map! Sometimes I wish to check if a key is present in the map without having to actually get the value. Redis provides a command HEXISTS to do this, and I can see that in RedissonMap we leverage this command to implement containsKey efficiently.
However, sometimes I would like to check the presence of multiple keys in the map, sometimes many thousands. The naive solution to simple call containsKey ends up round-tripping to redis many times.
Describe the solution you'd like
I would like a batch method (maybe something like containsKeys) which indicates the presence or absence of many keys at once, without round-tripping to redis many times.
Describe alternatives you've considered
I can call getAll() and just look at which keys got returned, however this returns all the values as well, which I don't care about in my case and which consume additional network + memory resources.
I could bypass RedissonMap and simply issue a pipelined request for many HEXISTS, but this is extra complexity I have to handle myself and it bypasses the RMap abstraction.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3739
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I'm fairly new to Redis/Redisson and have a question about an issue that I have encountered during Redis maintenance (planned switchover I think).
My application is running on Azure against Azure Cache for Redis
The application is using Redisson pub/sub listeners but after Redis maintenance only 1 of many listeners re-subscribed and other listeners fail to deliver new messages that are being published.
I'm not sure if I should increase some retries-related configuration to avoid this problem or is more in-depth investigation (including redisson logs) required.
Example of successful re-subscription:
07/07/2021 23:44:50.636 [redisson-netty-2-8] INFO onUnsubscribe vrckc-req-b5da10e2f29cc6c9dd7632279444fc8f
(...)
07/07/2021 23:44:51.702 [redisson-3-4] INFO onSubscribe vrckc-req-b5da10e2f29cc6c9dd7632279444fc8f
Example of failure (extending of RLock lease time) that happens during maintenance
07/07/2021 23:44:54.503 [redisson-timer-4-1] ERROR org.redisson.RedissonBaseLock Can't update lock vrckc-leader expiration
org.redisson.client.WriteRedisConnectionException: Unable to write command into connection! Node source: NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=0, freeSubscribeConnectionsCounter=value:50:queue:0, freeConnectionsAmount=23, freeConnectionsCounter=value:63:queue:0, freezeReason=null, client=[addr=rediss://10.151.20.4:15000], nodeType=MASTER, firstFail=0]]], connection: RedisConnection@1994070121 [redisClient=[addr=rediss://10.151.20.4:15000], channel=[id: 0xeb6e5b0a, L:0.0.0.0/0.0.0.0:54958], currentCommand=null], command: null, params: null after 1 retry attempts
Redis config that I'm using:
redisConfig.yaml: |-
clusterServersConfig:
idleConnectionTimeout: 10000
connectTimeout: 15000
pingConnectionInterval: 5000
tcpNoDelay: true
keepAlive: true
timeout: 3000
retryAttempts: 3
retryInterval: 1500
failedSlaveReconnectionInterval: 3000
failedSlaveCheckInterval: 60000
password: ${REDIS_AZURE_PASSWORD}
subscriptionsPerConnection: 5
clientName: null
subscriptionConnectionMinimumIdleSize: 1
subscriptionConnectionPoolSize: 50
slaveConnectionMinimumIdleSize: 24
slaveConnectionPoolSize: 64
masterConnectionMinimumIdleSize: 24
masterConnectionPoolSize: 64
readMode: "MASTER"
subscriptionMode: "SLAVE"
nodeAddresses:
- "rediss://${REDIS_AZURE_HOSTNAME}:{{ .Values.redis.azure.sslPort }}"
threads: 16
nettyThreads: 16
codec: !<org.redisson.client.codec.StringCodec> {}
transportMode: "NIO"
I would appreciate any help with this issue.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3740
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
i can‘t find "RedissonClient.loadBucketValues()"  in version 3.16.0
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3741
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
RedissonClient.getList() currently is doing a count on the list and retrieving every item one by one. We have a dynamic list that increases with time so the response time of the app also increases linearly with as the time to fetch more of the list items get longer.
From AWS xray tracing:
Sample LINDEX query:

{
    "default": {
        "db.connection_string": "<redacted>:6379",
        "db.statement": "LINDEX <redacted> 1",
        "db.system": "redis",
        "thread.name": "<redacted>",
        "thread.id": ""
    }
}

We have 267 items in the list and the above repeats for all items in the list:

If there a way to get all list items in redisson with LRANGE instead?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3742
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3743
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We're using redisson pro and getting class cast exceptions. Our dependencies in maven look like:
<dependency>
    <groupId>pro.redisson</groupId>
    <artifactId>redisson-spring-boot-starter</artifactId>
    <version>3.16.0-5</version>
    <exclusions>
        <exclusion>
            <groupId>pro.redisson</groupId>
            <artifactId>redisson-spring-data-25</artifactId>
        </exclusion>
    </exclusions>
</dependency>
<dependency>
    <groupId>pro.redisson</groupId>
    <artifactId>redisson-spring-data-23</artifactId>
    <version>3.16.0-5</version>
</dependency>

The exceptions we're getting:
2021-07-24 10:05:51,341 [trace=,span=] ERROR ErrorsLoggingHandler:47   - Exception occured. Channel: [id: 0x32a400e8, L:/192.168.205.61:55165 ! R:xuqsfh-0015-001.xuqsfh.gnfyko.euw1.cache.amazonaws.com/10.223.14.197:6379]
java.lang.ClassCastException: class org.redisson.client.protocol.CommandsData cannot be cast to class org.redisson.client.protocol.CommandData (org.redisson.client.protocol.CommandsData and org.redisson.client.protocol.CommandData are in unnamed module of loader 'app')
	at org.redisson.client.handler.CommandsQueue.channelInactive(CommandsQueue.java:56)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at org.redisson.client.handler.ConnectionWatchdog.channelInactive(ConnectionWatchdog.java:93)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:389)
	at io.netty.handler.codec.ByteToMessageDecoder.channelInactive(ByteToMessageDecoder.java:354)
	at io.netty.handler.ssl.SslHandler.channelInactive(SslHandler.java:1121)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:819)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)

Does someone have an idea how to resolve this?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3744
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
it doesn't introduce overhead, since mget commands joined in a batch (single request) to Redis
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3745
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We are experiencing what at first glance seems like network related errors using the latest version of redisson pro. However we noticed that this error only occurs on LPOP commands.
2021-07-26 09:31:05,547 [trace=,span=] ERROR                    h:221  - Command still hasn't been written into connection! Try to increase nettyThreads setting. Payload size in bytes: 0. Node source: NodeSource [slot=4753, addr=null, redisClient=null, redirect=null, entry=null], connection: RedisConnection [entry=[commandsBatch=830, entry=[freeSubscribeConnectionsAmount=0, freeSubscribeConnectionsCounter=value:47:queue:0, freeConnectionsAmount=24, freeConnectionsCounter=value:64:queue:0, freezeReason=null, client=[addr=rediss://xfv.gnfyko.euw1.cache.amazonaws.com:6379], nodeType=MASTER, firstFail=0], commandsBatchSemaphore=value:0:queue:2, sendWorkers=0, connectionsAmount=2], redisClient=[addr=rediss://xfv.gnfyko.euw1.cache.amazonaws.com:6379]], command: (LPOP), params: [prv::V1.0::{playlist.collection}:write-behind-queue] after 3 retry attempts
org.redisson.client.RedisTimeoutException: Command still hasn't been written into connection! Try to increase nettyThreads setting. Payload size in bytes: 0. Node source: NodeSource [slot=4753, addr=null, redisClient=null, redirect=null, entry=null], connection: RedisConnection [entry=[commandsBatch=830, entry=[freeSubscribeConnectionsAmount=0, freeSubscribeConnectionsCounter=value:47:queue:0, freeConnectionsAmount=24, freeConnectionsCounter=value:64:queue:0, freezeReason=null, client=[addr=rediss://xfv.gnfyko.euw1.cache.amazonaws.com:6379], nodeType=MASTER, firstFail=0], commandsBatchSemaphore=value:0:queue:2, sendWorkers=0, connectionsAmount=2], redisClient=[addr=rediss://xfv.gnfyko.euw1.cache.amazonaws.com:6379]], command: (LPOP), params: [prv::V1.0::{playlist.collection}:write-behind-queue] after 3 retry attempts

Increasing netty threads has no effect on this, also increasing timeout config did not improve the errors.
Also when deploying our code (on a test environment without load) we see a heavy increase in cpu usage on redis master nodes. The load increases by 50% and drops very slowly in about 1 hour to <5%
We are using the RedissonClusteredSpringLocalCachedCacheManager (but the same occurs when using RedissonClusteredSpringCacheManager)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3746
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We have 2 application servers (Tomcats) and our application is not sticky which mean that every request can reach different application server.
In our flow we upload data from one server to Redis and then read data from the second server but don't get the uploaded data.
Can the reason for this behavior can be related to local cache implementation in Redisson? Can we disable it per put request or only disable it for all Redisson client requests?
we use to get the data
RMapCache<String, Object> map = redisson.getMapCache
and to put data
map.fastPutAsync(key, value, units, timeUnit);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3747
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
After upgrading to redisson 3.16.1 there are build failures of native quarkus, the stracktrace points to netty. as far as i can see there was a minor version upgrade of netty in the last release, so maybe this is the reason, in 3.16.0 everything works fine.
Quarkus Version: 2.0.3 Final
Error: Classes that should be initialized at run time got initialized during image building: io.netty.buffer.ByteBufUtil the class was requested to be initialized at run time (from jar:file:///project/lib/io.netty.netty-buffer-4.1.65.Final.jar!/META-INF/native-image/io.netty/buffer/native-image.properties and from feature io.quarkus.runner.AutoFeature.beforeAnalysis). To see why io.netty.buffer.ByteBufUtil got initialized use --trace-class-initialization=io.netty.buffer.ByteBufUtil io.netty.buffer.PooledByteBufAllocator the class was requested to be initialized at run time (from jar:file:///project/lib/io.netty.netty-buffer-4.1.65.Final.jar!/META-INF/native-image/io.netty/buffer/native-image.properties and from feature io.quarkus.runner.AutoFeature.beforeAnalysis). To see why io.netty.buffer.PooledByteBufAllocator got initialized use --trace-class-initialization=io.netty.buffer.PooledByteBufAllocator io.netty.buffer.ByteBufAllocator the class was requested to be initialized at run time (from jar:file:///project/lib/io.netty.netty-buffer-4.1.65.Final.jar!/META-INF/native-image/io.netty/buffer/native-image.properties and from feature io.quarkus.runner.AutoFeature.beforeAnalysis). To see why io.netty.buffer.ByteBufAllocator got initialized use --trace-class-initialization=io.netty.buffer.ByteBufAllocator io.netty.buffer.AbstractReferenceCountedByteBuf the class was requested to be initialized at run time (from jar:file:///project/lib/io.netty.netty-buffer-4.1.65.Final.jar!/META-INF/native-image/io.netty/buffer/native-image.properties). To see why io.netty.buffer.AbstractReferenceCountedByteBuf got initialized use --trace-class-initialization=io.netty.buffer.AbstractReferenceCountedByteBuf com.oracle.svm.core.util.UserError$UserException: Classes that should be initialized at run time got initialized during image building: io.netty.buffer.ByteBufUtil the class was requested to be initialized at run time (from jar:file:///project/lib/io.netty.netty-buffer-4.1.65.Final.jar!/META-INF/native-image/io.netty/buffer/native-image.properties and from feature io.quarkus.runner.AutoFeature.beforeAnalysis). To see why io.netty.buffer.ByteBufUtil got initialized use --trace-class-initialization=io.netty.buffer.ByteBufUtil io.netty.buffer.PooledByteBufAllocator the class was requested to be initialized at run time (from jar:file:///project/lib/io.netty.netty-buffer-4.1.65.Final.jar!/META-INF/native-image/io.netty/buffer/native-image.properties and from feature io.quarkus.runner.AutoFeature.beforeAnalysis). To see why io.netty.buffer.PooledByteBufAllocator got initialized use --trace-class-initialization=io.netty.buffer.PooledByteBufAllocator io.netty.buffer.ByteBufAllocator the class was requested to be initialized at run time (from jar:file:///project/lib/io.netty.netty-buffer-4.1.65.Final.jar!/META-INF/native-image/io.netty/buffer/native-image.properties and from feature io.quarkus.runner.AutoFeature.beforeAnalysis). To see why io.netty.buffer.ByteBufAllocator got initialized use --trace-class-initialization=io.netty.buffer.ByteBufAllocator io.netty.buffer.AbstractReferenceCountedByteBuf the class was requested to be initialized at run time (from jar:file:///project/lib/io.netty.netty-buffer-4.1.65.Final.jar!/META-INF/native-image/io.netty/buffer/native-image.properties). To see why io.netty.buffer.AbstractReferenceCountedByteBuf got initialized use --trace-class-initialization=io.netty.buffer.AbstractReferenceCountedByteBuf at com.oracle.svm.core.util.UserError.abort(UserError.java:68) at com.oracle.svm.hosted.classinitialization.ConfigurableClassInitialization.checkDelayedInitialization(ConfigurableClassInitialization.java:545) at com.oracle.svm.hosted.classinitialization.ClassInitializationFeature.duringAnalysis(ClassInitializationFeature.java:228) at com.oracle.svm.hosted.NativeImageGenerator.lambda$runPointsToAnalysis$14(NativeImageGenerator.java:765) at com.oracle.svm.hosted.FeatureHandler.forEachFeature(FeatureHandler.java:71) at com.oracle.svm.hosted.NativeImageGenerator.runPointsToAnalysis(NativeImageGenerator.java:765) at com.oracle.svm.hosted.NativeImageGenerator.doRun(NativeImageGenerator.java:582) at com.oracle.svm.hosted.NativeImageGenerator.lambda$run$2(NativeImageGenerator.java:495) at java.base/java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1407) at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290) at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020) at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656) at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594) at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183) Error: Image build request failed with exit status 1
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3748
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi.
After adding sslProtocols option to redisson.yaml file I get error below:
redisson version: 3.16.1 for tomcat 8
After removing sslProtocols line no errors reported in tomcat console
28-Jul-2021 14:43:15.259 SEVERE [main] org.apache.catalina.mbeans.GlobalResourcesLifecycleListener.createMBeans Exception processing Global JNDI Resources javax.naming.NamingException: Can't parse yaml config conf/redisson.yaml [Root exception is com.fasterxml.jackson.core.JsonParseException: Unexpected character ('-' (code 45)) in numeric value: expected digit (0-9) to follow minus sign, for valid numeric value at [Source: (String)"--- singleServerConfig: idleConnectionTimeout: 10000 connectTimeout: 10000 timeout: 3000 retryAttempts: 3 retryInterval: 1500 password: P@ssword subscriptionsPerConnection: 5 clientName: "Client" address: "rediss://redis.local:6379" subscriptionConnectionMinimumIdleSize: 1 subscriptionConnectionPoolSize: 50 connectionMinimumIdleSize: 24 connectionPoolSize: 64 database: 1 dnsMonitoringInterval: 5000 sslProvider: OPENSSL sslProtocols: TLSv1.2 thread"[truncated 95 chars]; line: 1, column: 3]] at org.redisson.JndiRedissonFactory.buildClient(JndiRedissonFactory.java:57) at org.redisson.JndiRedissonFactory.getObjectInstance(JndiRedissonFactory.java:45) at org.apache.naming.factory.FactoryBase.getObjectInstance(FactoryBase.java:96) at javax.naming.spi.NamingManager.getObjectInstance(NamingManager.java:321) at org.apache.naming.NamingContext.lookup(NamingContext.java:847) at org.apache.naming.NamingContext.lookup(NamingContext.java:157) at org.apache.naming.NamingContextBindingsEnumeration.nextElementInternal(NamingContextBindingsEnumeration.java:115) at org.apache.naming.NamingContextBindingsEnumeration.next(NamingContextBindingsEnumeration.java:69) at org.apache.naming.NamingContextBindingsEnumeration.next(NamingContextBindingsEnumeration.java:32) at org.apache.catalina.mbeans.GlobalResourcesLifecycleListener.createMBeans(GlobalResourcesLifecycleListener.java:131) at org.apache.catalina.mbeans.GlobalResourcesLifecycleListener.createMBeans(GlobalResourcesLifecycleListener.java:138) at org.apache.catalina.mbeans.GlobalResourcesLifecycleListener.createMBeans(GlobalResourcesLifecycleListener.java:105) at org.apache.catalina.mbeans.GlobalResourcesLifecycleListener.lifecycleEvent(GlobalResourcesLifecycleListener.java:80) at org.apache.catalina.util.LifecycleBase.fireLifecycleEvent(LifecycleBase.java:123) at org.apache.catalina.util.LifecycleBase.setStateInternal(LifecycleBase.java:423) at org.apache.catalina.util.LifecycleBase.setState(LifecycleBase.java:366) at org.apache.catalina.core.StandardServer.startInternal(StandardServer.java:763) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) at org.apache.catalina.startup.Catalina.start(Catalina.java:688) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.catalina.startup.Bootstrap.start(Bootstrap.java:345) at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:476)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3749
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In our setup, we have sharded mode cluster consisting of 6 shares, 2 nodes per shard.
Our redisson client interacts with only the MASTER node in each shard.
Recently we experienced the following exception: "org.redisson.client.RedisLoadingException: LOADING Redis is loading the dataset in memory". Following that exception, we had been getting RedisTimeoutException on majority of the calls until we finally restarted our application services and the problems went away.
Any clue as to what might be the cause of this? I am suspecting this is a problem with the redisson client itself.
Redisson version: 3.11.6-3
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3750
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have the following test scenario:
  redis:
    image: redis
    ports:
      - "6379:6379"

@Configuration
class RedissonConfig {
    @Bean
    fun redissonClient(): RedissonClient {
        val config = Config()
        config
            .useSingleServer()
            .address = "redis://localhost:6379"

        return Redisson.create(config)
    }

    @Bean
    fun redissonReactiveClient(redissonClient: RedissonClient): RedissonReactiveClient {
        return redissonClient.reactive()
    }
}

@Component
class X(
    private val redisson: RedissonReactiveClient,
    private val curatorClient: CuratorFramework,
    ...
) {

    companion object {
        private val log = LoggerFactory.getLogger(X::class.java)
        private const val jobName = "X"
    }

    @PostConstruct
    fun x() = runBlocking {
        (1..1000)
            .map { i ->
                async(Dispatchers.IO) {
                    runWithRedis(i)
                }
            }
            .awaitAll()
    }

    suspend fun runWithRedis(i: Int) = coroutineScope {
        val currentTimeMillis = System.currentTimeMillis()
        val wasLockAcquired = redisson
            .getLock("the-lock-name")
            .tryLock(1, 30, TimeUnit.SECONDS)
            .awaitSingle()

        if (wasLockAcquired.not()) {
            log.info(
                "Job {}: Failed to acquire lock. Possible reason: another instance job might have already acquired the lock for this job type. Terminating job.",
                jobName
            )
            return@coroutineScope
        }

        log.info("Job {}: Lock acquired ${System.currentTimeMillis() - currentTimeMillis}", jobName)

        ...
    }

My expectation is the following: if the lock couldn't be acquired in 1s  then it should show Failed to acquire lock. If the lock is acquired then, in 30s, it should be automatically released by Redis (this 30s are very important as I only need to allow another run after this time). Only one should should be acquired in 30s. The problem is that most of the times I get multiple Lock acquired between 30s intervals.
2021-07-30 10:24:53.277  INFO 7960 --- [tcher-worker-65] i.m.r.s.job.x: Job X: Lock acquired 149
2021-07-30 10:24:53.317  INFO 7960 --- [tcher-worker-66] i.m.r.s.job.x: Job X: Lock acquired 93
2021-07-30 10:24:53.359  INFO 7960 --- [tcher-worker-35] i.m.r.s.job.x: Job X: Lock acquired 126
2021-07-30 10:24:53.396  INFO 7960 --- [tcher-worker-22] i.m.r.s.job.x: Job X: Lock acquired 140
2021-07-30 10:24:54.229  INFO 7960 --- [tcher-worker-66] i.m.r.s.job.X: Job X: Failed to acquire lock. Possible reason: another instance job might have already acquired the lock for this job type. Terminating job.
2021-07-30 10:24:54.229  INFO 7960 --- [tcher-worker-22] i.m.r.s.job.X: Job X: Failed to acquire lock. Possible reason: another instance job might have already acquired the lock for this job type. Terminating job.
2021-07-30 10:24:54.229  INFO 7960 --- [tcher-worker-50] i.m.r.s.job.X: Job X: Failed to acquire lock. Possible reason: another instance job might have already acquired the lock for this job type. Terminating job.
...

The code launches 1000 parallel execution tasks. Since Redis is (mostly) single threaded then I wasn't expecting any concurrency problems (and I'm pretty sure they aren't on the Redis side). I am also using a single node Redis.
I have also tried another solution using Zookeeper Leader Election and that one works as expected using the same caller function. It acquired a single lock at a time.
Am I doing something wrong here are we having a Redisson issue?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3751
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
version: redisson-3.13.2
add code:

consumer code:

add success, but Occasionally, data is not consumed .
There is no recurrence problem in the local stress test, but it occurs occasionally in the production environment
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3752
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
version:
redisson-3.14.1
When try to using both multiLock and Lock with same key
There are different effects according to the lock order
code like
        String key1 = "key1";
        String key2 = "key2";
        
        RLock lock1 = client.getLock(key1);
        lock.lock();
        // do sth.
        lock.unlock();

        String key1 = "key1";
        String key2 = "key2";
        List<String> keys = new ArrayList<>();
        keys.add(key1);
        keys.add(key2);
        List<RLock> rLocks = new ArrayList<>();
        for (String key : keys) {
            RLock lock = client.getLock(key);
            rLocks.add(lock);
        }
        RedissonMultiLock multiLock1 = new RedissonMultiLock(rLocks);
        multiLock1.lock();
        // do sth.
        multiLock1,unlock();

When lock lock1 first ,then lock multiLock1
multiLock1 stun for a few seconds and then, lock success(lock1 are not released)
When lock multiLock1 first ,then lock lock1
lock1 are stoped and waitting for the multiLock to release
it's confused
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3753
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3754
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Will it be an incompatible version when I upgrade from 3.11.x to 3.15.x?
Is there any reason or guideline for the version value?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3755
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I'm really confused as to why I got this error, and I might have misunderstood how topics work with objects in Java.
So basically when doing RedissonClient#getTopic(nameOfTheTopic).publish(objectToPublish), I'm getting this NotSerializableException.
The object I'm trying to send is this class:
import java.time.LocalDate;

public class ClassToPublish {

    private final String command;
    private final LocalDate date;

    public ClassToPublish(String command, LocalDate date) {
        this.command = command;
        this.date = date;
    }

    public String getCommand() {
        return command;
    }

    public LocalDate getDate() {
        return date;
    }

}
Can't you send classes other than the ones from the JRE or am I missing something that I need to do in order to be able to do so?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3756
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
this is my code :
`
String key = REDISSON_RATE_LIMIT + limit.prefix() + ":" +spel;
RRateLimiter rRateLimiter = redissonClient.getRateLimiter(key);
rRateLimiter.trySetRate(RateType.OVERALL, limit.rate(), limit.rateInterval(), limit.unit());
        if (limit.expireSecond() !=-1) {
            rRateLimiter.expire(limit.expireSecond(), TimeUnit.SECONDS);
        }

@RedissonRateLimit(prefix = "trade", spel = "#trade.rootMchId",
rate = 1, rateInterval = 2, unit = RateIntervalUnit.SECONDS, expireSecond = 5)
@PostMapping("/trade")
public ResponseEntity trade(@requestbody Trade trade) {
return ResponseEntity.ok("success");
}
`
then I fund a bug ：
5 seconds have passed， the  redis key “redisson_rate_limit:trade:rootMchId0001” has removed，but the redis key
"{redisson_rate_limit:trade:rootMchId0001}:permits" and “{redisson_rate_limit:trade:rootMchId0001}:value ”  still exist.
Who knows you can help me？please...
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3757
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
CommandEncoder throw NullPointerException all config is default
Redis version 5.x
Redisson version 3.16.1
WARN  i.n.c.AbstractChannelHandlerContext -Failed to mark a promise as failure because it has failed already: DefaultChannelPromise@731b15d2(failure: io.netty.handler.codec.EncoderException: java.lang.NullPointerException), unnotified cause: io.netty.handler.codec.EncoderException: java.lang.NullPointerException
at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
at org.redisson.client.handler.CommandEncoder.write(CommandEncoder.java:75)
at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)
at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:709)
at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:792)
at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:702)
at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:120)
at org.redisson.client.handler.CommandBatchEncoder.write(CommandBatchEncoder.java:45)
at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)
at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)
at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:790)
at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:758)
at org.redisson.client.handler.CommandsQueue.write(CommandsQueue.java:82)
at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)
at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)
at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)
at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)
at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NullPointerException
at org.redisson.client.handler.CommandEncoder.encode(CommandEncoder.java:130)
at org.redisson.client.handler.CommandEncoder.encode(CommandEncoder.java:99)
at org.redisson.client.handler.CommandEncoder.encode(CommandEncoder.java:55)
at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
... 22 more
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
at org.redisson.client.handler.CommandEncoder.write(CommandEncoder.java:75)
at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)
at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:709)
at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:792)
at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:702)
at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:120)
at org.redisson.client.handler.CommandBatchEncoder.write(CommandBatchEncoder.java:45)
at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)
at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)
at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:790)
at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:758)
at org.redisson.client.handler.CommandsQueue.write(CommandsQueue.java:82)
at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)
at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)
at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)
at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)
at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NullPointerException: null
at org.redisson.client.handler.CommandEncoder.encode(CommandEncoder.java:130)
at org.redisson.client.handler.CommandEncoder.encode(CommandEncoder.java:99)
at org.redisson.client.handler.CommandEncoder.encode(CommandEncoder.java:55)
at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
... 22 common frames omitted
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3758
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello, first time using redisson. I have a very basic setup with redisson 3.16.1 running on jdk 16.
Trying to use redis for a simple cache: RMap<UUID, String> uuidCache;
The setup is just like the basic examplte from the README.
But when launching the app, this exception is printed and redis doesn't seem to work.
 [15:30:37 ERROR] [org.redisson.client.handler.ErrorsLoggingHandler]: Exception occured. Channel: [id: 0x8a9de85b, L:/127.0.0.1:53284 - R:127.0.0.1/127.0.0.1:6379]
[03.08 15:30:38.240] INFO: [Proxy-2] java.lang.ExceptionInInitializerError: null
[03.08 15:30:38.240] INFO: [Proxy-2]    at org.jboss.marshalling.river.RiverUnmarshaller.doReadClassDescriptor(RiverUnmarshaller.java:1321) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at org.jboss.marshalling.river.RiverUnmarshaller.doReadClassDescriptor(RiverUnmarshaller.java:1064) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at org.jboss.marshalling.river.RiverUnmarshaller.doReadNewObject(RiverUnmarshaller.java:1381) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at org.jboss.marshalling.river.RiverUnmarshaller.doReadObject(RiverUnmarshaller.java:298) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at org.jboss.marshalling.river.RiverUnmarshaller.doReadObject(RiverUnmarshaller.java:231) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at org.jboss.marshalling.AbstractObjectInput.readObject(AbstractObjectInput.java:41) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at org.redisson.codec.MarshallingCodec.lambda$new$0(MarshallingCodec.java:146) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:366) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:183) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:122) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:107) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:507) ~[waterfall.jar:git:Waterfall-Bootstrap:1.17-R0.1-SNAPSHOT:93773f9:448]
[03.08 15:30:38.240] INFO: [Proxy-2]    at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) ~[waterfall.jar:git:Waterfall-Bootstrap:1.17-R0.1-SNAPSHOT:93773f9:448]
[03.08 15:30:38.240] INFO: [Proxy-2]    at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276) ~[waterfall.jar:git:Waterfall-Bootstrap:1.17-R0.1-SNAPSHOT:93773f9:448]
[03.08 15:30:38.240] INFO: [Proxy-2]    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[waterfall.jar:git:Waterfall-Bootstrap:1.17-R0.1-SNAPSHOT:93773f9:448]
[03.08 15:30:38.240] INFO: [Proxy-2]    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[waterfall.jar:git:Waterfall-Bootstrap:1.17-R0.1-SNAPSHOT:93773f9:448]
[03.08 15:30:38.240] INFO: [Proxy-2]    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[waterfall.jar:git:Waterfall-Bootstrap:1.17-R0.1-SNAPSHOT:93773f9:448]
[03.08 15:30:38.240] INFO: [Proxy-2]    at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[waterfall.jar:git:Waterfall-Bootstrap:1.17-R0.1-SNAPSHOT:93773f9:448]
[03.08 15:30:38.240] INFO: [Proxy-2]    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[waterfall.jar:git:Waterfall-Bootstrap:1.17-R0.1-SNAPSHOT:93773f9:448]
[03.08 15:30:38.240] INFO: [Proxy-2]    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[waterfall.jar:git:Waterfall-Bootstrap:1.17-R0.1-SNAPSHOT:93773f9:448]
[03.08 15:30:38.240] INFO: [Proxy-2]    at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[waterfall.jar:git:Waterfall-Bootstrap:1.17-R0.1-SNAPSHOT:93773f9:448]
[03.08 15:30:38.240] INFO: [Proxy-2]    at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) ~[waterfall.jar:git:Waterfall-Bootstrap:1.17-R0.1-SNAPSHOT:93773f9:448]
[03.08 15:30:38.240] INFO: [Proxy-2]    at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) ~[waterfall.jar:git:Waterfall-Bootstrap:1.17-R0.1-SNAPSHOT:93773f9:448]
[03.08 15:30:38.240] INFO: [Proxy-2]    at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) ~[waterfall.jar:git:Waterfall-Bootstrap:1.17-R0.1-SNAPSHOT:93773f9:448]
[03.08 15:30:38.240] INFO: [Proxy-2]    at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) ~[waterfall.jar:git:Waterfall-Bootstrap:1.17-R0.1-SNAPSHOT:93773f9:448]
[03.08 15:30:38.240] INFO: [Proxy-2]    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[waterfall.jar:git:Waterfall-Bootstrap:1.17-R0.1-SNAPSHOT:93773f9:448]
[03.08 15:30:38.240] INFO: [Proxy-2]    at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[waterfall.jar:git:Waterfall-Bootstrap:1.17-R0.1-SNAPSHOT:93773f9:448]
[03.08 15:30:38.240] INFO: [Proxy-2]    at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[waterfall.jar:git:Waterfall-Bootstrap:1.17-R0.1-SNAPSHOT:93773f9:448]
[03.08 15:30:38.240] INFO: [Proxy-2]    at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[waterfall.jar:git:Waterfall-Bootstrap:1.17-R0.1-SNAPSHOT:93773f9:448]
[03.08 15:30:38.240] INFO: [Proxy-2]    at java.lang.Thread.run(Thread.java:831) [?:?]
[03.08 15:30:38.240] INFO: [Proxy-2] Caused by: java.lang.reflect.InaccessibleObjectException: Unable to make protected java.util.AbstractMap() accessible: module java.base does not "opens java.util" to unnamed module @53b75da5
[03.08 15:30:38.240] INFO: [Proxy-2]    at java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:357) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:297) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at java.lang.reflect.Constructor.checkCanSetAccessible(Constructor.java:188) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at java.lang.reflect.Constructor.setAccessible(Constructor.java:181) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at org.jboss.marshalling.reflect.JDKSpecific$SerMethods.<init>(JDKSpecific.java:147) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at org.jboss.marshalling.reflect.SerializableClass.<init>(SerializableClass.java:84) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at org.jboss.marshalling.reflect.SerializableClassRegistry$1.computeValue(SerializableClassRegistry.java:62) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at org.jboss.marshalling.reflect.SerializableClassRegistry$1.computeValue(SerializableClassRegistry.java:59) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at java.lang.ClassValue.getFromHashMap(ClassValue.java:228) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at java.lang.ClassValue.getFromBackup(ClassValue.java:210) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at java.lang.ClassValue.get(ClassValue.java:116) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at org.jboss.marshalling.reflect.SerializableClassRegistry.lookup(SerializableClassRegistry.java:83) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at org.jboss.marshalling.reflect.SerializableClass.<init>(SerializableClass.java:76) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at org.jboss.marshalling.reflect.SerializableClassRegistry$1.computeValue(SerializableClassRegistry.java:62) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at org.jboss.marshalling.reflect.SerializableClassRegistry$1.computeValue(SerializableClassRegistry.java:59) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at java.lang.ClassValue.getFromHashMap(ClassValue.java:228) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at java.lang.ClassValue.getFromBackup(ClassValue.java:210) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at java.lang.ClassValue.get(ClassValue.java:116) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at org.jboss.marshalling.reflect.SerializableClassRegistry.lookup(SerializableClassRegistry.java:83) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at org.jboss.marshalling.river.ClassDescriptors.getSerializableClassDescriptor(ClassDescriptors.java:152) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at org.jboss.marshalling.river.ClassDescriptors.getSerializableClassDescriptor(ClassDescriptors.java:146) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    at org.jboss.marshalling.river.ClassDescriptors.<clinit>(ClassDescriptors.java:101) ~[?:?]
[03.08 15:30:38.240] INFO: [Proxy-2]    ... 30 more

Is this a knows issue?
Thanks for help.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3759
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@mrniko
This is a feature request.
Currently Spring supports only Kafka and RabbitMQ for cloud stream applications. There is no support for Redis Stream.
https://github.com/spring-cloud/spring-cloud-stream#binder-implementations
I think Redisson could implement this interface and provide redis binder via redisson.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3760
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3761
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RedissonMapCache#addListener is trying to detect OS type by executing INFO command, which is considered dangerous by Redis (part of its dangerous ACL list).
This causes exception:
NOPERM this user has no permissions to run the 'info' command or its subcommand
As a workaround, user can be granted an access to this command.
But, there should be a way to avoid INFO command at all (for example, by allowing to specify RedissonMapCache#osType explicitly along with adding something like BaseEventCodec.OSType#NONE).
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3762
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redis version
5.0.0
Redisson version
3.11.6 / 3.16.1
Redisson configuration
threads: 16
nettThreads: 64
scanInterval: 5000
retryAttempts: 0
timeout: 5000
Hi, I'm facing an issue when testing failover on AWS Elaticache
I'm using Redis Cluster with 2 slots, each slot contains 1 master and 1 slave.
It takes about 8 minutes after I trigger a failover event and the Redis works well but my services seem cannot recover by themselves.
I dump a thread capture and may get some useful information:

I'm using jetty as our web container and the operation I'm using with Redisson is quite simple - this.redissonClient.getBucket()
The reason why the service cannot recover is that threads are blocked in JVM, I can see 900 qtp* in JVM and their states look like this:

"qtp821513849-296" #296 prio=5 os_prio=0 tid=0x00007fe8f78eb800 nid=0x164 in Object.wait() [0x00007fe8b03b7000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:252)
	- locked <0x000000069ca55c50> (a io.netty.util.concurrent.ImmediateEventExecutor$ImmediatePromise)
	at org.redisson.misc.RedissonPromise.await(RedissonPromise.java:110)
	at org.redisson.misc.RedissonPromise.await(RedissonPromise.java:35)
	at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:142)
	at org.redisson.RedissonObject.get(RedissonObject.java:90)
	at org.redisson.RedissonBucket.get(RedissonBucket.java:97)
...


And the redisson-netty-* threads are all in epollWait

"redisson-netty-2-64" #1114 prio=5 os_prio=0 tid=0x00007fe8d5130000 nid=0x496 runnable [0x00007fe84e3b4000]
   java.lang.Thread.State: RUNNABLE
	at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
	at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
	at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
	- locked <0x0000000691506e68> (a io.netty.channel.nio.SelectedSelectionKeySet)
	- locked <0x0000000691506e58> (a java.util.Collections$UnmodifiableSet)
	- locked <0x0000000691506e10> (a sun.nio.ch.EPollSelectorImpl)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
	at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
	at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:824)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
	at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1044)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)

From my understanding, when the web requests try to get data from Redis Cluster, one of the nodes takes the task asynchronously then callback to the service by Netty epoll. So when the master failover, the tasks on this node cannot answer anymore, which makes those qtp* threads cannot finish.
I'm wondering if my guess is correct and how I can solve this issue, like giving a timeout for web requests or returning exceptions from Redisson side?
Although failover is not a common case, it still hurts a lot when my service cannot recover automatically.
Expecting for your response, thanks a lot.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3763
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have integrated redisson in tomcat as specified in doc. My application is built in spring framework and running on tomcat server 8.5. I am currently running 3 replicas of application in my kubernetes cluster where redis is also installed.
My tomcat context.xml is as follows:
<?xml version='1.0' encoding='utf-8'?>
<!--
  Licensed to the Apache Software Foundation (ASF) under one or more
  contributor license agreements.  See the NOTICE file distributed with
  this work for additional information regarding copyright ownership.
  The ASF licenses this file to You under the Apache License, Version 2.0
  (the "License"); you may not use this file except in compliance with
  the License.  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!-- The contents of this file will be loaded for each web application -->
<Context>


    <!-- Default set of monitored resources. If one of these changes, the    -->
    <!-- web application will be reloaded.                                   -->
    <WatchedResource>WEB-INF/web.xml</WatchedResource>
    <WatchedResource>${catalina.base}/conf/web.xml</WatchedResource>
    <Manager className="org.redisson.tomcat.RedissonSessionManager" configPath="${catalina.base}/conf/redisson.yaml" readMode="REDIS" updateMode="DEFAULT" />
    <!-- Uncomment this to disable session persistence across Tomcat restarts -->
    <!--
    <Manager pathname="" />
    -->

    <!-- Uncomment this to enable Comet connection tacking (provides events
         on session expiration as well as webapp lifecycle) -->
    <!--
    <Valve className="org.apache.catalina.valves.CometConnectionManagerValve" />
    -->

</Context>

My Redisson.yaml is as follows:
masterSlaveServersConfig:
  password: 'password'
  readMode: "MASTER_SLAVE"
  subscriptionMode: "SLAVE"
  slaveAddresses:
  - "redis://redis-replicas:6379"
  masterAddress: "redis://redis-master:6379"


But when my application starts and try to login i see following exception in my serer:
org.hibernate.LazyInitializationException: failed to lazily initialize a collection of role: com.model.users.roles, could not initialize proxy - no Session
        at org.hibernate.collection.internal.AbstractPersistentCollection.throwLazyInitializationException(AbstractPersistentCollection.java:582)
        at org.hibernate.collection.internal.AbstractPersistentCollection.withTemporarySessionIfNeeded(AbstractPersistentCollection.java:201)
        at org.hibernate.collection.internal.AbstractPersistentCollection.initialize(AbstractPersistentCollection.java:561)
        at org.hibernate.collection.internal.AbstractPersistentCollection.read(AbstractPersistentCollection.java:132)
        at org.hibernate.collection.internal.PersistentSet.iterator(PersistentSet.java:163)
        at com.code.controller.ApplicationController.home(ApplicationController.java:56)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209)
        at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136)
        at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)
        at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:871)
        at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:777)
        at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
        at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991)
        at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925)
        at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:978)
        at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:870)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:655)
        at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:855)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:764)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:232)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:167)
        at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:194)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:167)
        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317)
        at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127)
        at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91)
        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)
        at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114)
        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)
        at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137)
        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)
        at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111)
        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)
        at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170)
        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)
        at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)
        at org.springframework.security.web.session.ConcurrentSessionFilter.doFilter(ConcurrentSessionFilter.java:155)
        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)
        at org.springframework.security.web.authentication.AbstractAuthenticationProcessingFilter.doFilter(AbstractAuthenticationProcessingFilter.java:200)
        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)
        at com.code.util.URLFilter.doFilter(URLFilter.java:82)
        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)
        at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116)
        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)
        at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:64)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)
        at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105)
        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)
        at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)
        at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214)
        at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177)
        at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357)
        at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:194)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:167)
        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)
        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
        at org.redisson.tomcat.UsageValve.invoke(UsageValve.java:71)
        at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:544)
        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143)
        at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
        at org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:698)
        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:364)
        at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:624)
        at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
        at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:831)
        at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1651)
        at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
        at java.lang.Thread.run(Thread.java:748)

In redis ii see session keys in redisson/tomcat_sessions and they keep on growing when i refresh the page so it seems like its creating new session ion each refresh and not validating existing one
Can you tell me what's need to be changed here ?
Also there are no log statements printed by redisson can you also tell me how to enable debug logs for it ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3764
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
spring.redis.url=redis://mypassword@localhost:6379
Hope that the redisson-spring-boot-starter can support the above spring boot setting. Thanks!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3765
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I can set max size, eviction algorithm etc. using LocalCachedMapOptions, but it's unclear from the documentation if those options also apply to the backing RMap. Given that RLocalCachedMap does not subclass RMapCache, I'm guessing no, but would like to hear from a maintainer.
You can use this ticket for improving the documentation in this respect.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3766
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is your feature request related to a problem? Please describe.
I'd like to see metrics for low level Redis operations, like GET, SET etc.
Describe the solution you'd like
Expose metrics around these operations. The only available metrics is for RedissonCache, and there is no visibility into any of the other data structures.
As a less desirable solution, you may consider providing interceptors for a client to implement and export their own metrics.
Describe alternatives you've considered
None
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3767
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is your feature request related to a problem? Please describe.
RedissonReactiveClient is missing many of the features compared to  RedissonClient.

Returned RMapReactive has no methods to set max size or eviction algorithm.
No method to create a LocalCachedMap (or perhaps) LocalCachedMapReactive. There's an open issue #3671 for this point only.

Describe the solution you'd like
Bring feature parity between blocking and reactive API.
Describe alternatives you've considered
Using blocking API.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3768
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
So i have set up redis as read-through/write-behind cache for a mongoDB. Now there is data i want to persist when the application stops.
Writing into the cache isnt enough as the MapWriter that writes from redis into mongodb is run by the same application.
If i stop the application and write my data into the cache then my MapWriter wants to wait some seconds to batch write the data from cache into db.
But at this time the application is already stopped and nothing will be persisted.
Is there some way to flush the write-behind tasks in a blocking fashion?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3769
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3770
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you for proposed changes.
According to your descriptions, it covers 7 tasks. Please split it into PR per task.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3771
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We tried to update underlying node type in our Elasticache Redis cluster. When AWS starts switching to newly created nodes, we see a lot of exception:
org.redisson.client.RedisException: MOVED redirection loop detected. Node redis://<node_address>:6379 has further redirect to redis://<same_node_address>:6379
	at org.redisson.command.RedisExecutor.checkAttemptPromise(RedisExecutor.java:404) ~[redisson-3.13.5.jar:3.13.5]
	at org.redisson.command.RedisExecutor.lambda$execute$3(RedisExecutor.java:164) ~[redisson-3.13.5.jar:3.13.5]
	at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:183) ~[redisson-3.13.5.jar:3.13.5]
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:500) ~[netty-common-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:493) ~[netty-common-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:472) ~[netty-common-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:413) ~[netty-common-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:538) ~[netty-common-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:531) ~[netty-common-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:111) ~[netty-common-4.1.38.Final.jar:4.1.38.Final]
	at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:96) ~[redisson-3.13.5.jar:3.13.5]
	at org.redisson.client.protocol.CommandData.tryFailure(CommandData.java:78) ~[redisson-3.13.5.jar:3.13.5]
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:339) ~[redisson-3.13.5.jar:3.13.5]
	at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:196) ~[redisson-3.13.5.jar:3.13.5]
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:134) ~[redisson-3.13.5.jar:3.13.5]
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:104) ~[redisson-3.13.5.jar:3.13.5]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:505) ~[netty-codec-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) ~[netty-codec-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:283) ~[netty-codec-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374) ~[netty-transport-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360) ~[netty-transport-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352) ~[netty-transport-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1475) ~[netty-handler-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1224) ~[netty-handler-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1271) ~[netty-handler-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:505) ~[netty-codec-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:444) ~[netty-codec-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:283) ~[netty-codec-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374) ~[netty-transport-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360) ~[netty-transport-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352) ~[netty-transport-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1421) ~[netty-transport-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374) ~[netty-transport-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360) ~[netty-transport-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930) ~[netty-transport-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) ~[netty-transport-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:697) ~[netty-transport-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632) ~[netty-transport-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549) ~[netty-transport-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511) ~[netty-transport-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918) ~[netty-common-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.38.Final.jar:4.1.38.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.38.Final.jar:4.1.38.Final]
	at java.lang.Thread.run(Thread.java:829) [?:?]

Is it possible to scale Redis cluster vertically on the fly using Redisson?
Engine Version Compatibility: 6.0.5
Redisson version: 3.13.5, also tried 3.16.1
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3772
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
minor
since there is no way to pull request the wiki:
in the configuration section
"All property names matches" should be "All property names match" (not plural)
👆 6 places in a document that "match". no pun intended :)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3773
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3774
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Quarkus Redisson should work in native mode with this reproducer.
Actual behavior
The static analysis fails with a message like:
Error: Unsupported features in 3 methods
Detailed message:
Error: com.oracle.graal.pointsto.constraints.UnresolvedElementException: Discovered unresolved type during parsing: io.netty.channel.epoll.EpollEventLoopGroup. To diagnose the issue you can use the --allow-incomplete-classpath option. The missing type is then reported at run time when it is accessed the first time.
Trace: 
	at parsing org.redisson.connection.MasterSlaveConnectionManager.<init>(MasterSlaveConnectionManager.java:152)
Call path from entry point to org.redisson.connection.MasterSlaveConnectionManager.<init>(Config, UUID): 
	at org.redisson.connection.MasterSlaveConnectionManager.<init>(MasterSlaveConnectionManager.java:146)
	at org.redisson.connection.ReplicatedConnectionManager.<init>(ReplicatedConnectionManager.java:62)
	at org.redisson.config.ConfigSupport.createConnectionManager(ConfigSupport.java:199)
	at org.redisson.Redisson.<init>(Redisson.java:67)
	at org.redisson.Redisson.create(Redisson.java:108)
	at org.acme.GreetingResource.hello(GreetingResource.java:46)
	at com.oracle.svm.reflect.GreetingResource_hello_116f4f3295793f67a71f7bce0a46ea6d6055545a_122.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Method.java:566)
	at net.bytebuddy.description.annotation.AnnotationDescription$ForLoadedAnnotation.getValue(AnnotationDescription.java:645)
	at net.bytebuddy.description.annotation.AnnotationDescription$AbstractBase.toString(AnnotationDescription.java:471)
	at java.lang.String.valueOf(String.java:2951)
	at java.lang.StringBuilder.append(StringBuilder.java:168)
	at java.net.Proxy.<init>(Proxy.java:95)
	at com.oracle.svm.jni.JNIJavaCallWrappers.jniInvoke_VA_LIST:Ljava_net_Proxy_2_0002e_0003cinit_0003e_00028Ljava_net_Proxy_00024Type_2Ljava_net_SocketAddress_2_00029V(generated:0)
Error: com.oracle.graal.pointsto.constraints.UnresolvedElementException: Discovered unresolved type during parsing: io.netty.channel.epoll.EpollSocketChannel. To diagnose the issue you can use the --allow-incomplete-classpath option. The missing type is then reported at run time when it is accessed the first time.
Trace: 
	at parsing org.redisson.client.RedisClient.<init>(RedisClient.java:100)
Call path from entry point to org.redisson.client.RedisClient.<init>(RedisClientConfig): 
	at org.redisson.client.RedisClient.<init>(RedisClient.java:85)
	at org.redisson.client.RedisClient.create(RedisClient.java:82)
	at org.redisson.connection.MasterSlaveConnectionManager.createClient(MasterSlaveConnectionManager.java:425)
	at org.redisson.connection.MasterSlaveConnectionManager.connectToNode(MasterSlaveConnectionManager.java:243)
	at org.redisson.connection.MasterSlaveConnectionManager.connectToNode(MasterSlaveConnectionManager.java:230)
	at org.redisson.connection.ReplicatedConnectionManager$1.run(ReplicatedConnectionManager.java:129)
	at java.lang.Thread.run(Thread.java:829)
	at com.oracle.svm.core.thread.JavaThreads.threadStartRoutine(JavaThreads.java:567)
	at com.oracle.svm.core.posix.thread.PosixJavaThreads.pthreadStartRoutine(PosixJavaThreads.java:192)
	at com.oracle.svm.core.code.IsolateEnterStub.PosixJavaThreads_pthreadStartRoutine_e1f4a8c0039f8337338252cd8734f63a79b5e3df(generated:0)
Error: com.oracle.graal.pointsto.constraints.UnresolvedElementException: Discovered unresolved type during parsing: org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor. To diagnose the issue you can use the --allow-incomplete-classpath option. The missing type is then reported at run time when it is accessed the first time.
Trace: 
	at parsing org.redisson.executor.TasksRunnerService.decode(TasksRunnerService.java:318)
Call path from entry point to org.redisson.executor.TasksRunnerService.decode(TaskParameters): 
	at org.redisson.executor.TasksRunnerService.decode(TasksRunnerService.java:282)
	at org.redisson.executor.TasksRunnerService.executeCallable(TasksRunnerService.java:213)
	at com.oracle.svm.reflect.RemoteExecutorService_executeCallable_381a82befffa37d303c23f37564ab3150e3aec4c_864.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Method.java:566)
	at net.bytebuddy.description.annotation.AnnotationDescription$ForLoadedAnnotation.getValue(AnnotationDescription.java:645)
	at net.bytebuddy.description.annotation.AnnotationDescription$AbstractBase.toString(AnnotationDescription.java:471)
	at java.lang.String.valueOf(String.java:2951)
	at java.lang.StringBuilder.append(StringBuilder.java:168)
	at java.net.Proxy.<init>(Proxy.java:95)
	at com.oracle.svm.jni.JNIJavaCallWrappers.jniInvoke_VA_LIST:Ljava_net_Proxy_2_0002e_0003cinit_0003e_00028Ljava_net_Proxy_00024Type_2Ljava_net_SocketAddress_2_00029V(generated:0)

com.oracle.svm.core.util.UserError$UserException: Unsupported features in 3 methods
Detailed message:
Error: com.oracle.graal.pointsto.constraints.UnresolvedElementException: Discovered unresolved type during parsing: io.netty.channel.epoll.EpollEventLoopGroup. To diagnose the issue you can use the --allow-incomplete-classpath option. The missing type is then reported at run time when it is accessed the first time.
Trace: 
	at parsing org.redisson.connection.MasterSlaveConnectionManager.<init>(MasterSlaveConnectionManager.java:152)
Call path from entry point to org.redisson.connection.MasterSlaveConnectionManager.<init>(Config, UUID): 
	at org.redisson.connection.MasterSlaveConnectionManager.<init>(MasterSlaveConnectionManager.java:146)
	at org.redisson.connection.ReplicatedConnectionManager.<init>(ReplicatedConnectionManager.java:62)
	at org.redisson.config.ConfigSupport.createConnectionManager(ConfigSupport.java:199)
	at org.redisson.Redisson.<init>(Redisson.java:67)
	at org.redisson.Redisson.create(Redisson.java:108)
	at org.acme.GreetingResource.hello(GreetingResource.java:46)
	at com.oracle.svm.reflect.GreetingResource_hello_116f4f3295793f67a71f7bce0a46ea6d6055545a_122.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Method.java:566)
	at net.bytebuddy.description.annotation.AnnotationDescription$ForLoadedAnnotation.getValue(AnnotationDescription.java:645)
	at net.bytebuddy.description.annotation.AnnotationDescription$AbstractBase.toString(AnnotationDescription.java:471)
	at java.lang.String.valueOf(String.java:2951)
	at java.lang.StringBuilder.append(StringBuilder.java:168)
	at java.net.Proxy.<init>(Proxy.java:95)
	at com.oracle.svm.jni.JNIJavaCallWrappers.jniInvoke_VA_LIST:Ljava_net_Proxy_2_0002e_0003cinit_0003e_00028Ljava_net_Proxy_00024Type_2Ljava_net_SocketAddress_2_00029V(generated:0)
Error: com.oracle.graal.pointsto.constraints.UnresolvedElementException: Discovered unresolved type during parsing: io.netty.channel.epoll.EpollSocketChannel. To diagnose the issue you can use the --allow-incomplete-classpath option. The missing type is then reported at run time when it is accessed the first time.
Trace: 
	at parsing org.redisson.client.RedisClient.<init>(RedisClient.java:100)
Call path from entry point to org.redisson.client.RedisClient.<init>(RedisClientConfig): 
	at org.redisson.client.RedisClient.<init>(RedisClient.java:85)
	at org.redisson.client.RedisClient.create(RedisClient.java:82)
	at org.redisson.connection.MasterSlaveConnectionManager.createClient(MasterSlaveConnectionManager.java:425)
	at org.redisson.connection.MasterSlaveConnectionManager.connectToNode(MasterSlaveConnectionManager.java:243)
	at org.redisson.connection.MasterSlaveConnectionManager.connectToNode(MasterSlaveConnectionManager.java:230)
	at org.redisson.connection.ReplicatedConnectionManager$1.run(ReplicatedConnectionManager.java:129)
	at java.lang.Thread.run(Thread.java:829)
	at com.oracle.svm.core.thread.JavaThreads.threadStartRoutine(JavaThreads.java:567)
	at com.oracle.svm.core.posix.thread.PosixJavaThreads.pthreadStartRoutine(PosixJavaThreads.java:192)
	at com.oracle.svm.core.code.IsolateEnterStub.PosixJavaThreads_pthreadStartRoutine_e1f4a8c0039f8337338252cd8734f63a79b5e3df(generated:0)
Error: com.oracle.graal.pointsto.constraints.UnresolvedElementException: Discovered unresolved type during parsing: org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor. To diagnose the issue you can use the --allow-incomplete-classpath option. The missing type is then reported at run time when it is accessed the first time.
Trace: 
	at parsing org.redisson.executor.TasksRunnerService.decode(TasksRunnerService.java:318)
Call path from entry point to org.redisson.executor.TasksRunnerService.decode(TaskParameters): 
	at org.redisson.executor.TasksRunnerService.decode(TasksRunnerService.java:282)
	at org.redisson.executor.TasksRunnerService.executeCallable(TasksRunnerService.java:213)
	at com.oracle.svm.reflect.RemoteExecutorService_executeCallable_381a82befffa37d303c23f37564ab3150e3aec4c_864.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Method.java:566)
	at net.bytebuddy.description.annotation.AnnotationDescription$ForLoadedAnnotation.getValue(AnnotationDescription.java:645)
	at net.bytebuddy.description.annotation.AnnotationDescription$AbstractBase.toString(AnnotationDescription.java:471)
	at java.lang.String.valueOf(String.java:2951)
	at java.lang.StringBuilder.append(StringBuilder.java:168)
	at java.net.Proxy.<init>(Proxy.java:95)
	at com.oracle.svm.jni.JNIJavaCallWrappers.jniInvoke_VA_LIST:Ljava_net_Proxy_2_0002e_0003cinit_0003e_00028Ljava_net_Proxy_00024Type_2Ljava_net_SocketAddress_2_00029V(generated:0)

	at com.oracle.svm.core.util.UserError.abort(UserError.java:82)
	at com.oracle.svm.hosted.FallbackFeature.reportAsFallback(FallbackFeature.java:233)
	at com.oracle.svm.hosted.NativeImageGenerator.runPointsToAnalysis(NativeImageGenerator.java:764)
	at com.oracle.svm.hosted.NativeImageGenerator.doRun(NativeImageGenerator.java:532)
	at com.oracle.svm.hosted.NativeImageGenerator.run(NativeImageGenerator.java:491)
	at com.oracle.svm.hosted.NativeImageGeneratorRunner.buildImage(NativeImageGeneratorRunner.java:380)
	at com.oracle.svm.hosted.NativeImageGeneratorRunner.build(NativeImageGeneratorRunner.java:543)
	at com.oracle.svm.hosted.NativeImageGeneratorRunner.main(NativeImageGeneratorRunner.java:119)
	at com.oracle.svm.hosted.NativeImageGeneratorRunner$JDK9Plus.main(NativeImageGeneratorRunner.java:573)
Caused by: com.oracle.graal.pointsto.constraints.UnsupportedFeatureException: Unsupported features in 3 methods
Detailed message:
Error: com.oracle.graal.pointsto.constraints.UnresolvedElementException: Discovered unresolved type during parsing: io.netty.channel.epoll.EpollEventLoopGroup. To diagnose the issue you can use the --allow-incomplete-classpath option. The missing type is then reported at run time when it is accessed the first time.
Trace: 
	at parsing org.redisson.connection.MasterSlaveConnectionManager.<init>(MasterSlaveConnectionManager.java:152)
Call path from entry point to org.redisson.connection.MasterSlaveConnectionManager.<init>(Config, UUID): 
	at org.redisson.connection.MasterSlaveConnectionManager.<init>(MasterSlaveConnectionManager.java:146)
	at org.redisson.connection.ReplicatedConnectionManager.<init>(ReplicatedConnectionManager.java:62)
	at org.redisson.config.ConfigSupport.createConnectionManager(ConfigSupport.java:199)
	at org.redisson.Redisson.<init>(Redisson.java:67)
	at org.redisson.Redisson.create(Redisson.java:108)
	at org.acme.GreetingResource.hello(GreetingResource.java:46)
	at com.oracle.svm.reflect.GreetingResource_hello_116f4f3295793f67a71f7bce0a46ea6d6055545a_122.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Method.java:566)
	at net.bytebuddy.description.annotation.AnnotationDescription$ForLoadedAnnotation.getValue(AnnotationDescription.java:645)
	at net.bytebuddy.description.annotation.AnnotationDescription$AbstractBase.toString(AnnotationDescription.java:471)
	at java.lang.String.valueOf(String.java:2951)
	at java.lang.StringBuilder.append(StringBuilder.java:168)
	at java.net.Proxy.<init>(Proxy.java:95)
	at com.oracle.svm.jni.JNIJavaCallWrappers.jniInvoke_VA_LIST:Ljava_net_Proxy_2_0002e_0003cinit_0003e_00028Ljava_net_Proxy_00024Type_2Ljava_net_SocketAddress_2_00029V(generated:0)
Error: com.oracle.graal.pointsto.constraints.UnresolvedElementException: Discovered unresolved type during parsing: io.netty.channel.epoll.EpollSocketChannel. To diagnose the issue you can use the --allow-incomplete-classpath option. The missing type is then reported at run time when it is accessed the first time.
Trace: 
	at parsing org.redisson.client.RedisClient.<init>(RedisClient.java:100)
Call path from entry point to org.redisson.client.RedisClient.<init>(RedisClientConfig): 
	at org.redisson.client.RedisClient.<init>(RedisClient.java:85)
	at org.redisson.client.RedisClient.create(RedisClient.java:82)
	at org.redisson.connection.MasterSlaveConnectionManager.createClient(MasterSlaveConnectionManager.java:425)
	at org.redisson.connection.MasterSlaveConnectionManager.connectToNode(MasterSlaveConnectionManager.java:243)
	at org.redisson.connection.MasterSlaveConnectionManager.connectToNode(MasterSlaveConnectionManager.java:230)
	at org.redisson.connection.ReplicatedConnectionManager$1.run(ReplicatedConnectionManager.java:129)
	at java.lang.Thread.run(Thread.java:829)
	at com.oracle.svm.core.thread.JavaThreads.threadStartRoutine(JavaThreads.java:567)
	at com.oracle.svm.core.posix.thread.PosixJavaThreads.pthreadStartRoutine(PosixJavaThreads.java:192)
	at com.oracle.svm.core.code.IsolateEnterStub.PosixJavaThreads_pthreadStartRoutine_e1f4a8c0039f8337338252cd8734f63a79b5e3df(generated:0)
Error: com.oracle.graal.pointsto.constraints.UnresolvedElementException: Discovered unresolved type during parsing: org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor. To diagnose the issue you can use the --allow-incomplete-classpath option. The missing type is then reported at run time when it is accessed the first time.
Trace: 
	at parsing org.redisson.executor.TasksRunnerService.decode(TasksRunnerService.java:318)
Call path from entry point to org.redisson.executor.TasksRunnerService.decode(TaskParameters): 
	at org.redisson.executor.TasksRunnerService.decode(TasksRunnerService.java:282)
	at org.redisson.executor.TasksRunnerService.executeCallable(TasksRunnerService.java:213)
	at com.oracle.svm.reflect.RemoteExecutorService_executeCallable_381a82befffa37d303c23f37564ab3150e3aec4c_864.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Method.java:566)
	at net.bytebuddy.description.annotation.AnnotationDescription$ForLoadedAnnotation.getValue(AnnotationDescription.java:645)
	at net.bytebuddy.description.annotation.AnnotationDescription$AbstractBase.toString(AnnotationDescription.java:471)
	at java.lang.String.valueOf(String.java:2951)
	at java.lang.StringBuilder.append(StringBuilder.java:168)
	at java.net.Proxy.<init>(Proxy.java:95)
	at com.oracle.svm.jni.JNIJavaCallWrappers.jniInvoke_VA_LIST:Ljava_net_Proxy_2_0002e_0003cinit_0003e_00028Ljava_net_Proxy_00024Type_2Ljava_net_SocketAddress_2_00029V(generated:0)

	at com.oracle.graal.pointsto.constraints.UnsupportedFeatures.report(UnsupportedFeatures.java:129)
	at com.oracle.svm.hosted.NativeImageGenerator.runPointsToAnalysis(NativeImageGenerator.java:761)
	... 6 more
[quarkus-redis-camel-simplified-1.0.0-SNAPSHOT-runner:25230]      [total]: 109,195.17 ms,  6.38 GB
# Printing build artifacts to: /home/agallice/dev/projects/quarkus-redis-camel-simplified/target/quarkus-redis-camel-simplified-1.0.0-SNAPSHOT-native-image-source-jar/quarkus-redis-camel-simplified-1.0.0-SNAPSHOT-runner.build_artifacts.txt
Error: Image build request failed with exit status 1
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------

Steps to reproduce or test case
The README of this reproducer should explain what's needed.
Logically, running mvn clean integration-test -P native should be enough.
mvn, java, graalvm native-image and a valid testcontainer setup might be needed.
Redis version
There is a test container resource embedding redis 6.0.9 in RedisTestResource.java.
Redisson version
3.16.1
Redisson configuration
Basic single server here.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3775
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
org.redisson.client.RedisConnectionException: Unable to connect to Redis server: 150.109.250.34/150.109.250.34:6379
at org.redisson.connection.pool.ConnectionPool$1.lambda$run$0(ConnectionPool.java:160)
at org.redisson.connection.pool.ConnectionPool$1$$Lambda$22/44206143.accept(Unknown Source)
at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:183)
at org.redisson.misc.RedissonPromise$$Lambda$17/1473623671.operationComplete(Unknown Source)
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)
at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)
at io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:608)
at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)
at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:96)
at org.redisson.connection.pool.ConnectionPool.promiseFailure(ConnectionPool.java:330)
at org.redisson.connection.pool.ConnectionPool.lambda$createConnection$1(ConnectionPool.java:296)
at org.redisson.connection.pool.ConnectionPool$$Lambda$21/1213290808.accept(Unknown Source)
at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:183)
at org.redisson.misc.RedissonPromise$$Lambda$17/1473623671.operationComplete(Unknown Source)
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)
at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:570)
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:549)
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)
at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)
at io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:608)
at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)
at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:96)
at org.redisson.client.RedisClient$2$1.run(RedisClient.java:240)
at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)
at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:745)
Caused by: org.redisson.client.RedisException: ERR unknown command 'PROXY'. channel: [id: 0x25e8b191, L:/172.29.0.4:39298 - R:150.109.250.34/150.109.250.34:6379] command: (AUTH), params: (password masked)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:355)
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:196)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:134)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:104)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:498)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:377)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:355)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:377)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
... 4 more
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3776
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
RPriorityBlockedQueue element available to be taken by the second thread after the first one has been interrupted before the element appeared in the queue
Actual behavior
The element has been read by someone else
Steps to reproduce or test case
Testcase is almost the same as RedissonBlockingQueueTest.testTakeInterrupted() with exceptions:

getPriorityBlockingQueue() is used instead of getBlockingQueue()
Had to use @RepeatedTest(30) since it's not 100% reproducible. I have about 6 succeeds out of 30 runs.

import static org.assertj.core.api.Assertions.assertThat;

import java.time.Duration;
import java.util.concurrent.atomic.AtomicBoolean;

import org.awaitility.Awaitility;
import org.junit.jupiter.api.BeforeAll;
import org.junit.jupiter.api.RepeatedTest;
import org.junit.jupiter.api.Test;
import org.redisson.RedisRunner.RedisProcess;
import org.redisson.api.RBlockingQueue;
import org.redisson.api.RedissonClient;
import org.redisson.config.Config;

public class RedissonPriorityBlockingQueueInterruptTest {
    private static RedissonClient redisson;

    <T> RBlockingQueue<T> getQueue(RedissonClient redisson) {
        return redisson.getPriorityBlockingQueue("queue");
    }
    
    @BeforeAll
    public static void setUpClass() throws Exception {
        RedisProcess runner = new RedisRunner()
            .nosave()
            .randomDir()
            .randomPort()
            .run();

        Config config = new Config();
        config.useSingleServer().setAddress(runner.getRedisServerAddressAndPort());
        
        redisson = Redisson.create(config);
    }
    
    @RepeatedTest(30)
//    @Test
    public void testTakeInterrupted() throws InterruptedException {
        final AtomicBoolean interrupted = new AtomicBoolean();
        
        Thread t = new Thread() {
            public void run() {
                try {
                    RBlockingQueue<Integer> queue1 = getQueue(redisson);
                    queue1.take();
                } catch (InterruptedException e) {
                    interrupted.set(true);
                }
            };
        };

        t.start();
        t.join(1000);
        
        t.interrupt();
        Awaitility.await().atMost(Duration.ofSeconds(1)).untilTrue(interrupted);

        RBlockingQueue<Integer> q = getQueue(redisson);
        q.add(1);
        Thread.sleep(1000);
        assertThat(q.contains(1)).isTrue();        
    }
}

Redis version
4.0.14 (alpine)
Redisson version
3.15.6, 3.16.2-SNAPSHOT
Redisson configuration
Default, SingleServer
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3777
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is it necessary to explicitly remove a Topic listener before shutdown, or does shutdown remove it anyway?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3778
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hey
Not sure if this is an issue. I'm using a topic to transit data between two instances. Sometimes, listeners are unregistered randomly, and I don't know why, server is just publishing data, it works 1-5 times and then it breaks :/
Config:
redissonConfig.setCodec(new JsonJacksonCodec())
                .setThreads(8)
                .setNettyThreads(8)
                .useSingleServer());
Monitor (first wave it works, second doesn't) :
https://paste.domicraft.fr/vakuxahawa.json
Thanks for your help, if you need more details, tell me!
Redisson 3.16.1 - Redis 6.2.5
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3779
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
TransportMode Indicates the differences between different configurations
Why is NIO selected by default
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3780
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
The return value of this method about setIfAbsent is null when a key is exist. I think the return value should be false or zero.
   public V getNow() { Object result = this.result; return !(result instanceof DefaultPromise.CauseHolder) && result != SUCCESS && result != UNCANCELLABLE ? result : null; }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3781
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Redisson can detect the cluster nodes change  correctly.
Actual behavior

Steps to reproduce or test case
When redis cluster fail over.
And can not recover by itself.
Redis version
3.2.0
Redisson version
3.16.0
Redisson configuration
new Config().useClusterServers(xxx);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3782
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3783
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Exception throws like single redis server
Actual behavior
In cluster mode, this method will block the thread and no exception throws


Steps to reproduce or test case
    Config config = new Config();
    config.useClusterServers().addNodeAddress("redisUrl").setPassword("Password");
    RedissonClient redissonClient = Redisson.create(config);
    ArrayList<Object> redisKeys = new ArrayList<>();
    Redisson.create(config).getKeys().delete(redisKeys.toArray(new String[0]));
    redissonClient.shutdown();

Redis version
6.2.4
Redisson version
3.16.1
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3784
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@slf4j
@component
public class RedisDelayService {
@Autowired
private RedissonClient redissonClient;

/**
 * 添加到消息队列
 * @param value 添加到队列的对象
 * @param delay 延迟时间
 * @param timeUnit 时间单位
 * @param queueName 队列名称
 * @param <T>
 */
public <T> void addQueue(T value , long delay, TimeUnit timeUnit, String queueName){
    try {
        log.info("添加到延时队列【{}】【{}】【{}】",value,delay,queueName);
        RBlockingDeque<T> blockingDeque = redissonClient.getBlockingDeque(queueName);
        RDelayedQueue<T> delayedQueue = redissonClient.getDelayedQueue(blockingDeque);
        delayedQueue.offer(value,delay,timeUnit);
    } catch (Exception e) {
        log.error("添加到延时队列失败："+e.getMessage(),e);
        throw new RuntimeException("添加到延时队列失败");
    }
}


/**
 * 取值
 */
public <T> T take(String queueName) throws InterruptedException {
    RBlockingDeque<T> blockingDeque = redissonClient.getBlockingDeque(queueName);
    RDelayedQueue<T> delayedQueue = redissonClient.getDelayedQueue(blockingDeque);
    return blockingDeque.take();
}

}
@component
@slf4j
public class RedisDelayQueueRunner implements ApplicationRunner {
@Autowired
private RedissonClient redissonClient;
@Autowired
private RedisDelayService redisDelayService;

@Override
public void run(ApplicationArguments args) throws Exception {

    ScheduledThreadPoolExecutor scheduledThreadPoolExecutor = new ScheduledThreadPoolExecutor(1);

    scheduledThreadPoolExecutor
            .scheduleWithFixedDelay(
                    () -> {
                        log.info(Thread.currentThread().getName());
                        Employer callCdr = null;
                        try {
                            callCdr = redisDelayService.take("delay_queue");
                        }catch (InterruptedException e){
                               log.info(e.getMessage());
                               e.printStackTrace();
                        }
                        log.info("订单取消时间：" + new SimpleDateFormat("hh:mm:ss").format(new Date()) + "==订单生成时间" + callCdr.getPutTime());
                        },
                    1, 1, TimeUnit.SECONDS);

}

}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3785
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Normal traversal
Actual behavior
org.redisson.client.RedisException: ERR invalid cursor. channel: [id: 0x804adbe4, L:/ip:port - R:r-2zegt08tg2p1e87247.redis.rds command: (SCAN), params: [72057594037929616, MATCH, STS_REDIS_KEY_SECRET_V1:*, COUNT, 10]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:343)
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:178)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:117)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:102)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:677)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:612)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:529)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:491)
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base/java.lang.Thread.run(Thread.java:829)
Steps to reproduce or test case
@Autowired
RedissonClient redissonClient
public void reloadAllUserPermission() {
Stream keysStream = redissonClient.getKeys().getKeysStreamByPattern(“STS_REDIS_KEY”+ "*", 10);
keysStream.forEach(item -> {
RBucket rBucket = redissonClient.getBucket(item);
UserCacheDO userCacheDO = rBucket.get();
});
Redis version
5.0.5
Redisson version
3.14.1
Redisson configuration
@configuration
public class RedissonConfig {
@Value("${redis.host}")
private String redisLoginHost;
@Value("${redis.port}")
private Integer redisLoginPort;
@Value("${redis.password}")
private String redisLoginPassword;


@Bean
public RedissonClient redissonClient() {
    return createRedis(redisLoginHost, redisLoginPort, redisLoginPassword);
}

private RedissonClient createRedis(String redisHost, Integer redisPort, String redisPassword) {
    Config config = new Config();
    SingleServerConfig singleServerConfig = config.useSingleServer();
    singleServerConfig.setAddress("redis://" + redisHost + ":" + redisPort + "");
    if (DataUtils.isNotEmpty(redisPassword)) {
        singleServerConfig.setPassword(redisPassword);
    }
    config.setCodec(FastjsonCodec.INSTANCE);
    return Redisson.create(config);
}

}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3786
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3787
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
ERROR o.r.client.handler.CommandDecoder - Unable to decode data. channel: [id: 0x72310cd6, L:/127.0.0.1:14072 - R:127.0.0.1/127.0.0.1:6379], reply: ReplayingDecoderByteBuf(ridx=128, widx=128), command: (HGET), params: [role, PooledUnsafeDirectByteBuf(ridx: 0, widx: 8, cap: 256)]
com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of org.springframework.security.core.authority.SimpleGrantedAuthority (no Creators, like default constructor, exist): cannot deserialize from Object value (no delegate- or property-based Creator)
at [Source: (io.netty.buffer.ByteBufInputStream); line: 1, column: 104] (through reference chain: java.util.ArrayList[0])
at com.fasterxml.jackson.databind.exc.InvalidDefinitionException.from(InvalidDefinitionException.java:67)
at com.fasterxml.jackson.databind.DeserializationContext.reportBadDefinition(DeserializationContext.java:1764)
at com.fasterxml.jackson.databind.DatabindContext.reportBadDefinition(DatabindContext.java:400)
at com.fasterxml.jackson.databind.DeserializationContext.handleMissingInstantiator(DeserializationContext.java:1209)
at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromObjectUsingNonDefault(BeanDeserializerBase.java:1415)
at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeFromObject(BeanDeserializer.java:362)
at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:230)
at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:197)
at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedForId(AsPropertyTypeDeserializer.java:139)
at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:107)
at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromAny(AsPropertyTypeDeserializer.java:208)
at com.fasterxml.jackson.databind.deser.std.UntypedObjectDeserializer$Vanilla.deserializeWithType(UntypedObjectDeserializer.java:771)
at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer._deserializeFromArray(CollectionDeserializer.java:357)
at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:244)
at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:28)
at com.fasterxml.jackson.databind.jsontype.impl.AsArrayTypeDeserializer._deserialize(AsArrayTypeDeserializer.java:120)
at com.fasterxml.jackson.databind.jsontype.impl.AsArrayTypeDeserializer.deserializeTypedFromArray(AsArrayTypeDeserializer.java:53)
at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromAny(AsPropertyTypeDeserializer.java:206)
at com.fasterxml.jackson.databind.deser.std.UntypedObjectDeserializer$Vanilla.deserializeWithType(UntypedObjectDeserializer.java:771)
at com.fasterxml.jackson.databind.deser.impl.TypeWrappedDeserializer.deserialize(TypeWrappedDeserializer.java:74)
at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:322)
at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4593)
at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3585)
at org.redisson.codec.JsonJacksonCodec$2.decode(JsonJacksonCodec.java:99)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:366)
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:183)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:122)
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:107)
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:507)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
2021-08-20 16:02:53 [XNIO-1 task-1] ERROR me.zhengjie.config.RedisConfig - Redis occur handleCacheGetError：key -> [auth:1]
org.redisson.client.RedisException: Unexpected exception while processing command
I found key auth:1 is ["java.util.ArrayList",{"@Class":"org.springframework.security.core.authority.SimpleGrantedAuthority","role":"admin"}]].
I think the problem is jackson turn this value to List.
But I don't know how to solve it exactly.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3788
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Master redis node should never get GetType commands.
Actual behavior
After unexpected traffic-load (spike) on redis, redisson starts sending gettype commands to master nodes instead of slave nodes.
Steps to reproduce or test case
On sudden spikes , this issue has been observed , its random in nature. Issue goes away after service restart.
(Also , happens very frequently.)
Redis version
5.0.6
Redisson version
3.15.0
Redisson configuration
// Spring boot Java config :
Config config = new Config();
config.setCodec(StringCodec.INSTANCE)
	.useClusterServers()
	.setCheckSlotsCoverage(false)
	.setMasterConnectionPoolSize(64)
	.setMasterConnectionMinimumIdleSize(8)
	.setSlaveConnectionPoolSize(64)
	.setSlaveConnectionMinimumIdleSize(8)
	.setKeepAlive(true)
	.setTcpNoDelay(true)
	.setPingConnectionInterval(10000)
	.setScanInterval(2000)
	.setPassword(password)
	.setTimeout(1000)
	.addNodeAddress(hosts);
client = Redisson.create(config);

Other Details


Both client service accessing the redis cluster and the redis cluster are in the same VPC


Redis cluster : AWS Elastic Cache is used. Cluster is 3 shards with 6 nodes  with each shard containing one master and one replica node. Instance type of each node is r6g.2xlarge


Commands used :zadd and zrevRangeByScore only.


Behaviour of nodes during the problem :


Set type cmds
1:27 AM -> 0002-002 went out of comission
1:29 AM -> 0002-001 stopped taking incoming commands
1:30 AM -> 0002-001 stil not taking incoming commands
1:31 AM -> 0002-001 recovers
1:31 AM -> 0002-002 recovers
1:32 AM -> 0003-001 reduced number of requests
1:32 AM -> 0003-002 went out of comission
1:33 AM -> 0003-001 starts recovering
1:33 AM -> 0003-002 still out of comission
1:34 AM -> 0003-002 recovered
1:34 AM -> 0003-002 recovered
Get type cmds
1:27 AM -> 0002-002 - went out
1:28 AM -> 0002-002 - same
1:31 AM -> 0002-002 - recovered
1:32 AM -> 0003-002 - went out
1:33 AM -> 0003-002 - still out
1:33 AM -> 0002-001 - get commands started (master)
1:34 AM -> 0003-002 - recovered
1:35 AM -> 0003-001 - get commands started (master)
Since then we are seeing get cmds being run on 0002-001 & 0003-001 , which are master nodes.

Once the slaves are recovered, instead of using slaves for zrevRangeByScore , we see calls at master for zrevRangeByScore commands.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3789
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I try netty-resolver-dns-native-macos 4.1.67.Final and 4.1.65.Final and 4.1.63.Final but didn't work.
I found netty maybe not support m1 how can I solve this problem.
redisson - 3.16.1
spring-boot - 2.5.2
apple m1
ERROR i.n.r.d.DnsServerAddressStreamProviders - Unable to load io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider, fallback to system defaults. This may result in incorrect DNS resolutions on MacOS.
java.lang.reflect.InvocationTargetException: null
at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
at io.netty.resolver.dns.DnsServerAddressStreamProviders.(DnsServerAddressStreamProviders.java:64)
at org.redisson.connection.MasterSlaveConnectionManager.(MasterSlaveConnectionManager.java:187)
at org.redisson.connection.MasterSlaveConnectionManager.(MasterSlaveConnectionManager.java:139)
at org.redisson.connection.SingleConnectionManager.(SingleConnectionManager.java:30)
at org.redisson.config.ConfigSupport.createConnectionManager(ConfigSupport.java:190)
at org.redisson.Redisson.(Redisson.java:67)
at org.redisson.Redisson.create(Redisson.java:108)
at me.zhengjie.config.RedisConfig.redisson(RedisConfig.java:111)
at me.zhengjie.config.RedisConfig$$EnhancerBySpringCGLIB$$9a155270.CGLIB$redisson$2()
at me.zhengjie.config.RedisConfig$$EnhancerBySpringCGLIB$$9a155270$$FastClassBySpringCGLIB$$28ee32e8.invoke()
at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:244)
at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:331)
at me.zhengjie.config.RedisConfig$$EnhancerBySpringCGLIB$$9a155270.redisson()
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154)
at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:653)
at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:486)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1334)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1177)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:564)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524)
at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1380)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1300)
at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:887)
at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791)
at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:229)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1354)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1204)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:564)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524)
at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1380)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1300)
at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:887)
at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791)
at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:229)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1354)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1204)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:564)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524)
at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1380)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1300)
at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:887)
at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791)
at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:229)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1354)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1204)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:564)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524)
at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:410)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1334)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1177)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:564)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524)
at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:233)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveNamedBean(DefaultListableBeanFactory.java:1273)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveNamedBean(DefaultListableBeanFactory.java:1234)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveBean(DefaultListableBeanFactory.java:494)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBean(DefaultListableBeanFactory.java:349)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBean(DefaultListableBeanFactory.java:342)
at org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration.getSingleBeanOrNull(GlobalMethodSecurityConfiguration.java:181)
at org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration.accessDecisionManager(GlobalMethodSecurityConfiguration.java:253)
at org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration.methodSecurityInterceptor(GlobalMethodSecurityConfiguration.java:143)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154)
at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:653)
at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:638)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1334)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1177)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:564)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524)
at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:213)
at org.springframework.security.access.intercept.aopalliance.MethodSecurityMetadataSourceAdvisor.getAdvice(MethodSecurityMetadataSourceAdvisor.java:104)
at org.springframework.aop.aspectj.AspectJProxyUtils.isAspectJAdvice(AspectJProxyUtils.java:73)
at org.springframework.aop.aspectj.AspectJProxyUtils.makeAdvisorChainAspectJCapableIfNecessary(AspectJProxyUtils.java:54)
at org.springframework.aop.aspectj.autoproxy.AspectJAwareAdvisorAutoProxyCreator.extendAdvisors(AspectJAwareAdvisorAutoProxyCreator.java:95)
at org.springframework.aop.framework.autoproxy.AbstractAdvisorAutoProxyCreator.findEligibleAdvisors(AbstractAdvisorAutoProxyCreator.java:98)
at org.springframework.aop.framework.autoproxy.AbstractAdvisorAutoProxyCreator.getAdvicesAndAdvisorsForBean(AbstractAdvisorAutoProxyCreator.java:78)
at org.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator.wrapIfNecessary(AbstractAutoProxyCreator.java:338)
at org.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator.postProcessAfterInitialization(AbstractAutoProxyCreator.java:290)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsAfterInitialization(AbstractAutowireCapableBeanFactory.java:437)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1790)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:602)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524)
at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:944)
at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918)
at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583)
at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:145)
at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:754)
at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:434)
at org.springframework.boot.SpringApplication.run(SpringApplication.java:338)
at org.springframework.boot.SpringApplication.run(SpringApplication.java:1343)
at org.springframework.boot.SpringApplication.run(SpringApplication.java:1332)
at me.zhengjie.AppRun.main(AppRun.java:46)
Caused by: java.lang.UnsatisfiedLinkError: io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider.resolvers()[Lio/netty/resolver/dns/macos/DnsResolver;
at io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider.resolvers(Native Method)
at io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider.retrieveCurrentMappings(MacOSDnsServerAddressStreamProvider.java:107)
at io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider.(MacOSDnsServerAddressStreamProvider.java:103)
... 132 common frames omitted
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3790
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello, our redisson session manager 3.10.6 has stopped persisting session data. It stays as long as browser session is on, but won't work otherwise, means closing browser and opening.
We are using SHIRO for authentication and authorisation, and redisson usually works in background with session management. However, with a recently introduced virtual host in tomcat and few tweaks in server.xml and nginx (upstream) new server block, the persistence has gone.
On top of it, we are also using BigBlueButton web conference solution which also work with redid-server. It developed some problems of its own, now not storing sessions as well.
This started happening once we introduced new domain and virtual host to the web server.
Below are the technical details
tomcat/lib has redisson 3.10.6 tomcat-all and tomcat-7
tomcat/conf has redisson.conf file
singleServerConfig:
idleConnectionTimeout: 10000
pingTimeout: 1000
connectTimeout: 10000
timeout: 3000
retryAttempts: 3
retryInterval: 1500
password: null
subscriptionsPerConnection: 5
clientName: null
address: "redis://127.0.0.1:6379"
subscriptionConnectionMinimumIdleSize: 1
subscriptionConnectionPoolSize: 50
connectionMinimumIdleSize: 32
connectionPoolSize: 64
database: 0
dnsMonitoringInterval: 5000
threads: 0
nettyThreads: 0
codec: !<org.redisson.codec.JsonJacksonCodec> {}
transportMode: "NIO"
Project maven pom.xml has redisson 3.10.6 dependency

org.redisson
redisson
3.10.6

Shiro.ini has default web session manager set
sessionManager = org.apache.shiro.web.session.mgt.DefaultWebSessionManager
We made all kinds of changes and combinations, but still cannot make redisson persist our session. Help!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3791
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
检查了redis配置插槽正常工作满足16384，端口也正常
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3792
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
I was writing some unit tests and I discovered that I could not perform any operations on a second instance of RedissonLocalCachedMap when I was storing non primitive key/values in the map.
My expectation is that a second instance of RedissonLocalCachedMap would be able to read values from a map as long as RedissonMap could. This is preventing me from using RedissonLocalCachedMap in my code.
Actual behavior
An exception is thrown
Unexpected exception while processing command
org.redisson.client.RedisException: Unexpected exception while processing command
	at org.redisson.command.CommandAsyncService.convertException(CommandAsyncService.java:324)
	at org.redisson.command.CommandAsyncService.get(CommandAsyncService.java:121)
	at org.redisson.RedissonObject.get(RedissonObject.java:82)
	at org.redisson.RedissonMap.readAllValues(RedissonMap.java:850)
	at ai.argo.viaduct.discovery.redis.RedissonDemo.localCachedMapNotWorking(RedissonDemo.kt:48)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:675)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at ...
Caused by: com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot deserialize value of type `java.lang.String` from Object value (token `JsonToken.START_OBJECT`)
 at [Source: (io.netty.buffer.ByteBufInputStream); line: 1, column: 1]
	at com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59)
	at com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1601)
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1375)
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1280)
	at com.fasterxml.jackson.databind.DeserializationContext.extractScalarFromObject(DeserializationContext.java:872)
	at com.fasterxml.jackson.databind.deser.std.StringDeserializer.deserialize(StringDeserializer.java:62)
	at com.fasterxml.jackson.databind.deser.std.StringDeserializer.deserialize(StringDeserializer.java:11)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:322)
	at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4593)
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3585)
	at org.redisson.codec.TypedJsonJacksonCodec$2.decode(TypedJsonJacksonCodec.java:63)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:358)
	at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:402)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:367)
	at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:177)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:116)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:101)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:508)
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more

Steps to reproduce or test case
import com.fasterxml.jackson.databind.DeserializationFeature
import com.fasterxml.jackson.module.kotlin.jacksonObjectMapper
import org.junit.jupiter.api.BeforeEach
import org.junit.jupiter.api.Test
import org.redisson.api.LocalCachedMapOptions
import org.redisson.api.RLocalCachedMap
import org.redisson.api.RMap
import org.redisson.client.codec.Codec
import org.redisson.codec.TypedJsonJacksonCodec
import java.util.UUID

class RedissonDemo : RedisIntegrationTestBase() {

    data class DemoObject(
        val id: UUID
    )


    @BeforeEach
    fun beforeEach() {
        redisClient.keys.flushall()
    }

    @Test
    fun mapWorking() {
        val map1: RMap<String, DemoObject> = redisClient.getMap("test", generateCodec())
        val map2: RMap<String, DemoObject> = redisClient.getMap("test", generateCodec())
        map1.put("key", DemoObject(UUID.randomUUID()))
        map1.readAllValues()
        map2.readAllValues()
    }

    @Test
    fun localCachedMapNotWorking() {
        val map1: RLocalCachedMap<String, DemoObject> = redisClient.getLocalCachedMap("test", generateCodec(), LocalCachedMapOptions.defaults())
        val map2: RLocalCachedMap<String, DemoObject> = redisClient.getLocalCachedMap("test", generateCodec(), LocalCachedMapOptions.defaults())
        map1.put("key", DemoObject(UUID.randomUUID()))
        map1.readAllValues()
        map2.readAllValues() // FAILS HERE
    }

    /**
     * Generates a Jackson codec that supports Kotlin classes.
     */
    private fun generateCodec(): Codec {
        // Needed to serialize/deserialize kotlin objects into redis
        val objectMapper = jacksonObjectMapper()
            .configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false)

        return TypedJsonJacksonCodec(String::class.java, DemoObject::class.java, objectMapper)
    }
}
Redis version
6+
Redisson version
3.15.5
Redisson configuration
val address: String = redis.host
val port: Int = redis.firstMappedPort
val config = Config()
config.useSingleServer().address = "redis://$address:$port"
redisClient = Redisson.create(config)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3793
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
hi,
we have the following exception even we change the configuration to :
useThreadClassLoader = false
java.io.IOException: java.lang.ClassNotFoundException: com.panaya.as.blexecuter.imp.BaseBLContext
at org.redisson.codec.MarshallingCodec$3.decode(MarshallingCodec.java:153) ~[redisson-all-3.14.0.jar:3.14.0]
at org.redisson.codec.SnappyCodec$3.decode(SnappyCodec.java:84) ~[redisson-all-3.14.0.jar:3.14.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:356) [redisson-all-3.14.0.jar:3.14.0]
at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:400) [redisson-all-3.14.0.jar:3.14.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:365) [redisson-all-3.14.0.jar:3.14.0]
at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:178) [redisson-all-3.14.0.jar:3.14.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:117) [redisson-all-3.14.0.jar:3.14.0]
at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:102) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:501) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [redisson-all-3.14.0.jar:3.14.0]
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [redisson-all-3.14.0.jar:3.14.0]
at java.lang.Thread.run(Thread.java:748) [na:1.8.0_261]
Caused by: java.lang.ClassNotFoundException: com.panaya.as.blexecuter.imp.BaseBLContext
at org.apache.catalina.loader.WebappClassLoaderBase.loadClass(WebappClassLoaderBase.java:1952) ~[catalina.jar:7.0.105]
at org.apache.catalina.loader.WebappClassLoaderBase.loadClass(WebappClassLoaderBase.java:1795) ~[catalina.jar:7.0.105]
at java.lang.Class.forName0(Native Method) ~[na:1.8.0_261]
at java.lang.Class.forName(Class.java:348) ~[na:1.8.0_261]
at org.jboss.marshalling.AbstractClassResolver.loadClass(AbstractClassResolver.java:129) ~[redisson-all-3.14.0.jar:3.14.0]
at org.jboss.marshalling.AbstractClassResolver.resolveClass(AbstractClassResolver.java:110) ~[redisson-all-3.14.0.jar:3.14.0]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadClassDescriptor(RiverUnmarshaller.java:1033) ~[redisson-all-3.14.0.jar:3.14.0]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadNewObject(RiverUnmarshaller.java:1366) ~[redisson-all-3.14.0.jar:3.14.0]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadObject(RiverUnmarshaller.java:283) ~[redisson-all-3.14.0.jar:3.14.0]
at org.jboss.marshalling.river.RiverUnmarshaller.doReadObject(RiverUnmarshaller.java:216) ~[redisson-all-3.14.0.jar:3.14.0]
at org.jboss.marshalling.AbstractObjectInput.readObject(AbstractObjectInput.java:41) ~[redisson-all-3.14.0.jar:3.14.0]
at org.redisson.codec.MarshallingCodec$3.decode(MarshallingCodec.java:151) ~[redisson-all-3.14.0.jar:3.14.0]
... 26 common frames omitted
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3794
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3795
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Our redis cluster is composed of three nodes, and each node is loaded with two redis pods. Two redis pods die when a single node goes down. But redisson always tries to connect these dead redis pods.
When a single node goes down:
e5c76dbb3a07d6273bd710df937961620f1eadac 100.64.47.80:6379@16379 slave,fail 248aad504cfd0d86482eec2127bb9cc2fab52785 1629723963951 1629723963000 29 connected
80f97ed19137edf941960e90cf669c2adaa3823e 100.64.214.78:6379@16379 master - 0 1629770356000 31 connected 10923-16383
5f4659cc2a0dab399f4ac74ca2138954cf9c231b 100.64.47.89:6379@16379 master,fail - 1629723963649 1629723961000 23 connected
248aad504cfd0d86482eec2127bb9cc2fab52785 100.64.9.44:6379@16379 myself,master - 0 1629770356000 29 connected 5461-10922
6423ebd354791ce655f6a1e98225384a85576d5c 100.64.214.122:6379@16379 master - 0 1629770356419 20 connected 0-5460
66ad650d65a34d1bc619ac13cc467bbe71d9f7ee 100.64.9.2:6379@16379 slave 6423ebd354791ce655f6a1e98225384a85576d5c 0 1629770357420 20 connected

When the redis cluster returns to normal
e5c76dbb3a07d6273bd710df937961620f1eadac 100.64.47.98:6379@16379 slave 248aad504cfd0d86482eec2127bb9cc2fab52785 0 1629770520848 29 connected
80f97ed19137edf941960e90cf669c2adaa3823e 100.64.214.78:6379@16379 master - 0 1629770519847 31 connected 10923-16383
5f4659cc2a0dab399f4ac74ca2138954cf9c231b 100.64.47.72:6379@16379 slave 80f97ed19137edf941960e90cf669c2adaa3823e 0 1629770519000 31 connected
248aad504cfd0d86482eec2127bb9cc2fab52785 100.64.9.44:6379@16379 myself,master - 0 1629770518000 29 connected 5461-10922
6423ebd354791ce655f6a1e98225384a85576d5c 100.64.214.122:6379@16379 master - 0 1629770518000 20 connected 0-5460
66ad650d65a34d1bc619ac13cc467bbe71d9f7ee 100.64.9.2:6379@16379 slave 6423ebd354791ce655f6a1e98225384a85576d5c 0 1629770518845 20 connected

Redisson always tries to reconnect the changed redis pod(100.64.47.80) even after cluster recovery.
netstat -anp | grep "100.64.47.80"
tcp        0      1 100.64.214.69:51134     100.64.47.80:6379       SYN_SENT    13/java

2021-08-24 10:01:42:002 [redisson-timer-4-1] DEBUG [cea-collector,cea-collector-5bd5fb7584-clxj9,,,,13] org.redisson.client.handler.ConnectionWatchdog.tryReconnect:110 - reconnecting RedisConnection@717315379 [redisClient=[addr=redis://100.64.47.80:6379], channel=[id: 0x49e8aef6, L:/100.64.214.69:59118 ! R:100.64.47.80/100.64.47.80:6379], currentCommand=null] to 100.64.47.80/100.64.47.80:6379
2021-08-24 10:02:00:202 [redisson-timer-4-1] DEBUG [cea-collector,cea-collector-5bd5fb7584-clxj9,,,,13] org.redisson.client.handler.ConnectionWatchdog.tryReconnect:110 - reconnecting RedisConnection@717315379 [redisClient=[addr=redis://100.64.47.80:6379], channel=[id: 0x49e8aef6, L:/100.64.214.69:59118 ! R:100.64.47.80/100.64.47.80:6379], currentCommand=null] to 100.64.47.80/100.64.47.80:6379
2021-08-24 10:02:18:402 [redisson-timer-4-1] DEBUG [cea-collector,cea-collector-5bd5fb7584-clxj9,,,,13] org.redisson.client.handler.ConnectionWatchdog.tryReconnect:110 - reconnecting RedisConnection@717315379 [redisClient=[addr=redis://100.64.47.80:6379], channel=[id: 0x49e8aef6, L:/100.64.214.69:59118 ! R:100.64.47.80/100.64.47.80:6379], currentCommand=null] to 100.64.47.80/100.64.47.80:6379
2021-08-24 10:02:36:702 [redisson-timer-4-1] DEBUG [cea-collector,cea-collector-5bd5fb7584-clxj9,,,,13] org.redisson.client.handler.ConnectionWatchdog.tryReconnect:110 - reconnecting RedisConnection@717315379 [redisClient=[addr=redis://100.64.47.80:6379], channel=[id: 0x49e8aef6, L:/100.64.214.69:59118 ! R:100.64.47.80/100.64.47.80:6379], currentCommand=null] to 100.64.47.80/100.64.47.80:6379
2021-08-24 10:02:54:902 [redisson-timer-4-1] DEBUG [cea-collector,cea-collector-5bd5fb7584-clxj9,,,,13] org.redisson.client.handler.ConnectionWatchdog.tryReconnect:110 - reconnecting RedisConnection@717315379 [redisClient=[addr=redis://100.64.47.80:6379], channel=[id: 0x49e8aef6, L:/100.64.214.69:59118 ! R:100.64.47.80/100.64.47.80:6379], currentCommand=null] to 100.64.47.80/100.64.47.80:6379

Here is the complete log.
cea-collector.log
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3796
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3797
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Currently, the "lpush" command of redis >= 2.4 supports multiple elements at a time, while the corresponding "RDeque.addFirst()" in redisson only supports one element.

https://redis.io/commands/lpush
Similar commands that are not fully supported include "rpush", "sadd", "srem".
Hope these features are supported, thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3798
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
hi,
regard #3793  wasn't able to reopen
we tried to remove jar from app, but it wasn't able to recognize the app classes that we saved in the cache ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3799
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
public RFuture<Boolean> trySetPermitsAsync(int permits) {
        return commandExecutor.evalWriteAsync(getRawName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,
                "local value = redis.call('get', KEYS[1]); " +
                "if (value == false or value == 0) then "
                    + "redis.call('set', KEYS[1], ARGV[1]); "
                    + "redis.call('publish', KEYS[2], ARGV[1]); "
                    + "return 1;"
                + "end;"
                + "return 0;",
                Arrays.<Object>asList(getRawName(), getChannelName()), permits);
    }
value == 0 is aways false , because value is String Type .
and in tryAcquireAsync method,  use tonumber method change String to int .
    public RFuture<Boolean> tryAcquireAsync(int permits) {
        if (permits < 0) {
            throw new IllegalArgumentException("Permits amount can't be negative");
        }
        if (permits == 0) {
            return RedissonPromise.newSucceededFuture(true);
        }

        return commandExecutor.evalWriteAsync(getRawName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,
                  "local value = redis.call('get', KEYS[1]); " +
                  "if (value ~= false and tonumber(value) >= tonumber(ARGV[1])) then " +
                      "local val = redis.call('decrby', KEYS[1], ARGV[1]); " +
                      "return 1; " +
                  "end; " +
                  "return 0;",
                  Collections.<Object>singletonList(getRawName()), permits);
    }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3800
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello,
I've got rather confusing experience with loadAll() method. I used it on startup to 'sync' redisson map with database, however, it doesn't clean values not existed in database.
I can use
RMap.clear()
RMap.loadAll()

but it is not atomic and I've found no functions to lock entire map access while I do this.
As loadAll() calls loadAllKeys(), maybe it better to clean nonexistent keys at the end of loading if loadAllKeys = true?
Reproduction snipped to illustrate:
class Main {

    private val mapLoader = object : MapLoader<Int, String> {
        val data = mutableMapOf(
            1 to "foo",
            2 to "bar"
        )

        fun update() {
            data.clear()
            data[3] = "foobar"
        }

        override fun load(key: Int) = data[key]
        override fun loadAllKeys() = data.keys.toMutableList()
    }

    fun run() {
        val config = Config()
        val redisson = Redisson.create(config)
        val map: RMap<Int, String> = redisson.getMap(
            "test-map",
            MapOptions.defaults<Int, String>().loader(mapLoader)
        )

        map.clear()
        map.loadAll(true, 1)
        require(map.size == 2)
        mapLoader.update()
        map.loadAll(true, 1)
        println(map.entries)
    }
}

fun main() = Main().run()

will print [1=foo, 2=bar, 3=foobar]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3801
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
https://javadoc.io/doc/org.redisson/redisson/latest/index.html.
In the search box on the right, type redisson.
In the  search suggestions, scroll down to the Types section (second from the top), and click on org.redisson.Redisson.
Stare at the error below and wonder why.

AccessDeniedAccess Denied1YBT0RFTFR6X25GVLkDrkQL3l4T52jteTAMOSTWvQLTmEgvpARsyLKeTFzJYDrS2/NpAodRRM4AxpfmjY0HDMuMN8n8=
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3802
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
redis.call('hmget', KEYS[1], ARGV[2]) ... 


redis call trace  once
redis command hmget

Actual behavior
2021-08-31 17:42:32.294 DEBUG 35400 --- [           main] org.redisson.command.RedisExecutor       : acquired connection for command (EVAL) and params [local insertable = false; local v = redis.call('hget', KEYS[1], ARGV[2]); if v == false then inserta..., 8, A:1, redisson__timeout__set:{A:1}, redisson__idle__set:{A:1}, redisson_map_cache_created:{A:1}, redisson_map_cache_updated:{A:1}, redisson__map_cache__last_access__set:{A:1}, redisson_map_cache_removed:{A:1}, {A:1}:redisson_options, ...] from slot NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null] using node localhost/127.0.0.1:6379... RedisConnection@1777130355 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xfbf9de49, L:/127.0.0.1:41972 - R:localhost/127.0.0.1:6379], currentCommand=null]
2021-08-31 17:42:32.299 DEBUG 35400 --- [isson-netty-2-8] org.redisson.command.RedisExecutor       : connection released for command (EVAL) and params [local insertable = false; local v = redis.call('hget', KEYS[1], ARGV[2]); if v == false then inserta..., 8, A:1, redisson__timeout__set:{A:1}, redisson__idle__set:{A:1}, redisson_map_cache_created:{A:1}, redisson_map_cache_updated:{A:1}, redisson__map_cache__last_access__set:{A:1}, redisson_map_cache_removed:{A:1}, {A:1}:redisson_options, ...] from slot NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null] using connection RedisConnection@1777130355 [redisClient=[addr=redis://localhost:6379], channel=[id: 0xfbf9de49, L:/127.0.0.1:41972 - R:localhost/127.0.0.1:6379], currentCommand=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@7e3d5650(success: true)], command=(EVAL), params=[local insertable = false; local v = redis.call('hget', KEYS[1], ARGV[2]); if v == false then inserta..., 8, A:1, redisson__timeout__set:{A:1}, redisson__idle__set:{A:1}, redisson_map_cache_created:{A:1}, redisson_map_cache_updated:{A:1}, redisson__map_cache__last_access__set:{A:1}, redisson_map_cache_removed:{A:1}, {A:1}:redisson_options, ...], codec=org.redisson.codec.JsonJacksonCodec]]
2021-08-31 17:42:32.300 DEBUG 35400 --- [           main] org.redisson.command.RedisExecutor       : acquired connection for command (EVAL) and params [local insertable = false; local v = redis.call('hget', KEYS[1], ARGV[2]); if v == false then inserta..., 8, A:1, redisson__timeout__set:{A:1}, redisson__idle__set:{A:1}, redisson_map_cache_created:{A:1}, redisson_map_cache_updated:{A:1}, redisson__map_cache__last_access__set:{A:1}, redisson_map_cache_removed:{A:1}, {A:1}:redisson_options, ...] from slot NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null] using node localhost/127.0.0.1:6379... RedisConnection@2041929189 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x31eb7129, L:/127.0.0.1:41984 - R:localhost/127.0.0.1:6379], currentCommand=null]
2021-08-31 17:42:32.302 DEBUG 35400 --- [sson-netty-2-12] org.redisson.command.RedisExecutor       : connection released for command (EVAL) and params [local insertable = false; local v = redis.call('hget', KEYS[1], ARGV[2]); if v == false then inserta..., 8, A:1, redisson__timeout__set:{A:1}, redisson__idle__set:{A:1}, redisson_map_cache_created:{A:1}, redisson_map_cache_updated:{A:1}, redisson__map_cache__last_access__set:{A:1}, redisson_map_cache_removed:{A:1}, {A:1}:redisson_options, ...] from slot NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null] using connection RedisConnection@2041929189 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x31eb7129, L:/127.0.0.1:41984 - R:localhost/127.0.0.1:6379], currentCommand=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@68d4819c(success: true)], command=(EVAL), params=[local insertable = false; local v = redis.call('hget', KEYS[1], ARGV[2]); if v == false then inserta..., 8, A:1, redisson__timeout__set:{A:1}, redisson__idle__set:{A:1}, redisson_map_cache_created:{A:1}, redisson_map_cache_updated:{A:1}, redisson__map_cache__last_access__set:{A:1}, redisson_map_cache_removed:{A:1}, {A:1}:redisson_options, ...], codec=org.redisson.codec.JsonJacksonCodec]]
2021-08-31 17:42:32.324 DEBUG 35400 --- [           main] org.redisson.command.RedisExecutor       : acquired connection for command (EVAL) and params [local currentTime = tonumber(table.remove(ARGV, 1)); local maxSize = tonumber(redis.call('hget', KEY..., 8, A:1, redisson__timeout__set:{A:1}, redisson__idle__set:{A:1}, redisson_map_cache_created:{A:1}, redisson_map_cache_updated:{A:1}, redisson__map_cache__last_access__set:{A:1}, redisson_map_cache_removed:{A:1}, {A:1}:redisson_options, ...] from slot NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null] using node localhost/127.0.0.1:6379... RedisConnection@501303000 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x750edc21, L:/127.0.0.1:41970 - R:localhost/127.0.0.1:6379], currentCommand=null]
2021-08-31 17:42:32.326 DEBUG 35400 --- [isson-netty-2-4] org.redisson.command.RedisExecutor       : connection released for command (EVAL) and params [local currentTime = tonumber(table.remove(ARGV, 1)); local maxSize = tonumber(redis.call('hget', KEY..., 8, A:1, redisson__timeout__set:{A:1}, redisson__idle__set:{A:1}, redisson_map_cache_created:{A:1}, redisson_map_cache_updated:{A:1}, redisson__map_cache__last_access__set:{A:1}, redisson_map_cache_removed:{A:1}, {A:1}:redisson_options, ...] from slot NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null] using connection RedisConnection@501303000 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x750edc21, L:/127.0.0.1:41970 - R:localhost/127.0.0.1:6379], currentCommand=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@59ccce76(success)], command=(EVAL), params=[local currentTime = tonumber(table.remove(ARGV, 1)); local maxSize = tonumber(redis.call('hget', KEY..., 8, A:1, redisson__timeout__set:{A:1}, redisson__idle__set:{A:1}, redisson_map_cache_created:{A:1}, redisson_map_cache_updated:{A:1}, redisson__map_cache__last_access__set:{A:1}, redisson_map_cache_removed:{A:1}, {A:1}:redisson_options, ...], codec=org.redisson.codec.JsonJacksonCodec]]
2021-08-31 17:42:33.342 DEBUG 35400 --- [aitility-thread] org.redisson.command.RedisExecutor       : acquired connection for command (EVAL) and params [local expireHead = redis.call('zrange', KEYS[2], 0, 0, 'withscores'); local currentTime = tonumber(t..., 5, A:1, redisson__timeout__set:{A:1}, redisson__idle__set:{A:1}, redisson__map_cache__last_access__set:{A:1}, {A:1}:redisson_options, 1630399353335, PooledUnsafeDirectByteBuf(ridx: 0, widx: 4, cap: 256), PooledUnsafeDirectByteBuf(ridx: 0, widx: 3, cap: 256), ...] from slot NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null] using node localhost/127.0.0.1:6379... RedisConnection@1672945630 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x03a06d25, L:/127.0.0.1:41968 - R:localhost/127.0.0.1:6379], currentCommand=null]
2021-08-31 17:42:33.361 DEBUG 35400 --- [sson-netty-2-10] org.redisson.command.RedisExecutor       : connection released for command (EVAL) and params [local expireHead = redis.call('zrange', KEYS[2], 0, 0, 'withscores'); local currentTime = tonumber(t..., 5, A:1, redisson__timeout__set:{A:1}, redisson__idle__set:{A:1}, redisson__map_cache__last_access__set:{A:1}, {A:1}:redisson_options, 1630399353335, PooledUnsafeDirectByteBuf(ridx: 0, widx: 4, cap: 256), PooledUnsafeDirectByteBuf(ridx: 0, widx: 3, cap: 256), ...] from slot NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null] using connection RedisConnection@1672945630 [redisClient=[addr=redis://localhost:6379], channel=[id: 0x03a06d25, L:/127.0.0.1:41968 - R:localhost/127.0.0.1:6379], currentCommand=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@638f1e84(success: {a2=A(id=a2, age=20), a=A(id=a, age=10), a3=A(id=a3, age=30), a4=A(id=a4, age=40)})], command=(EVAL), params=[local expireHead = redis.call('zrange', KEYS[2], 0, 0, 'withscores'); local currentTime = tonumber(t..., 5, A:1, redisson__timeout__set:{A:1}, redisson__idle__set:{A:1}, redisson__map_cache__last_access__set:{A:1}, {A:1}:redisson_options, 1630399353335, PooledUnsafeDirectByteBuf(ridx: 0, widx: 4, cap: 256), PooledUnsafeDirectByteBuf(ridx: 0, widx: 3, cap: 256), ...], codec=org.redisson.codec.JsonJacksonCodec]]


Steps to reproduce or test case

save

        RedisMeta redisMeta = RedisSupport.findRedisMeta(obj);
        Object id = RedisSupport.findId(obj);

        RMapCache<Object, Object> mapCache = redisson.getMapCache(redisMeta.getNamespaceAndVersion());

        
        
            mapCache.fastPut(id, obj);


get

        RMapCache<K, V> mapCache = redisson.getMapCache(redisMeta.getNamespaceAndVersion());
        return mapCache.getAll(seq(ids).toSet());

Redis version
embeded-redis:0.7.3
Redisson version
3.16.1
Redisson configuration
org.redisson.spring.starter.RedissonAutoConfiguration
and codec custom
    @ConditionalOnMissingBean(value = RedissonAutoConfigurationCustomizer.class)
    @Bean
    RedissonAutoConfigurationCustomizer redissonCodecCustomizer() {
        return (config) -> {
            config.setCodec(JsonJacksonCodec.INSTANCE);
        };
    }


springboot logging config

logging:
  level:
    org.redisson: debug


SAMPLE DATA

SAMPLE CODE
    public <K, V> Map<K, V> findAllByIdsAsMap(Collection<K> ids, Class<V> clazz) {
        RedisMeta redisMeta = RedisSupport.findRedisMeta(clazz);
        RMapCache<K, V> mapCache = redisson.getMapCache(redisMeta.getNamespaceAndVersion());
        return mapCache.getAll(seq(ids).toSet());
    }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3803
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is your feature request related to a problem? Please describe.
The API to trim a redis stream (see the correspoding XTRIM command) supports different strategies via the org.redisson.api.stream.TrimStrategy type.
Yet the additional command parameters in the overloaded methods (e.g. trim, trimAsync, trimNonStrictAsync) will allow only ints.
Specifically you can now only pass a

int threshold (to say how many messages you want to keep)
int limit (to remove up to a given number of messages)

Those are inconsistent with the TrimStrategy.MINID which expects a message Id as input.
Since the message Ids are composed of a timestamp in millis from epoch and a number, the current int param won't be able to technically be used for such a job, even ignoring the semantics of the param.
An int is not enough to encode a valid millis timestamp which is part of the message Id.
Describe the solution you'd like
It would be nice to provide overloaded methods taking an instance of org.redisson.api.StreamMessageId, and - most importantly- a simple String, to allow partial matches.
Describe alternatives you've considered
I will probably use a work-around by calling the low-level redis client, but the issue is mostly about the current API which is a bit misleading in what it provides.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3804
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Rate limit decreases over the time in highly concurrent environment.
Demo of such drift is on screenshot. Rate there has been limited by only RRateLimiter.

Expected behavior
Limit should not change without explicit call of setRate() with new value.
Actual behavior
Limit changes over hours. As a workaround I explicitly call setRate() with the same values time to time.
Steps to reproduce or test case
Just regular usage, nothing special:
    final long limitPerSecond = 115;
    final RRateLimiter limiter = redisson.getRateLimiter(name);
    limiter.setRate(RateType.OVERALL, limitPerSecond, 1000, RateIntervalUnit.MILLISECONDS);
    // ...
    limiter.acquire();

Redis version
6.0.5
Redisson version
3.16.1
Redisson configuration
    final Config config = new Config();
    config.useSingleServer().setAddress(url);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3805
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Since Redis 6.2 sentinel may return hostnames in result of "SENTINEL SENTINELS", "SENTINEL SLAVES", or "SENTINEL GET_MASTER_ADDR_BY_NAME" commands.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3806
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thank you for proposed changes.
Did you try this example https://github.com/redisson/redisson/blob/master/.github/CONTRIBUTING.md#running-the-tests
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3807
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3808
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3809
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3810
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3811
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3812
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3813
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3814
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3815
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3816
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3817
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3818
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3819
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3820
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3821
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3822
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3823
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3824
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3825
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3826
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3827
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3828
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3829
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3830
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3831
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3832
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3833
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3834
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3835
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3836
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3837
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3838
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3839
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3840
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3841
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3842
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3843
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3844
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3845
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3846
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3847
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3848
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3849
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3850
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3851
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3852
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3853
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3854
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3855
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3856
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3857
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3858
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3859
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3860
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3861
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3862
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3863
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3864
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3865
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3866
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3867
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3868
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3869
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3870
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3871
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3872
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3873
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3874
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3875
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3876
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3877
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3878
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3879
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3880
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3881
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3882
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3883
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3884
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3885
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3886
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3887
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3888
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3889
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3890
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3891
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3892
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3893
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3894
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3895
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3896
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3897
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3898
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3899
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3900
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3901
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3902
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3903
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3904
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3905
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3906
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3907
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3908
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3909
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3910
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3911
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3912
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3913
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3914
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3915
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3916
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3917
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3918
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3919
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3920
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3921
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3922
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3923
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3924
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3925
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3926
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3927
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3928
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3929
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3930
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3931
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
String deserialization with high concurrency "{}"  or Object reference  "[com.game.logical.global.bean.DropRateData@2ab839d5]"
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3932
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I noticed weird warnings in our logs during investigation of one of issues:
level | WARN
logger_name | io.netty.util.concurrent.DefaultPromise
message | An exception was thrown by org.redisson.misc.RedissonPromise$Lambda$1511/0x0000000801836b20.operationComplete()

j.l.IllegalArgumentException: port out of range:-1
	at java.net.InetSocketAddress.checkPort(InetSocketAddress.java:152)
	at java.net.InetSocketAddress.createUnresolved(InetSocketAddress.java:263)
	at o.r.c.MasterSlaveConnectionManager.resolveIP(MasterSlaveConnectionManager.java:706)
	at o.r.c.MasterSlaveConnectionManager.resolveIP(MasterSlaveConnectionManager.java:695)
	at o.r.c.SentinelConnectionManager.resolveIP(SentinelConnectionManager.java:617)
	at o.r.c.SentinelConnectionManager.lambda$checkSlavesChange$20(SentinelConnectionManager.java:460)
	at o.r.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:187)
	at i.n.u.c.DefaultPromise.notifyListener0(DefaultPromise.java:578)
	at i.n.u.c.DefaultPromise.notifyListeners0(DefaultPromise.java:571)
	at i.n.u.c.DefaultPromise.notifyListenersNow(DefaultPromise.java:550)
	at i.n.u.c.DefaultPromise.notifyListeners(DefaultPromise.java:491)
	at i.n.u.c.DefaultPromise.setValue0(DefaultPromise.java:616)
	at i.n.u.c.DefaultPromise.setSuccess0(DefaultPromise.java:605)
	at i.n.u.c.DefaultPromise.trySuccess(DefaultPromise.java:104)
	at o.r.misc.RedissonPromise.trySuccess(RedissonPromise.java:82)
	at o.r.c.handler.CommandDecoder.completeResponse(CommandDecoder.java:460)
	at o.r.c.handler.CommandDecoder.handleResult(CommandDecoder.java:454)
	at o.r.c.handler.CommandDecoder.decodeResult(CommandDecoder.java:443)
	at o.r.c.handler.CommandDecoder.decodeList(CommandDecoder.java:437)
	at o.r.c.handler.CommandDecoder.decode(CommandDecoder.java:392)
	at o.r.c.handler.CommandDecoder.decodeCommand(CommandDecoder.java:198)
	at o.r.c.handler.CommandDecoder.decode(CommandDecoder.java:137)
	at o.r.c.handler.CommandDecoder.decode(CommandDecoder.java:113)
	at i.n.h.c.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:507)
	at i.n.h.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
	at i.n.h.c.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
	at i.n.c.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at i.n.c.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at i.n.c.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at i.n.c.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	... 12 frames truncated

Right before this warning, trace logs:
channel: [id: 0x786eaac2, L:/10.0.41.255:43594 - R:10.0.31.235/10.0.31.235:26379] message: *3
$8
SENTINEL
$9
SENTINELS
$8
mymaster

reply: *2
*28
$4
name
$40
5f4ff5b1f3024ce375ab027ac24adb717305f02c
$2
ip
$10
10.0.56.43
$4
port
$5
26379
$5
runid
$40
5f4ff5b1f3024ce375ab027ac24adb717305f02c
$5
flags
$8
sentinel
$21
link-pending-commands
$1
0
$13
link-refcount
$1
1
$14
last-ping-sent
$1
0
$18
last-ok-ping-reply
$3
718
$15
last-ping-reply
$3
718
$23
down-after-milliseconds
$5
60000
$18
last-hello-message
$2
56
$12
voted-leader
$1
?
$18
voted-leader-epoch
$1
0
*28
$4
name
$40
6b28db582bd8af66c1e0ddbcc9afcce2daba4354
$2
ip
$10
10.0.60.42
$4
port
$5
26379
$5
runid
$40
6b28db582bd8af66c1e0ddbcc9afcce2daba4354
$5
flags
$8
sentinel
$21
link-pending-commands
$1
0
$13
link-refcount
$1
1
$14
last-ping-sent
$1
0
$18
last-ok-ping-reply
$3
316
$15
last-ping-reply
$3
316
$23
down-after-milliseconds
$5
60000
$18
last-hello-message
$3
426
$12
voted-leader
$1
?
$18
voted-leader-epoch
$1
7
, channel: [id: 0x786eaac2, L:/10.0.41.255:43594 - R:10.0.31.235/10.0.31.235:26379], command: CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@34d3a715(incomplete)], command=(SENTINEL SENTINELS), params=[mymaster], codec=org.redisson.client.codec.StringCodec]

reply: *2
$11
10.0.31.235
$4
6379
*5
*44
$4
name
$16
10.0.58.188:6379
$2
ip
$11
10.0.58.188
$4
port
$4
6379
$5
runid
$0

$5
flags
$12
s_down,slave
$21
link-pending-commands
$3
103
$13
link-refcount
$1
1
$14
last-ping-sent
$9
167589089
$18
last-ok-ping-reply
$9
167589089
$15
last-ping-reply
$9
167589089
$11
s-down-time
$9
167529071
$23
down-after-milliseconds
$5
60000
$12
info-refresh
$1
0
$13
role-reported
$5
slave
$18
role-reported-time
$9
167589089
$21
master-link-down-time
$1
0
$18
master-link-status
$3
err
$11
master-host
$1
?
$11
master-port
$1
0
$14
slave-priority
$3
100
$17
slave-repl-offset
$1
0
$17
replica-announced
$1
1
*42
$4
name
$15
10.0.60.42:6379
$2
ip
$10
10.0.60.42
$4
port
$4
6379
$5
runid
$40
38ac99a2a058225db080405b2701473967fa0a8c
$5
flags
$5
slave
$21
link-pending-commands
$1
0
$13
link-refcount
$1
1
$14
last-ping-sent
$1
0
$18
last-ok-ping-reply
$3
316
$15
last-ping-reply
$3
316
$23
down-after-milliseconds
$5
60000
$12
info-refresh
$4
9649
$13
role-reported
$5
slave
$18
role-reported-time
$9
167578985
$21
master-link-down-time
$1
0
$18
master-link-status
$2
ok
$11
master-host
$11
10.0.31.235
$11
master-port
$4
6379
$14
slave-priority
$3
100
$17
slave-repl-offset
$11
12625586437
$17
replica-announced
$1
1
*44
$4
name
$15
10.0.36.94:6379
$2
ip
$10
10.0.36.94
$4
port
$4
6379
$5
runid
$40
5de7475daacc09beb036ecbc0ced560a3db62b4b
$5
flags
$12
s_down,slave
$21
link-pending-commands
$2
60
$13
link-refcount
$1
1
$14
last-ping-sent
$9
167014504
$18
last-ok-ping-reply
$9
167015344
$15
last-ping-reply
$9
167015344
$11
s-down-time
$9
166954476
$23
down-after-milliseconds
$5
60000
$12
info-refresh
$9
167015560
$13
role-reported
$5
slave
$18
role-reported-time
$9
167589089
$21
master-link-down-time
$1
0
$18
master-link-status
$2
ok
$11
master-host
$11
10.0.31.235
$11
master-port
$4
6379
$14
slave-priority
$3
100
$17
slave-repl-offset
$10
9241323106
$17
replica-announced
$1
1
*42
$4
name
$15
10.0.56.43:6379
$2
ip
$10
10.0.56.43
$4
port
$4
6379
$5
runid
$40
1ccbc44a900dfea4c23c8f85cca350c75f1c335a
$5
flags
$5
slave
$21
link-pending-commands
$1
0
$13
link-refcount
$1
1
$14
last-ping-sent
$1
0
$18
last-ok-ping-reply
$3
316
$15
last-ping-reply
$3
316
$23
down-after-milliseconds
$5
60000
$12
info-refresh
$4
9649
$13
role-reported
$5
slave
$18
role-reported-time
$9
166976648
$21
master-link-down-time
$1
0
$18
master-link-status
$2
ok
$11
master-host
$11
10.0.31.235
$11
master-port
$4
6379
$14
slave-priority
$3
100
$17
slave-repl-offset
$11
12625586437
$17
replica-announced
$1
1
*44
$4
name
$16
10.0.14.221:6379
$2
ip
$11
10.0.14.221
$4
port
$4
6379
$5
runid
$0

$5
flags
$25
s_down,slave,disconnected
$21
link-pending-commands
$1
3
$13
link-refcount
$1
1
$14
last-ping-sent
$9
167589089
$18
last-ok-ping-reply
$9
167589089
$15
last-ping-reply
$9
167589089
$11
s-down-time
$9
167529071
$23
down-after-milliseconds
$5
60000
$12
info-refresh
$1
0
$13
role-reported
$5
slave
$18
role-reported-time
$9
167589089
$21
master-link-down-time
$1
0
$18
master-link-status
$3
err
$11
master-host
$1
?
$11
master-port
$1
0
$14
slave-priority
$3
100
$17
slave-repl-offset
$1
0
$17
replica-announced
$1
1
, channel: [id: 0x786eaac2, L:/10.0.41.255:43594 - R:10.0.31.235/10.0.31.235:26379], command: CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@25919dc9(incomplete)], command=(SENTINEL SLAVES), params=[mymaster], codec=org.redisson.client.codec.StringCodec]

reply: *2
$11
10.0.31.235
$4
6379
*5
*44
$4
name
$16
10.0.58.188:6379
$2
ip
$11
10.0.58.188
$4
port
$4
6379
$5
runid
$0

$5
flags
$12
s_down,slave
$21
link-pending-commands
$3
103
$13
link-refcount
$1
1
$14
last-ping-sent
$9
167589089
$18
last-ok-ping-reply
$9
167589089
$15
last-ping-reply
$9
167589089
$11
s-down-time
$9
167529071
$23
down-after-milliseconds
$5
60000
$12
info-refresh
$1
0
$13
role-reported
$5
slave
$18
role-reported-time
$9
167589089
$21
master-link-down-time
$1
0
$18
master-link-status
$3
err
$11
master-host
$1
?
$11
master-port
$1
0
$14
slave-priority
$3
100
$17
slave-repl-offset
$1
0
$17
replica-announced
$1
1
*42
$4
name
$15
10.0.60.42:6379
$2
ip
$10
10.0.60.42
$4
port
$4
6379
$5
runid
$40
38ac99a2a058225db080405b2701473967fa0a8c
$5
flags
$5
slave
$21
link-pending-commands
$1
0
$13
link-refcount
$1
1
$14
last-ping-sent
$1
0
$18
last-ok-ping-reply
$3
316
$15
last-ping-reply
$3
316
$23
down-after-milliseconds
$5
60000
$12
info-refresh
$4
9649
$13
role-reported
$5
slave
$18
role-reported-time
$9
167578985
$21
master-link-down-time
$1
0
$18
master-link-status
$2
ok
$11
master-host
$11
10.0.31.235
$11
master-port
$4
6379
$14
slave-priority
$3
100
$17
slave-repl-offset
$11
12625586437
$17
replica-announced
$1
1
*44
$4
name
$15
10.0.36.94:6379
$2
ip
$10
10.0.36.94
$4
port
$4
6379
$5
runid
$40
5de7475daacc09beb036ecbc0ced560a3db62b4b
$5
flags
$12
s_down,slave
$21
link-pending-commands
$2
60
$13
link-refcount
$1
1
$14
last-ping-sent
$9
167014504
$18
last-ok-ping-reply
$9
167015344
$15
last-ping-reply
$9
167015344
$11
s-down-time
$9
166954476
$23
down-after-milliseconds
$5
60000
$12
info-refresh
$9
167015560
$13
role-reported
$5
slave
$18
role-reported-time
$9
167589089
$21
master-link-down-time
$1
0
$18
master-link-status
$2
ok
$11
master-host
$11
10.0.31.235
$11
master-port
$4
6379
$14
slave-priority
$3
100
$17
slave-repl-offset
$10
9241323106
$17
replica-announced
$1
1
*42
$4
name
$15
10.0.56.43:6379
$2
ip
$10
10.0.56.43
$4
port
$4
6379
$5
runid
$40
1ccbc44a900dfea4c23c8f85cca350c75f1c335a
$5
flags
$5
slave
$21
link-pending-commands
$1
0
$13
link-refcount
$1
1
$14
last-ping-sent
$1
0
$18
last-ok-ping-reply
$3
316
$15
last-ping-reply
$3
316
$23
down-after-milliseconds
$5
60000
$12
info-refresh
$4
9649
$13
role-reported
$5
slave
$18
role-reported-time
$9
166976648
$21
master-link-down-time
$1
0
$18
master-link-status
$2
ok
$11
master-host
$11
10.0.31.235
$11
master-port
$4
6379
$14
slave-priority
$3
100
$17
slave-repl-offset
$11
12625586437
$17
replica-announced
$1
1
*44
$4
name
$16
10.0.14.221:6379
$2
ip
$11
10.0.14.221
$4
port
$4
6379
$5
runid
$0

$5
flags
$25
s_down,slave,disconnected
$21
link-pending-commands
$1
3
$13
link-refcount
$1
1
$14
last-ping-sent
$9
167589089
$18
last-ok-ping-reply
$9
167589089
$15
last-ping-reply
$9
167589089
$11
s-down-time
$9
167529071
$23
down-after-milliseconds
$5
60000
$12
info-refresh
$1
0
$13
role-reported
$5
slave
$18
role-reported-time
$9
167589089
$21
master-link-down-time
$1
0
$18
master-link-status
$3
err
$11
master-host
$1
?
$11
master-port
$1
0
$14
slave-priority
$3
100
$17
slave-repl-offset
$1
0
$17
replica-announced
$1
1
, channel: [id: 0x786eaac2, L:/10.0.41.255:43594 - R:10.0.31.235/10.0.31.235:26379], command: CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@65cf84fb(incomplete)], command=(SENTINEL GET-MASTER-ADDR-BY-NAME), params=[mymaster], codec=org.redisson.client.codec.StringCodec]

Redis version
6.2.5
Redisson version
3.16.4
Redisson configuration
Using redis sentinel configuration: mater=mymaster, nodes=[redis://redis-sentinel-node-0.redis-sentinel-headless:26379, redis://redis-sentinel-node-1.redis-sentinel-headless:26379, redis://redis-sentinel-node-2.redis-sentinel-headless:26379]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3933
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi!
In your application you use jcache 1.0.0 version. This version has not correct license file. This page https://github.com/jsr107/jsr107spec/commits/master/LICENSE.txt shows that license was change on Oct 11, 2015 and than was corrected from JSR-000107 JCACHE 2.9 Public Review - Updated Specification to Apache License, Version 2.0 on Oct 14, 2016.
Release jcache 1.0.0 was on 18 March 2014. LICENSE file version was: https://github.com/jsr107/jsr107spec/blob/v1.0.0/LICENSE.txt
This causes some problems with other users using your application. Using jcache 1.1.0 version or higher will help to resolve this problem.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3934
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
The connection pool remain stable and keep the number of opened connection to the minimum.
Actual behavior
Connection pool is full of blocked connection and redisson can't open another connection to perform any request.
Steps to reproduce or test case
We have not idea what was the cause of this. The only thing we know is:

We have one service that use redisson and on both instance of this service the number of opened connection has increased since 10 days without any connection being freed. When we restarted the two instances of the service, the number of open connections on our redis dropped by 80. On the JVM side, there is no thread stuck during this period.


We are using redisson for distributed task using the RScheduledExecutorService. It's possible to have task that are cancelled during execution.
Redis version
5.0.6
Redisson version
3.15.6
Redisson configuration
Replicated server with a node config containing one worker group of 5 with 8 redis thread, 16 netty thread and a the default MasterPubSub connection pool (24min, 64 max)
Here is some log about the problem after the connection pool is full of blocked connection:
Oct 30, 2021 @ 03:07:01.382 | ERROR | redisson-timer-4-1 | Can't process the remote service request with id 018e66f563eb11b7a9bbc0c6cab625427c | 
Oct 30, 2021 @ 03:06:48.782 | ERROR | redisson-timer-4-1 | Unable to acquire connection! RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@3bb0d6ab(failure: java.util.concurrent.CancellationException)]Increase connection pool size. Node source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null], command: (EVAL), params: [local expiredTaskIds = redis.call('zrangebyscore', KEYS[2], 0, ARGV[1], 'limit', 0, ARGV[2]); local ..., 4, {timerExecutor:org.redisson.executor.RemoteExecutorService}, {timerExecutor:org.redisson.executor.RemoteExecutorService}:scheduler, {timerExecutor:org.redisson.executor.RemoteExecutorService}:scheduler-channel, {timerExecutor:org.redisson.executor.RemoteExecutorService}:retry-interval, 1635556002381, 50] after 0 retry attempts | 
Oct 30, 2021 @ 03:06:37.282 | ERROR | redisson-timer-4-1 | Unable to acquire connection! RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@3f42e81b(failure: java.util.concurrent.CancellationException)]Increase connection pool size. Node source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null], command: (EVAL), params: [local expiredTaskIds = redis.call('zrangebyscore', KEYS[2], 0, ARGV[1], 'limit', 0, ARGV[2]); local ..., 4, {timerExecutor:org.redisson.executor.RemoteExecutorService}, {timerExecutor:org.redisson.executor.RemoteExecutorService}:scheduler, {timerExecutor:org.redisson.executor.RemoteExecutorService}:scheduler-channel, {timerExecutor:org.redisson.executor.RemoteExecutorService}:retry-interval, 1635555990882, 50] after 0 retry attempts | 
Oct 30, 2021 @ 03:06:24.382 | ERROR | redisson-timer-4-1 | Can't send response: RemoteServiceResponse [result=null, error=org.redisson.client.RedisTimeoutException: Unable to acquire connection! RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@4e06c5e7(failure: java.util.concurrent.CancellationException)]Increase connection pool size. Node source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null], command: (EVAL), params: [local scheduled = redis.call('zscore', KEYS[5], ARGV[3]);if scheduled == false then redis.call('hdel..., 6, {timerExecutor:org.redisson.executor.RemoteExecutorService}:counter, {timerExecutor:org.redisson.executor.RemoteExecutorService}:status, {timerExecutor:org.redisson.executor.RemoteExecutorService}:termination-topic, {timerExecutor:org.redisson.executor.RemoteExecutorService}:tasks, {timerExecutor:org.redisson.executor.RemoteExecutorService}:scheduler, {timerExecutor:org.redisson.executor.RemoteExecutorService}:retry-interval, 1, 2, ...] after 0 retry attempts] for request: RemoteServiceRequest [requestId=0142cded9f752cac200a1f5479f3bc7518, methodName=scheduleCallable, signature=[3143983607692024834, -697753227114447020], args=[org.redisson.executor.params.ScheduledParameters@5e6a753c], options=RemoteInvocationOptions[ackTimeoutInMillis=null, executionTimeoutInMillis=3600000], date=1635555941133] |
Oct 30, 2021 @ 03:06:18.030 | ERROR | redisson-3-3 | Can't execute: RemoteServiceRequest [requestId=0142cded9f752cac200a1f5479f3bc7518, methodName=scheduleCallable, signature=[3143983607692024834, -697753227114447020], args=[org.redisson.executor.params.ScheduledParameters@5e6a753c], options=RemoteInvocationOptions[ackTimeoutInMillis=null, executionTimeoutInMillis=3600000], date=1635555941133] |
Oct 30, 2021 @ 03:06:11.583 | ERROR | redisson-3-3 | [org.redisson.command.RedisExecutor$2.run(RedisExecutor.java:187), io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:669), io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:744), io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:469), io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30), java.base/java.lang.Thread.run(Thread.java:830)]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3935
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
我们spring应用的配置文件,密码都必须加密
希望可以在应用读取配置后把它解码然后才实例化RedissonClient
目前想到的方式是实现
org.springframework.beans.factory.config.BeanPostProcessor接口的postProcessAfterInitialization方法
在RedisProperties或RedissonProperties初始化后置处理，对密码进行解密
但是不知道有什么更加优雅的方法。
有没有类似
https://github.com/alibaba/druid/blob/1.2.8/src/main/java/com/alibaba/druid/pool/DruidAbstractDataSource.java#L1681-L1693
的方式?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3936
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I want to a sort queue and it can remove the duplicate elements.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3937
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Explored and Tried lot of ways to automate redis sentinel process of auto discovering failed/resurrected master node in Master Slave Setup.  Tried this setup in containerized environment, unless I manually restart one of the sentinels the old master node will be discovered by the sentinels and would be converted as slave in the new master.
Need immediate help for this issue
Sample Snippet of Redisson Sentinel Setup
@bean
@qualifier("redissonSentinelClient")
public RedissonClient redissonSentinelClient() {
Config config = new Config();
List sentinelAddresses = List.of(redisUrl+"redis-sentinel-1:26380",redisUrl+"redis-sentinel-2:26380",
redisUrl+"redis-sentinel-3:26380");
config.setCodec(new JsonJacksonCodec());
config.useSentinelServers()
.setMasterName(master)
.setSentinelAddresses(sentinelAddresses);
this.redissonClient = Redisson.create(config);
return redissonClient;
}
sample docker compose file for sentinel setup
redis-sentinel-1:
image: redis
container_name: redis-sentinel-1
command: >
bash -c "echo 'port 26380' > sentinel.conf &&
echo 'dir /tmp' >> sentinel.conf &&
echo 'sentinel resolve-hostnames yes' >> sentinel.conf &&
echo 'sentinel monitor mymaster master 6378 2' >> sentinel.conf &&
echo 'sentinel down-after-milliseconds mymaster 300' >> sentinel.conf &&
echo 'sentinel parallel-syncs mymaster 1' >> sentinel.conf &&
echo 'sentinel failover-timeout mymaster 200' >> sentinel.conf &&
echo 'protected-mode no' >> sentinel.conf &&
cat sentinel.conf &&
redis-server sentinel.conf --sentinel"
#ports:
#  - 26380:26380
depends_on:
- master
- slave-a
- slave-b
Please let me know what I'm missing in the setup and provide workaround at the earliest
Thanks
Varun
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3938
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Redis Sentinel should auto reconfigure the resurrected master from failover and be placed as slave under new master. This setup is working only when I manually restart one of the sentinel node
Actual behavior
Resurrected master from failover is not added back into master slave setup and becomes an independent node unless one of the sentinel node is restarted and old master becomes a slave to the new master
Steps to reproduce or test case

Setup a RedissonClient with Sentinel setup
@bean
@qualifier("redissonSentinelClient")
public RedissonClient redissonSentinelClient() {
Config config = new Config();
List sentinelAddresses = List.of(redisUrl+"redis-sentinel-1:26380",redisUrl+"redis-sentinel-2:26380",
redisUrl+"redis-sentinel-3:26380");
config.setCodec(new JsonJacksonCodec());
config.useSentinelServers()
.setMasterName(master)
.setSentinelAddresses(sentinelAddresses);
System.out.println("The Sentinel Address are : " + config.useSentinelServers().getSentinelAddresses());
System.out.println("The Sentinel Master name is : " + config.useSentinelServers().getMasterName());
this.redissonClient = Redisson.create(config);
return redissonClient;
}
Add Redis-sentinel as service in docker compose file
redis-sentinel-1:
image: redis
container_name: redis-sentinel-1
command: >
bash -c "echo 'port 26380' > sentinel.conf &&
echo 'dir /tmp' >> sentinel.conf &&
echo 'sentinel resolve-hostnames yes' >> sentinel.conf &&
echo 'sentinel monitor mymaster master 6378 2' >> sentinel.conf &&
echo 'sentinel down-after-milliseconds mymaster 300' >> sentinel.conf &&
echo 'sentinel parallel-syncs mymaster 1' >> sentinel.conf &&
echo 'sentinel failover-timeout mymaster 200' >> sentinel.conf &&
echo 'protected-mode no' >> sentinel.conf &&
cat sentinel.conf &&
redis-server sentinel.conf --sentinel"
#ports:
- 26380:26380
depends_on:

master
slave-a
slave-b



Redis version
6.2.6
Redisson version
3.16.4
Redisson configuration
@bean
@qualifier("redissonSentinelClient")
public RedissonClient redissonSentinelClient() {
Config config = new Config();
List sentinelAddresses = List.of(redisUrl+"redis-sentinel-1:26380",redisUrl+"redis-sentinel-2:26380",
redisUrl+"redis-sentinel-3:26380");
config.setCodec(new JsonJacksonCodec());
config.useSentinelServers()
.setMasterName(master)
.setSentinelAddresses(sentinelAddresses);
System.out.println("The Sentinel Address are : " + config.useSentinelServers().getSentinelAddresses());
System.out.println("The Sentinel Master name is : " + config.useSentinelServers().getMasterName());
this.redissonClient = Redisson.create(config);
return redissonClient;
}
@bean
public RMapCache<Long, Employee> employeeRMapCache() {
MapOptions<Long,Employee> options =  MapOptions.<Long,Employee>defaults().loader(mapLoader());
final RMapCache<Long, Employee> EmployeeRMapCache = redissonSentinelClient().getMapCache(CACHE_NAME,options);
return EmployeeRMapCache;
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3939
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello,
There is a significant performance drop and loss of scalability after upgrading Redisson client from 2.2.12 to 3.10.6.
The performance (throughput - number of requests per second) dropped by almost 40% and the scalability of the Spring-boot app using it was lost, meaning that adding more instances of the Spring-boot app doesn't increase the system's throughput.
Some technical details:
Redis 3.0.7 64 bit in cluster mode - 3 masters and 3 slaves.
Spring-boot 1.4.1.RELEASE (12 instances, one on its own machine)
Please find attached redisson.json file redisson-3.10.6.json.txt
The reason why the client was originally upgraded was because of the following error that appeared in the log:

ERROR - An error occurred when opening a session. Error: Can't aquire connection to /10.110.195.54:7000 org.redisson.client.RedisConnectionException: Can't aquire connection to /10.110.195.54:7000
at org.redisson.connection.pool.ConnectionPool.get(ConnectionPool.java:180)

With the previous client version the performance was excellent and the solution was scalable.
Please advise.
Regards,
Nethanel
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3940
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We observed and intermittent issue after Azure Redis scheduled maintenance.
The issue occurred on one of service pods; other pods didn't experience the same issue.
Our application creates a pub/sub listener, publishes messages every second but doesn't get these events back; as a result it thinks Redisson-Redis connection is broken and so resubscribes, but the same issue occurs even with new listeners. The issue has persisted for many hours, even though Redis maintenance was fairly short.
In attached logs (both from our service and from Redisson) following can be seen:
// we subscribe to vrckc-redis-hb-7bbb8f6c4b-hb67l topic
08/11/2021 11:08:24.825 [RMS] INFO com.avaya.vrc.kc.ixil.RedissonMessageSubscriber subscribe() vrckc-redis-hb-7bbb8f6c4b-hb67l => sl=1964278001, l=1880120247
// we publish messages on this topic every second and Redisson APIs return without errors
08/11/2021 11:08:24.827 [RMS] TRACE com.avaya.vrc.kc.ixil.RedissonMessageSubscriber publishHeartbeat() 1636369704825 in 1 ms
08/11/2021 11:08:25.827 [RMS] TRACE com.avaya.vrc.kc.ixil.RedissonMessageSubscriber publishHeartbeat() 1636369705825 in 2 ms
08/11/2021 11:08:26.828 [RMS] TRACE com.avaya.vrc.kc.ixil.RedissonMessageSubscriber publishHeartbeat() 1636369706826 in 2 ms
08/11/2021 11:08:27.828 [RMS] TRACE com.avaya.vrc.kc.ixil.RedissonMessageSubscriber publishHeartbeat() 1636369707826 in 2 ms
08/11/2021 11:08:28.828 [RMS] TRACE com.avaya.vrc.kc.ixil.RedissonMessageSubscriber publishHeartbeat() 1636369708826 in 2 ms
08/11/2021 11:08:29.828 [RMS] TRACE com.avaya.vrc.kc.ixil.RedissonMessageSubscriber publishHeartbeat() 1636369709826 in 2 ms
// we didn't get notified about any of 6 messages sent before so we think Redisson-Redis connection is down
08/11/2021 11:08:30.827 [RMS] WARN com.avaya.vrc.kc.ixil.RedissonMessageSubscriber publishHeartbeat() heartbeats not received in a timely manner. c=1636369710827, lr=1636369704825, lp=1636369709826
Expected behavior
Published messages are received back
Actual behavior
Published messages are not received back
Steps to reproduce or test case
Issue intermittent, observed after Azure Redis scheduled maintenance on one of service pods; other pods didn't experience the same issue
Redis version
Redisson version
3.15.6
Redisson configuration
config: ---
clusterServersConfig:
idleConnectionTimeout: 10000
connectTimeout: 15000
timeout: 3000
retryAttempts: 3
retryInterval: 1500
password: "..."
subscriptionsPerConnection: 5
sslEnableEndpointIdentification: true
sslProvider: "JDK"
pingConnectionInterval: 5000
keepAlive: true
tcpNoDelay: true
nameMapper: !<org.redisson.api.DefaultNameMapper> {}
loadBalancer: !<org.redisson.connection.balancer.RoundRobinLoadBalancer> {}
slaveConnectionMinimumIdleSize: 24
slaveConnectionPoolSize: 64
failedSlaveReconnectionInterval: 3000
failedSlaveCheckInterval: 60000
masterConnectionMinimumIdleSize: 24
masterConnectionPoolSize: 64
readMode: "MASTER"
subscriptionMode: "SLAVE"
subscriptionConnectionMinimumIdleSize: 1
subscriptionConnectionPoolSize: 50
dnsMonitoringInterval: 5000
natMapper: !<org.redisson.api.DefaultNatMapper> {}
nodeAddresses:
"rediss://ixcc-qa-redis.redis.cache.windows.net:6380"
scanInterval: 5000
checkSlotsCoverage: true
threads: 16
nettyThreads: 16
codec: !<org.redisson.client.codec.StringCodec> {}
referenceEnabled: true
transportMode: "NIO"
lockWatchdogTimeout: 30000
reliableTopicWatchdogTimeout: 600000
keepPubSubOrder: true
useScriptCache: false
minCleanUpDelay: 5
maxCleanUpDelay: 1800
cleanUpKeysAmount: 100
nettyHook: !<org.redisson.client.DefaultNettyHook> {}
useThreadClassLoader: true
addressResolverGroupFactory: !<org.redisson.connection.DnsAddressResolverGroupFactory> {}

fragment.log
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3941
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Sorry, copied code from other projects isn't allowed.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3942
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3943
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
can't get  envirement variable config,@buildstep is Before it
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3944
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
when i  use stringRedisTemplate.getExpire(key, TimeUnit) to judge key is not set expire time, i expect -1, but it return 0.however i user spring-boot-starter-data-redis, it return -1 with expect. here is the environment:
the redis i use is sentinel , and redisson version is 3.16.1 or 3.11.1, springboot version 2.1.6.RELEASE
here is the test case and result:
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3945
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hey,
In the production environment, we found that the memory occupied by the program has been increasing. Using the top command, we found that the value of RES has been increasing, even exceeding Xmx. We use jconsole.exe to observe that the number of threads and classes is stable, and the size of heap memory and meta space are within the normal range. Therefore, we begin to suspect that the program is constantly occupying native memory and is not released.
When we use gperftools to analyze the memory allocation occupied by the program, we will find that the method unsafe.Allocatememory0 occupies a very large proportion of memory and increases over time.


This is the original PDF file generated using gperftools analyzer memory
redisson-demo_1318.pdf
redisson-demo_1450.pdf
After debugging with debug, it is found that the thread redisson-netty calls unsafe.Allocatememory().

After modifying the redisson configuration so that redisson is no longer used to connect to redis, we use gperftools to observe that there is no Unsafe_AllocateMemory0, and the memory occupied by the program remains stable and will not increase,so we now suspect that redisson caused the program's native memory leak
Expected behavior
We hope to get your help so that we can use redisson without increasing the memory all the time
My environment
redis 5.0.12
redisson 3.12.4
springboot 2.4.2
openjdk version "11" 2018-09-25
redisson config
redisson:
  address: redis://127.0.0.1:6379
  password: ''
  threads: 32
  nettyThreads: 100
  connectionPoolSize: 100
  masterConnectionMinimumIdleSize: 10
  slaveConnectionPoolSize: 100
  slaveConnectionMinimumIdleSize: 10
  masterConnectionPoolSize: 100
  connectionMinimumIdleSize: 10
  bloomfilterDefaultExpectedInsertions: 1000
  bloomfilterDefaultFalseProbability: 0.05

Steps to reproduce or test case
redisson_demo.zip

unzip redisson_ demo.zip
modify start.sh to set your redis address
execute start.sh to start the jar
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3946
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
What can cause such an error?
Exception in thread "redisson-3-4" java.lang.ClassCastException: java.lang.String cannot be cast to java.util.Set
	at org.redisson.RedissonMap.readAllEntrySet(zb:513)
	at org.redisson.spring.session.RedissonSessionRepository$RedissonSession.load(RedissonSessionRepository.java:97)
	at org.redisson.spring.session.RedissonSessionRepository.findById(RedissonSessionRepository.java:319)
	at org.redisson.spring.session.RedissonSessionRepository.onMessage(RedissonSessionRepository.java:261)
	at org.redisson.spring.session.RedissonSessionRepository.onMessage(RedissonSessionRepository.java:53)
	at org.redisson.d.onPatternMessage(ol:156)
	at org.redisson.client.RedisPubSubConnection.onMessage(RedisPubSubConnection.java:84)
	at org.redisson.client.handler.CommandPubSubDecoder.lambda$enqueueMessage$0(CommandPubSubDecoder.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
[epollEventLoopGroup-2-5] WARN io.netty.channel.DefaultChannelPipeline - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
java.lang.IncompatibleClassChangeError: Found interface org.objectweb.asm.MethodVisitor, but class was expected
	at com.esotericsoftware.reflectasm.ConstructorAccess.insertConstructor(ConstructorAccess.java:128)
	at com.esotericsoftware.reflectasm.ConstructorAccess.get(ConstructorAccess.java:98)
	at com.esotericsoftware.kryo.Kryo$DefaultInstantiatorStrategy.newInstantiatorOf(Kryo.java:1271)
	at com.esotericsoftware.kryo.Kryo.newInstantiator(Kryo.java:1127)
	at com.esotericsoftware.kryo.Kryo.newInstance(Kryo.java:1136)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.create(FieldSerializer.java:562)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:538)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:813)
	at org.redisson.codec.KryoCodec$1.decode(KryoCodec.java:126)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:402)
	at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:446)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:411)
	at org.redisson.client.handler.CommandDecoder.decodeCommandBatch(CommandDecoder.java:300)
	at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:233)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:160)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:129)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502)
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:796)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:432)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:333)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:906)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3947
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I want to configure Redisson Client to connect it to AWS ElasticCache. There is not much documentation that what's the best practice to do so.
AWS ElasticCache provides Primary Endpoint and Reader Endpoint for writes and reads respectively.
Now instead of mentioning each nodes endpoint I would prefer to use Primary Endpoint and Reader Endpoint.
But from what I saw in multiple github issues in this repo, it was advises to use node endpoints directly. Why was that ? Reader Endpoint helps me to add more servers to Redis without changing the code base. Will Redisson pick up more servers automatically ?
Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3948
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Redisson shall be able to support sentinel authentication.
Maybe a sentinelUsername shall suffice.
Actual behavior
Only the sentinel Password is used for authentication
Steps to reproduce or test case
Redis version
6.2.6
Redisson version
3.16.4
Redisson configuration
username:  "myserusername"
password: "myserverpassword"
...
sentinelPassword: "mysentinelpassword"
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3949
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I tried integrating redisson into our springboot project, but got the following error upon adding the dependency:
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.cache.annotation.ProxyCachingConfiguration': Unsatisfied dependency expressed through method 'setConfigurers' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'cacheConfig': Initialization of bean failed; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.cache.config.internalJCacheAdvisor' defined in class path resource [org/springframework/cache/jcache/config/ProxyJCacheConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.cache.jcache.interceptor.BeanFactoryJCacheOperationSourceAdvisor]: Factory method 'cacheAdvisor' threw exception; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'jCacheOperationSource' defined in class path resource [org/springframework/cache/jcache/config/ProxyJCacheConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.cache.jcache.interceptor.JCacheOperationSource]: Factory method 'cacheOperationSource' threw exception; nested exception is java.lang.NoSuchFieldError: cacheManager
Here are all the Redis-related dependencies we have:
implementation "redis.clients:jedis:3.6.1"
implementation "org.springframework.boot:spring-boot-starter-data-redis:2.5.2"
implementation "org.redisson:redisson:3.16.4"
Before adding redisson dependency, there was no error. I was wondering if there is any conflict between these dependencies or their versions? Thanks.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3950
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
hello, I believe that I have fixed the issue in  #3875 please check it out and let me know
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3951
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3952
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I don't want to give my email address, so please fix it yourself
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3953
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello.
We have a huge sorted set (1m+ elements), that should be processed in parallel by different application instances. We came up to the idea to have a LUA script that will call a ZSCAN command using a saved cursor to return each element to app only once. Due to single-threaded nature of Redis engine, it would make a iterator, shared across all clients.
I didn't find anything like it in Redisson. If you think that this feature would be useful, I can prepare a PR in a week. If not - sorry for disturbance
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3954
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3955
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi!
First of all, thanks for an amazing library! 🌟
I'm looking for advice here on the client configuration for the following setup:
Redis 4 instance consists of:

1 master
2 slaves
sentinels

All servers are, so to say, ephemeral, and hence in front of the instances, there is haproxy server + bird2 that together achieve anycast advertisement of a fixed IP address and proxy traffic to the current master. Users are instructed to connect to master only and given the DNS entry for the anycast IP. Slaves are not in use and are only there to pick up the role of master in the event of the failover. Setup is similar to what is described in haproxy blog.
As a result, for Redission client I have only a single host:ip endpoint to use in configuration. I tried configuring Redission with both:

useSingleServer().setAddress("redis://anycasted-ip:port") and
useReplicatedServers().addNodeAddress("redis://anycasted-ip:port")

It seems neither of these two appear to be able to detect a failover event. When failover happens and a new master is elected, Redission keeps using existing established connections trying to write to what now became a slave, and getting:
READONLY You can't write against a read-only slave

My question is: isn't useReplicatedServers() supposed to periodically check the actual ROLE of a server it is connected to, so that when such a "silent" change in topology happens behind haproxy? Could it be that it is a problem on haproxy side, that keeps proxying traffic through open connections to previously connected node? I'd expect exactly a periodic ROLE check to address this.
Thank you.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3956
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello,
After deploying redisson to my tomcat cluster sessionID does not update at all and it is causing all kinds of problems.
context.xml:
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3957
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We have a Problem were subscriptions seem to be removed (still in PublishSubscribeService#name2PubSubConnection but not showing on redis server itself)
Expected behavior
PubSubConnections should not be closed
Actual behavior
PubSubConnections get closed even with multiple active subscriptions that don't get reconnected from watchdog as the RedisConnection was marked as closed via setClosed(true)
	at org.redisson.client.RedisConnection.closeAsync(RedisConnection.java:353) ~[?:?]
	at org.redisson.connection.IdleConnectionWatcher.lambda$new$1(IdleConnectionWatcher.java:77) ~[?:?]
	at io.netty.util.concurrent.PromiseTask.runTask(PromiseTask.java:98) [our-jar]
	at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:176) [our-jar]
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164) [our-jar]
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472) [our-jar]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500) [our-jar]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) [our-jar]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [our-jar]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [our-jar]
	at java.base/java.lang.Thread.run(Thread.java:832) [?:?]

Steps to reproduce or test case
Not yet but maybe if you could point us in a direction
Redis version
5.0.3
Redisson version
3.16.4
Redisson configuration
Single node with
useThreadClassLoader=: alse
nettyThreads: 4
subscriptionConnectionPoolSize: 12
connectionMinimumIdleSize: 6
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3958
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In https://github.com/redisson/redisson/wiki/2.-Configuration#242-cluster-yaml-config-format
i see parameter and its value (codec and the class that implements it):
codec: !<org.redisson.codec.MarshallingCodec> {}
But what do the symbols mean:

! (exclamation mark)
<> (angle brackets)
{} (curly brackets)

?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3959
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
throw error
Caused by: java.lang.NullPointerException: null
	at java.base/java.io.Reader.<init>(Reader.java:167) ~[na:na]
	at java.base/java.io.InputStreamReader.<init>(InputStreamReader.java:72) ~[na:na]
	at org.redisson.config.ConfigSupport.fromYAML(ConfigSupport.java:174) ~[redisson-3.16.4.jar:3.16.4]
	at org.redisson.config.Config.fromYAML(Config.java:632) ~[redisson-3.16.4.jar:3.16.4]
	at org.redisson.mybatis.RedissonCache.setRedissonConfig(RedissonCache.java:106) ~[redisson-mybatis-3.16.4.jar:3.16.4]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:566) ~[na:na]
	at org.apache.ibatis.reflection.invoker.MethodInvoker.invoke(MethodInvoker.java:44) ~[mybatis-3.5.7.jar:3.5.7]
	at org.apache.ibatis.reflection.wrapper.BeanWrapper.setBeanProperty(BeanWrapper.java:180) ~[mybatis-3.5.7.jar:3.5.7]
	... 63 common frames omitted
Steps to reproduce or test case
add StudentMapper.java
@Mapper
public interface StudentMapper extends BaseMapper<StudentPo> {
    @Override
    StudentPo selectById(@Param("id") Serializable id);
}
add StudentMapper.xml
<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd" >
<mapper namespace="io.github.gcdd1993.mybatis.cache.mapper.StudentMapper">
    <cache type="org.redisson.mybatis.RedissonCache">
        <property name="timeToLive" value="200000"/>
        <property name="maxIdleTime" value="100000"/>
        <property name="maxSize" value="100000"/>
        <property name="redissonConfig" value="redisson.yaml"/>
    </cache>
    <select id="selectById" resultType="io.github.gcdd1993.mybatis.cache.model.StudentPo">
        select *
        from student
        where id = #{id}
    </select>
</mapper>
add redisson.yaml at src/main/resources/redisson.yaml
singleServerConfig:
  address: "redis://127.0.0.1:16379"
at org.redisson.mybatis.RedissonCache#105, i found
InputStream is = getClass().getResourceAsStream(config);
is it should be InputStream is = getClass().getClassLoader().getResourceAsStream(config);?
Redis version
6.2.6
Redisson version
3.16.4
Redisson configuration
src/main/resources/redisson.yaml
singleServerConfig:
  address: "redis://127.0.0.1:16379"
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3960
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Will fix DCO later
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3961
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello,
I am trying to fetch  a value for a particular key from a replicated  multinode cluster.  This cluster has 2 nodes. Node1, Node2 with authentication on. I am inserting values and trying to fetch the same value.
Key-value pair insertion happened in node1. And while fetching the same key-value pair , I am suspecting it it trying to get it from node2.
Please find my code below
--configuration
Config config = new Config();
config.useReplicatedServers()
.addNodeAddress(node1).addNodeAddress(node2).setUsername(userName).setPassword(password)
.setReadMode(ReadMode.MASTER_SLAVE);
multiInstanceClient = Redisson.create(config);
---storig
if (redissonClient != null) {
RMapCache<String, String> cache = redissonClient.getMapCache(CLIENT_MAP, StringCodec.INSTANCE);
cache.put(tokenId, tokenValue,ttl,  TimeUnit.SECONDS);
return true;
}
--- fetching the value
if (redissonClient != null) {
RMapCache<Object, Object> cache = redissonClient.getMapCache(CLIENT_MAP);
if (!cache.isEmpty()) {    // size is 3 and the key is present in the list but still returning null on cache.get(key)
return cache.get(key) != null ? cache.get(key).toString() : null;
}
}
From redis cli I had to do readonly on node2 inorder to c the keys. If readonly is only option to fetch the key-value pair from java code, how to code it?
Help is appreciated . Thank you in advance.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3962
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I got such an error when I try to clear the RedissonLocalCachedMap.
Redisson version:3.16.3 
2021-11-19 11:45:11:912 [redisson-netty-2-6] TRACE org.redisson.client.handler.CommandPubSubDecoder.decode:134 - reply: *3
$7
message
$43
{bdcampus:bdcampus-bind-fullKeyCache}:topic
$115
{"@class":"org.redisson.cache.LocalCachedMapClear","releaseSemaphore":false,"requestId":"cB+BvVX2HzwIsdIW11VcsA=="}
, channel: [id: 0x00eb8b6e, L:/100.66.209.243:49952 - R:redis-cluster/100.66.209.208:6379], command: null
2021-11-19 11:45:11:912 [redisson-netty-2-3] DEBUG org.redisson.command.RedisExecutor.releaseConnection:536 - connection released for command (EVALSHA) and params [34cf7f8699dd099ce2a9aa94e01d4942168c7a3f, 3, bdcampus:bdcampus-bind-fullKeyCache, {bdcampus:bdcampus-bind-fullKeyCache}:topic, redisson__cache_updates_log:{bdcampus:bdcampus-bind-fullKeyCache}, PooledUnsafeDirectByteBuf(ridx: 0, widx: 115, cap: 256), PooledUnsafeDirectByteBuf(ridx: 0, widx: 22, cap: 256), PooledUnsafeDirectByteBuf(ridx: 0, widx: 60, cap: 256)] from slot NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null] using connection RedisConnection@1829243899 [redisClient=[addr=redis://redis-cluster:6379], channel=[id: 0xc6fc6d40, L:/100.66.209.243:49954 - R:redis-cluster/100.66.209.208:6379], currentCommand=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@c12e552(success: true)], command=(EVALSHA), params=[34cf7f8699dd099ce2a9aa94e01d4942168c7a3f, 3, bdcampus:bdcampus-bind-fullKeyCache, {bdcampus:bdcampus-bind-fullKeyCache}:topic, redisson__cache_updates_log:{bdcampus:bdcampus-bind-fullKeyCache}, PooledUnsafeDirectByteBuf(ridx: 0, widx: 115, cap: 256), PooledUnsafeDirectByteBuf(ridx: 0, widx: 22, cap: 256), PooledUnsafeDirectByteBuf(ridx: 0, widx: 60, cap: 256)], codec=org.redisson.client.codec.LongCodec], usage=0]
2021-11-19 11:45:11:913 [redisson-netty-2-6] ERROR org.redisson.client.handler.CommandPubSubDecoder.decodeCommand:88 - Unable to decode data. channel: [id: 0x00eb8b6e, L:/100.66.209.243:49952 - R:redis-cluster/100.66.209.208:6379], reply: ReplayingDecoderByteBuf(ridx=190, widx=190)
java.lang.IllegalArgumentException: Can't parse packet
	at org.redisson.cache.LocalCachedMessageCodec$1.decode(LocalCachedMessageCodec.java:112)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:383)
	at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:427)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:392)
	at org.redisson.client.handler.CommandPubSubDecoder.decodeCommand(CommandPubSubDecoder.java:84)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:137)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:94)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:501)
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
2021-11-19 11:45:11:913 [redisson-netty-2-6] ERROR org.redisson.client.handler.ErrorsLoggingHandler.exceptionCaught:47 - Exception occured. Channel: [id: 0x00eb8b6e, L:/100.66.209.243:49952 - R:redis-cluster/100.66.209.208:6379]
io.netty.handler.codec.DecoderException: java.lang.IllegalArgumentException: Can't parse packet
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:421)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: Can't parse packet
	at org.redisson.cache.LocalCachedMessageCodec$1.decode(LocalCachedMessageCodec.java:112)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:383)
	at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:427)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:392)
	at org.redisson.client.handler.CommandPubSubDecoder.decodeCommand(CommandPubSubDecoder.java:84)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:137)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:94)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:501)
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
	... 17 common frames omitted
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3963
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi, I am having trouble injecting beans into scheduled tasks. I am able to connect with redis to do other things so I don't believe it is a configuration issue.  ​I saw someone else had posted a similar issue but it seems like it got closed without being resolved: #2318
Essentially, I am trying to schedule a tasks on a distributed server to send a reminder to a user after x amount of time. In order to do this, I need to inject a bean to be able to get the current state of the user at the time the task is executed and another bean to be able to send the notification. However, I am running into the same Null Pointer and Not Serializable exceptions as from the issue above.
I have also tried another approach where I register the task to a RRemoteService so when it tries to execute, it will call a server-side RRemoteService that has the dependencies autowired. However, when I do that, it gives an IllegalArgumentException: Unable to serialize lambda.
I'm pretty stuck on what to do and I was wondering if someone could help provide guidance on if this would even be possible with Redisson or if I should try to find another solution? It would be helpful if someone could provide an example of an @Autowired service being injected into a task and it working.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3964
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
springboot start is ok
the redisson and redis  initialize is ok
now, stringRedisTemplate  can set value ，but get value is null
o.r.cluster.ClusterConnectionManager Redis cluster nodes configuration got from /ip:8010:
c3bbb85e6f200xxxx21a0d8565c6f6e ip:8010@18010 master - 0 1637305290350 3 connected 5461-10922
8e53000a0c899xxxxece55b0bdfcb33 ip:8011@18011 slave 01757b52eb979ce033a1e432b39f8a50ad618f67 0 1637305291351 5 connected
ac91af2954dadxxxxc3f24063c068ca ip:8010@18010 myself,master - 0 1637305290000 1 connected 0-5460
b2c347e18d3f1xxxxb3dc7719d32469 ip:8011@18011 slave c3bbb85e6f200ad51d6f340b6721a0d8565c6f6e 0 1637305290549 6 connected
01757b52eb979xxxx9f8a50ad618f67 ip:8010@18010 master - 0 1637305289548 5 connected 10923-16383
c388804b57f8axxxx9c23b1d2e8a5cd ip:8011@18011 slave ac91af2954dad6da0ba19fa272c3f24063c068ca 0 1637305290000 4 connected
c.z.s.b.a.c.redis.RedisBidConfig setKey:biaoshuFile:908279900552007681:909736514967568385
c.z.s.b.a.c.redis.RedisBidConfig StringRedisTemplate标识：null
c.z.s.b.a.c.redis.RedisBidConfig StringRedisTemplate-xxp标识：null
c.z.s.b.a.c.redis.RedisBidConfig stringRedisTemplate,org.springframework.data.redis.core.StringRedisTemplate@67c6cf76
c.z.s.b.a.c.redis.RedisBidConfig getKey:biaoshuFile:908279900552007681:909736514967568385
c.z.s.b.a.c.redis.RedisBidConfig StringRedisTemplate标识：null
c.z.s.b.a.c.redis.RedisBidConfig StringRedisTemplate-xxp标识：null
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3965
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello, i search distributed lock, that if one redis instance crash all setted locks can be transfered and accessed from other redis instances.
I think this situation is solved only by redlock or multilock with 3 redis master nodes but not cluster ?
In documentation:
8.4. RedLock
This object is deprecated. RLock operations now propagated to all Redis slaves.

Is a blocking redundancy scheme possible with master-slave replication(sentinel, not cluster) ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3966
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
We found an unexpected behavior using the Redisson local cache in our application.
This application is loading a redis map constantly using Redisson local cache, executing put and get operations.
The get operation returns the expected value almost all the time, but sometimes we found that it does not return the expected value. The expected value is what the application just put before the get operation.
This is something that only happens when we use a LocalCachedMap. If we switch to a Map then it works as expected. Anyway, we need to use a LocalCachedMap in this application.
In short: we expect to execute a put operation, then a get operation with the same key and receive the value that we just put before.
Actual behavior
Sometimes we execute a put operation on a "localCachedMap", then a get operation with the same key and receive a different value than what we just put before.
Steps to reproduce or test case
A test to reproduce the issue:
@Test
public void testLocalCacheMultiplePutAndGet() {
    RMap<String, String> map = redisson.getLocalCachedMap("test", LocalCachedMapOptions.defaults());

    for (int i = 0; i < 50_000; i++) {
        map.delete();

        map.put("key", "value1");
        String cachedValue1 = map.get("key");

        map.put("key", "value2");
        String cachedValue2 = map.get("key");

        assertThat(cachedValue2).as("iteration " + i).isEqualTo("value2");
    }
}
It fails on different iterations when you execute the test more than once:
org.opentest4j.AssertionFailedError: [iteration 305] 
expected: "value2"
 but was: "value1"

(...)

org.opentest4j.AssertionFailedError: [iteration 1226] 
expected: "value2"
 but was: "value1"

(...)

org.opentest4j.AssertionFailedError: [iteration 342] 
expected: "value2"
 but was: "value1"

We tried to remove the line 292 from RedissonLocalCachedMap.getAsync() and the test just works:
future.onComplete((value, e) -> {
    if (e != null) {
        return;
    }
    
    if (storeCacheMiss || value != null) {
//        cachePut(cacheKey, key, value);
    }
});
But we don't know why it reaches that line because the getAsync() method should end on line 262 when it finds the value on the local cache (the value should be on the local cache because we execute a put before the get):
if (cacheValue != null && (storeCacheMiss || cacheValue.getValue() != null)) {
    return RedissonPromise.newSucceededFuture((V) cacheValue.getValue());
}
Redis version
Redis 5.0.7
Redisson version
3.16.5-SNAPSHOT
Redisson configuration
Default configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3967
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
How to get rid of this too much log? I use this dependency. i do not have anything else. logging.level.root=off does not help.
		<dependency>
			<groupId>org.redisson</groupId>
			<artifactId>redisson-spring-boot-starter</artifactId>
			<version>3.16.2</version>
		</dependency>

15:14:56.022 [redisson-netty-2-13] DEBUG org.redisson.connection.ClientConnectionsEntry - new pubsub connection created: RedisPubSubConnection@1592540002 [redisClient=[addr=redis://127.0.0.1:6379], channel=[id: 0x00142ce9, L:/127.0.0.1:65416 - R:127.0.0.1/127.0.0.1:6379], currentCommand=null]
15:14:56.025 [redisson-netty-2-15] DEBUG org.redisson.connection.ClientConnectionsEntry - new connection created: RedisConnection@1511803612 [redisClient=[addr=redis://127.0.0.1:6379], channel=[id: 0x73552984, L:/127.0.0.1:65411 - R:127.0.0.1/127.0.0.1:6379], currentCommand=null]
15:14:56.027 [redisson-netty-2-16] DEBUG org.redisson.connection.ClientConnectionsEntry - new connection created: RedisConnection@108778343 [redisClient=[addr=redis://127.0.0.1:6379], channel=[id: 0xd6f062fe, L:/127.0.0.1:65412 - R:127.0.0.1/127.0.0.1:6379], currentCommand=null]
15:14:56.027 [redisson-netty-2-17] DEBUG org.redisson.connection.ClientConnectionsEntry - new connection created: RedisConnection@1763894632 [redisClient=[addr=redis://127.0.0.1:6379], channel=[id: 0x3bda704e, L:/127.0.0.1:65409 - R:127.0.0.1/127.0.0.1:6379], currentCommand=null]
15:14:56.031 [redisson-netty-2-23] DEBUG org.redisson.connection.ClientConnectionsEntry - new connection created: RedisConnection@405954248 [redisClient=[addr=redis://127.0.0.1:6379], channel=[id: 0xadaf551e, L:/127.0.0.1:65414 - R:127.0.0.1/127.0.0.1:6379], currentCommand=null]
15:14:56.030 [redisson-netty-2-21] DEBUG org.redisson.connection.ClientConnectionsEntry - new connection created: RedisConnection@1967836677 [redisClient=[addr=redis://127.0.0.1:6379], channel=[id: 0x7d0af250, L:/127.0.0.1:65417 - R:127.0.0.1/127.0.0.1:6379], currentCommand=null]
15:14:56.029 [redisson-netty-2-18] DEBUG org.redisson.connection.ClientConnectionsEntry - new connection created: RedisConnection@722387409 [redisClient=[addr=redis://127.0.0.1:6379], channel=[id: 0x96a31b96, L:/127.0.0.1:65410 - R:127.0.0.1/127.0.0.1:6379], currentCommand=null]
15:14:56.037 [redisson-netty-2-13] INFO org.redisson.connection.pool.MasterPubSubConnectionPool - 1 connections initialized for 127.0.0.1/127.0.0.1:6379
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3968
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
How to get the list of group names associated with a stream?
I was hoping I could see the group names by calling stream.getInfo(). But we do not have any.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3969
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Local cache exists after redis' key expired. Here is my code:
RLocalCachedMap<Object, Object> map = Redisson.create().getLocalCachedMap("testMap", LocalCachedMapOptions.defaults());
map.put("aaa", "bbb");
map.expire(10000L, TimeUnit.MILLISECONDS);
Thread.sleep(20000L);
Object val = map.get("aaa");

Expected result: val is null.
Actual result: val is "bbb".
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3970
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3971
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3972
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We are experiencing the error what seems like network related errors using the 3.13.2 version of redisson.
Caused by: org.redisson.client.RedisTimeoutException: Command still hasn't been written into connection! Increase nettyThreads and/or retryInterval settings. Payload size in bytes: 0. Node source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null], connection: RedisConnection@1897737917 [redisClient=[addr=redis://10.0.2.185:6379], channel=[id: 0xcfc764bc, L:/172.xx.xx.xx:36380 - R:/10.0.2.185:6379], currentCommand=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@7fdadeee(failure: java.util.concurrent.CancellationException)], command=(GET), params=[[115, 101, 114, 118, 105, 99, 101, 58, 109, 101, ...]], codec=org.redisson.client.codec.ByteArrayCodec]], command: (GET), params: [[115, 101, 114, 118, 105, 99, 101, 58, 109, 101, ...]] after 3 retry attempts
at org.redisson.command.RedisExecutor$2.run(RedisExecutor.java:200)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:672)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:747)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:472)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
... 1 common frames omitted

config:
nettyThreads: 32
retryInterval: 1.5s

We run  code in the docker of rancher,  then have been occurred  on some pods. so confused am I.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3973
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
for(String key:keys){ 
batch.getMap(key).readAllMapAsync(); 
}
BatchResult<?> result = batch.execute(); 
pipelineMapList = (List<Map<String, String>>) result.getResponses(); 

Are pipelineMapList and keys kept the same order? If not, is there a way to get ordered result with response to the keys order.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3974
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redisson:3.16.3
2021-11-23T09:19:58.498Z APP 2021-11-23 09:19:58.445 [redisson-timer-4-1] ERROR org.redisson.client.handler.PingConnectionHandler - Unable to send PING command over channel: [id: 0x47a3d5e2, L:/1**..118.:38562 - R:.6.79.87/.6.79.87:6381]
2021-11-23T09:19:58.499Z APP  at org.redisson.client.RedisConnection.lambda$async$1(RedisConnection.java:255)
2021-11-23T09:19:58.499Z APP org.redisson.client.RedisTimeoutException: Command execution timeout for command: (PING), params: [], Redis client: [addr=redis://**.6.79.87:6381]
2021-11-23T09:19:58.500Z APP  at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:747)
2021-11-23T09:19:58.500Z APP  at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:472)
2021-11-23T09:19:58.500Z APP  at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:672)
2021-11-23T09:19:58.501Z APP  at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
2021-11-23T09:19:58.501Z APP  at java.lang.Thread.run(Thread.java:748)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3975
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Code  :
RMap.readAllValues().stream().forEach => OOM Getting here..
Can someone please help me out, Is any available solution to read this load data in RMap, or will have to be read in batches ??
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3976
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Insertion order should be preserved regardless of codecs configuration but unfortunately it is working only for StringCodec . The problem with string codec is during retrieval it will display the contents as "to string" implementation of java . So need resolution for JSONJackson Codec for preserving insertion order
Actual behavior
Currently it is not working for JSONJackson Codec , it is only working for String codec
Steps to reproduce or test case
Just Create a Bean of RedissonClient and then setup a RMap or RMapCache Bean with JSONJacksonCodec instance and try to insert the contents into redis the latest item is placed first and the previous one to the last no insertion order is maintained
Redis version
6.2.6
Redisson version
3.16.3
Redisson configuration
@bean
public RedissonClient redissonClient() {
    Config    config = new Config();
        config.useSingleServer().setAddress("redis://127.0.0.1:6379");

    this.redissonClient = Redisson.create(config);
    return redissonClient;
}

@bean
public RMap<Long, Employee> employeeRMapCache() {
final RMap<Long, Employee> employeeRMapCache = redissonClient().getMap(CACHE_NAME, JsonJacksonCodec.INSTANCE, MapOptions.<Long, Employee>defaults()
.writer(getMapWriter())
return employeeRMapCache;
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3977
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Thanks for contribution!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3978
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
This is a extension of the issue #3966 because we could not reproduce the problem with the provided test.
So, we are trying to provide a new test trying to reproduce the actual issue that we observed on our application.
Expected behavior
We execute these operations on a local cache that points to a redis map already initialized:

get initial value
put new value
get new value

We expect to receive the new value on the third operation.
Actual behavior
Sometimes we get the initial value on the third operation.
Steps to reproduce or test case
A test to reproduce the issue:
@Test
public void testLocalCacheGetAndPut() {
    int numberOfKeys = 5_000;

    initializeRedis(numberOfKeys);

    RMap<String, String> localCachedMap = redisson.getLocalCachedMap("test", LocalCachedMapOptions.defaults());
    for (int i = 0; i < numberOfKeys; i++) {
        localCachedMap.get("key" + i);
        localCachedMap.put("key" + i, "value-" + i);
        String cachedValue = localCachedMap.get("key" + i);
        assertThat(cachedValue).isEqualTo("value-" + i);
    }
}

private void initializeRedis(int numberOfKeys) {
    RMap<String, String> map = redisson.getMap("test");
    for (int i = 0; i < numberOfKeys; i++) {
        map.put("key" + i, "initial-value");
    }
}
It fails on different iterations when you execute the test more than once:
org.opentest4j.AssertionFailedError: 
expected: "value-377"
 but was: "initial-value"

(...)

org.opentest4j.AssertionFailedError: 
expected: "value-1109"
 but was: "initial-value"

(...)

org.opentest4j.AssertionFailedError: 
expected: "value-0"
 but was: "initial-value"

Redis version
Redis 5.0.7
Redisson version
3.16.5-SNAPSHOT
Redisson configuration
Default configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3979
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
集群模式下推送的延时任务到达队列中，但是部分延时任务没有在take的时候弹出，没有报错信息
redisson：3.16.3
RBlockingQueue<T> blockingFairQueue = redissonClient.getBlockingQueue(queueName);
RDelayedQueue<T> delayedQueue = redissonClient.getDelayedQueue(blockingFairQueue);
delayedQueue.offer(t, delay, timeUnit);

while (!Thread.currentThread().isInterrupted() && !destroy) {
                try {
                    RBlockingQueue<T> blockingFairQueue = redissonClient.getBlockingQueue(queueName);
                    T t = blockingFairQueue.take();
                    log.info("监听队列线程{},获取到值:{}", queueName, JSON.toJSONString(t));
                    executor.execute(() -> {
                        try {
                            listener.invoke(t);
                        } catch (Exception e) {
                            log.error("延迟队列{}发送任务异常：", queueName, e);
                        }
                    });
                } catch (Exception e) {
...
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3980
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Specification we are using:
AWS Elasticache- Redis 5.0.6 (Cluster Mode with master and slave)
Redisson library; 3.16.4
connectTimeout: 3000
timeout: 1000
retryAttempts: 1
slaveConnectionMinimulIdleSize: 24
slaveConnectionPoolSize: 64
masterConnectionMinimulIdleSize: 24
masterConnectionPoolSize: 64
nodeAddres: clusterendpoint:6379
readmode: SLAVE
using: ClusterServers and RBucket to set and get
We are intermittently facing the below error. I think this is because the Master instance is loosing connection to the slave instance.
org.redisson.client.RedisConnectionException: SlaveConnectionPool no available Redis entries. Master entry host: XX.XXX.XXX/XX.XXX.XXX:6379 Disconnected hosts: [XX.XXX.XXX/1XX.XXX.XXX:6379]
at org.redisson.connection.pool.ConnectionPool.get(ConnectionPool.java:216)
at org.redisson.connection.pool.SlaveConnectionPool.get(SlaveConnectionPool.java:30)
at org.redisson.connection.balancer.LoadBalancerManager.nextConnection(LoadBalancerManager.java:273)
at org.redisson.connection.MasterSlaveEntry.connectionReadOp(MasterSlaveEntry.java:499)
at org.redisson.connection.MasterSlaveConnectionManager.connectionReadOp(MasterSlaveConnectionManager.java:549)
at org.redisson.command.RedisExecutor.getConnection(RedisExecutor.java:555)
at org.redisson.command.RedisExecutor.execute(RedisExecutor.java:121)
at org.redisson.command.RedisExecutor$2.run(RedisExecutor.java:251)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:669)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:744)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:469)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base/java.lang.Thread.run(Thread.java:829)
If we check the elasticache, all instance in the cluster are in available status.
Only way to resolve is to redeploy the application.
Any idea on configuration that should be tweaked? Or does redisson provides any time interval to refresh the connection to avoid this?
I checked the other post but looks it is closed but doesn't have an answer to the question.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3981
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Spec Used:
Redis Version: 5.0.6 (AWS Elasticache with cluster mode)
Redisson: 3.16.4
ConnectTimeout: 3000
timeout: 1000
retryAttempt: 1
readMode: SLAVE
slaveConnectionMinimumIdleSize: 24
slaveConnectionPoolSize: 64
masterConnectionMinimumIdleSize: 24
masterConnectionPoolSize: 64
using: ClusterMode and Rbucket for GET and SET
We intermittently get below error .. I think this is because the Master instance is loosing connection with the Slave instance. If we check in Elasticache, all the nodes are in "available" status.  Only solution we do is to redeploy the app to resolve the error.
Any idea what parameter should be added or tweaked related to this issue? or can Redisson provide any interval option to refresh the connection pool?
org.redisson.client.RedisConnectionException: SlaveConnectionPool no available Redis entries. Master entry host: XX,XXX.XXX/XX,XXX.XXX:6379 Disconnected hosts: [XX,XXX.XXX/XX,XXX.XXX:6379]
at org.redisson.connection.pool.ConnectionPool.get(ConnectionPool.java:216)
at org.redisson.connection.pool.SlaveConnectionPool.get(SlaveConnectionPool.java:30)
at org.redisson.connection.balancer.LoadBalancerManager.nextConnection(LoadBalancerManager.java:273)
at org.redisson.connection.MasterSlaveEntry.connectionReadOp(MasterSlaveEntry.java:499)
at org.redisson.connection.MasterSlaveConnectionManager.connectionReadOp(MasterSlaveConnectionManager.java:549)
at org.redisson.command.RedisExecutor.getConnection(RedisExecutor.java:555)
at org.redisson.command.RedisExecutor.execute(RedisExecutor.java:121)
at org.redisson.command.RedisExecutor$2.run(RedisExecutor.java:251)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:669)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:744)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:469)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base/java.lang.Thread.run(Thread.java:829)
Note: I verifed the post 2535 .. it is in closed state but the question isn't addressed.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3982
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redisson locks can consistency guarantee as raft consensus protocol (ex:hazelcast) with schemes cluser and master+slave(sentinel) ? It dont have problems as has hazelcast before cp-subsystem(ver3.12) "at least once" https://docs.hazelcast.org/docs/3.11.2/manual/html-single/index.html#exactly-once-at-least-once-or-at-most-once-execution
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3983
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behaviour : When the Redis pod(stateful set) restarts, the application should be able to reconnect to the redis pod automatically.
Actual behaviour : When the Redis pod restarts, the application is unable to reconnect to Redis even after multiple retry attempts. I tried this in a single node setup. When Redis pod is brought down, another pod is spun up in few seconds. But the app is unable to reconnect automatically. After the app pod restart, it works fine.
This is the exception thrown.
org.redisson.client.RedisConnectionException: SlaveConnectionPool no available Redis entries. Master entry host: / Disconnected hosts: [/]
at org.redisson.connection.pool.ConnectionPool.get(ConnectionPool.java:216)
at org.redisson.connection.pool.SlaveConnectionPool.get(SlaveConnectionPool.java:30)
at org.redisson.connection.balancer.LoadBalancerManager.nextConnection(LoadBalancerManager.java:275)
at org.redisson.connection.MasterSlaveEntry.connectionReadOp(MasterSlaveEntry.java:503)
at org.redisson.connection.MasterSlaveConnectionManager.connectionReadOp(MasterSlaveConnectionManager.java:549)
at org.redisson.command.RedisExecutor.getConnection(RedisExecutor.java:572)
at org.redisson.command.RedisExecutor.execute(RedisExecutor.java:124)
at org.redisson.command.RedisExecutor$2.run(RedisExecutor.java:254)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:672)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:747)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:472)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
Redis version : 6.2.3
Redisson version :
Tried both 3.15.5 and 3.16.4 - Facing same issue in both
Redisson configuration :
config.useReplicatedServers()
.setReadMode(ReadMode.MASTER_SLAVE)
.setScanInterval(masterScanInterval)
.setPassword(redisPassword)
.addNodeAddress(redisUrl.split(","))
Please let me know if there's any workaround for this other than the restart. Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3984
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Sometimes Redisson seems to be stuck when calling Redisson.shutdown(). Some Services are stuck for mutliple days. But it seems to be a very rare event,
"Server thread" #35 prio=5 os_prio=0 cpu=31288610.68ms elapsed=200436.69s tid=0x00007f6d9b42d000 nid=0x3f4809 in Object.wait()  [0x00007f6d374ed000]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)
	at java.lang.Object.wait(java.base@14.0.1/Native Method)
	- waiting on <no object reference available>
	at java.lang.Thread.join(java.base@14.0.1/Thread.java:1297)
	- locked <0x0000000745219408> (a io.netty.util.concurrent.FastThreadLocalThread)
	at io.netty.util.HashedWheelTimer.stop(HashedWheelTimer.java:383)
	at org.redisson.connection.MasterSlaveConnectionManager.shutdown(MasterSlaveConnectionManager.java:622)
	at org.redisson.connection.MasterSlaveConnectionManager.shutdown(MasterSlaveConnectionManager.java:585)
	at org.redisson.Redisson.shutdown(Redisson.java:658)
	at net.gommehd.idlecommons.session.connect.redisson.PrefixedRedisClient.shutdown(PrefixedRedisClient.java:562)
	at net.gommehd.idlecommons.session.connect.redisson.RedissonSession.close(RedissonSession.java:21)
	at net.gommehd.idlecommons.session.SessionModule.onDisable(SessionModule.java:48)
	at net.gommehd.goframe.core.loader.ModuleLoader.disableModules(ModuleLoader.java:248)
	at net.gommehd.goframe.core.ModuleLoaderPlugin.onDisable(ModuleLoaderPlugin.java:65)
	at org.bukkit.plugin.java.JavaPlugin.setEnabled(JavaPlugin.java:323)
	at org.bukkit.plugin.java.JavaPluginLoader.disablePlugin(JavaPluginLoader.java:364)
	at org.bukkit.plugin.SimplePluginManager.disablePlugin(SimplePluginManager.java:424)
	at org.bukkit.plugin.SimplePluginManager.disablePlugins(SimplePluginManager.java:417)
	at org.bukkit.craftbukkit.v1_8_R3.CraftServer.disablePlugins(CraftServer.java:338)
	at net.minecraft.server.v1_8_R3.MinecraftServer.stop(MinecraftServer.java:461)
	at net.minecraft.server.v1_8_R3.MinecraftServer.run(MinecraftServer.java:596)
	at java.lang.Thread.run(java.base@14.0.1/Thread.java:832)

This is the Thread netty tries to join. Stack trace does not seem to change over time (took multiple thread dumps)
"redisson-timer-10-1" #199 prio=5 os_prio=0 cpu=124713629.34ms elapsed=200430.55s tid=0x00007f6b4c060000 nid=0x3f48ab runnable  [0x00007f6c20bf6000]
   java.lang.Thread.State: RUNNABLE
	at java.util.WeakHashMap$HashIterator.hasNext(java.base@14.0.1/WeakHashMap.java:800)
	at org.redisson.command.RedisExecutor$2.run(RedisExecutor.java:191)
	at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:672)
	at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:747)
	at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:472)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(java.base@14.0.1/Thread.java:832)

Expected behavior
Redisson.shutdown() should be blocking but not for ever
Actual behavior
Redisson.shutdown() is stuck for days (in some rare cases) and the Timer thread is taking huge amounts of processing power (this is not a typical profiler bug with parking threads but acutally showing in the process list)
Steps to reproduce or test case
Not tried but maybe if you could point us in a direction.
Redis version
5.0.3
Redisson version
3.16.5-SNAPSHOT (as we need the topic fix)
Redisson configuration
Single node with
useThreadClassLoader=: alse
nettyThreads: 4
subscriptionConnectionPoolSize: 12
connectionMinimumIdleSize: 6
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3985
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello all i am trying to access json filed in criteria query but getting above error could you please help me for the same.
subquery.select(root).where(this.criteriaBuilder.equal((packageRoot.get("publis")), userEmail));
here publis is the json in repository
@createdby
@column(name = "pub_by", columnDefinition = "jsonb", updatable = false)
@type(type = "jsonb")
private User publis;
and error is below
java.lang.IllegalArgumentException: com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'local': was expecting (JSON String, Number, Array, Object or token 'null', 'true' or 'false')
at [Source: (String)"local.user@registry.com"; line: 1, column: 6]
at com.vladmihalcea.hibernate.type.util.ObjectMapperWrapper.toJsonNode(ObjectMapperWrapper.java:68) ~[hibernate-types-52-2.4.3.jar:na]
at com.vladmihalcea.hibernate.type.json.internal.JsonTypeDescriptor.unwrap(JsonTypeDescriptor.java:105) ~[hibernate-types-52-2.4.3.jar:na]
at com.vladmihalcea.hibernate.type.json.internal.JsonBinarySqlTypeDescriptor$1.doBind(JsonBinarySqlTypeDescriptor.java:25) ~[hibernate-types-52-2.4.3.jar:na]
at org.hibernate.type.descriptor.sql.BasicBinder.bind(BasicBinder.java:73) ~[hibernate-core-5.4.32.Final.jar:5.4.32.Final]
at org.hibernate.type.AbstractStandardBasicType.nullSafeSet(AbstractStandardBasicType.java:276) ~[hibernate-core-5.4.32.Final.jar:5.4.32.Final]
at org.hibernate.type.AbstractStandardBasicType.nullSafeSet(AbstractStandardBasicType.java:271) ~[hibernate-core-5.4.32.Final.jar:5.4.32.Final]
at org.hibernate.param.NamedParameterSpecification.bind(NamedParameterSpecification.java:53) ~[hibernate-core-5.4.32.Final.jar:5.4.32.Final]
at org.hibernate.loader.hql.QueryLoader.bindParameterValues(QueryLoader.java:648) ~[hibernate-core-5.4.32.Final.jar:5.4.32.Final]
at org.hibernate.loader.Loader.bindPreparedStatement(Loader.java:2125) ~[hibernate-core-5.4.32.Final.jar:5.4.32.Final]
at org.hibernate.loader.Loader.prepareQueryStatement(Loader.java:2102) ~[hibernate-core-5.4.32.Final.jar:5.4.32.Final]
at org.hibernate.loader.Loader.executeQueryStatement(Loader.java:2034) ~[hibernate-core-5.4.32.Final.jar:5.4.32.Final]
at org.hibernate.loader.Loader.executeQueryStatement(Loader.java:2012) ~[hibernate-core-5.4.32.Final.jar:5.4.32.Final]
at org.hibernate.loader.Loader.doQuery(Loader.java:948) ~[hibernate-core-5.4.32.Final.jar:5.4.32.Final]
at org.hibernate.loader.Loader.doQueryAndInitializeNonLazyCollections(Loader.java:349) ~[hibernate-core-5.4.32.Final.jar:5.4.32.Final]
at org.hibernate.loader.Loader.doList(Loader.java:2843) ~[hibernate-core-5.4.32.Final.jar:5.4.32.Final]
at org.hibernate.loader.Loader.doList(Loader.java:2825) ~[hibernate-core-5.4.32.Final.jar:5.4.32.Final]
at org.hibernate.loader.Loader.listIgnoreQueryCache(Loader.java:2657) ~[hibernate-core-5.4.32.Final.jar:5.4.32.Final]
at org.hibernate.loader.Loader.list(Loader.java:2652) ~[hibernate-core-5.4.32.Final.jar:5.4.32.Final]
at org.hibernate.loader.hql.QueryLoader.list(QueryLoader.java:506) ~[hibernate-core-5.4.32.Final.jar:5.4.32.Final]
at org.hibernate.hql.internal.ast.QueryTranslatorImpl.list(QueryTranslatorImpl.java:400) ~[hibernate-core-5.4.32.Final.jar:5.4.32.Final]
at org.hibernate.engine.query.spi.HQLQueryPlan.performList(HQLQueryPlan.java:219) ~[hibernate-core-5.4.32.Final.jar:5.4.32.Final]
at org.hibernate.internal.SessionImpl.list(SessionImpl.java:1414) ~[hibernate-core-5.4.32.Final.jar:5.4.32.Final]
at org.hibernate.query.internal.AbstractProducedQuery.doList(AbstractProducedQuery.java:1636) ~[hibernate-core-5.4.32.Final.jar:5.4.32.Final]
at org.hibernate.query.internal.AbstractProducedQuery.list(AbstractProducedQuery.java:1604) ~[hibernate-core-5.4.32.Final.jar:5.4.32.Final]
at org.hibernate.query.Query.getResultList(Query.java:165) ~[hibernate-core-5.4.32.Final.jar:5.4.32.Final]
at org.hibernate.query.criteria.internal.compile.CriteriaQueryTypeQueryAdapter.getResultList(CriteriaQueryTypeQueryAdapter.java:76) ~[hibernate-core-5.4.32.Final.jar:5.4.32.Final]
at com.sap.apac.lcnc.library.repository.LibraryArtifactRepositoryCustomImpl.findAllArtifactsWithFilter(LibraryArtifactRepositoryCustomImpl.java:104) ~[classes/:na]
at com.sap.apac.lcnc.library.repository.LibraryArtifactRepositoryCustomImpl$$FastClassBySpringCGLIB$$e8ae07f5.invoke() ~[classes/:na]
at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) ~[spring-core-5.3.12.jar:5.3.12]
at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:783) ~[spring-aop-5.3.12.jar:5.3.12]
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) ~[spring-aop-5.3.12.jar:5.3.12]
at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:753) ~[spring-aop-5.3.12.jar:5.3.12]
at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137) ~[spring-tx-5.3.12.jar:5.3.12]
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.12.jar:5.3.12]
at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:753) ~[spring-aop-5.3.12.jar:5.3.12]
at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:698) ~[spring-aop-5.3.12.jar:5.3.12]
at com.sap.apac.lcnc.library.repository.LibraryArtifactRepositoryCustomImpl$$EnhancerBySpringCGLIB$$bac61a19.findAllArtifactsWithFilter() ~[classes/:na]
at com.sap.apac.lcnc.library.service.LibraryService.getAllArtifacts(LibraryService.java:107) ~[classes/:na]
at com.sap.apac.lcnc.library.service.LibraryService$$FastClassBySpringCGLIB$$bbd19e44.invoke() ~[classes/:na]
at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) ~[spring-core-5.3.12.jar:5.3.12]
at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:689) ~[spring-aop-5.3.12.jar:5.3.12]
at com.sap.apac.lcnc.library.service.LibraryService$$EnhancerBySpringCGLIB$$2f8e75eb.getAllArtifacts() ~[classes/:na]
at com.sap.apac.lcnc.library.controller.LibraryController.getArtifacts(LibraryController.java:62) ~[classes/:na]
at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]
at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
at java.base/java.lang.reflect.Method.invoke(Method.java:566) ~[na:na]
at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205) ~[spring-web-5.3.12.jar:5.3.12]
at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150) ~[spring-web-5.3.12.jar:5.3.12]
at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117) ~[spring-webmvc-5.3.12.jar:5.3.12]
at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) ~[spring-webmvc-5.3.12.jar:5.3.12]
at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) ~[spring-webmvc-5.3.12.jar:5.3.12]
at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.3.12.jar:5.3.12]
at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1067) ~[spring-webmvc-5.3.12.jar:5.3.12]
at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963) ~[spring-webmvc-5.3.12.jar:5.3.12]
at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) ~[spring-webmvc-5.3.12.jar:5.3.12]
at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) ~[spring-webmvc-5.3.12.jar:5.3.12]
at javax.servlet.http.HttpServlet.service(HttpServlet.java:655) ~[tomcat-embed-core-9.0.54.jar:4.0.FR]
at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) ~[spring-webmvc-5.3.12.jar:5.3.12]
at javax.servlet.http.HttpServlet.service(HttpServlet.java:764) ~[tomcat-embed-core-9.0.54.jar:4.0.FR]
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) ~[tomcat-embed-websocket-9.0.54.jar:9.0.54]
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:204) ~[spring-security-web-5.4.9.jar:5.4.9]
at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:183) ~[spring-security-web-5.4.9.jar:5.4.9]
at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:358) ~[spring-web-5.3.12.jar:5.3.12]
at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:271) ~[spring-web-5.3.12.jar:5.3.12]
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) ~[spring-web-5.3.12.jar:5.3.12]
at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.12.jar:5.3.12]
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-5.3.12.jar:5.3.12]
at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.12.jar:5.3.12]
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:97) ~[spring-boot-actuator-2.4.12.jar:2.4.12]
at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.12.jar:5.3.12]
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) ~[spring-web-5.3.12.jar:5.3.12]
at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.12.jar:5.3.12]
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at com.sap.apac.lcnc.shared.security.xss.XSSFilter.doFilter(XSSFilter.java:26) ~[classes/:na]
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:540) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.catalina.valves.RemoteIpValve.invoke(RemoteIpValve.java:769) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:357) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:382) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:895) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1722) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) ~[tomcat-embed-core-9.0.54.jar:9.0.54]
at java.base/java.lang.Thread.run(Thread.java:829) ~[na:na]
Caused by: com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'local': was expecting (JSON String, Number, Array, Object or token 'null', 'true' or 'false')
at [Source: (String)"local.user@registry.com"; line: 1, column: 6]
at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1851) ~[jackson-core-2.11.4.jar:2.11.4]
at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:717) ~[jackson-core-2.11.4.jar:2.11.4]
at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._reportInvalidToken(ReaderBasedJsonParser.java:2898) ~[jackson-core-2.11.4.jar:2.11.4]
at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._handleOddValue(ReaderBasedJsonParser.java:1944) ~[jackson-core-2.11.4.jar:2.11.4]
at com.fasterxml.jackson.core.json.ReaderBasedJsonParser.nextToken(ReaderBasedJsonParser.java:776) ~[jackson-core-2.11.4.jar:2.11.4]
at com.fasterxml.jackson.databind.ObjectMapper._readTreeAndClose(ObjectMapper.java:4553) ~[jackson-databind-2.11.2.jar:2.11.2]
at com.fasterxml.jackson.databind.ObjectMapper.readTree(ObjectMapper.java:2972) ~[jackson-databind-2.11.2.jar:2.11.2]
at com.vladmihalcea.hibernate.type.util.ObjectMapperWrapper.toJsonNode(ObjectMapperWrapper.java:66) ~[hibernate-types-52-2.4.3.jar:na]
... 106 common frames omitted
2021-11-26 04:12:15.964  INFO 21844 --- [nio-8080-exec-2] c.s.a.l.s.c.h.TenantConnectionProvider   : [RELEASE CONNECTION FOR TENANT] tlocaltenant
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3986
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
That code format is stable and I see a change in the code format
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3987
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3988
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
On connection with redis I'm getting this:
org.redisson.client.RedisConnectionException: Unable to connect to Redis server: IP/IP:6379
at org.redisson.connection.pool.ConnectionPool$1.lambda$run$0(ConnectionPool.java:158) ~[CuriosLibrary-1.1.0-BETA-shaded(1).jar:?]
at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:183) ~[CuriosLibrary-1.1.0-BETA-shaded(1).jar:?]
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578) ~[patched_1.17.1.jar:git-Airplane-92]
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552) ~[patched_1.17.1.jar:git-Airplane-92]
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491) ~[patched_1.17.1.jar:git-Airplane-92]
at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616) ~[patched_1.17.1.jar:git-Airplane-92]
at io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:609) ~[patched_1.17.1.jar:git-Airplane-92]
at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117) ~[patched_1.17.1.jar:git-Airplane-92]
at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:96) ~[CuriosLibrary-1.1.0-BETA-shaded(1).jar:?]
at org.redisson.connection.pool.ConnectionPool.promiseFailure(ConnectionPool.java:313) ~[CuriosLibrary-1.1.0-BETA-shaded(1).jar:?]
at org.redisson.connection.pool.ConnectionPool.lambda$createConnection$3(ConnectionPool.java:279) ~[CuriosLibrary-1.1.0-BETA-shaded(1).jar:?]
at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:183) ~[CuriosLibrary-1.1.0-BETA-shaded(1).jar:?]
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578) ~[patched_1.17.1.jar:git-Airplane-92]
at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:571) ~[patched_1.17.1.jar:git-Airplane-92]
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:550) ~[patched_1.17.1.jar:git-Airplane-92]
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491) ~[patched_1.17.1.jar:git-Airplane-92]
at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616) ~[patched_1.17.1.jar:git-Airplane-92]
at io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:609) ~[patched_1.17.1.jar:git-Airplane-92]
at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117) ~[patched_1.17.1.jar:git-Airplane-92]
at org.redisson.misc.RedissonPromise.tryFailure(RedissonPromise.java:96) ~[CuriosLibrary-1.1.0-BETA-shaded(1).jar:?]
at org.redisson.client.RedisClient$2$1.run(RedisClient.java:242) ~[CuriosLibrary-1.1.0-BETA-shaded(1).jar:?]
at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164) ~[patched_1.17.1.jar:git-Airplane-92]
at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472) ~[patched_1.17.1.jar:git-Airplane-92]
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500) ~[patched_1.17.1.jar:git-Airplane-92]
at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[patched_1.17.1.jar:git-Airplane-92]
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[patched_1.17.1.jar:git-Airplane-92]
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[patched_1.17.1.jar:git-Airplane-92]
at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.redisson.client.RedisTimeoutException: Command execution timeout for command: (AUTH), params: (password masked), Redis client: [addr=redis://IP:6379]
at org.redisson.client.RedisConnection.lambda$async$1(RedisConnection.java:251) ~[CuriosLibrary-1.1.0-BETA-shaded(1).jar:?]
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:669) ~[patched_1.17.1.jar:git-Airplane-92]
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:744) ~[patched_1.17.1.jar:git-Airplane-92]
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:469) ~[patched_1.17.1.jar:git-Airplane-92]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3989
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am unable to understand this error. Please help.
Execution exception[[RedisException: ERR Error running script (call to f_0fd7cdd6c1224471b29d6f7fc503462f3b252f12): @user_script:1: user_script:1: bad argument #2 to 'unpack' (data string too short) . channel: [id: 0xd4089e92, L:/10.212.134.41:60921 - R:core-dev-redis.6cbkbd.0001.aps1.cache.amazonaws.com/192.168.2.46:6379] command: (EVAL), params: [local result = {}; local idleKeys = {}; local res; if (#ARGV == 4) then  res = redis.call('hscan', K..., 3, ALLUS_XXX, redisson__timeout__set:{ALLUS_XXX}, redisson__idle__set:{ALLUS_XXX}, 1637948919729, 0, 10]]]\
I am trying to read using getMapCache(ALLUS_XXX)
also, in redis cli if I do hgetall ALLUS_XXX.  This is the output
 1) "3"
 2) "{\"ev\":\"Q\",\"sym\":\"XXX\",\"bx\":\"3\",\"ax\":\"21\",\"bp\":331.27,\"ap\":331.3,\"bs\":2,\"as\":1,\"t\":\"1637948895747\",\"q\":\"42893371\",\"z\":3}"
 3) "2"
 4) "{\"ev\":\"Q\",\"sym\":\"XXX\",\"bx\":\"2\",\"ax\":\"19\",\"bp\":330.03,\"ap\":330.13,\"bs\":2,\"as\":3,\"t\":\"1637949585689\",\"q\":\"46053648\",\"z\":3}"
 5) "12"
 6) "{\"ev\":\"Q\",\"sym\":\"XXX\",\"bx\":\"12\",\"ax\":\"11\",\"bp\":329.91,\"ap\":330.25,\"bs\":1,\"as\":12,\"t\":\"1637949676507\",\"q\":\"46258127\",\"z\":3}"
 7) "9"
 8) "{\"ev\":\"Q\",\"sym\":\"XXX\",\"bx\":\"9\",\"ax\":\"15\",\"bp\":330.43,\"ap\":330.44,\"bs\":3,\"as\":3,\"t\":\"1637949113455\",\"q\":\"43838492\",\"z\":3}"
 9) "15"
10) "{\"ev\":\"Q\",\"sym\":\"XXX\",\"bx\":\"15\",\"ax\":\"12\",\"bp\":330.34,\"ap\":330.37,\"bs\":2,\"as\":4,\"t\":\"1637949549028\",\"q\":\"45809932\",\"z\":3}"
11) "10"
12) "{\"ev\":\"Q\",\"sym\":\"XXX\",\"bx\":\"10\",\"ax\":\"12\",\"bp\":330.26,\"ap\":330.37,\"bs\":1,\"as\":2,\"t\":\"1637949585833\",\"q\":\"46055016\",\"z\":3}"
13) "18"
14) "{\"ev\":\"Q\",\"sym\":\"XXX\",\"bx\":\"18\",\"ax\":\"11\",\"bp\":330.15,\"ap\":330.25,\"bs\":2,\"as\":12,\"t\":\"1637949683953\",\"q\":\"46258667\",\"z\":3}"
15) "1"
16) "{\"ev\":\"Q\",\"sym\":\"XXX\",\"bx\":\"1\",\"ax\":\"17\",\"bp\":330.21,\"ap\":330.31,\"bs\":4,\"as\":1,\"t\":\"1637949583379\",\"q\":\"46033150\",\"z\":3}"
17) "11"
18) "{\"ev\":\"Q\",\"sym\":\"XXX\",\"bx\":\"11\",\"ax\":\"12\",\"bp\":329.91,\"ap\":330.2,\"bs\":4,\"as\":1,\"t\":\"1637949688637\",\"q\":\"46259504\",\"z\":3}"
19) "7"
20) "{\"ev\":\"Q\",\"sym\":\"XXX\",\"bx\":\"7\",\"ax\":\"11\",\"bp\":330.15,\"ap\":330.25,\"bs\":2,\"as\":12,\"t\":\"1637949684316\",\"q\":\"46258719\",\"z\":3}"
21) "20"
22) "{\"ev\":\"Q\",\"sym\":\"XXX\",\"bx\":\"20\",\"ax\":\"12\",\"bp\":330.11,\"ap\":330.26,\"bs\":1,\"as\":1,\"t\":\"1637949586232\",\"q\":\"46058248\",\"z\":3}"
23) "19"
24) "{\"ev\":\"Q\",\"sym\":\"XXX\",\"bx\":\"19\",\"ax\":\"11\",\"bp\":329.91,\"ap\":330.25,\"bs\":2,\"as\":12,\"t\":\"1637949676537\",\"q\":\"46258138\",\"z\":3}"
25) "8"
26) "{\"ev\":\"Q\",\"sym\":\"XXX\",\"bx\":\"8\",\"ax\":\"11\",\"bp\":330.06,\"ap\":330.25,\"bs\":1,\"as\":12,\"t\":\"1637949685035\",\"q\":\"46258880\",\"z\":3}"
27) "17"
28) "{\"ev\":\"Q\",\"sym\":\"XXX\",\"bx\":\"17\",\"ax\":\"17\",\"bp\":329.37,\"ap\":330.16,\"bs\":2,\"as\":2,\"t\":\"1637949606270\",\"q\":\"46241118\",\"z\":3}"
29) "21"
30) "{\"ev\":\"Q\",\"sym\":\"XXX\",\"bx\":\"21\",\"ax\":\"12\",\"bp\":330.9,\"ap\":331.09,\"bs\":1,\"as\":1,\"t\":\"1637949581667\",\"q\":\"46012327\",\"z\":3}"

This is easlily reproducible,

 HMSET ALLUS_XXX 1 "{\"ev\":\"Q\",\"sym\":\"XXX\",\"bx\":\"1\",\"ax\":\"20\",\"bp\":157.2,\"ap\":157.21,\"bs\":5,\"as\":1,\"t\":\"1637949207844\",\"q\":\"60303179\",\"z\":3}"
Now try to access this using redisson getMapCache("ALLUS_XXX").readAllEntrySet()
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3990
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
询问分布式调度任务服务（Scheduler Service）中，如何达到在多台工作服务器（worker）上每次只有其中一台执行任务？
我的配置代码如下：
配置代码：
@bean(destroyMethod = "shutdown")
public RedissonNode redissonNode(@qualifier("redissonConfig") Config config, @qualifier("redissonClient") RedissonClient redissonClient) {
RedissonNodeConfig nodeConfig = new RedissonNodeConfig(config);
nodeConfig.setExecutorServiceWorkers(Collections.singletonMap(GoogleRefundService.executorServiceName, 1));
RedissonNode node = RedissonNode.create(nodeConfig, redissonClient);
node.start();
return node;
}
调度任务代码：
@value("${sdk.payment.thirdparty.google.refund.cronSchedule:0/5 * * * * ?}")
private String refundCronSchedule;
@PostConstruct
public void initGoogleRefundSchedule() {
    ExecutorOptions options = ExecutorOptions.defaults();
    // 设定为0则不进行重试
    options.taskRetryInterval(0, TimeUnit.MINUTES);
    RScheduledExecutorService executorService = redissonClient.getExecutorService(executorServiceName, options);
    int taskCount = executorService.getTaskCount();
    log.info("initGoogleRefundSchedule taskCount:{}", taskCount);
    if (taskCount == 0) {
        executorService.schedule((Runnable & Serializable) () -> log.info("task has been executed!"), CronSchedule.of(refundCronSchedule));
    }
}

按照配置，会每隔5秒钟输出一次log("task has been executed!"), 目前在单台服务器上启动，调度任务服务可以运行
但是如果在多台服务器上启动服务，每台服务器上的进程都会每隔5秒输出一次，可我希望达到的效果是：在多台工作服务器（worker）上，每次只有其中一台（或随机，或轮询，或抢占）每隔5秒执行一次任务。
请问我应该如何配置分布式调度任务服务，才能达到这个效果？
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3991
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Inquire about the distributed scheduling task service (Scheduler Service), how to achieve that only one of the multiple worker servers (worker) executes tasks at a time?
My code is as follows:
Configuration code:
@Bean(destroyMethod = "shutdown")
public RedissonNode redissonNode(@Qualifier("redissonConfig") Config config, @Qualifier("redissonClient") RedissonClient redissonClient) {
    RedissonNodeConfig nodeConfig = new RedissonNodeConfig(config);
    nodeConfig.setExecutorServiceWorkers(Collections.singletonMap(GoogleRefundService.executorServiceName, 1));
    RedissonNode node = RedissonNode.create(nodeConfig, redissonClient);
    node.start();
    return node;
}

Schedule task code:
@Value("${sdk.payment.thirdparty.google.refund.cronSchedule:0/5 * * * * ?}")
private String refundCronSchedule;

@PostConstruct
public void initGoogleRefundSchedule() {
    ExecutorOptions options = ExecutorOptions.defaults();
    // 设定为0则不进行重试
    options.taskRetryInterval(0, TimeUnit.MINUTES);
    RScheduledExecutorService executorService = redissonClient.getExecutorService(executorServiceName, options);
    int taskCount = executorService.getTaskCount();
    log.info("initGoogleRefundSchedule taskCount:{}", taskCount);
    if (taskCount == 0) {
        executorService.schedule((Runnable & Serializable) () -> log.info("task has been executed!"), CronSchedule.of(refundCronSchedule));
    }
}

According to the configuration, log("task has been executed!") will be output every 5 seconds. It is currently started on a single server, and the scheduled task service can run.
But if you start the service on multiple servers, the process on each server will output every 5 seconds, but what I want to achieve is: on multiple workers (workers), only one of them (or Random, or polling, or preemption) execute a task every 5 seconds.
How should I configure the distributed scheduling task service to achieve this effect?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3992
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
rename session id
Actual behavior
org.springframework.data.redis.RedisSystemException: CROSSSLOT Keys in request don't hash to the same slot. channel: [id: 0xd86c1794, L:/11.2.2.202:58295 - R:11.11.113.183/11.11.113.183:6379] command: (RENAME), promise: RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@35d041c2(incomplete)], params: [[103, 119, 58, 115, 101, 115, 115, 105, 111, 110, ...], [103, 119, 58, 115, 101, 115, 115, 105, 111, 110, ...]]; nested exception is org.redisson.client.RedisException: CROSSSLOT Keys in request don't hash to the same slot. channel: [id: 0xd86c1794, L:/11.2.2.202:58295 - R:11.11.113.183/11.11.113.183:6379] command: (RENAME), promise: RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@35d041c2(incomplete)], params: [[103, 119, 58, 115, 101, 115, 115, 105, 111, 110, ...], [103, 119, 58, 115, 101, 115, 115, 105, 111, 110, ...]]
at org.redisson.spring.data.connection.RedissonBaseReactive.lambda$write$3(RedissonBaseReactive.java:94)
Suppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException:
Error has been observed at the following site(s):
|_ checkpoint ⇢ org.springframework.security.web.server.authentication.logout.LogoutWebFilter [DefaultWebFilterChain]
|_ checkpoint ⇢ org.springframework.security.web.server.savedrequest.ServerRequestCacheWebFilter [DefaultWebFilterChain]
|_ checkpoint ⇢ org.springframework.security.web.server.context.SecurityContextServerWebExchangeWebFilter [DefaultWebFilterChain]
|_ checkpoint ⇢ org.springframework.security.web.server.authentication.AuthenticationWebFilter [DefaultWebFilterChain]
|_ checkpoint ⇢ org.springframework.security.web.server.authentication.AuthenticationWebFilter [DefaultWebFilterChain]
|_ checkpoint ⇢ org.springframework.security.web.server.authentication.AuthenticationWebFilter [DefaultWebFilterChain]
|_ checkpoint ⇢ org.springframework.security.web.server.authentication.AuthenticationWebFilter [DefaultWebFilterChain]
|_ checkpoint ⇢ org.springframework.security.web.server.context.ReactorContextWebFilter [DefaultWebFilterChain]
|_ checkpoint ⇢ org.springframework.security.web.server.header.HttpHeaderWriterWebFilter [DefaultWebFilterChain]
|_ checkpoint ⇢ org.springframework.security.config.web.server.ServerHttpSecurity$ServerWebExchangeReactorContextWebFilter [DefaultWebFilterChain]
|_ checkpoint ⇢ org.springframework.security.web.server.WebFilterChainProxy [DefaultWebFilterChain]
|_ checkpoint ⇢ org.springframework.cloud.sleuth.instrument.web.TraceWebFilter [DefaultWebFilterChain]
|_ checkpoint ⇢ org.springframework.boot.actuate.metrics.web.reactive.server.MetricsWebFilter [DefaultWebFilterChain]
|_ checkpoint ⇢ HTTP POST "/auth/logout" [ExceptionHandlingWebHandler]
Steps to reproduce or test case
My app is a spring cloud gateway app, and store session information in Redis through Redission.
This is my facroty bean:
@Bean
fun reactiveRedisConnectionFactory(redissonClient: RedissonClient): ReactiveRedisConnectionFactory {
    return RedissonConnectionFactory(redissonClient)
}

I found some issurs with the same CROSSSLOT error at October, 2020 and fixed by https://github.com/redisson/redisson/pull/3141/commits
But the reactive connection do not use the ReactiveKeyCommands class fixed in that PR. Maybe this bug is happening again?
Redisson version
org.redisson:redisson and redisson-spring-data-24,  version is 3.16.4
Redisson configuration
Redisson config in cluster mode
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3993
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redisson can client-side sharding or partitioning ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3994
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I tried RLock(Redisson master branch, redis 5.0.5) with the following config and tried to test whether synchronous replication works with master-slave. After I killed one replica and the lock can still be granted(there was only one client trying to get the lock), what I expect is that the client failed to acquired the lock cause the command was not able to propagate to all the replicas.
MasterSlaveServersConfig masterSlaveServersConfig = config.useMasterSlaveServers();
        masterSlaveServersConfig
            .setPassword("XXX")
            .setMasterConnectionPoolSize(10)
            .setMasterConnectionMinimumIdleSize(10)
            .setConnectTimeout(5000)
            .setTimeout(5000)
            .setMasterAddress("redis://XXXX:6379")
            .addSlaveAddress("redis://XXXX:6379")
            .addSlaveAddress("redis://XXXX:6379");
After debug for a while, I found that BatchResult for EVAL & WAIT command was not checked in RedissonBaseLock.evalWriteAsync method,  i.e the syncedSlaves in BatchResult was not checked.
// org.redisson.RedissonBaseLock

protected <T> RFuture<T> evalWriteAsync(....) { 
  
     future.onComplete((res, ex) -> {
            // BatchResult is not checked here !!!
            if (ex != null) {
                r.tryFailure(ex);
                return;
            }

            r.trySuccess(result.getNow());
        });

}
So is it because i misunderstand the synchronous replication mechanism used in Redisson or it's a bug
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3995
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[DC-STG][ERROR][sort][2021-11-28 15:02:10.497][]-[]-[][Thread-12] (ThreadPoolAgent.java:55)[get()] -> 系统异常
java.util.concurrent.ExecutionException: org.springframework.dao.InvalidDataAccessApiUsageException: Unable to send command! Try to increase 'nettyThreads' and/or connection pool size settings Node source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=0, freeSubscribeConnectionsCounter=value:49:queue:0, freeConnectionsAmount=19, freeConnectionsCounter=value:59:queue:0, freezed=false, freezeReason=null, client=[addr=redis://192.168.53.179:6379], nodeType=MASTER, firstFail=0]]], connection: RedisConnection@131875383 [redisClient=[addr=redis://192.168.53.179:6379], channel=[id: 0x699c31ec, L:/100.111.156.155:48866 - R:192.168.53.179/192.168.53.179:6379], currentCommand=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@18ca11e9(failure: org.redisson.client.RedisTimeoutException: Command execution timeout for command: (PING), params: [], Redis client: [addr=redis://192.168.53.179:6379])], command=(PING), params=[], codec=org.redisson.client.codec.StringCodec]], command: (GET), params: [[115, 122, 45, 100, 99, 58, 115, 111, 114, 116, ...]] after 3 retry attempts; nested exception is org.redisson.client.RedisTimeoutException: Unable to send command! Try to increase 'nettyThreads' and/or connection pool size settings Node source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=0, freeSubscribeConnectionsCounter=value:49:queue:0, freeConnectionsAmount=19, freeConnectionsCounter=value:59:queue:0, freezed=false, freezeReason=null, client=[addr=redis://192.168.53.179:6379], nodeType=MASTER, firstFail=0]]], connection: RedisConnection@131875383 [redisClient=[addr=redis://192.168.53.179:6379], channel=[id: 0x699c31ec, L:/100.111.156.155:48866 - R:192.168.53.179/192.168.53.179:6379], currentCommand=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@18ca11e9(failure: org.redisson.client.RedisTimeoutException: Command execution timeout for command: (PING), params: [], Redis client: [addr=redis://192.168.53.179:6379])], command=(PING), params=[], codec=org.redisson.client.codec.StringCodec]], command: (GET), params: [[115, 122, 45, 100, 99, 58, 115, 111, 114, 116, ...]] after 3 retry attempts
at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[?:1.8.0_91]
at java.util.concurrent.FutureTask.get(FutureTask.java:192) ~[?:1.8.0_91]
at com.szatc.biz.service.sort.common.agent.ThreadPoolAgent.get(ThreadPoolAgent.java:52) [classes!/:1.0.0-SNAPSHOT]
at com.szatc.biz.service.sort.sort.impl.DataCacheImpl.init(DataCacheImpl.java:135) [classes!/:1.0.0-SNAPSHOT]
at com.szatc.biz.service.sort.sort.SortManagerCommon.setTime(SortManagerCommon.java:42) [classes!/:1.0.0-SNAPSHOT]
at com.szatc.biz.service.sort.sort.impl.SortServiceImpl.sortRealtime(SortServiceImpl.java:63) [classes!/:1.0.0-SNAPSHOT]
at com.szatc.biz.service.sort.controller.job.SortJobHandler.sortRealTime(SortJobHandler.java:109) [classes!/:1.0.0-SNAPSHOT]
at sun.reflect.GeneratedMethodAccessor579.invoke(Unknown Source) ~[?:?]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_91]
at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_91]
at com.xxl.job.core.handler.impl.MethodJobHandler.execute(MethodJobHandler.java:29) [xxl-job-core-2.3.0.jar!/:?]
at com.xxl.job.core.thread.JobThread.run(JobThread.java:163) [xxl-job-core-2.3.0.jar!/:?]
Caused by: org.springframework.dao.InvalidDataAccessApiUsageException: Unable to send command! Try to increase 'nettyThreads' and/or connection pool size settings Node source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=0, freeSubscribeConnectionsCounter=value:49:queue:0, freeConnectionsAmount=19, freeConnectionsCounter=value:59:queue:0, freezed=false, freezeReason=null, client=[addr=redis://192.168.53.179:6379], nodeType=MASTER, firstFail=0]]], connection: RedisConnection@131875383 [redisClient=[addr=redis://192.168.53.179:6379], channel=[id: 0x699c31ec, L:/100.111.156.155:48866 - R:192.168.53.179/192.168.53.179:6379], currentCommand=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@18ca11e9(failure: org.redisson.client.RedisTimeoutException: Command execution timeout for command: (PING), params: [], Redis client: [addr=redis://192.168.53.179:6379])], command=(PING), params=[], codec=org.redisson.client.codec.StringCodec]], command: (GET), params: [[115, 122, 45, 100, 99, 58, 115, 111, 114, 116, ...]] after 3 retry attempts; nested exception is org.redisson.client.RedisTimeoutException: Unable to send command! Try to increase 'nettyThreads' and/or connection pool size settings Node source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=0, freeSubscribeConnectionsCounter=value:49:queue:0, freeConnectionsAmount=19, freeConnectionsCounter=value:59:queue:0, freezed=false, freezeReason=null, client=[addr=redis://192.168.53.179:6379], nodeType=MASTER, firstFail=0]]], connection: RedisConnection@131875383 [redisClient=[addr=redis://192.168.53.179:6379], channel=[id: 0x699c31ec, L:/100.111.156.155:48866 - R:192.168.53.179/192.168.53.179:6379], currentCommand=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@18ca11e9(failure: org.redisson.client.RedisTimeoutException: Command execution timeout for command: (PING), params: [], Redis client: [addr=redis://192.168.53.179:6379])], command=(PING), params=[], codec=org.redisson.client.codec.StringCodec]], command: (GET), params: [[115, 122, 45, 100, 99, 58, 115, 111, 114, 116, ...]] after 3 retry attempts
at org.redisson.spring.data.connection.RedissonExceptionConverter.convert(RedissonExceptionConverter.java:48) ~[redisson-spring-data-21-3.11.2.jar!/:3.11.2]
at org.redisson.spring.data.connection.RedissonExceptionConverter.convert(RedissonExceptionConverter.java:35) ~[redisson-spring-data-21-3.11.2.jar!/:3.11.2]
at org.springframework.data.redis.PassThroughExceptionTranslationStrategy.translate(PassThroughExceptionTranslationStrategy.java:44) ~[spring-data-redis-2.1.8.RELEASE.jar!/:2.1.8.RELEASE]
at org.redisson.spring.data.connection.RedissonConnection.transform(RedissonConnection.java:234) ~[redisson-spring-data-21-3.11.2.jar!/:3.11.2]
at org.redisson.spring.data.connection.RedissonConnection.syncFuture(RedissonConnection.java:229) ~[redisson-spring-data-21-3.11.2.jar!/:3.11.2]
at org.redisson.spring.data.connection.RedissonConnection.sync(RedissonConnection.java:459) ~[redisson-spring-data-21-3.11.2.jar!/:3.11.2]
at org.redisson.spring.data.connection.RedissonConnection.read(RedissonConnection.java:840) ~[redisson-spring-data-21-3.11.2.jar!/:3.11.2]
at org.redisson.spring.data.connection.RedissonConnection.get(RedissonConnection.java:574) ~[redisson-spring-data-21-3.11.2.jar!/:3.11.2]
at org.springframework.data.redis.cache.DefaultRedisCacheWriter.lambda$get$1(DefaultRedisCacheWriter.java:109) ~[spring-data-redis-2.1.8.RELEASE.jar!/:2.1.8.RELEASE]
at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:242) ~[spring-data-redis-2.1.8.RELEASE.jar!/:2.1.8.RELEASE]
at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:109) ~[spring-data-redis-2.1.8.RELEASE.jar!/:2.1.8.RELEASE]
at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:82) ~[spring-data-redis-2.1.8.RELEASE.jar!/:2.1.8.RELEASE]
at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58) ~[spring-context-5.1.9.RELEASE.jar!/:5.1.9.RELEASE]
at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:73) ~[spring-context-5.1.9.RELEASE.jar!/:5.1.9.RELEASE]
at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:554) ~[spring-context-5.1.9.RELEASE.jar!/:5.1.9.RELEASE]
at org.springframework.cache.interceptor.CacheAspectSupport.findCachedItem(CacheAspectSupport.java:519) ~[spring-context-5.1.9.RELEASE.jar!/:5.1.9.RELEASE]
at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:401) ~[spring-context-5.1.9.RELEASE.jar!/:5.1.9.RELEASE]
at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:345) ~[spring-context-5.1.9.RELEASE.jar!/:5.1.9.RELEASE]
at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:61) ~[spring-context-5.1.9.RELEASE.jar!/:5.1.9.RELEASE]
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.1.7.RELEASE.jar!/:5.1.7.RELEASE]
at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688) ~[spring-aop-5.1.7.RELEASE.jar!/:5.1.7.RELEASE]
at com.szatc.biz.service.sort.service.impl.PointsKeywordServiceImpl$$EnhancerBySpringCGLIB$$d538eda5.selectAll() ~[classes!/:1.0.0-SNAPSHOT]
at com.szatc.biz.service.sort.sort.impl.DataCacheImpl.lambda$init$0(DataCacheImpl.java:117) ~[classes!/:1.0.0-SNAPSHOT]
at org.springframework.cloud.sleuth.instrument.async.TraceCallable.call(TraceCallable.java:70) ~[spring-cloud-sleuth-core-2.1.1.RELEASE.jar!/:2.1.1.RELEASE]
at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_91]
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[?:1.8.0_91]
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[?:1.8.0_91]
at java.lang.Thread.run(Thread.java:745) ~[?:1.8.0_91]
Caused by: org.redisson.client.RedisTimeoutException: Unable to send command! Try to increase 'nettyThreads' and/or connection pool size settings Node source: NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=0, freeSubscribeConnectionsCounter=value:49:queue:0, freeConnectionsAmount=19, freeConnectionsCounter=value:59:queue:0, freezed=false, freezeReason=null, client=[addr=redis://192.168.53.179:6379], nodeType=MASTER, firstFail=0]]], connection: RedisConnection@131875383 [redisClient=[addr=redis://192.168.53.179:6379], channel=[id: 0x699c31ec, L:/100.111.156.155:48866 - R:192.168.53.179/192.168.53.179:6379], currentCommand=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@18ca11e9(failure: org.redisson.client.RedisTimeoutException: Command execution timeout for command: (PING), params: [], Redis client: [addr=redis://192.168.53.179:6379])], command=(PING), params=[], codec=org.redisson.client.codec.StringCodec]], command: (GET), params: [[115, 122, 45, 100, 99, 58, 115, 111, 114, 116, ...]] after 3 retry attempts
at org.redisson.command.CommandAsyncService$6.run(CommandAsyncService.java:715) ~[redisson-3.11.2.jar!/:3.11.2]
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:672) ~[netty-all-4.1.58.Final.jar!/:4.1.58.Final]
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:747) ~[netty-all-4.1.58.Final.jar!/:4.1.58.Final]
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:472) ~[netty-all-4.1.58.Final.jar!/:4.1.58.Final]
at java.lang.Thread.run(Thread.java:745) ~[?:1.8.0_91]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3996
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
no OutOfMemoryError on applications using the same Redis server but the previous version of redisson 3.16.3
Actual behavior
applications starting to OOM running version 3.16.3 while an application running with 3.16.5 was fine
crm@thread-pool-redisson-general-netty@thread-4
  at io.netty.buffer.AbstractByteBuf.checkReadableBytes0(I)V (AbstractByteBuf.java:1442)
  at io.netty.buffer.AbstractByteBuf.checkReadableBytes(I)V (AbstractByteBuf.java:1428)
  at io.netty.buffer.AbstractByteBuf.readBytes([BII)Lio/netty/buffer/ByteBuf; (AbstractByteBuf.java:895)
  at io.netty.buffer.AbstractByteBuf.readBytes([B)Lio/netty/buffer/ByteBuf; (AbstractByteBuf.java:903)
  at org.redisson.cache.LocalCachedMessageCodec.lambda$new$0(Lio/netty/buffer/ByteBuf;Lorg/redisson/client/handler/State;)Ljava/lang/Object; (LocalCachedMessageCodec.java:68)
  at org.redisson.cache.LocalCachedMessageCodec$$Lambda$1805+0x0000000801d6ab08.decode(Lio/netty/buffer/ByteBuf;Lorg/redisson/client/handler/State;)Ljava/lang/Object; (Unknown Source)
  at org.redisson.client.handler.CommandDecoder.decode(Lio/netty/buffer/ByteBuf;Lorg/redisson/client/protocol/CommandData;Ljava/util/List;Lio/netty/channel/Channel;ZLjava/util/List;)V (CommandDecoder.java:383)
  at org.redisson.client.handler.CommandDecoder.decodeList(Lio/netty/buffer/ByteBuf;Lorg/redisson/client/protocol/CommandData;Ljava/util/List;Lio/netty/channel/Channel;JLjava/util/List;ZLjava/util/List;)V (CommandDecoder.java:427)
  at org.redisson.client.handler.CommandDecoder.decode(Lio/netty/buffer/ByteBuf;Lorg/redisson/client/protocol/CommandData;Ljava/util/List;Lio/netty/channel/Channel;ZLjava/util/List;)V (CommandDecoder.java:392)
  at org.redisson.client.handler.CommandPubSubDecoder.decodeCommand(Lio/netty/channel/Channel;Lio/netty/buffer/ByteBuf;Lorg/redisson/client/protocol/QueueCommand;I)V (CommandPubSubDecoder.java:84)
  at org.redisson.client.handler.CommandDecoder.decode(Lio/netty/channel/ChannelHandlerContext;Lio/netty/buffer/ByteBuf;Lorg/redisson/client/protocol/QueueCommand;I)V (CommandDecoder.java:137)
  at org.redisson.client.handler.CommandDecoder.decode(Lio/netty/channel/ChannelHandlerContext;Lio/netty/buffer/ByteBuf;Ljava/util/List;)V (CommandDecoder.java:94)
  at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(Lio/netty/channel/ChannelHandlerContext;Lio/netty/buffer/ByteBuf;Ljava/util/List;)V (ByteToMessageDecoder.java:507)
  at io.netty.handler.codec.ReplayingDecoder.callDecode(Lio/netty/channel/ChannelHandlerContext;Lio/netty/buffer/ByteBuf;Ljava/util/List;)V (ReplayingDecoder.java:366)
  at io.netty.handler.codec.ByteToMessageDecoder.channelRead(Lio/netty/channel/ChannelHandlerContext;Ljava/lang/Object;)V (ByteToMessageDecoder.java:276)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(Ljava/lang/Object;)V (AbstractChannelHandlerContext.java:379)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(Lio/netty/channel/AbstractChannelHandlerContext;Ljava/lang/Object;)V (AbstractChannelHandlerContext.java:365)
  at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(Ljava/lang/Object;)Lio/netty/channel/ChannelHandlerContext; (AbstractChannelHandlerContext.java:357)
  at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(Lio/netty/channel/ChannelHandlerContext;Ljava/lang/Object;)V (DefaultChannelPipeline.java:1410)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(Ljava/lang/Object;)V (AbstractChannelHandlerContext.java:379)
  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(Lio/netty/channel/AbstractChannelHandlerContext;Ljava/lang/Object;)V (AbstractChannelHandlerContext.java:365)
  at io.netty.channel.DefaultChannelPipeline.fireChannelRead(Ljava/lang/Object;)Lio/netty/channel/ChannelPipeline; (DefaultChannelPipeline.java:919)
  at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read()V (AbstractNioByteChannel.java:166)
  at io.netty.channel.nio.NioEventLoop.processSelectedKey(Ljava/nio/channels/SelectionKey;Lio/netty/channel/nio/AbstractNioChannel;)V (NioEventLoop.java:719)
  at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized()V (NioEventLoop.java:655)
  at io.netty.channel.nio.NioEventLoop.processSelectedKeys()V (NioEventLoop.java:581)
  at io.netty.channel.nio.NioEventLoop.run()V (NioEventLoop.java:493)
  at io.netty.util.concurrent.SingleThreadEventExecutor$4.run()V (SingleThreadEventExecutor.java:986)
  at io.netty.util.internal.ThreadExecutorMap$2.run()V (ThreadExecutorMap.java:74)
  at java.lang.Thread.run()V (Thread.java:832)

Steps to reproduce or test case
access the same Redis server with different versions of the library (3.16.3 vs. 3.16.5)
Redis version
5.0.3
Redisson version
3.16.3 and 3.16.5
Redisson configuration
local cache map config
    @Nonnull
    @Override
    public <T extends RedisCacheable> RedisWithLocalCache<String, T> getLocallyCachedMap(@Nonnull final CacheKey cacheName,
            final int cacheSize,
            @Nonnull final Duration timeToLive,
            @Nonnull final Duration localCacheTimeToLive) {
        final var options = LocalCachedMapOptions.<String, T> defaults() //
                .cacheSize(cacheSize) //
                .timeToLive(timeToLive.toMillis()) //
                .maxIdle(localCacheTimeToLive.toMillis()) //
                .evictionPolicy(LocalCachedMapOptions.EvictionPolicy.LRU) //
                .reconnectionStrategy(LocalCachedMapOptions.ReconnectionStrategy.LOAD) //
                .syncStrategy(LocalCachedMapOptions.SyncStrategy.UPDATE) //
                .writeMode(MapOptions.WriteMode.WRITE_BEHIND);
        return new RedisWithLocalCacheWrapper<>(redisson.getLocalCachedMap(cacheName.keyName(), options));
    }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3997
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
2021-11-30 21:12:10.804 [http-nio-8010-exec-5] ERROR o.a.c.c.C.[.[.[/psai_saas].[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [/psai_saas] threw exception [Request processing failed; nested exception is org.redisson.client.RedisNodeNotFoundException: Node: NodeSource [slot=1627, addr=//101.253.171.129:6379, redisClient=null, redirect=MOVED, entry=null] hasn't been discovered yet] with root cause
org.redisson.client.RedisNodeNotFoundException: Node: NodeSource [slot=1627, addr=//101.253.171.129:6379, redisClient=null, redirect=MOVED, entry=null] hasn't been discovered yet
at org.redisson.connection.MasterSlaveConnectionManager.connectionWriteOp(MasterSlaveConnectionManager.java:543)
at org.redisson.command.CommandAsyncService.getConnection(CommandAsyncService.java:684)
at org.redisson.command.CommandAsyncService.async(CommandAsyncService.java:539)
at org.redisson.command.CommandAsyncService$8.run(CommandAsyncService.java:628)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:669)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:744)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:469)
at java.lang.Thread.run(Thread.java:748)
rdisson version :3.8.2
#Redisson配置
masterSlaveServersConfig:
idleConnectionTimeout: 10000
connectTimeout: 10000
timeout: 3000
retryAttempts: 3
retryInterval: 1500
failedAttempts: 3
password: "is666"
subscriptionsPerConnection: 5
clientName: null
loadBalancer: !<org.redisson.connection.balancer.RoundRobinLoadBalancer> {}
slaveSubscriptionConnectionMinimumIdleSize: 1
slaveSubscriptionConnectionPoolSize: 50
slaveConnectionMinimumIdleSize: 32
slaveConnectionPoolSize: 64
masterConnectionMinimumIdleSize: 32
masterConnectionPoolSize: 64
readMode: "SLAVE"
slaveAddresses:
- "redis://101.253.171.129:6380"
- "redis://101.253.171.130:6380"
- "redis://101.253.171.131:6380"
masterAddress: "redis://101.253.171.131:6379"
database: 0
threads: 0
nettyThreads: 0
codec: !<org.redisson.codec.JsonJacksonCodec> {}
transportMode: "NIO"
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3998
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Can I configure this command somewhere?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/3999
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
6.2.1
Redisson version
3.16.4
Redisson configuration
结合 StringRedisTemplate 使用   restore  的时候，
当恢复的 KEY 已经存在的时候，
replace 参数传 false 时，数据没有被修改抛出 org.redisson.client.RedisBusyException 异常。
replace 参数传 true 时，数据被修改 但是也 抛出 org.redisson.client.RedisBusyException 异常。
不知道是不是源代码这里出了问题， restore(key, ttlInMillis, serializedValue);   是不是应该是在 else 里面的呀。
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4000
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When upgrade the redisson version from 3.10.4 to 3.16.4
netty-transport should be 4.1.68
just upgrade the redisson version 3.16.4 in a gradle project
3.16.4
Hello, I have the same issue for 3.16.4. I am using gradle and I updated my redissson version from 3.10.4 to 3.16.4 to solve a CVE. But when I checked the dependencies I realised that some how I do not know why, the versions were downgraded from 4.1.68 to 4.1.65 for netty-transport (it comes with redisson).
Could you take a look, please?
Thank you.
Here is the output;
+--- org.redisson:redisson:3.16.4
| +--- io.netty:netty-common:4.1.68.Final -> 4.1.65.Final
| +--- io.netty:netty-codec:4.1.68.Final -> 4.1.65.Final
| | +--- io.netty:netty-common:4.1.65.Final
| | +--- io.netty:netty-buffer:4.1.65.Final
| | | --- io.netty:netty-common:4.1.65.Final
| | --- io.netty:netty-transport:4.1.65.Final
| | +--- io.netty:netty-common:4.1.65.Final
| | +--- io.netty:netty-buffer:4.1.65.Final ()
| | --- io.netty:netty-resolver:4.1.65.Final
| | --- io.netty:netty-common:4.1.65.Final
| +--- io.netty:netty-buffer:4.1.68.Final -> 4.1.65.Final ()
| +--- io.netty:netty-transport:4.1.68.Final -> 4.1.65.Final ()
| +--- io.netty:netty-resolver:4.1.68.Final -> 4.1.65.Final ()
| +--- io.netty:netty-resolver-dns:4.1.68.Final -> 4.1.65.Final
| | +--- io.netty:netty-common:4.1.65.Final
| | +--- io.netty:netty-buffer:4.1.65.Final ()
| | +--- io.netty:netty-resolver:4.1.65.Final ()
| | +--- io.netty:netty-transport:4.1.65.Final ()
| | +--- io.netty:netty-codec:4.1.65.Final ()
| | +--- io.netty:netty-codec-dns:4.1.65.Final
| | | +--- io.netty:netty-common:4.1.65.Final
| | | +--- io.netty:netty-buffer:4.1.65.Final ()
| | | +--- io.netty:netty-transport:4.1.65.Final ()
| | | --- io.netty:netty-codec:4.1.65.Final ()
| | --- io.netty:netty-handler:4.1.65.Final
| | +--- io.netty:netty-common:4.1.65.Final
| | +--- io.netty:netty-resolver:4.1.65.Final ()
| | +--- io.netty:netty-buffer:4.1.65.Final ()
| | +--- io.netty:netty-transport:4.1.65.Final ()
| | --- io.netty:netty-codec:4.1.65.Final ()
| +--- io.netty:netty-handler:4.1.68.Final -> 4.1.65.Final ()
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4001
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
We use redisson to connect to 3 redis nodes in replicated mode and MASTER_SLAVE read mode (AWS ElastiCache).
We expect to distribute the redis read operations evenly among the 3 redis nodes.
Actual behavior
Since the upgrade of redisson to version 3.16.15 PRO we notice that our application does not distribute the redis read opeations evenly to all the nodes, and only one redis node receives almost 100% of the read operations.
Yesterday at 20:40 we deployed our application with only one change: upgrade redisson from 3.16.4 to 3.16.5.
And today at 11:10 we rolled back our application to the redisson 3.16.4 version.
This graph shows:

Until 20:40 the 3 redis nodes received the read operations evenly (redisson 3.16.4)
From 20:40 just one redis node receives almost all the read operations (upgrade to redisson 3.16.5)
From 11:10 the 3 redis nodes receive the read operations evenly again (rollback to redisson 3.16.4)


Steps to reproduce or test case
Connect to 3 nodes in replicated mode and MASTER_SLAVE read mode.
Execute multiple read operations.
Check redis read operations metrics.
Redis version
Redis 5.0.7
Redisson version
3.16.15 PRO
Redisson configuration

replicated mode
MASTER_SLAVE read mode
3 AWS ElastiCache nodes (1 master + 2 slaves)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4002
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is your feature request related to a problem? Please describe.
MessageListener can be annotated by FunctionalInterface to use lambda?
Describe the solution you'd like
java.lang.FunctionalInterface
Describe alternatives you've considered
this interface have only one method  onMessage  now
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4003
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Connected using SentinelServer config, all the Redis pods(1master, 2 slave) are up and running in the Kubernetes cluster. Sentinels are also running along with the Redis containers like a sidecar. No WARN logs to be printed when connection is fine.
I am connecting to the Redis headless service in kube.
Actual behavior
Getting continuous WARN logs like below for all the IPs where Redis pods are running
02 Dec 2021 14:03:15,355  WARN [redisson-netty-5-30]  SentinelConnectionManager:546 - sentinel: redis://10.244.164.253:26379 is down
02 Dec 2021 14:03:15,356  WARN [redisson-netty-5-30]  SentinelConnectionManager:546 - sentinel: redis://10.244.154.103:26379 is down
02 Dec 2021 14:03:15,356  WARN [redisson-netty-5-30]  SentinelConnectionManager:546 - sentinel: redis://10.244.226.111:26379 is down
02 Dec 2021 14:03:19,548  WARN [redisson-netty-2-19]  SentinelConnectionManager:546 - sentinel: redis://10.244.164.253:26379 is down
02 Dec 2021 14:03:19,548  WARN [redisson-netty-2-19]  SentinelConnectionManager:546 - sentinel: redis://10.101.141.35:26379 is down
02 Dec 2021 14:03:19,548  WARN [redisson-netty-2-19]  SentinelConnectionManager:546 - sentinel: redis://10.244.226.111:26379 is down
02 Dec 2021 14:03:19,552  INFO [redisson-netty-2-22]  SentinelConnectionManager:613 - sentinel: redis://10.102.102.69:26379 added
02 Dec 2021 14:03:19,731  INFO [redisson-netty-5-25]  SentinelConnectionManager:613 - sentinel: redis://10.244.164.253:26379 added
02 Dec 2021 14:03:19,732  INFO [redisson-netty-5-21]  SentinelConnectionManager:613 - sentinel: redis://10.244.154.103:26379 added
02 Dec 2021 14:03:19,732  INFO [redisson-netty-5-23]  SentinelConnectionManager:613 - sentinel: redis://10.244.226.111:26379 added
02 Dec 2021 14:03:19,885  INFO [redisson-netty-2-26]  SentinelConnectionManager:613 - sentinel: redis://10.244.226.111:26379 added
Steps to reproduce or test case
3 Redis pods running along with Sentinels
App connected to Redis with Sentinel config
Redis version
6.2.3
Redisson version
3.16.5
Redisson configuration
String redisUrls = "redis://redis:26379";
config.useSentinelServers()
.setReadMode(ReadMode.MASTER_SLAVE)
.setScanInterval(5000)
.setRetryAttempts(2)
.setRetryInterval(1000)
.setPassword(redisPassword)
.setPingConnectionInterval(5000)
.setMasterName("redis-master")
.addSentinelAddress(redisUrls.split(","));
Please let me know if i have mis-configured anything. Thanks.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4004
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Using Java 16/17 I can connect with a host by host name successfully, just as with Java 8
Actual behavior
When running the same code with Java 8, I can successfully connect to a remote host by name, but with Java 9, 16 and 17 I cannot.
Stacktrace:
java.lang.ExceptionInInitializerError
at xxx
Caused by: java.net.UnknownHostException: failed to resolve 'somehost' after 10 queries
at io.netty.resolver.dns.DnsResolveContext.finishResolve(DnsResolveContext.java:1046)
at io.netty.resolver.dns.DnsResolveContext.tryToFinishResolve(DnsResolveContext.java:999)
at io.netty.resolver.dns.DnsResolveContext.query(DnsResolveContext.java:417)
at io.netty.resolver.dns.DnsResolveContext.onResponse(DnsResolveContext.java:628)
at io.netty.resolver.dns.DnsResolveContext.access$400(DnsResolveContext.java:65)
at io.netty.resolver.dns.DnsResolveContext$2.operationComplete(DnsResolveContext.java:461)
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)
at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:571)
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:550)
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)
at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)
at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:605)
at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)
at io.netty.resolver.dns.DnsQueryContext.trySuccess(DnsQueryContext.java:200)
at io.netty.resolver.dns.DnsQueryContext.finish(DnsQueryContext.java:192)
at io.netty.resolver.dns.DnsNameResolver$DnsResponseHandler.channelRead(DnsNameResolver.java:1301)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
at io.netty.channel.nio.AbstractNioMessageChannel$NioMessageUnsafe.read(AbstractNioMessageChannel.java:97)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)
at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base/java.lang.Thread.run(Thread.java:833)
Steps to reproduce or test case
I am using Redisson, which is using Netty:
Config config = new Config();
config.useSingleServer()
        .setAddress("redis://somehost:5379");
CLIENT = Redisson.create(config);

Redis version
6.2.6 (dockerised)
Redisson version
Tried 3.16.4 and 3.16.5
Redisson configuration
As above
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4005
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Have 1 master and 1 slave (with AWS ElastiCache). When testing failover by through modifying of the node type of the redis instance, expect after failover that there are no errors when querying the new master/slave.
Actual behavior
Getting the following error message:
Can't find replicaAddr/<host> in slaves! Available slaves: [[addr=master1Addr], [addr=master1Addr], [addr=master1Addr], [addr=replicaAddr]]
Trace:
  at java.lang.Thread.getStackTrace(Thread.java:1596)
   at ch.qos.logback.core.UnsynchronizedAppenderBase.doAppend(UnsynchronizedAppenderBase.java:84)
   at ch.qos.logback.core.spi.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:51)
   at ch.qos.logback.classic.Logger.appendLoopOnAppenders(Logger.java:270)
   at ch.qos.logback.classic.Logger.callAppenders(Logger.java:257)
   at ch.qos.logback.classic.Logger.buildLoggingEventAndAppend(Logger.java:421)
   at ch.qos.logback.classic.Logger.filterAndLog_2(Logger.java:414)
   at ch.qos.logback.classic.Logger.error(Logger.java:530)
   at org.redisson.connection.balancer.LoadBalancerManager.unfreeze(LoadBalancerManager.java:127)
   at org.redisson.connection.MasterSlaveEntry.slaveUp(MasterSlaveEntry.java:424)
   at org.redisson.connection.ReplicatedConnectionManager.slaveUp(ReplicatedConnectionManager.java:206)
   at org.redisson.connection.ReplicatedConnectionManager.lambda$checkNode$5(ReplicatedConnectionManager.java:195)
   at org.redisson.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:187)
   at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)
   at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:571)
   at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:550)
   at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)
   at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)
   at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:605)
   at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)
   at org.redisson.misc.RedissonPromise.trySuccess(RedissonPromise.java:82)
   at org.redisson.client.handler.CommandDecoder.completeResponse(CommandDecoder.java:460)
   at org.redisson.client.handler.CommandDecoder.handleResult(CommandDecoder.java:454)
   at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:385)
   at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:198)
   at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:137)
   at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:113)
   at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:507)
   at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
   at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
   at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
   at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
   at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
   at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
   at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
   at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
   at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
   at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
   at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)
   at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)
   at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)
   at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
   at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
   at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
   at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
   at java.lang.Thread.run(Thread.java:831)

Steps to reproduce or test case

Deploy Service
Modify node type of redis instance
View application logs and see errors

Redis version
6.0.5
Redisson version
3.16.5
Redisson configuration
    redissonConfig
      .useReplicatedServers()
      .setTimeout(5000)
      .setNodeAddresses(addressList);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4006
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
请问这个问题解决了吗？在哪个版本解决的？
我现在用的是redisson-spring-data-24:3.15.2
spring-projects/spring-data-redis/issues/2147
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4007
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
When using RRateLimiter.expire(), RRateLimiter sets TTL to config Hash set, but doesn't set TTL to value and permits.
IIUC, value and permits consumes more memory compared to config Hash set.
Is there a way to expire value and permits?
NOTE:

config = key returned bygetRawName()
value = key returned by https://github.com/redisson/redisson/blob/redisson-3.16.6/redisson/src/main/java/org/redisson/RedissonRateLimiter.java#L53-L55
permits = key returned by https://github.com/redisson/redisson/blob/redisson-3.16.6/redisson/src/main/java/org/redisson/RedissonRateLimiter.java#L45-L47
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4008
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
This is happening on my CI/CD tool (Semaphore CI). After adding the Redisson dependency, the build always fails with the error:
*** buffer overflow detected ***: /usr/lib/jvm/java-11-openjdk-amd64/bin/java terminated
My CI/CD uses a Ubuntu 18.04 VM and has Java 11.0.11 installed.
I think the problem is likely related to that VM, as if I run the tests locally (Ubuntu 20.04, OpenJDK Runtime Environment AdoptOpenJDK-11.0.11+9) the tests are executed as expected.
Has anybody had this problem before? Do you have any idea on what might be creating this error?
Thanks in advance for any help!
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4009
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
We want to enforce that Application can only read the data from Redis Master node but is not able to write or make into modifications into the Redis Master node in replicatedServerConfig. Can you please inform how can we do that?  Is that using readMode :MASTER ? Can you please provide the yaml configuration for that ?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4010
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hey guys.
When moving from version 3.16.3 to 3.16.5 I've noticed compilation issues due to the missing method getAmount() which underneath was running freeConnectionsCounter.getCounter():
https://github.com/redisson/redisson/blob/redisson-3.16.3/redisson/src/main/java/org/redisson/connection/ClientConnectionsEntry.java#L155-L157
My question is was that intentional and is there a substitute method somewhere? I couldn't find a quick solution for this.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4011
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have a limit of 20 connections per server and in previous versions the initialization was correct. But in version 3.16.5, the SlaveConnectionPool was initialized, which creates 24 connections by default. But I cannot reduce their number for configuration in single server mode and I cannot disable the creation of this pool either.
Expected behavior
2021-12-08 12:04:26.535    INFO 297287 --- [           main] org.redisson.Version                     : Redisson 3.16.4
2021-12-08 12:04:26.806    INFO 297287 --- [isson-netty-2-3] o.r.c.pool.MasterConnectionPool          : 4 connections initialized for 127.0.0.1/127.0.0.1:6383
2021-12-08 12:04:26.808    INFO 297287 --- [isson-netty-2-3] o.r.c.pool.MasterPubSubConnectionPool    : 1 connections initialized for 127.0.0.1/127.0.0.1:6383
Actual behavior
2021-12-08 12:06:41.232    INFO 297579 --- [           main] org.redisson.Version                     : Redisson 3.16.5
2021-12-08 12:06:41.540    INFO 297579 --- [isson-netty-2-2] o.r.c.pool.MasterPubSubConnectionPool    : 1 connections initialized for 127.0.0.1/127.0.0.1:6383
2021-12-08 12:06:41.540    INFO 297579 --- [isson-netty-2-4] o.r.c.pool.PubSubConnectionPool          : 1 connections initialized for 127.0.0.1/127.0.0.1:6383
2021-12-08 12:06:41.544    INFO 297579 --- [isson-netty-2-4] o.r.c.pool.MasterConnectionPool          : 4 connections initialized for 127.0.0.1/127.0.0.1:6383
2021-12-08 12:06:41.553    INFO 297579 --- [isson-netty-2-4] o.r.connection.pool.SlaveConnectionPool  : 24 connections initialized for 127.0.0.1/127.0.0.1:6383
Steps to reproduce or test case
Redis version
Redisson version
3.16.5,...
Redisson configuration
single server
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4012
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4013
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4014
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4015
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4016
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4017
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4018
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4019
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4020
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4021
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4022
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4023
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4024
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4025
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4026
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4027
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4028
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4029
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4030
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4031
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4032
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4033
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4034
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4035
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4036
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4037
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4038
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4039
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4040
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4041
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4042
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4043
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4044
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4045
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4046
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4047
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4048
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4049
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4050
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4051
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4052
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4053
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4054
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4055
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4056
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4057
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4058
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4059
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4060
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4061
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4062
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4063
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4064
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4065
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4066
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4067
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4068
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4069
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4070
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4071
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4072
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4073
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4074
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4075
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4076
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4077
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4078
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4079
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4080
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4081
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4082
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4083
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4084
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4085
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4086
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4087
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4088
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4089
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4090
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4091
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4092
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4093
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4094
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4095
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4096
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4097
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4098
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4099
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4100
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4101
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4102
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4103
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4104
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4105
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4106
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4107
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4108
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4109
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4110
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4111
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4112
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4113
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4114
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4115
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4116
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4117
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4118
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4119
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4120
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4121
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4122
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4123
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4124
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4125
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4126
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4127
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4128
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4129
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4130
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4131
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4132
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4133
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4134
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4135
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4136
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4137
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4138
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4139
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4140
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4141
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4142
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4143
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4144
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4145
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4146
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4147
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4148
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4149
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4150
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4151
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4152
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[]
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4153
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In my code, I am trying to acquire a fair lock with a fixed waitTime and leaseTime as so
fairLock.tryLockAsync(waitTime, leaseTime, timeUnit, ID)
Occasionally, I face this error
ERR Error running script (call to f_762bfafa6be221431a0b668685dd15c926483619): @user_script:1: user_script:1: attempt to compare nil with number. channel: [id: 0xacec2457, L:/10.60.19.200:56300 - R:[redisURI]/[redisURI]:6379] command: (EVAL), promise: java.util.concurrent.CompletableFuture@7b16e88f[Not completed], params: [while true do local firstThreadId2 = redis.call('lindex', KEYS[2], 0);if firstThreadId2 == false the..., 3, lockName, redisson_lock_queue:{lockName}, redisson_lock_timeout:{lockName}, 36000, 8fe4a548-fa9f-42a3-8482-1d24d038f24f:830040972163392702, 36000, 1645538812661], stack trace: org.redisson.client.RedisException: ERR Error running script (call to f_762bfafa6be221431a0b668685dd15c926483619): @user_script:1: user_script:1: attempt to compare nil with number. channel: [id: 0xacec2457, L:/10.60.19.200:56300 - R:[redisURI]/[redisURI]:6379] command: (EVAL), promise: java.util.concurrent.CompletableFuture@7b16e88f[Not completed], params: [while true do local firstThreadId2 = redis.call('lindex', KEYS[2], 0);if firstThreadId2 == false the..., 3, lockName, redisson_lock_queue:{lockName}, redisson_lock_timeout:{lockName}, 36000, 8fe4a548-fa9f-42a3-8482-1d24d038f24f:830040972163392702, 36000, 1645538812661]
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:370)
	at org.redisson.client.handler.CommandDecoder.decodeCommandBatch(CommandDecoder.java:271)
	at org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:210)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:137)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:113)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:510)
	at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:279)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:833)

I also see a queue is being formed for the fair lock, even though it is not currently held.
The waiting requests eventually time out after the waitTime expires.
The queue is being formed for the same lock that this exception is being thrown for.
At times, I have also seen the queue being formed for no reason without this error being thrown.
I am not able to reproduce this locally,
Redis version
6.x
Redisson version
3.16.8
Redisson configuration
config.useSingleServer().apply {
    path.toIntOrNull()?.also {
        database = it
    } ?: run {
        logger.warn { "Unable to parse database number: $path from redis configuration" }
    }
}
config.nettyThreads = 64
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4154
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hello, I started getting weird exception after sentinel cluster failover. Application restart does not help. Looks like sentinel cluster might be at a faulty state, but there's no signs of it.
Redisson version: 3.16.7
Caused by: j.lang.IllegalStateException: Only 2 of 1 slaves were synced
	at org.redisson.RedissonBaseLock.lambda$evalWriteAsync$0(RedissonBaseLock.java:235)
	at o.r.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:187)
	at i.n.u.c.DefaultPromise.notifyListener0(DefaultPromise.java:578)
	at i.n.u.c.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)
	at i.n.u.c.DefaultPromise.notifyListeners(DefaultPromise.java:491)
	at i.n.u.c.DefaultPromise.setValue0(DefaultPromise.java:616)
	at i.n.u.c.DefaultPromise.setSuccess0(DefaultPromise.java:605)
	at i.n.u.c.DefaultPromise.trySuccess(DefaultPromise.java:104)
	at o.r.misc.RedissonPromise.trySuccess(RedissonPromise.java:82)
	at o.r.c.CommandBatchService.lambda$executeAsync$7(CommandBatchService.java:331)
	at o.r.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:187)
	at i.n.u.c.DefaultPromise.notifyListener0(DefaultPromise.java:578)
	at i.n.u.c.DefaultPromise.notifyListeners0(DefaultPromise.java:571)
	at i.n.u.c.DefaultPromise.notifyListenersNow(DefaultPromise.java:550)
	at i.n.u.c.DefaultPromise.notifyListeners(DefaultPromise.java:491)
	at i.n.u.c.DefaultPromise.setValue0(DefaultPromise.java:616)
	at i.n.u.c.DefaultPromise.setSuccess0(DefaultPromise.java:605)
	at i.n.u.c.DefaultPromise.trySuccess(DefaultPromise.java:104)
	at o.r.misc.RedissonPromise.trySuccess(RedissonPromise.java:82)
	at o.r.c.RedisCommonBatchExecutor.handleResult(RedisCommonBatchExecutor.java:164)
	at o.r.command.RedisExecutor.checkAttemptPromise(RedisExecutor.java:465)
	at o.r.command.RedisExecutor.lambda$execute$3(RedisExecutor.java:173)
	at o.r.misc.RedissonPromise.lambda$onComplete$0(RedissonPromise.java:187)
	at i.n.u.c.DefaultPromise.notifyListener0(DefaultPromise.java:578)
	at i.n.u.c.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)
	at i.n.u.c.DefaultPromise.notifyListeners(DefaultPromise.java:491)
	at i.n.u.c.DefaultPromise.setValue0(DefaultPromise.java:616)
	at i.n.u.c.DefaultPromise.setSuccess0(DefaultPromise.java:605)
	at i.n.u.c.DefaultPromise.trySuccess(DefaultPromise.java:104)
	at o.r.misc.RedissonPromise.trySuccess(RedissonPromise.java:82)

Steps to reproduce or test case
Still figuring it out. We were experimenting on sentinel cluster with 3 nodes, killing master for test purposes.
Redis info
Server
redis_version:6.2.6
redis_git_sha1:00000000
redis_git_dirty:0
redis_build_id:117005704b7d572d
redis_mode:standalone
os:Linux 5.4.156-83.273.amzn2.x86_64 x86_64
arch_bits:64
multiplexing_api:epoll
atomicvar_api:c11-builtin
gcc_version:8.3.0
process_id:1
process_supervised:no
run_id:8d5d7867c0685a1a162696c505793e870f44ef25
tcp_port:6379
server_time_usec:1645556982046578
uptime_in_seconds:6823
uptime_in_days:0
hz:10
configured_hz:10
lru_clock:1389813
executable:/redis-server
config_file:
io_threads_active:0

# Clients
connected_clients:221
cluster_connections:0
maxclients:10000
client_recent_max_input_buffer:40
client_recent_max_output_buffer:0
blocked_clients:0
tracking_clients:0
clients_in_timeout_table:0

# Memory
used_memory:12026224
used_memory_human:11.47M
used_memory_rss:23326720
used_memory_rss_human:22.25M
used_memory_peak:27203384
used_memory_peak_human:25.94M
used_memory_peak_perc:44.21%
used_memory_overhead:7255192
used_memory_startup:810480
used_memory_dataset:4771032
used_memory_dataset_perc:42.54%
allocator_allocated:12542192
allocator_active:14557184
allocator_resident:21155840
total_system_memory:16593977344
total_system_memory_human:15.45G
used_memory_lua:39936
used_memory_lua_human:39.00K
used_memory_scripts:880
used_memory_scripts_human:880B
number_of_cached_scripts:2
maxmemory:0
maxmemory_human:0B
maxmemory_policy:noeviction
allocator_frag_ratio:1.16
allocator_frag_bytes:2014992
allocator_rss_ratio:1.45
allocator_rss_bytes:6598656
rss_overhead_ratio:1.10
rss_overhead_bytes:2170880
mem_fragmentation_ratio:1.91
mem_fragmentation_bytes:11118000
mem_not_counted_for_evict:2554
mem_replication_backlog:1048576
mem_clients_slaves:41024
mem_clients_normal:4532984
mem_aof_buffer:2560
mem_allocator:jemalloc-5.1.0
active_defrag_running:0
lazyfree_pending_objects:0
lazyfreed_objects:0

# Persistence
loading:0
current_cow_size:0
current_cow_size_age:0
current_fork_perc:0.00
current_save_keys_processed:0
current_save_keys_total:0
rdb_changes_since_last_save:3481418
rdb_bgsave_in_progress:0
rdb_last_save_time:1645550247
rdb_last_bgsave_status:ok
rdb_last_bgsave_time_sec:0
rdb_current_bgsave_time_sec:-1
rdb_last_cow_size:741376
aof_enabled:1
aof_rewrite_in_progress:0
aof_rewrite_scheduled:0
aof_last_rewrite_time_sec:1
aof_current_rewrite_time_sec:-1
aof_last_bgrewrite_status:ok
aof_last_write_status:ok
aof_last_cow_size:5128192
module_fork_in_progress:0
module_fork_last_cow_size:0
aof_current_size:65106117
aof_base_size:931967
aof_pending_rewrite:0
aof_buffer_length:0
aof_rewrite_buffer_length:0
aof_pending_bio_fsync:0
aof_delayed_fsync:0

# Stats
total_connections_received:700643
total_commands_processed:11386723
instantaneous_ops_per_sec:1422
total_net_input_bytes:1028876426
total_net_output_bytes:46767630387
instantaneous_input_kbps:119.32
instantaneous_output_kbps:6807.82
rejected_connections:0
sync_full:3
sync_partial_ok:0
sync_partial_err:2
expired_keys:67829
expired_stale_perc:1.05
expired_time_cap_reached_count:0
expire_cycle_cpu_milliseconds:337
evicted_keys:0
keyspace_hits:2623786
keyspace_misses:324519
pubsub_channels:3
pubsub_patterns:0
latest_fork_usec:680
total_forks:10
migrate_cached_sockets:0
slave_expires_tracked_keys:0
active_defrag_hits:0
active_defrag_misses:0
active_defrag_key_hits:0
active_defrag_key_misses:0
tracking_total_keys:0
tracking_total_items:0
tracking_total_prefixes:0
unexpected_error_replies:0
total_error_replies:7
dump_payload_sanitizations:0
total_reads_processed:7655271
total_writes_processed:10129346
io_threaded_reads_processed:0
io_threaded_writes_processed:0

# Replication
role:master
connected_slaves:2
slave0:ip=redis-sentinel-node-1.redis-sentinel-headless.default.svc.cluster.local,port=6379,state=online,offset=28711301244,lag=1
slave1:ip=redis-sentinel-node-0.redis-sentinel-headless.default.svc.cluster.local,port=6379,state=online,offset=28711301244,lag=1
master_failover_state:no-failover
master_replid:ab572f8c1c8a733396709bade2a5bc700701ec86
master_replid2:01e55261afc7c5505d7da94699e5a403d2eef737
master_repl_offset:28711301281
second_repl_offset:28196501650
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:28710252706
repl_backlog_histlen:1048576

# CPU
used_cpu_sys:206.684823
used_cpu_user:174.922001
used_cpu_sys_children:0.035053
used_cpu_user_children:0.152909
used_cpu_sys_main_thread:205.938414
used_cpu_user_main_thread:174.665218

# Modules

# Errorstats
errorstat_ERR:count=4
errorstat_NOAUTH:count=3

# Cluster
cluster_enabled:0

# Keyspace
db0:keys=8696,expires=8696,avg_ttl=106041980

Sentinel config:
dir "/tmp"
port 26379
sentinel monitor mymaster redis-sentinel-node-2.redis-sentinel-headless.default.svc.cluster.local 6379 2
sentinel down-after-milliseconds mymaster 2000
sentinel failover-timeout mymaster 5000
# User-supplied sentinel configuration:
# End of sentinel configuration
sentinel auth-pass mymaster ***
requirepass "***"
sentinel myid 6b28db582bd8af66c1e0ddbcc9afcce2daba4354
sentinel known-replica mymaster redis-sentinel-node-1.redis-sentinel-headless.default.svc.cluster.local 6379
sentinel known-sentinel mymaster redis-sentinel-node-1.redis-sentinel-headless.default.svc.cluster.local 26379 5add24b6f14969527b26e2b3d62ebfa73e2de554
sentinel known-replica mymaster redis-sentinel-node-0.redis-sentinel-headless.default.svc.cluster.local 6379
sentinel known-sentinel mymaster redis-sentinel-node-2.redis-sentinel-headless.default.svc.cluster.local 26379 5f4ff5b1f3024ce375ab027ac24adb717305f02c
sentinel announce-hostnames yes
sentinel resolve-hostnames yes
sentinel announce-port 26379
sentinel announce-ip "redis-sentinel-node-0.redis-sentinel-headless.default.svc.cluster.local"
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4155
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
the execute method does not compare the parameter length and parameter type. When a method is overloaded,such as the ttl method, it may cause java.lang.IllegalArgumentException exceptions.
@OverRide
public Object execute(String command, byte[]... args) {
for (Method method : this.getClass().getDeclaredMethods()) {
if (method.getName().equalsIgnoreCase(command) && Modifier.isPublic(method.getModifiers())) {
try {
Object t = execute(method, args);
if (t instanceof String) {
return ((String) t).getBytes();
}
return t;
} catch (IllegalArgumentException e) {
if (isPipelined()) {
throw new RedisPipelineException(e);
}
                throw new InvalidDataAccessApiUsageException(e.getMessage(), e);
            }
        }
    }
    throw new UnsupportedOperationException();
}

private Object execute(Method method, byte[]... args) {
    if (method.getParameterTypes().length > 0 && method.getParameterTypes()[0] == byte[][].class) {
        return ReflectionUtils.invokeMethod(method, this, args);
    }
    if (args == null) {
        return ReflectionUtils.invokeMethod(method, this);
    }
    return ReflectionUtils.invokeMethod(method, this, Arrays.asList(args).toArray());
}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4156
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4157
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
All keys matching pattern are deleted
Actual behavior
Keys are not deleted
Steps to reproduce or test case
internal fun purge() {
        client.keys.deleteByPattern("$metadataNamespace*")
        client.keys.deleteByPattern("$valueNamespace*")
    }

The above code works correctly on 3.16.7 to delete all keys matching 2 patterns we pass in.  On 3.16.8 the keys are not deleted.
Redis version
6.2.6
Redisson version
3.16.8
Redisson configuration
RedisDataShelf.Builder(
        "test",
        defaultTtl,
        client,
        NullCryptApi(),
        TemporaryFileStore(Files.createTempDirectory("RedisDataShelfTest"))
    )
    ```
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4158
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Hi,
I have 2 module A and B, using same Redisson 3.16.1. The modules are using a RLocalCachedMap. I want to change Redisson version of B server to 3.16.8. And I'm facing with exception.
java.lang.IndexOutOfBoundsException: readerIndex(21) + length(1668246830) exceeds writerIndex(264): UnpooledSlicedByteBuf(ridx: 21, widx: 264, cap: 264/264, unwrapped: PooledUnsafeDirectByteBuf(ridx: 672, widx: 896, cap: 1024))
	at io.netty.buffer.AbstractByteBuf.checkReadableBytes0(AbstractByteBuf.java:1442)
	at io.netty.buffer.AbstractByteBuf.checkReadableBytes(AbstractByteBuf.java:1428)
	at io.netty.buffer.AbstractByteBuf.readBytes(AbstractByteBuf.java:895)
	at io.netty.buffer.AbstractByteBuf.readBytes(AbstractByteBuf.java:903)
	at org.redisson.cache.LocalCachedMessageCodec.lambda$new$0(LocalCachedMessageCodec.java:68)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:383)
	at org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:427)
	at org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:392)

I know that LocalCachedMessageCodec encode and decode methods were changed for a reason. And this exception is thrown when LocalCachedMap updated.
I wonder that does it have any way to run server A and B with different Redisson version?
P/s: That is my example. Now I have more than 10 modules are using Redisson and I just want to update some of them
Thanks
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4159
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I'd like to add a Distributed data structure named RedissonMapMultimap (It'll be similar to RedissonListMultimap).
For The following Map:
Map("id1" to Map("innerId1" : "value1", "innerId2": "value2")) 
the user could use the RedissonMapMultimap to get value1 without making 2 network calls / writing the logic themselves.
The interface will have functions like RedissonMapMultimap.get(key: Key, innerKey: Key).
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4160
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have keys in array of ByteArray (ByteArray for each key) and I am wondering if redisson enable returning value/timeout/null(miss) for different key with batch execute. Would batch support this? Or batch.execute() is just an atomic operation and will fail for all batch once a key is missed?
eg:
val batch = redissonClient.createBatch();
keys.foreach(key -> batch.getBucket(key).async.get();
val vals = batch.excute().getResponse()
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4161
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is your feature request related to a problem? Please describe.
My application uses TOML for its configurations and it would be nice if the Redisson configs were TOML too. TOML is an INI-like human-readable config language that's increasing in popularity.
Here's some references on TOML:

https://toml.io/
https://github.com/toml-lang/toml
https://en.wikipedia.org/wiki/TOML

Describe the solution you'd like
TOML support should be added to Redisson Config using Jackson.
Redisson Config seems to use Jackson to handle JSON and YAML. As of Jackson 2.13, jackson-dataformats-text supports TOML in addition to YAML. It seems that Redisson upgraded to Jackson 2.13 with commit 3f457c9 on Dec 21, 2021.
By adding the TOML backend, jackson-dataformats-toml, the TomlFactory type can be used similar to how the YAMLFactory type is used in org.redisson.config.ConfigSupport.
Describe alternatives you've considered
Current workaround is to not use TOML and have Redisson's configs stored in YAML. Resulting in my application requiring multiple config formats.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4162
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Currently I don't plan to remove JSON support in 3.x version. Can you suggest changes without removing JSON?

Maybe I forgot to add it back somewhere, but as far as I can tell my changes leave the existing JSON code in tact. Several of the diffs may seem like the code is being removed, but I'm just moving it so the code attempts to parse as TOML before trying JSON.
There were a few instances I found where the code only handled YAML so I only updated with TOML support.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4163
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Simplest service interface:
public interface IService {
  void ping();
}

Service Implementation:
public class MyService implements IService {
  public MyService() {
    RedissonClient client = Redisson.create();

    // register myself as a remote service
    client.getRemoteService(JsonJacksonCodec.INSTANCE).register(IService.class, this);
  }

  public void ping() {
    Logger.getGlobal().info("I was pinged");
  }
}

Client:
public class Client {
  public Client() {
    RedissonClient client = Redisson.create();

    IService service = client.getRemoteService(JsonJacksonCodec.INSTANCE).get(IService.class);

    // test communication with "ping"
    service.ping();
    Logger.getGlobal().info("pinged");
  }
}

Service is instantiated locally and then the client (both on same JVM, Redis server is running locally with default Ubuntu 20 configuration)
Expected behavior

Log to have the line "I was pinged"
Log to have the line "pinged"
No timeout or exceptions

Actual behavior

Log has "I was pinged"
Exception:


org.redisson.remote.RemoteServiceTimeoutException: No response after 30000ms for request: RemoteServiceRequest [requestId=46edfd042fba0b14bf6469bb490c0d42, methodName=ping, signature=[-5212114190830492821, -5560568237385073498], args=null, options=RemoteInvocationOptions[ackTimeoutInMillis=1000, executionTimeoutInMillis=30000], date=1645976606667]
at org.redisson.remote.SyncRemoteProxy$1.invoke(SyncRemoteProxy.java:133)
at jdk.proxy4/jdk.proxy4.$Proxy47.ping(Unknown Source)

Steps to reproduce or test case
Use code above
Redis version
$ redis-server --version
Redis server v=5.0.7 sha=00000000:0 malloc=jemalloc-5.2.1 bits=64 build=636cde3b5c7a3923

Redisson version
<!-- Redis client: Redisson -->
		<dependency>
			<groupId>org.redisson</groupId>
			<artifactId>redisson</artifactId>
			<version>3.16.4</version>
		</dependency>

		<!-- https://mvnrepository.com/artifact/com.fasterxml.jackson.core/jackson-databind -->
		<dependency>
			<groupId>com.fasterxml.jackson.core</groupId>
			<artifactId>jackson-databind</artifactId>
			<version>2.13.0</version>
		</dependency>

		<!-- https://mvnrepository.com/artifact/com.fasterxml.jackson.core/jackson-annotations -->
		<dependency>
			<groupId>com.fasterxml.jackson.core</groupId>
			<artifactId>jackson-annotations</artifactId>
			<version>2.13.0</version>
		</dependency>

Redisson configuration
As seen in the code, bare minimal
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4164
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Used classes:
public class Value<T> {
  public T value;
}

public class IntegerValue<Integer> implements Serializable {
	/**
	 * 
	 */
	private static final long serialVersionUID = 1L;

  public IntegerValue(int value) {
    this.value = value;
  }
}

public class DoubleValue<Double> implements Serializable {
	/**
	 * 
	 */
	private static final long serialVersionUID = 1L;

  public DoubleValue(double value) {
    this.value = value;
  }
}

public class StringValue<String> implements Serializable {
	/**
	 * 
	 */
	private static final long serialVersionUID = 1L;

  public StringValue(String value) {
    this.value = value;
  }
}


Service interface:
public interface IService {
  void set(Map<String, Value<?>> values);
  Map<String, Value<?>> get();
}

Service Implementation:
public class MyService implements IService {
  private Map<String, Value<?>> values = Collections.synchronizedMap(new HashMap<>());
  public MyService() {
    RedissonClient client = Redisson.create();

    // register myself as a remote service
    client.getRemoteService().register(IService.class, this);

    // Set some initial value
    values.put("initial", new IntegerValue(17));
  }

  public void set(Map<String, Value<?>> values) {
    Logger.getGlobal().info("Set values");
    this.values = Collections.synchronizedMap(values);

    for (Map.Entry<String, Value<?>> entry: values.entrySet())
      Logger.getGlobal().info("S: key = "+entry.getKey()+", value = "+entry.getValue());
  }

  public Map<String, Value<?>> get() {
    return values;
  }
}

Client:
public class Client {
  public Client() {
    RedissonClient client = Redisson.create();

    IService service = client.getRemoteService().get(IService.class);

    // get initial value
    Map<String, Value<?>> values = service.get();

    // check what we've got
    for (Map.Entry<String, Value<?>> entry: values.entrySet())
      Logger.getGlobal().info("C: key = "+entry.getKey()+", value = "+entry.getValue());

    // change something
    values.put("another", new StringValue("value"));

    // send to the service
    service.set(values);
  }
}

Service is instantiated locally and then the client (both on same JVM, Redis server is running locally with default Ubuntu 20 configuration)
Expected behavior
Expected log output:
C: key = initial, value = [class of IntegerValue & address]
S: key = initial, value = [class of IntegerValue & address]
S: key = another, value = [class of StringValue & address]
Actual behavior
Actual log output:
C: key = initial, value = null
S: key = initial, value = null
S: key = another, value = null
Steps to reproduce or test case
Code as above
Redis version
$ redis-server --version
Redis server v=5.0.7 sha=00000000:0 malloc=jemalloc-5.2.1 bits=64 build=636cde3b5c7a3923

Redisson version
<!-- Redis client: Redisson -->
		<dependency>
			<groupId>org.redisson</groupId>
			<artifactId>redisson</artifactId>
			<version>3.16.4</version>
		</dependency>

		<!-- https://mvnrepository.com/artifact/com.fasterxml.jackson.core/jackson-databind -->
		<dependency>
			<groupId>com.fasterxml.jackson.core</groupId>
			<artifactId>jackson-databind</artifactId>
			<version>2.13.0</version>
		</dependency>

		<!-- https://mvnrepository.com/artifact/com.fasterxml.jackson.core/jackson-annotations -->
		<dependency>
			<groupId>com.fasterxml.jackson.core</groupId>
			<artifactId>jackson-annotations</artifactId>
			<version>2.13.0</version>
		</dependency>

Redisson configuration
As seen in the code, bare minimal
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4165
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
Error not occurring.
Actual behavior
Error occurring.
Steps to reproduce or test case
Create a topic and send objects through the topic every second. After a few minutes or so this error occurs repeatedly randomly.
[19:25:12 ERROR] [org.redisson.client.handler.PingConnectionHandler]: Unable to send PING command over channel: [id: 0x1b4d363c, L:/<IP Redacted> - R:<IP Redacted>]
org.redisson.client.RedisTimeoutException: Command execution timeout for command: (PING), params: [], Redis client: [addr=<IP Redacted>]
        at org.redisson.client.RedisConnection.lambda$async$0(RedisConnection.java:245) ~[?:?]
        at io.netty.util.HashedWheelTimer$HashedWheelTimeout.run(HashedWheelTimer.java:715) ~[velocity.jar:3.1.1]
        at io.netty.util.concurrent.ImmediateExecutor.execute(ImmediateExecutor.java:34) ~[velocity.jar:3.1.1]
        at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:703) ~[velocity.jar:3.1.1]
        at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:790) ~[velocity.jar:3.1.1]
        at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:503) ~[velocity.jar:3.1.1]
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[velocity.jar:3.1.1]
        at java.lang.Thread.run(Thread.java:831) [?:?]
Redis version
6.2.3
Redisson version
3.16.8
Redisson configuration
 Config config = new Config();
        config.setCodec(new JsonJacksonCodec());
        config.setKeepPubSubOrder(true);
        config.setThreads(4);
        config.setNettyThreads(8);
        var msc = config.useSingleServer();
        msc.setAddress("redis://" + url + ":" + port);
        msc.setUsername(user);
        msc.setPassword(pass);
        msc.setTcpNoDelay(true);
        msc.setConnectionMinimumIdleSize(2);
        msc.setConnectionPoolSize(32);
        msc.setSubscriptionConnectionMinimumIdleSize(1);
        msc.setSubscriptionConnectionPoolSize(32);
        msc.setSubscriptionsPerConnection(5);
        msc.setTimeout(3000);
        msc.setConnectTimeout(10000);
        msc.setRetryAttempts(3);
        msc.setRetryInterval(1500);
        msc.setPingConnectionInterval(10000);
Question
Is there maven dependencies for snapshot versions such as 3.16.9? If not, can they be added?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4166
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I am saving and later retrieving a serialized object using an RBucket. When doing so, the serialVersionUID has no effect - redisson tries to retrieve and de-serialized the object and throws an exception it this fails. Is this done this way deliberately? Is there a way to make redisson respect the serialVersionUID, or do I need to serialize and de-serialize  the object myself?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4167
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
In my code, I am trying to acquire a fair lock with a fixed waitTime and leaseTime as so
fairLock.tryLockAsync(waitTime, leaseTime, timeUnit, ID)
Sometimes, all the requests will get queued up for apparently no reason, while no request has acquired the lock.
I can see a wait queue being formed for the lock, but the actual lock is not held by anyone.
Eventually, all of these waiting requests will time out and fail, and new requests will work fine.
This seems to happen randomly when there are a lot of simultaneous requests.
I am not able to reproduce this locally.
Redis version
6.x
Redisson version
3.16.8
Redisson configuration
config.useSingleServer().apply {
    path.toIntOrNull()?.also {
        database = it
    } ?: run {
        logger.warn { "Unable to parse database number: $path from redis configuration" }
    }
}
config.nettyThreads = 64
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4168
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Please add a below settings description in cluster settings wiki
failedSlaveReconnectionInterval
Default value: 3000
Interval of Redis Slave reconnection attempt when it was excluded from internal list of available servers. On each timeout event Redisson tries to connect to disconnected Redis server. Value in milliseconds.
failedSlaveCheckInterval
Default value: 60000
Redis Slave node failing to execute commands is excluded from the internal list of available nodes when the time interval from the moment of first Redis command execution failure on this server reaches defined value. Value in milliseconds.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4169
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
No description provided.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4170
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redisson/redisson-tomcat/redisson-tomcat-8/src/main/java/org/redisson/tomcat/RedissonSession.java
    
    
         Line 483
      in
      e0d9c18
    
  
  
    

        
          
           if (readMode == ReadMode.MEMORY) { 
        
    
  


Is this condition here restricting REDIS read mode from syncing attributes between tomcats utilizing same JSESSIONID for the same user?

Have two tomcats running same application. Sticky session disabled.
Redission tomcat session manager configured (version 3.16.4)
Scenario:
Tomcat1 --> updates a attribute in Session.
After 1 second, Tomcat2 --> reads the same attribute in session but do not have updated value but instead it reads the old value.

@mrniko could you please help?
Please help on fixing this scenario.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4171
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
There's an existing closed bug #1548 that seems to be manifesting in my installation.  I'm using AWS Managed Redis CLUSTER with Hibernate.

ERROR [mylj,6221345d0f4ad9a5bd79127fd4f5f470,ef81dea77c5f0729] 1 --- [nio-8080-exec-2] org.redisson.hibernate.RedissonStorage : MOVED redirection loop detected. Node redis://10.95.240.133:6379 has further redirect to redis://10.95.240.133:6379
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4172
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I submit tasks to RExecutorService with ExecutorOptions.taskRetryInterval=5m and expect the tasks will be resumed by another nodes after 5m if some nodes are down.
In my test , I submit 32 tasks to 2 nodes ( Server A/B , each have 20 threads to consume tasks ) , each consume 16 tasks.
The tasks take 30 seconds to complete and I manually kill one node (Server B) before tasks complete.
I expect Server A will consume all 32 tasks after 5m
Expected behavior
Server A will consume all 32 tasks after 5m.
Actual behavior
Server A only consume 16 tasks, another 16 tasks consume by Server B ( but not complete) remain in scheduler and tasks and are NOT processed by Server A.
Steps to reproduce or test case
Redis version
6.0.9
Redisson version
3.16.4
Redisson configuration
    int timeout = 60 * 1000;
    Config config = new Config();
    config.useSingleServer()
            .setAddress("redis://" + hostName + ":" + port) //
            .setConnectionMinimumIdleSize(4) //
            .setNameMapper(new KKNameMapper())
            .setConnectionPoolSize(64) //
            .setTimeout(timeout)
            .setIdleConnectionTimeout(timeout)
            .setConnectTimeout(timeout)
            .setKeepAlive(true)

        ExecutorOptions executorOptions = ExecutorOptions.defaults() //
                .taskRetryInterval(5, TimeUnit.MINUTES);

    WorkerOptions options = WorkerOptions.defaults()
            // Defines task timeout since task execution start moment
            .taskTimeout(60, TimeUnit.SECONDS)
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4173
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have a LockFactory class which provides the default and multilock. The following code results in a bad request with no logs at all:
public Uni<Void> test() {
        Lock lock = lockFactory.getLock("test Lock");
        return lock.acquire()
                .invoke(() -> Log.debug("\n\n\nLockAcquired : " + lock + "\n\n\n"))
                .eventually(lock::release);
    }

application.json
quarkus:
  redisson:
    cluster-servers-config:
      nodeAddresses: ${REDIS_HOSTS}

In normal mode and in native mode locally, I see redisson logs. However, when I deploy the native build, I don't see a single redisson log. Any ideas what might be happening here?
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4174
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
org.redisson.connection.SentinelConnectionManager
row  175   break;  is bug
it let this code always error.
throw new RedisConnectionException("SENTINEL SENTINELS command returns less than 2 nodes! At least two sentinels should be defined in Redis configuration. Set checkSentinelsList = false to avoid this check.", lastException);
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4175
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Is there a way to retrieve the value of all the keys matching the given pattern?
Also, can it be generalised to any key type? I'm able to get keys matching the pattern but how can we get all the values at once too?
Below is code snippet, however here I'm calling get for each key:
public void getRateLimiterKeyValues() {
        String pattern = API_RATE_LIMITER_KEY.concat("*");
        Iterable<String> keys = redisson.getKeys().getKeysByPattern(pattern);
        String[] cache = StreamSupport.stream(keys.spliterator(), false).toArray(String[]::new);

        for (String key : cache) {
            log.info("Key: {} value: {}", key, redisson.getRateLimiter(key).getConfig().toString());
        }
    }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4176
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Using RRateLimiter if the thread which acquired the permit crashed or is long-running the permits never again become available again. Have created a rate limiter as below and once the permit is acquired even if the thread crashes or is closed the permit doesn't get available again.

Expected behaviour
Permits should get available again when the thread crashes or is closed
Actual behaviour
Permits not getting available
Redis version
redis_version:6.2.4
Redisson version
3.16.8
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4177
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
about issue#4033,I don't need to wait,so i set waittime=0,but the result is failure,why Rlock set waittime=0 result is successful?i need get the lock fail,end business at once.
see source code,when waitime=0,leaseTime assignment zero.

Expected behavior
Actual behavior
Steps to reproduce or test case
Redis version
6.2.6
Redisson version
3.16.8
Redisson configuration
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4178
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I have an annotation RLock which works with an aspect, it work well in some programs.
Here is the codes:
public Object process(ProceedingJoinPoint joinPoint, RLock rLock) throw Throwable {
    String key = evaluateKey(rLock.key()); 
    RLock lock = redissonClient.getLock(key);
    boolean flag =f alse;
    try {
        flag = lock.tryLock(waitTime, leaseTime, timeUnit);
        if (flag) {
            return joinPoint.proceed();
        } else {
             throw new HexinLockException("Lock failed.");
        }
    } finally {
       if (flag && lock.isLocked()) {
           lock.unlock();
       }
    }
}
Someday a program throws Exception at every tryLock in two of three containers. I checked ELK and find RedisTimeoutException before the first exception.
By the way, every container works with only one thread to consume kafka messages.
It seems taht  the first RLock unlock timeout and then redisson treats next RLocks as reentrant cause they have the same thread Id.
How to ensure that the lock could be released correctly after unlock timeout.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4179
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Elastic-cache recently released a data-tiering which lets offload LRU keys to disk.
In an attempt to onboard to the feature, we ran some tests where we would fill up our memory till 100% and observe keys being offloaded to disk. We repeated the test using both redis-benchmark tool & Redisson ( Client we use for production).
With redisson as soon as MemoryUtilisation reached 100% we observed a sudden spike in CPU , accompanied with WriteRedisConnectionException . This CPU spike lead to node failures again and again. We didnt observe the same behaviour with redis-benchmark tool.
My question is : Why would there be a spike in CPU with Redisson ? How can we avoid this & is there an ability to perform exponential backoff timeout in redisson?
Redisson Error Message when memory reaches 100%  : Error message: org.redisson.client.WriteRedisConnectionException: Unable to write command into connection! Increase connection pool size).
** Setup for Replicating behaviour **
Redis Cluster : 1 shard with 1 replica of node type r6gd.2xlarge.
Redisson Config :
REDIS_SCAN_INTERVAL_MS = (int) Duration.ofMinutes(1).toMillis();
REDIS_PING_CONNECTION_INTERVAL_MS = 5000;
RETRY_INTERVAL = 50;
RETRY_ATTEMPTS = 3;
TIMEOUT = 30000;
CONNECTION_TIMEOUT = 60000 * 5;
NETTY_THREADS = 128;

redissonConfig
        .useClusterServers()
        .addNodeAddress(redisAddress)
        .setScanInterval(REDIS_SCAN_INTERVAL_MS)
        .setRetryInterval(RETRY_INTERVAL)
        .setRetryAttempts(RETRY_ATTEMPTS)
        .setPingConnectionInterval(REDIS_PING_CONNECTION_INTERVAL_MS)
        .setKeepAlive(true)
        .setConnectTimeout(CONNECTION_TIMEOUT)
        .setTimeout(TIMEOUT);

IMO, the timeouts are already quite high. I dont see new connections being formed as well.
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4180
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Redisson version :

To create Redisson Client :
    // 1. Create config object
    Config config = new Config();
    config.setNettyThreads(64);
    config.useSingleServer().setAddress("redis://"+redisAddress+":"+redisPort).setPassword(redisPassword);
    return Redisson.create(config);

We have the following RMapCache beans that will basically create the RMapCache for us :
@configuration
public class RedisConfig {
private final RedissonClient redissonClient;

public RedisConfig(RedissonClient redissonClient) {
    this.redissonClient = redissonClient;
}

@Bean
RMapCache<String, List<LocalizedData>> localizedDataCache (){return redissonClient.getMapCache(Constants.LOCALIZED_DATA_REDIS_HASH);}

//MarketHierarchyRedisHash is the mapCache name
@Bean
RMapCache<String, MarketHierarchy> marketHierarchyCache (){return redissonClient.getMapCache(Constants.MARKET_HIERARCHY_REDIS_HASH);}

@Bean
RMapCache<String, MarketHierarchy> marketHierarchyCacheOld (){return redissonClient.getMapCache(Constants.MARKET_HIERARCHY_REDIS_HASH_OLD);}

}
Stacktrace :

Expected :
For our spring application to start without any issues.  The application fails to start because the redisson client cannot be initialized. This error is intermittent and difficult to reproduce all the time
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4181
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Expected behavior
When I remove values, using RedissonLocalCachedMap#removeAsync method, expectation is that values are removed i.e. no longer retrievable from cache.
Actual behavior
Does not seem to be the case. "Removed" values are retrievable via "getAsync" operation
Steps to reproduce or test case
Here's the reproducible test project: https://github.com/62mkv/redisson-remove-repro/blob/master/src/test/java/com/example/redissonremoverepro/RedissonRemoveReproApplicationTests.java
Steps to reproduce:

clone the project
./gradlew check (test fails)
go to build/test-results/test, file is TEST-com.example.redissonremoverepro.RedissonRemoveReproApplicationTests.xml
in the system-out element body, we observe the following:

Testing value:bba34688-fdd7-4756-8508-50ff169ff365=Value{uuid=bba34688-fdd7-4756-8508-50ff169ff365, name='value2', attribute=2}
Removing value:bba34688-fdd7-4756-8508-50ff169ff365=Value{uuid=bba34688-fdd7-4756-8508-50ff169ff365, name='value2', attribute=2}
Testing value:96a878ab-bc2e-41cc-9fc4-e41ecffb8a68=Value{uuid=96a878ab-bc2e-41cc-9fc4-e41ecffb8a68, name='value4', attribute=4}
Removing value:96a878ab-bc2e-41cc-9fc4-e41ecffb8a68=Value{uuid=96a878ab-bc2e-41cc-9fc4-e41ecffb8a68, name='value4', attribute=4}
Testing value:8fbb1b7d-6292-4d32-8ebd-63295bee3250=Value{uuid=8fbb1b7d-6292-4d32-8ebd-63295bee3250, name='value1', attribute=1}
Testing value:d588bf37-005e-414b-a17d-a45ac72f78bd=Value{uuid=d588bf37-005e-414b-a17d-a45ac72f78bd, name='value3', attribute=3}

i.e. all values with even "attribute" are removed from the cache.
However, the test fails with:
expectation "expectComplete" failed (expected: onComplete(); actual: onNext(Value{uuid=69d54141-3cfb-4a84-81ae-7812b7fb6ce4, name='value4', attribute=4}))

Redis version
5.0.3
Redisson version
3.16.8
Redisson configuration
            Config config = new Config();
            config.useSingleServer().setAddress("redis://" + address + ":" + port);
            RedissonClient client = Redisson.create(config);

            cache = client.getLocalCachedMap("test-cache", LocalCachedMapOptions.<String, Value>defaults()
                    .storeMode(LocalCachedMapOptions.StoreMode.LOCALCACHE_REDIS)
                    .reconnectionStrategy(LocalCachedMapOptions.ReconnectionStrategy.LOAD)
                    .syncStrategy(LocalCachedMapOptions.SyncStrategy.UPDATE));
            cache.preloadCache();
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4182
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Reisson version： 3.16.5
Redis: single sence
在使用redisson 过程中，正常使用redisson delay queue 时，会在运行过程中抛出

我确认redis 服务是正常的，因为另外一个redisson 延时队列并没有问题。服务重启后正常
导致这种问题的原因可能是什么？ 是因为连接突然不可用导致的吗？
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4183
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
I use redisson to subscribe message in my project, I found the pubsub connection will lost and message will be not received any more. No any exceptions can be found in log, so I tured log level to DEBUG on org.redisson. Then I found following logs, and I not sure is it normal or not:
on project start
2022/03/15 15:37:07.368 [ty-2-14] DEBUG ClientConnectionsEntry [-|-|-] - new pubsub connection created: RedisPubSubConnection@1163063656 [redisClient=[addr=redis://myredis-servrer:6379], channel=
[id: 0xdbb90202, L:/10.118.1.218:47226 - R:myredis-servrer/10.118.2.6:6379], currentCommand=null]
2022/03/15 15:37:07.373 [ty-2-10] INFO  MasterConnectionPool [-|-|-] - 5 connections initialized for myredis-servrer/10.118.2.6:6379
2022/03/15 15:37:07.376 [ty-2-14] INFO  MasterPubSubConnectionPool [-|-|-] - 1 connections initialized for myredis-servrer/10.118.2.6:6379
almost 4 hours later
2022/03/15 19:36:55.840 [ty-2-32] DEBUG ClientConnectionsEntry [-|-|-] - new pubsub connection created: RedisPubSubConnection@1656211046 [redisClient=[addr=redis://myredis-servrer:6379], channel=[id: 0xf3a494a2, L:/10.118.1.218:37412 - R:myredis-servrer/10.118.2.6:6379], currentCommand=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@6c702440(incomplete)], command=(PING), params=[], codec=org.redisson.client.codec.StringCodec]]
and  13 seconds later
2022/03/15 19:37:09.041 [tty-2-8] DEBUG IdleConnectionWatcher [-|-|-] - Connection [id: 0xdbb90202, L:/10.118.1.218:47226 ! R:myredis-servrer/10.118.2.6:6379] has been closed due to idle timeout. Not used for 13167 ms
It seems the pubsub connection on port 47226 is replaced by an new pubsub connection on port 37412.
But CLIENT LIST with redis-cli show:
id=4824 addr=10.118.1.218:37412 laddr=10.118.2.6:6379 fd=19 name= age=12092 idle=22 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 argv-mem=0 obl=0 oll=0 omem=0 tot-mem=20496 events=r cmd=ping user=default redir=-1
flags is N not P.
This is my redisson.yaml:
singleServerConfig:
idleConnectionTimeout: 10000
connectTimeout: 10000
timeout: 3000
retryAttempts: 3
retryInterval: 1500
password: null
clientName: null
address: "redis://myredis-server:6379"
subscriptionConnectionMinimumIdleSize: 1
subscriptionConnectionPoolSize: 50
subscriptionsPerConnection: 5
connectionMinimumIdleSize: 5
connectionPoolSize: 64
database: 0
dnsMonitoringInterval: 60000
pingConnectionInterval: 30000
keepAlive: true
threads: 16
nettyThreads: 32
codec: !<org.redisson.codec.FstCodec> {}
transportMode: "NIO"
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4184
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
redisson version: 3.16.8
JDK: 1.8.0.312
system: macOS 12.3 (21E230)
cpu: Apple M1 Pro
RedissonMultiLock cannot use the public boolean tryLock(long waitTime, long leaseTime, TimeUnit unit) with RedissonSpinLock
It will throw such exception like this:
stack trace:
java.lang.ClassCastException: org.redisson.RedissonSpinLock cannot be cast to org.redisson.RedissonLock
	at org.redisson.RedissonMultiLock.lambda$tryLock$3(RedissonMultiLock.java:424)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at org.redisson.RedissonMultiLock.tryLock(RedissonMultiLock.java:426)
        ...

In the method public boolean tryLock(long waitTime, long leaseTime, TimeUnit unit) of RedissonMultiLock, there is such a block of codes.
        if (leaseTime != -1) {
            acquiredLocks.stream()
                    .map(l -> (RedissonLock) l)  // <---- this line
                    .map(l -> l.expireAsync(unit.toMillis(leaseTime), TimeUnit.MILLISECONDS))
                    .forEach(f -> f.toCompletableFuture().join());
        }
But RedissonSpinLock cannot cast to RedissonLock. It inherit from RedissonBaseLock but not RedissonLock.
Could it be like this?
        if (leaseTime != -1) {
            acquiredLocks.stream()
                    .map(l -> (RedissonExpirable) l)
                    .map(l -> l.expireAsync(unit.toMillis(leaseTime), TimeUnit.MILLISECONDS))
                    .forEach(f -> f.toCompletableFuture().join());
        }
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
https://github.com/redisson/redisson/issues/4185
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
version 3.16.1,see the exceptions:
org.redisson.client.RedisTimeoutException: Unable to acquire connection! RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@4bc618ba(failure: java.util.concurrent.CancellationException)]Increase connection pool size. Node source: NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=0, freeSubscribeConnectionsCounter=value:49:queue:0, freeConnectionsAmount=22, freeConnectionsCounter=value:-2144903244:queue:26923, freezeReason=null, client=[addr=redis://], nodeType=MASTER, firstFail=0]]], command: null, params: null after 0 retryattempts
at org.redisson.command.RedisExecutor$2.run(RedisExecutor.java:187)
at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:672)
at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:747)
at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:472)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.lang.Thread.run(Thread.java:748)
Use Default configuration，Restart the service before resuming
It can be reproduced using the following code and configuration
@test
void tryLock() throws InterruptedException {
ExecutorService tw = Executors.newFixedThreadPool(500);
CountDownLatch latch2 = new CountDownLatch(1);
for (int i = 0; i < 1000; i++) {
tw.execute(()->{
try {
latch2.await();
} catch (InterruptedException e) {
e.printStackTrace();
}
manger.tryLock();
});
}
    latch2.countDown();
    Thread.sleep(30000);
}
 public void tryLock() {
      RLock lock = redisson.getLock("test::lock");
      try {
          if (lock.tryLock(500, TimeUnit.MILLISECONDS)) {
              try {
                  Thread.sleep(2000);
                  log.info("lock over=======================");
              } finally {
                  lock.unlock();
              }
          }else {
              log.info("unLock over");
          }
      } catch (Exception e) {
          log.error("Try lock fail", e);
      }
  }

singleServerConfig:
idleConnectionTimeout: 10000
connectTimeout: 10000
timeout: 3000
retryAttempts: 3
retryInterval: 1500
password:
connectionMinimumIdleSize: 1
connectionPoolSize: 2
database: 1
address: "redis://"
How to solve
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
